{
  "cells": [
    {
      "metadata": {
        "id": "f39265e9f70e5a54"
      },
      "cell_type": "code",
      "source": [
        "# This notebook shows how to extract a taxonomy of mitigation actions from AI incident mitigation texts.\n",
        "# It demonstrates the prompts and workflow using GPT-5-mini for batch API calls,\n",
        "# including how to prepare the input file, submit the batch job and retrieve the output files."
      ],
      "id": "f39265e9f70e5a54",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n",
        "Load required libraries."
      ],
      "metadata": {
        "id": "F6ufYzbc_Uuo"
      },
      "id": "F6ufYzbc_Uuo"
    },
    {
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2026-01-13T18:56:06.312639Z",
          "start_time": "2026-01-13T18:56:06.299420Z"
        },
        "id": "initial_id"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import ast"
      ],
      "id": "initial_id",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI API Key Configuration  \n",
        "Load the OpenAI API key from the .env file."
      ],
      "metadata": {
        "id": "EQv7nVRO-bVX"
      },
      "id": "EQv7nVRO-bVX"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:12:34.499240Z",
          "start_time": "2026-01-13T19:12:34.479554Z"
        },
        "id": "789ae7e2f01f0737"
      },
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "id": "789ae7e2f01f0737",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading and Overview\n",
        "Load the dataset containing AI incident mitigation texts and check its structure and summary information.  \n",
        "Each row represents a single AI incident, and the \"mitigation_taken\" column lists all mitigation actions associated with that incident."
      ],
      "metadata": {
        "id": "hVcVBrlY-fzf"
      },
      "id": "hVcVBrlY-fzf"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:12:50.934173Z",
          "start_time": "2026-01-13T19:12:50.923265Z"
        },
        "id": "e7797542abba5870"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('DATASET.csv')"
      ],
      "id": "e7797542abba5870",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:12:52.389442Z",
          "start_time": "2026-01-13T19:12:52.384678Z"
        },
        "id": "48eea120fdb19b92"
      },
      "cell_type": "code",
      "source": [
        "# Check for unique values of column \"mitigation_taken\"\n",
        "df['mitigation_taken'].nunique()"
      ],
      "id": "48eea120fdb19b92",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:14:13.103763Z",
          "start_time": "2026-01-13T19:14:13.098290Z"
        },
        "id": "df30fda1f27d9318"
      },
      "cell_type": "code",
      "source": [
        "# Filter the dataset to show rows where no mitigation actions were taken\n",
        "df[df[\"mitigation_taken\"] == \"['No mitigation taken']\"]"
      ],
      "id": "df30fda1f27d9318",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:14:15.611972Z",
          "start_time": "2026-01-13T19:14:15.608306Z"
        },
        "id": "38bb22fb74f34c66"
      },
      "cell_type": "code",
      "source": [
        "# Remove rows where no mitigation actions were taken\n",
        "df = df[df[\"mitigation_taken\"] != \"['No mitigation taken']\"]\n",
        "df = df.reset_index(drop=True)"
      ],
      "id": "38bb22fb74f34c66",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:14:17.959206Z",
          "start_time": "2026-01-13T19:14:17.955481Z"
        },
        "id": "faa91e7b5555cc8b"
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "id": "faa91e7b5555cc8b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:14:38.803082Z",
          "start_time": "2026-01-13T19:14:38.795582Z"
        },
        "id": "ec33184dfd7176f1"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "id": "ec33184dfd7176f1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI Batch API\n",
        "This section prepares and configures batch API calls using GPT-5-mini to analyze AI incident mitigation data.\n",
        "\n",
        "- **Dataset:** We use a dataset of AI incident texts, where each row represents a single incident and the \"mitigation_taken\" column contains all mitigation actions associated with that incident.\n",
        "\n",
        "- **What is being done:** The code splits the dataset into manageable batches and constructs structured tasks for the OpenAI Batch API. Each task contains a set of mitigation statements and instructions for GPT-5-mini to derive a hierarchical taxonomy of mitigation actions (categories and subcategories).\n",
        "\n",
        "- **How it is being done:**\n",
        "  1. **Batching:** The dataset is divided into chunks (default 200 incidents per batch) to avoid exceeding API limits.\n",
        "  2. **Data processing:** For each batch, all mitigation statements are extracted. Strings representing lists are safely parsed to ensure a consistent list format.\n",
        "  3. **Task creation:** For each batch, a task dictionary is created containing:\n",
        "     - A unique ID for the batch\n",
        "     - The API endpoint (`/v1/chat/completions`)\n",
        "     - GPT-5-mini as the model\n",
        "     - System instructions explaining the rules, constraints and expected output format\n",
        "     - User instructions including the list of mitigation statements\n",
        "  4. **Task collection:** Each prepared task is appended to a list of tasks ready to be submitted to the OpenAI Batch API."
      ],
      "metadata": {
        "id": "Ty7ufSalEcyw"
      },
      "id": "Ty7ufSalEcyw"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:15:05.621023Z",
          "start_time": "2026-01-13T19:15:05.585340Z"
        },
        "id": "fe2cac3c15abedb7"
      },
      "cell_type": "code",
      "source": [
        "# Define the batch size for processing the dataset in chunks\n",
        "batch_size = 200\n",
        "tasks = []\n",
        "\n",
        "# Loop through the dataset in batches\n",
        "for start in range(0, len(df), batch_size):\n",
        "    batch = df.iloc[start:start + batch_size]\n",
        "\n",
        "    # Collect all mitigation statements for the current batch\n",
        "    mitigation_texts = []\n",
        "    for _, row in batch.iterrows():\n",
        "        mitigations = row.get('mitigation_taken', [\"No mitigation taken\"])\n",
        "\n",
        "        if isinstance(mitigations, str):\n",
        "            try:\n",
        "                mitigations = ast.literal_eval(mitigations)\n",
        "            except (ValueError, SyntaxError):\n",
        "                mitigations = [mitigations]\n",
        "\n",
        "        if not isinstance(mitigations, list):\n",
        "            mitigations = [str(mitigations)]\n",
        "\n",
        "        mitigation_texts.extend(mitigations)\n",
        "\n",
        "    # Build the batch task using the collected mitigation statements\n",
        "    task = {\n",
        "        \"custom_id\": f\"batch_{start}\",\n",
        "        \"method\": \"POST\",\n",
        "        \"url\": \"/v1/chat/completions\",\n",
        "        \"body\": {\n",
        "            \"model\": \"gpt-5-mini\",\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. \"\n",
        "                        \"Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\\n\\n\"\n",
        "                        \"RULES OF LOGIC:\\n\"\n",
        "                        \"1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\\n\"\n",
        "                        \"2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\\n\\n\"\n",
        "                        \"CONSTRAINTS:\\n\"\n",
        "                        \"- Organize output as categories with subcategories.\\n\"\n",
        "                        \"- Maximum of 15 top-level categories.\\n\"\n",
        "                        \"- Output MUST be valid JSON and nothing else.\"\n",
        "                    )\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": (\n",
        "                        \"I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\\n\\n\"\n",
        "                        \"Output format:\\n\"\n",
        "                        \"{\\n\"\n",
        "                        '  \"derived_taxonomy\": {\\n'\n",
        "                        \"    \\\"Category A\\\": [\\\"Subcat A1\\\", \\\"Subcat A2\\\"],\\n\"\n",
        "                        \"    \\\"Category B\\\": [...],\\n\"\n",
        "                        \"    ...\\n\"\n",
        "                        \"  }\\n\"\n",
        "                        \"}\\n\\n\"\n",
        "                        \"<mitigation_statements>\\n\"\n",
        "                        + \"\\n\".join(f\"- {m}\" for m in mitigation_texts) +\n",
        "                        \"\\n</mitigation_statements>\"\n",
        "                    )\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    tasks.append(task)\n"
      ],
      "id": "fe2cac3c15abedb7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:15:14.840329Z",
          "start_time": "2026-01-13T19:15:14.833898Z"
        },
        "id": "82bd9cdcec8f98ca"
      },
      "cell_type": "code",
      "source": [
        "file_name = \"TASK.jsonl\"\n",
        "\n",
        "# Write each task object to a JSONL file\n",
        "with open(file_name, 'w') as file:\n",
        "    for obj in tasks:\n",
        "        file.write(json.dumps(obj) + '\\n')"
      ],
      "id": "82bd9cdcec8f98ca",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:16:45.295249Z",
          "start_time": "2026-01-13T19:15:25.323344Z"
        },
        "id": "557396533c339c20"
      },
      "cell_type": "code",
      "source": [
        "# Upload the batch input file to OpenAI and register it for batch processing\n",
        "batch_file = client.files.create(\n",
        "    file=open(file_name, \"rb\"),\n",
        "    purpose=\"batch\"\n",
        ")\n",
        "print(batch_file)"
      ],
      "id": "557396533c339c20",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:23:57.102002Z",
          "start_time": "2026-01-13T19:23:56.469221Z"
        },
        "id": "a50305fc2b2d55c9"
      },
      "cell_type": "code",
      "source": [
        "# Create a batch job using the uploaded input file\n",
        "batch_job = client.batches.create(\n",
        "    input_file_id=batch_file.id,\n",
        "    endpoint=\"/v1/chat/completions\",\n",
        "    completion_window=\"24h\"\n",
        ")"
      ],
      "id": "a50305fc2b2d55c9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:37:01.860107Z",
          "start_time": "2026-01-13T19:37:01.029239Z"
        },
        "id": "3259e4d46bd6d11e"
      },
      "cell_type": "code",
      "source": [
        "# Optional - poll the batch job status until completion\n",
        "while True:\n",
        "    batch_job = client.batches.retrieve(batch_job.id)\n",
        "    if batch_job.status != \"completed\":\n",
        "        time.sleep(10)\n",
        "        print(batch_job.status)\n",
        "    else:\n",
        "        print(f\"job {batch_job.id} is done\")\n",
        "        break"
      ],
      "id": "3259e4d46bd6d11e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:37:04.049396Z",
          "start_time": "2026-01-13T19:37:03.289237Z"
        },
        "id": "844fd72fa5897dc5"
      },
      "cell_type": "code",
      "source": [
        "# Print batch job information\n",
        "batch = client.batches.retrieve(batch_job.id)\n",
        "print(batch)"
      ],
      "id": "844fd72fa5897dc5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:37:13.766064Z",
          "start_time": "2026-01-13T19:37:13.764085Z"
        },
        "id": "f9fe5b5a525900c1"
      },
      "cell_type": "code",
      "source": [
        "output_file_id = batch.output_file_id\n",
        "print(output_file_id)"
      ],
      "id": "f9fe5b5a525900c1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-13T19:37:17.413002Z",
          "start_time": "2026-01-13T19:37:16.362346Z"
        },
        "id": "67479181bf67f6c9"
      },
      "cell_type": "code",
      "source": [
        "# Save batch output file locally in JSONL format\n",
        "with open(\"RESULT.jsonl\", \"wb\") as f:\n",
        "    for chunk in client.files.content(output_file_id).iter_bytes():\n",
        "        f.write(chunk)"
      ],
      "id": "67479181bf67f6c9",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}