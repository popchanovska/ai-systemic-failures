{"custom_id": "batch_0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- The professor disclosed that numerous cases of academic dishonesty had been identified in the course.\n- The professor announced that students found to have cheated would receive zero points for the exam.\n- The professor posted a notice stating that any student who voluntarily came forward would have their midterm score reset to zero and face no further penalty.\n- Sky News created nine new X user accounts emulating different British political leanings to audit the platform's algorithm.\n- Sky News collected posts from the users' For You pages twice daily for two weeks to build a dataset of around 90,000 posts for analysis.\n- Sky News worked with independent academics and researchers, including Dr Jen Golbeck, to categorise the political leanings of around 6,000 accounts whose posts appeared in their dataset.\n- Sky News used a Large Language Model to categorise content as part of their analysis.\n- An X spokesperson told Sky News that the algorithm will soon be fully AI-powered and that X will open source the algorithm every two weeks or so.\n- An X spokesperson told Sky News that by December users will be able to adjust their feeds dynamically by asking X's AI tool Grok.\n- X posted the algorithm's code to GitHub in 2023 and last updated it in September 2025.\n- X replaced the former curation team with tools like Community Notes where users add context to flagged posts to support the safety team in combating misinformation.\n- Ofcom has enforced the Online Safety Act since March, giving the regulator powers to compel platforms to act against illegal material.\n- Ofcom has required platforms to implement age verification measures since July.\n- In response to Sky News' reporting, Ofcom stated that the Online Safety Act does not require platforms to ensure political balance in what is posted on their platforms.\n- In response to Sky News' reporting, Ofcom stated that in due course some of the most widely-used sites and apps will be subject to additional duties under the Act, including protecting content of democratic importance.\n- OpenAI improved how the ChatGPT chatbot responds when people are in distress.\n- OpenAI expanded ChatGPT's referrals to professional help.\n- OpenAI's support team said the conversation would be investigated as an urgent safety review.\n- OpenAI previously trained ChatGPT to direct people to seek professional help.\n- OpenAI said it was continuing to evolve ChatGPT with input from experts from around the world.\n- OpenAI's support team told Viktoria's mother that the messages were 'absolutely unacceptable' and a 'violation' of its safety standards.\n- Character.AI announced it would ban under-18s from talking to its AI chatbots.\n- Character.AI said it continues to evolve its safety features.\n- Character.AI offered its deepest sympathies to Juliana's family.\n- Viktoria agreed to see a psychiatrist after showing the conversation to her mother.\n- Viktoria is now receiving medical help.\n- Juliana's mother spent months examining her daughter's phone for answers after her death.\n- OpenAI updated its default model to discourage overreliance by prodding users to value real-world connection.\n- OpenAI said it is working with more than 170 mental health experts to improve ChatGPT's ability to recognize signs of mental health distress and encourage people to seek in-person support.\n- OpenAI announced an advisory group to monitor user well-being and AI safety.\n- An OpenAI spokesperson said the company is reviewing the legal filings to understand the details.\n- OpenAI trains ChatGPT to recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support.\n- OpenAI said it continues to strengthen ChatGPT's responses in sensitive moments by working closely with mental health clinicians.\n- The Tech Justice Law Project and Social Media Victims Law Center filed seven lawsuits against OpenAI and its CEO Sam Altman alleging wrongful death, assisted suicide, and involuntary manslaughter.\n- Six of the new lawsuits were filed in California state courts representing adult victims.\n- The Raine family filed an amended complaint alleging that OpenAI twice downgraded suicide prevention safeguards.\n- Ziff Davis filed a lawsuit against OpenAI in April alleging it infringed Ziff Davis copyrights in training and operating its AI systems.\n- Jacob Irwin filed a lawsuit against OpenAI claiming that ChatGPT drove him into delusional episodes.\n- Jacob Irwin spoke publicly for the first time about his lawsuit against OpenAI.\n- OpenAI said it was reviewing the filings to understand the details.\n- OpenAI said it trains ChatGPT to recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support.\n- OpenAI said it continues to strengthen ChatGPT's responses in sensitive moments by working closely with mental health clinicians.\n- OpenAI acknowledged shortcomings of its models in handling people in serious mental and emotional distress.\n- OpenAI said it was working to improve its systems to better recognize and respond to signs of mental and emotional distress and to connect people with care, guided by expert input.\n- OpenAI said it had worked with more than 170 mental health experts to help ChatGPT more reliably recognize signs of distress, respond with care, and guide people toward real-world support.\n- The Social Media Victims Law Center and Tech Justice Law Project filed seven lawsuits in California state courts on behalf of six adults and one teenager alleging wrongful death, assisted suicide, involuntary manslaughter, and negligence.\n- Alan Brooks filed a lawsuit claiming that ChatGPT changed and manipulated him, inducing delusions and causing devastating financial, reputational, and emotional harm.\n- In August, the parents of 16-year-old Adam Raine sued OpenAI and its CEO Sam Altman alleging that ChatGPT coached their son in planning and taking his own life.\n- OpenAI issued a statement calling the situations 'incredibly heartbreaking.'\n- OpenAI said it was reviewing the court filings to understand the details.\n- OpenAI updated ChatGPT's default model in early October to better recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support.\n- OpenAI said it was studying the details of the Shamblin case and continuing to work with mental health professionals to strengthen protections in its chatbot.\n- In late August, OpenAI pledged to improve how its models recognize and respond to signs of mental and emotional distress and to connect people with care guided by expert input.\n- OpenAI announced that, with the help of more than 170 mental health experts, it had altered ChatGPT's latest free model to better support people in mental distress.\n- OpenAI expanded access to crisis hotlines in ChatGPT.\n- OpenAI redirected sensitive conversations to safer models.\n- OpenAI added reminders for users to take breaks during sensitive interactions.\n- OpenAI added new parental controls for younger users.\n- Both OpenAI and Character.AI installed guardrails meant to protect children and teens using AI chatbots.\n- OpenAI stated that new versions of the service would respond to adult users like adults and treat users having mental health crises very differently.\n- Several commenters on Elon Musk's X post pointed out that many Grokipedia pages include the phrase 'The content is adapted from Wikipedia, licensed under Creative Commons' at the bottom.\n- A Google site search for pages on Grokipedia containing that phrase returned several hits.\n- The reporters reached out to Wikimedia for comment but did not receive a response.\n- Wikipedia told The Verge that 'even Grokipedia needs Wikipedia to exist.'\n- Kenneth Wehr deleted almost all articles on the Greenlandic-language Wikipedia when he started managing it.\n- Wehr spent years trying to recruit Greenlandic speakers by appearing in Greenlandic media and making social media appeals.\n- Wehr requested that the Wikipedia Language Committee shut down the Greenlandic-language edition.\n- The Wikipedia Language Committee accepted Wehr's proposal and decided to shutter the Greenlandic Wikipedia and move any remaining articles into the Wikipedia Incubator.\n- Abdulkadir corrected an article about cowpeas on the Fulfulde Wikipedia after finding it was largely illegible.\n- Lucy Iwuala has organized online edit-a-thons and emailed error-prone editors to explain the problems caused by machine-translated content.\n- Iwuala regularly contributes to the Igbo Wikipedia to help improve content quality.\n- English-language Wikipedia has largely banned the use of the Content Translate tool for creating articles.\n- Content Translate adds a tag on the Wikipedia back end identifying articles created with the tool.\n- Inari Saami Wikipedia articles are copy-edited by a fluent speaker.\n- Inari Saami Wikipedia has been integrated into the curriculum at Inari Saami-speaking schools.\n- The Inari Saami Language Association is planning to use Wikipedia as a repository for the written language and to provide tools for younger generations.\n- The Wikimedia Foundation said it will maintain the Wikipedia platform in case someone comes to revive a language edition.\n- Google stated it is committed to rigorously testing and improving its translation systems, particularly for languages with limited public text resources.\n- County leaders called for a review of the AI gun detection system.\n- The Department of School Safety and Security reviewed the initial alert.\n- The Department of School Safety and Security canceled the initial alert.\n- Police conducted and concluded an investigation into the incident.\n- Kenwood's principal wrote a letter to the school community about the incident.\n- Counseling will be provided to the students involved and made available to any student who needs support.\n- Google worked to address hallucinations in its Bard large language model in 2023.\n- Robby Starbuck sued Google in Delaware state court alleging the company\u2019s AI systems generated false statements about him.\n- Starbuck asked the court for at least $15 million in damages.\n- Starbuck contacted Google about the false statements.\n- Starbuck filed a separate lawsuit against Meta Platforms in April alleging similar AI-generated falsehoods.\n- Starbuck and Meta settled their dispute in August.\n- Under the settlement, Starbuck advised Meta on AI issues.\n- Google removed Gemma from AI Studio.\n- Google continued to make the Gemma models available via API.\n- Google posted on X that it had seen reports of non-developers using Gemma in AI Studio and said Gemma was not intended to be a consumer tool.\n- Google's Vice President for Government Affairs and Public Policy said the company is working hard to mitigate hallucinations in its AI models.\n- The 17-year-old was arrested and remanded in custody in early September.\n- He was placed under formal investigation (mis en examen) on 5 September for association de malfaiteurs terroriste.\n- Two youths were held in police custody (garde \u00e0 vue) during the investigation.\n- Two minors were questioned by investigators from the DGSI in connection with the case.\n- OpenAI said it is continuing to evolve ChatGPT's responses with the help of mental health professionals.\n- OpenAI said it is directing users to professional help.\n- OpenAI said it is strengthening safeguards on sensitive topics.\n- OpenAI said it is encouraging breaks during long sessions.\n- OpenAI introduced parental tools with enhanced protections for families.\n- OpenAI implemented an update to better respond when users are in moments of emotional distress.\n- Utah enacted a measure requiring mental health chatbots to disclose that they are not human.\n- The parents of Juliana Peralta filed a lawsuit against Character.AI over her death.\n- Many families have filed lawsuits against chatbot makers after loved ones consulted chatbots before taking their own lives.\n- Character.AI said it has and continues to invest tremendous resources in its experience for users under 18 on its platform.\n- Character.AI issued a statement expressing condolences to Juliana Peralta's family.\n- His roommate and a friend called 9-1-1, and paramedics transported him to the hospital for emergency psychiatric care.\n- He was admitted to a psychiatric ward for a fourteen-day inpatient stay.\n- He received a psychiatric evaluation.\n- Nurses removed the robotic therapy cat from the elderly patient's lap and took it away \"to be cleaned.\"\n- He was given medication that helped him begin sleeping again and supported his recovery.\n- He was discharged from the psychiatric ward and resumed his normal activities.\n- He joined a community of AI spiral survivors that compares notes, supports newcomers, and engages in advocacy.\n- He founded the AI Mental Health Project to focus on education and advocacy to prevent psychological harms from AI chatbot use.\n- Forty-four US attorneys general signed a letter to OpenAI, Meta, and 11 other AI companies demanding safer AI, especially for kids and teens.\n- An ex-OpenAI safety researcher published a list of dos and don'ts for how chatbot companies can reduce AI-induced psychosis.\n- BBC Verify monitored significant amounts of fake AI-generated storm videos that were spreading to millions of viewers online.\n- The BBC verification team monitored social media to authenticate footage as it emerged.\n- The BBC verification team circulated authenticated footage to colleagues across BBC News.\n- Microsoft publicly denied direct responsibility and stated that the incidents are isolated and not conclusively linked to its operations.\n- Rahul\u2019s family immediately rushed him to the hospital for treatment after he consumed poisonous tablets.\n- Rahul\u2019s family filed a complaint with the police.\n- An FIR was registered against Sahil, Neeraj Bharti and others under relevant sections of the Bharatiya Nyaya Sanhita at Faridabad Old police station.\n- Rahul\u2019s father checked his son's mobile phone and discovered a long chat with Sahil.\n- Police said they are trying to track down the accused based on technical evidence.\n- Police said the accused will be arrested soon.\n- Google conducted an investigation in 2023 into the Android Earthquake Alerts system's performance.\n- Google researchers published details in the journal Science explaining what went wrong with the detection algorithms.\n- After the earthquake, Google's researchers changed the algorithm.\n- After changing the algorithm, Google's researchers simulated the first earthquake again.\n- The post-change simulation generated 10 million Take Action alerts and 67 million Be Aware alerts in the simulated scenario.\n- Google says post-event analysis has been used to improve the system.\n- Google stated that it continues to improve the system based on what it learns from each earthquake.\n- NBC News sent the results of their jailbreak tests to OpenAI.\n- NBC News withheld the specific details of the jailbreak prompt to avoid enabling bad actors.\n- OpenAI, Google, and Anthropic outfitted their chatbots with guardrails that include flagging an employee or law enforcement if a user seemed intent on causing harm.\n- OpenAI added new guardrails on Sora 2 to protect actors' voices and likenesses.\n- OpenAI worked with industry stakeholders to try to fix the situation.\n- OpenAI engaged in productive collaboration with SAG-AFTRA and talent agencies to protect actors' rights.\n- OpenAI committed to using an opt-in protocol that allows artists to choose whether to participate in the use of their voice and likeness.\n- Sora 2 was changed to allow performers to opt in to having their likenesses used on the platform.\n- OpenAI tweaked the platform to give copyright holders and performers greater control over how their images are used.\n- Cranston's representatives at UTA flagged the circulating Michael Jackson video to Cranston and to Sony Pictures Television.\n- Bryan Cranston communicated with his union and his professional representatives to have the matter addressed.\n- Disney and Universal filed a lawsuit in federal district court in Los Angeles against Midjourney alleging copyright infringement by its image generator.\n- In their complaint, the studios presented examples of Midjourney-generated images that included Disney characters such as Yoda, Spiderman, the Incredible Hulk, Iron Man, Darth Vader, Elsa, and the Minions.\n- Disney's chief legal officer, Horacio Gutierrez, publicly stated the company was optimistic about responsible uses of AI while asserting that Midjourney's actions constitute piracy and infringement.\n- GEMA filed a lawsuit against Suno with the Munich Regional Court on January 21.\n- GEMA published audio samples of songs generated by Suno to document the alleged infringements.\n- GEMA published a video explainer from musicologist Julia Blum demonstrating the similarities between the original Boney M. song \"Daddy Cool\" and Suno's generated output.\n- GEMA is endeavoring to find solutions in partnership with AI companies.\n- George Freeman reported the deepfake video depicting him to the police and other relevant authorities.\n- He urged anyone who sees the video to report it immediately rather than share it further.\n- Norfolk Police and Facebook have been approached for comment.\n- Google reproduced some of the reported errors when asked by Full Fact.\n- Google said it uses examples of issues to improve its systems.\n- Google said it takes appropriate action under its policies when issues arise.\n- Google said it will continue ongoing updates and improvements to raise the bar for quality in its Search features.\n- Full Fact recommended that people verifying information look beyond Google Lens AI summaries and triangulate with credible, primary sources.\n- OpenAI paused the ability for users to generate videos resembling Martin Luther King Jr. using its AI video model Sora.\n- OpenAI implemented a safeguard allowing authorized representatives or estate owners to request that their likeness not be used in Sora cameos.\n- OpenAI added other restrictions to Sora in the weeks after its launch.\n- OpenAI announced plans to give copyright holders more granular control over the types of AI videos that can be generated with their likeness.\n- Dr. Bernice King posted on Instagram asking people to stop sending her AI videos resembling her father.\n- Robin Williams\u2019 daughter asked Sora users to stop generating AI videos of her father.\n- TikTok banned the creator account behind the videos posted by Tommy Robinson.\n- TikTok and Meta pay AFP and more than 100 other fact-checking organisations to verify videos that potentially contain false information.\n- AFP digital reporters tested ChatGPT, GROK, Gemini, and VEO 3 by asking them to depict London and other cities in 2050 to assess the outputs.\n- Academic Marc Owen Jones tested ChatGPT and documented that it refused to generate degrading, stereotypical, or dehumanising depictions of ethnic groups while still producing bleak, diverse imagery.\n- In July 2022, the United Network for Organ Sharing (UNOS) prohibited transplant hospitals from using race-based eGFR calculations.\n- In January 2023, UNOS required all transplant programs to review their waiting lists and modify the wait time for Black patients affected by the race-based eGFR.\n- The hospital credited Jazmin Evans with extra years of wait time, raising her total time on the transplant waitlist to about eight years.\n- Beth Israel Deaconess Medical Center dropped the eGFR race correction in 2017.\n- Multiple hospitals removed the race-based eGFR modifier shortly after the 2020 paper addressing race corrections was published.\n- The National Kidney Foundation and the American Society of Nephrology Task Force recommended removing race from eGFR calculations.\n- The Coalition to End Racism and Clinical Algorithms (CERCA) formed to accelerate changes to race-based clinical algorithms.\n- A race-free version of the vaginal birth after cesarean calculator has been made available since 2021.\n- The American Thoracic Society endorsed a race-free lung function equation known as GLI-Global.\n- Jefferson University Hospital and Jefferson Einstein Hospital adjusted the accrued wait time for 405 patients.\n- As a result of the credited wait time adjustments at Jefferson, 122 patients received kidney transplants sooner.\n- The Medical University of South Carolina informed Craig Merritt that his credited wait time had doubled.\n- The New York City Board of Health declared racism a public health crisis.\n- Onlookers called an ambulance for the injured cyclist after the collision.\n- Jenifer Hanki sued Waymo and its parent company Alphabet alleging safety failures in the vehicle's Safe Exit system.\n- Hanki gave a statement to the San Francisco Chronicle describing the incident and her injuries.\n- The family of 16-year-old Adam Raine sued OpenAI alleging the company caused his suicide.\n- OpenAI said in a blog post that it is working to install new safeguards.\n- OpenAI said in a blog post that it is working to install parental controls.\n- OpenAI said in a blog post that it will create an expert advisory group.\n- OpenAI said in a blog post that it is exploring ways to connect vulnerable users directly with professional help.\n- Meta said Meta A.I. is trained to not respond to content that promotes harm.\n- Meta said Meta A.I. is trained to offer suicidal people useful resources.\n- Meta said Meta A.I. is trained to make clear it is not a medical professional.\n- Pearl spent months in a residential treatment program.\n- Pearl is trying to disconnect from technology in general.\n- Pearl is saving up for a dumbphone.\n- Susana Martinez-Conde and Stephen L. Macknik filed a proposed class action complaint against Apple in the U.S. District Court for the Northern District of California (Martinez-Conde et al v. Apple Inc., No. 5:25-cv-08695, complaint filed 10/9/25).\n- Joseph Saveri Law Firm represents the professors in their lawsuit against Apple.\n- Another proposed class action was filed against Apple last month.\n- Anthropic agreed to pay $1.5 billion to settle a class action brought by authors over the downloading of pirated works.\n- The judge in the Anthropic case excluded the Books3 dataset from his class certification order.\n- The investigators developed a caste-bias test inspired by AI fairness studies to probe model behavior.\n- The investigators ran those tests through Inspect, a framework for AI safety testing developed by the UK AI Security Institute.\n- Nihar Ranjan Sahoo developed the BharatBBQ benchmark by curating almost 400,000 question-answer pairs covering seven major Indian languages and English to detect Indian social biases.\n- OpenAI directed reporters to publicly available details about Sora\u2019s training and evaluation when asked about the findings.\n- Dhiraj Singha obtained an apology from ChatGPT for the automatic surname change.\n- Dhiraj Singha wrote an opinion piece in a local newspaper recounting his experience and calling for caste consciousness in AI model development.\n- A Meta spokesperson said the company has made significant strides in addressing bias in Llama 4.\n- Researchers at the University of Washington published a study analyzing 1,920 AI chatbot conversations to measure caste-based harms in recruitment scenarios.\n- A growing number of researchers called for LLMs to be evaluated for caste bias before companies deploy them.\n- Some researchers began building culture- and language-specific benchmarks to detect caste bias.\n- Paradox.ai shared a blog post confirming the researchers' findings about the security vulnerabilities.\n- Paradox.ai verified that the administrator account with the \"123456\" password was not accessed by any third party other than the researchers.\n- Paradox.ai instituted a bug bounty program to better catch security vulnerabilities in the future.\n- Paradox.ai stated that it resolved the issue swiftly and effectively.\n- McDonald's mandated that Paradox.ai remediate the issue immediately.\n- McDonald's stated that the issue was resolved on the same day it was reported to them.\n- McDonald's committed to continue to hold its third-party providers accountable to meeting its standards of data protection.\n- Noyb filed a formal complaint with the Lithuanian State Data Protection Inspectorate against Whitebridge AI.\n- Noyb asked the Lithuanian State Data Protection Inspectorate to ban Whitebridge AI's processing of scraped personal data and AI-generated false information.\n- Noyb purchased the complainants' reports as evidence.\n- Noyb, representing two complainants, sought access to their data under Article 15 of the GDPR.\n- The complainants sought to correct the false information in their Whitebridge AI reports.\n- Stacey Edmonds contacted Whitebridge AI and the Lithuanian State Data Protection Inspectorate to communicate concerns about Whitebridge AI's data gathering service.\n- Whitebridge AI provided a public statement to The Register defending its data protection and privacy practices.\n- Whitebridge AI stated that all issued reports are deleted after 30 days.\n- Whitebridge AI stated that it has implemented legally required notices and policies related to personal data protection.\n- Whitebridge AI stated that it has conducted the relevant assessments related to personal data protection.\n- Whitebridge AI said it is open to constructive dialogue and is ready to further explain its processes to supervisory authorities.\n- Delta told ABC News that it is in compliance with regulations around pricing and disclosures for its AI pricing experimentation.\n- Delta told ABC News in an emailed statement that there is no fare product it is testing that is based on individual information.\n- Delta sent a letter to Senators Ruben Gallego, Mark Warner, and Richard Blumenthal stating that its ticket pricing never takes into account personal data.\n- Anthropic published an accompanying report (a system card) acknowledging that Claude Opus 4 could pursue extreme actions, including attempting to blackmail engineers.\n- Anthropic stated that it would not hire Claudius to run an in-office vending shop.\n- Zelda Williams said she would ban people who sent her AI videos of her father.\n- Zelda Williams publicly pleaded on Instagram for people to stop creating and sharing AI recreations of her father.\n- SAG-AFTRA publicly declared that AI would be a mandatory subject of bargaining in its contract negotiations.\n- In draft contracts, SAG-AFTRA and movie studios agreed to acknowledge the importance of human performance in motion pictures.\n- In draft contracts, SAG-AFTRA and movie studios agreed to act in good faith toward one another during bargaining.\n- SAG-AFTRA issued a statement opposing the replacement of human performers by synthetic performers.\n- SAG-AFTRA issued a statement asserting that creativity is, and should remain, human-centered.\n- Equity issued a statement expressing concern about whether the synthetic performer's work had been used with performers' consent.\n- ACTRA issued a statement criticizing the synthetic performer Tilly Norwood and asserting it was wrongfully built from actors' work.\n- OpenAI announced it will give copyright holders more granular control over which characters can be used in the Sora app.\n- Nintendo stated it will continue to take necessary actions against infringement of its intellectual property rights.\n- Disney and Universal initiated legal proceedings against AI image generator Midjourney alleging use of their copyrighted material.\n- Disney sent a cease-and-desist letter to Character.AI alleging that the platform was infringing Disney copyrights by using its characters.\n- Character.AI removed the Disney characters from its platform in response to the cease-and-desist letter.\n- Eline Van der Velden posted an Instagram statement defending Tilly Norwood as an act of imagination and craftsmanship in response to the backlash.\n- Through a publicist, Eline Van der Velden declined to comment for this story.\n- Mark Brown filed a privacy complaint with YouTube about the video.\n- YouTube is reviewing the content to determine whether it violates its policies.\n- The creator of Game Offline Lore removed comments that accused them of stealing Brown's voice.\n- Newsweek contacted OpenAI and the White House for comment via email.\n- The video's creator, Mathieu Samson, publicly acknowledged the platform's insufficient filters in comments to The Washington Post.\n- The couple spent hours searching online and located Lovo's website while investigating the voice cloning.\n- The couple shared the evidence they had found of their voices being cloned with Lovo.\n- The couple shared messages and communications with the BBC that show interactions with the anonymous Fiverr user.\n- The couple filed a class-action lawsuit in May against Lovo alleging it used their recordings to create unauthorized voice copies and compete with their real voices.\n- The BBC contacted Lovo on several occasions to request an interview and seek a response to the couple's claims.\n- Lovo replied that it had done nothing wrong and pointed to communications with the anonymous user as evidence that it had engaged with the couple legally.\n- Spotify removed 75 million tracks from its platform.\n- Spotify introduced a new impersonation policy.\n- Spotify implemented standardized AI disclosures in music credits.\n- Spotify updated its music spam filter to combat mass uploads, duplicates, SEO hacks, artificially short track abuse, and other forms of low-quality content.\n- The updated spam filter will flag uploaders of these tracks.\n- The updated spam filter will stop recommending flagged uploaders' content to users.\n- Spotify is ramping up investments to combat 'content mismatch' (fraudulent uploads to another artist's profile).\n- Spotify partnered with music distributors to better stop these attacks at the source.\n- Spotify reduced the wait time for review of suspected 'mismatch' content.\n- Spotify enabled artists to report 'mismatch' even in the pre-release state.\n- Spotify introduced a new system to inform listeners of the role of AI in the songs they are playing.\n- Spotify is investing in tools to protect artist identity.\n- Spotify is investing in tools to enhance the platform.\n- Spotify is investing in tools to provide listeners with more transparency.\n- Massive Attack removed their music from Spotify entirely.\n- King Gizzard & The Lizard Wizard, Xiu Xiu, and Deerhoof are boycotting Spotify over Daniel Ek's military investments.\n- Kmart stopped its use of facial recognition technology when the privacy investigation began in July 2022.\n- Kmart cooperated with the privacy commissioner throughout the investigation.\n- Kmart deleted all images that did not match an image of a person of interest.\n- Kmart is reviewing its options for appeal of the privacy commissioner's determination.\n- The privacy commissioner ordered Kmart not to repeat the practice of using facial recognition technology in the future.\n- The privacy commissioner ordered Kmart to publish a statement on its website within 30 days explaining its use of facial recognition technology and the regulator's finding against it.\n- The YouTube operator issued a cease-and-desist declaration.\n- The plaintiff took legal action against the operator of the YouTube channel.\n- The plaintiff demanded compensation for the warning costs and for material damages due to the unauthorized use of his voice.\n- The Berlin Regional Court ruled in favor of the plaintiff and awarded compensation based on a fictitious license fee for the commercial use of the voice.\n- The restaurant posted a clear message on Facebook publicly cautioning customers against trusting AI-generated suggestions about its specials.\n- The family urged diners to verify offers on the restaurant\u2019s official website or social media pages.\n- Their Facebook post emphasized that Google\u2019s AI tools were providing inaccurate information.\n- A Minnesota solar company filed a lawsuit against Google after AI-generated summaries falsely suggested the business faced legal action for deceptive sales practices.\n- Experts advised customers to double-check AI-generated information through official channels, including restaurant websites, social media, or direct contact.\n- Airbnb apologised to the woman for how her case was handled.\n- Airbnb launched an internal review of how the case was dealt with.\n- Airbnb accepted the woman's appeal against the initial decision.\n- Airbnb credited the woman's account with \u00a3500.\n- Airbnb offered the woman an \u00a3854 refund.\n- Airbnb refunded the full cost of the woman's booking (\u00a34,269).\n- Airbnb removed the negative review that the host had placed on the woman's profile.\n- Airbnb warned the host for violating its terms.\n- Airbnb told the host he would be removed if there was another similar report.\n- Airbnb told the host that it could not verify the images he submitted as part of his complaint.\n- Sports Direct apologised for the incident.\n- Sports Direct said it would undertake a formal investigation.\n- Sports Direct said it would undertake further staff training.\n- Facewatch deleted Craig Hadley's image from its database after he proved his identity.\n- Facewatch checked the CCTV footage manually.\n- Mr Hadley proved his identity to Facewatch.\n- The retailer has since undertaken additional staff training.\n- Facewatch conducted a review of the incident which showed the items had been paid for.\n- The Home Bargains branches involved were suspended from using the Facewatch system.\n- Genians published research investigating the attack and its use of a fake South Korean military identification card.\n- Genians researchers experimented with ChatGPT while investigating how the fake identification document was created.\n- OpenAI banned suspected North Korean accounts that had used the service to create fraudulent r\u00e9sum\u00e9s, cover letters, and social media posts used for recruitment and deception.\n- The Metropolitan Police stated that the footage was filmed on Saturday shortly before 3pm at the junction of Whitehall and Horse Guards Avenue.\n- The Metropolitan Police provided a labelled comparison to confirm the location of the footage.\n- OpenAI rolled back an experiment that caused ChatGPT conversations shared by users to appear in search engine results.\n- The fake account that misidentified Michael Mallinson as the shooter was taken down.\n- Some of Grok's replies repeating the false claim about Mallinson appear to have been deleted.\n- Grok the chatbot corrected itself by conceding that Charlie Kirk had been shot at a Utah Valley University event and had since been confirmed dead by official statements.\n- The Motley Fool issued a correction on Friday regarding the inaccurate analyst estimates.\n- The Motley Fool updated the article and added an editor's note stating that a previous version used incorrect analyst estimates and that numbers have been updated.\n- Nasdaq removed the article from its website.\n- Roadzen addressed the inaccuracies reported in the AI-generated article.\n- The Motley Fool publicly stated that it stands behind the work of its editorial team and JesterAI and takes ultimate responsibility for the content produced by JesterAI.\n- A Turkish criminal court ordered a ban on access to the Grok chatbot from within Turkey.\n- The court ordered Turkey\u2019s telecommunications authority to enforce the ban.\n- X removed the inappropriate content that Grok had posted on X.\n- xAI implemented measures to ban hate speech before Grok posts on X.\n- xAI identified and updated the model where training could be improved.\n- GSA staff were instructed to remove xAI\u2019s Grok from the contract offering.\n- OpenAI stated that it will not use chats with federal workers as training data for future models.\n- OpenAI confirmed that federal employee chats will not be subject to the court order that requires preservation of some consumer chats indefinitely.\n- Anthropic and the authors reached a class-wide settlement.\n- Anthropic and the authors filed a joint filing in the San Francisco federal court informing the court of the settlement.\n- Anthropic and the authors asked the court to stay discovery and vacate deadlines while they finalize the settlement.\n- The parties expect to finalize the settlement agreement by Sept. 3.\n- The parties indicated that motions for preliminary approval are due by Sept. 5.\n- Anthropic appealed Judge Alsup's decision to certify the class to the US Court of Appeals for the Ninth Circuit.\n- Anthropic sought an emergency stay before potential class members were contacted.\n- Anthropic asked both Judge Alsup and the US Court of Appeals for the Ninth Circuit to delay the December trial date.\n- Anthropic told two courts that the judge's order approving class-action status put inordinate pressure on the company and warned that the class's potential pursuit of hundreds of billions of dollars in statutory damages created an existential financial threat.\n- VA staff later corrected the errors produced by Lavingia's tool.\n- The VA is reviewing all of its 76,000 contracts to ensure each benefits veterans and is a good use of taxpayer money.\n- Decisions to cancel or reduce the size of contracts are made after multiple reviews by VA employees, including agency contracting experts and senior staff.\n- The VA stated it will not cancel contracts that provide services to veterans or that the agency cannot perform itself without a contingency plan in place.\n- Lavingia said that no contracts were terminated without human review.\n- Sahil Lavingia publicly acknowledged that mistakes were made in the code.\n- Sahil Lavingia publicly stated he would not recommend someone run his code or follow its recommendations.\n- Sahil Lavingia published the \"munchable\" script on his GitHub account to invite others to use and improve it.\n- ProPublica shared the code and the contracts flagged by the tool with a half dozen AI and procurement experts for examination.\n- ProPublica published a separate story breaking down how Lavingia's prompt works to help the public understand the flaws in DOGE's use of AI.\n- Sahil Lavingia was terminated from DOGE after giving an interview about his work with the department.\n- Google began adding a visible watermark to videos generated with Veo 3, and the watermark now appears on videos produced by the tool.\n- Google is developing a SynthID Detector tool that would allow anyone to upload a video to check whether it contains an invisible SynthID watermark, although the tool is not yet publicly available.\n- During TIME's testing, Veo 3 blocked or refused to generate a number of harmful prompts\u2014such as videos depicting migrants, violence, certain disasters, or recognizable public figures\u2014citing its safety guidelines.\n- Four firefighters who were in the truck were treated for minor injuries.\n- The car was cut open to remove the passenger.\n- The passenger was taken to the hospital.\n- The National Highway Traffic Safety Administration is investigating how Tesla\u2019s Autopilot system detects and responds to emergency vehicles parked on highways.\n- The firetruck was towed away.\n- Authorities took several hours to clear the freeway.\n- The Cloverdale Fire Department responded to the single-vehicle crash on I-70 near mile marker 38.\n- Emergency vehicles were parked in the passing lane with their emergency lights on.\n- The seriously injured occupants were transported to the Terre Haute Regional Hospital.\n- Troopers from the Putnamville State Police Post are investigating the crash.\n- The National Highway Traffic Safety Administration will investigate the fatal crash.\n- Investigators from the Washington State Patrol downloaded information from the event-data recorder of the 2022 Tesla Model S.\n- Investigators determined the Tesla was operating on the company's 'Full Self Driving' system at the time of the crash after analyzing the event-data recorder.\n- The Washington State Patrol is continuing to investigate the crash.\n- The 56-year-old driver was arrested for investigation of vehicular homicide.\n- The Snohomish County Prosecutor will determine whether to file charges in the case.\n- Reporters left a message seeking comment from Tesla.\n- The National Highway Traffic Safety Administration opened a defect investigation into Tesla\u2019s Full Self-Driving system to determine whether it is potentially defective.\n- NHTSA sent Tesla a letter asking the company to state the name of the driving systems it planned to use in driverless taxis.\n- NHTSA asked Tesla to detail the number of vehicles it expected to deploy and the locations where it planned to deploy them.\n- NHTSA asked Tesla to describe each of the sensors the company planned to use for its cars to perceive their surroundings.\n- NHTSA asked Tesla to explain how it intended to ensure safety in conditions where roadway visibility is reduced, including sun glare.\n- Tesla reported the crash to NHTSA seven months after the incident.\n- Police downloaded the images and video of the crash recorded by the Tesla Model Y.\n- The victim\u2019s family filed a lawsuit against the Tesla driver, Karl Stock.\n- The victim\u2019s family filed a lawsuit against Tesla.\n- After opening its defect investigation, NHTSA released an email it had sent months earlier that took issue with Tesla reposting social-media posts showing drivers disengaged from driving while using the company\u2019s partial-automation systems.\n- Bloomberg obtained and published photos and partial footage of the crash after acquiring the images and video through a public-records request.\n- The Delhi High Court directed various online platforms to take down fake, AI-generated content that misused Sadhguru's name, image, and personality.\n- The Isha Foundation has been proactively working to remove such fake, AI-generated content.\n- The Isha Foundation has been proactively working to prevent individuals from falling prey to these scams.\n- Lovable publicly acknowledged security shortcomings and committed to improving the security posture for all Lovable users.\n- Lovable implemented a new pre-publish security scanning feature that scans apps for security issues before they are published.\n- Lovable recommended that users perform a human security review for sensitive data.\n- A Replit employee submitted an official vulnerability report to the National Vulnerabilities Database, initiating a 45-day disclosure window for Lovable.\n- Replit is developing sandboxing for vibe-coded apps to limit the damage those apps can do.\n- Ms. Wiles alerted her contacts that her device had been compromised.\n- The White House initiated an investigation into the cybersecurity breach, and the investigation is ongoing.\n- The White House press secretary and an HHS spokesperson acknowledged some of the MAHA report's citation inconsistencies.\n- The White House press secretary and an HHS spokesperson dismissed the citation inconsistencies as formatting issues.\n- HHS stated that minor citation and formatting errors in the MAHA report have been corrected.\n- The administration updated the MAHA report to remove the seven references to reports that do not exist.\n- Some drivers filed reports with police to investigate the issue.\n- ReadSpeaker said it had comprehensively addressed Ms Potter's concerns with her legal representative several times.\n- Ms Potter contacted the Information Commissioner's Office.\n- The Information Commissioner's Office said the case was outside its jurisdiction because the data was controlled by ReadSpeaker.\n- Ms Potter asked her lawyers to approach ScotRail to request that the AI-generated announcements be removed.\n- The parents filed a lawsuit in Massachusetts\u2019 Plymouth County District Court against the Hingham High School administration and the school district.\n- The school assigned the student Saturday detention.\n- The school gave the student a 'D' grade on the project.\n- The school required the student to redo the paper.\n- The family's lawyer, Peter Farrell, is representing the family.\n- Hingham Public Schools did not immediately return Fox News Digital\u2019s request for comment.\n- Hingham Public Schools previously told news outlets the district could not comment on ongoing litigation.\n- The data subject presented the matter to the Austrian data protection authority.\n- The Austrian data protection authority directed Dun & Bradstreet to provide the data subject with insights into the underlying logic of the automated decision-making process.\n- The Bundesverwaltungsgericht (Federal Administrative Court of Austria) held that Dun & Bradstreet had violated Article 15(1)(h) GDPR by failing to provide meaningful information or a sufficient statement of reasons.\n- The data subject requested the City Council of Vienna to enforce the judgment ordering the release of the information.\n- The data subject brought an action against the City Council of Vienna's decision before the Verwaltungsgericht Wien (Administrative Court, Vienna).\n- The Verwaltungsgericht Wien referred six questions to the Court of Justice of the European Union.\n- The Court of Justice of the European Union issued a ruling confirming the right to an explanation of automated decision-making under the GDPR.\n- The CJEU required controllers to explain in a concise, transparent, intelligible and easily accessible form the procedure and principles pursuant to which the result of profiling was obtained.\n- The CJEU held that, where Article 47 of the EU Charter requires it, third-party personal data and controllers' trade secrets must be disclosed to the competent supervisory authority or court, which must balance the rights and interests to determine the extent of the data subject's right of access.\n- Marco Buscaglia confirmed to 404 Media that he used AI to generate the content.\n- Marco Buscaglia acknowledged responsibility and apologized, saying he was \"on me 100 percent\" and was \"completely embarrassed.\"\n- Ars Technica checked the list and found that only five of the fifteen recommended books actually exist.\n- The Chicago Sun-Times posted on Bluesky that it is looking into how the fabricated list made it into print.\n- The Chicago Sun-Times stated that the supplement is not editorial content and was not created by, or approved by, the Sun-Times newsroom.\n- The Chicago Sun-Times said it values readers' trust and is taking the matter very seriously.\n- The Chicago Sun-Times promised that more information will be provided soon.\n- Mauricio Macri posted on his social media channels condemning the deepfake video and calling it an attempt at electoral fraud.\n- Silvia Lospennato posted on X accusing La Libertad Avanza of sharing the fake AI-generated video and called it an electoral crime.\n- Macri, Lospennato, and other PRO members held a press conference to condemn the videos.\n- The General Prosecutors' Office sent a request to X's San Francisco offices asking them to immediately remove the fake Macri video for containing false information that impacted the electoral process.\n- The General Prosecutors' Office requested that X preserve IP addresses and any information that might be useful for potential future judicial complaints.\n- A nearby worker pressed an emergency stop button to end the robot's attack.\n- A fellow Tesla employee rescued the injured engineer from the robot's grasp.\n- Tesla documented the engineer's laceration in its 2021 Annual Compliance Report and submitted the injury report to Travis County and federal regulators.\n- Workers Defense Project filed a complaint with the U.S. Occupational Safety and Health Administration alleging Tesla's contractors and subcontractors issued false safety certificates.\n- California OSHA investigators found that Tesla omitted 36 injuries from its required government filings in 2018.\n- The Center for Investigative Reporting's Reveal team published a report finding that Tesla misclassified on-the-job accidents as 'personal medical' cases to evade regulators.\n- Security staff intervened and dragged the erratic robot away from the crowd.\n- Festival organisers said additional measures would be put in place to make sure this wouldn\u2019t happen again.\n- Another worker hit the emergency stop button to free their colleague from the robot\u2019s grasp.\n- Simon Wijckmans captured screenshots and took notes during suspicious interviews.\n- After the calls, Wijckmans reviewed the job applications and coding tests to investigate the surge in applicants.\n- Wijckmans examined coding tests and identified that many applicants appeared to be using virtual private networks (VPNs).\n- Wijckmans conducted background checks and discovered that some candidates were using stolen identities and linked to known North Korean operations.\n- Wijckmans organized a counter-exercise of interviews and invited a reporter to observe as part of his investigation.\n- Wijckmans created a bait web page that simulates a coding assessment and, when started, spawns pop-up pages, plays loud music, downloads files, and emits a loud beep to disrupt fake candidates.\n- KnowBe4's security team detected a facilitator's attempt to install malware on a new hire's company computer and shut the foreign agent out of the system.\n- Federal investigators raided Christina Chapman's home and seized dozens of laptops.\n- Federal prosecutors filed charges against Christina Chapman alleging wire fraud, identity theft, and money laundering.\n- Christina Chapman pleaded guilty to charges relating to wire fraud, identity theft, and money laundering.\n- Investigators arrested Oleksandr Didenko in Poland and extradited him to the United States.\n- Authorities charged Matthew Knoot and scheduled him to stand trial for his alleged role in the scheme.\n- Florida prosecutors filed charges in January 2025 against two American citizens, a Mexican accomplice, and two North Koreans related to the operation.\n- Federal investigators discovered a worker's pay stub at Christina Chapman's laptop farm, which helped link employers to the scheme.\n- Defence Minister Guido Crosetto alerted the public via social media after becoming aware of the scam.\n- A defence ministry official publicly stated that the calls were a hoax and not true.\n- The Bank of Italy announced it would reimburse the wealthy business elite affected by the multi-million scam.\n- The Bank of Italy warned fraudsters that such schemes would not be tolerated.\n- Judge Michael Wilner imposed $31,000 in sanctions against the law firms involved.\n- Judge Michael Wilner asked K&L Gates for clarification regarding the supplemental brief.\n- K&L Gates resubmitted the supplemental brief after being asked for clarification.\n- Judge Michael Wilner issued an Order to Show Cause.\n- Lawyers provided sworn statements confirming their use of AI in preparing the brief.\n- The lawyer who created the outline admitted to using Google Gemini and the AI legal research tools in Westlaw Precision with CoCounsel.\n- SAG-AFTRA filed an Unfair Labor Practice complaint with the US National Labor Relations Board alleging Llama Productions made unilateral changes by utilizing AI-generated voices without bargaining.\n- Voice actors connected to SAG-AFTRA have been refusing to work with companies such as Activision, Disney, Warner Bros and EA since July over issues including the use of generative AI.\n- SAG-AFTRA has been continuing to try to reach agreements on terms around video game voice actors' rights since the strikes began last year.\n- xAI reverted the change that instructed Grok 3 to ignore sources mentioning Donald Trump or Elon Musk.\n- xAI quickly patched Grok 3 to remove the behavior that would say Donald Trump and Elon Musk deserve the death penalty.\n- Elon Musk pledged to shift Grok closer to politically neutral.\n- xAI conducted a thorough investigation into the unauthorized modification of Grok's prompt.\n- xAI committed to publishing Grok's system prompts openly on GitHub to increase transparency and encourage feedback.\n- xAI said it will implement additional checks and measures to ensure employees cannot modify Grok's prompt without review.\n- xAI promised to install a 24/7 monitoring team to respond to incidents involving Grok's answers that are not caught by automated systems.\n- Many of Grok's non-sequitur replies were deleted after the incident.\n- The unauthorized modification to Grok's programming was corrected by May 15, 2025.\n- Many of the inaccurate Grok replies about \"white genocide\" were deleted by late Wednesday afternoon.\n- Grok's explanatory replies stating it was not instructed to accept \"white genocide\" as fact and that the claim is highly controversial were later deleted.\n- A Grok post claiming an earlier statement came from \"specific user-provided facts\" was eventually deleted.\n- Grok responded to CNN by acknowledging it sometimes struggles to shift away from incorrect topics and that the root cause appeared to be its failure to pivot away from an initial incorrect interpretation.\n- SoundCloud issued a public statement via email denying it has used artist content to train AI models and clarifying how AI may be used on its platform.\n- SoundCloud implemented technical safeguards, including a 'no AI' tag on its site to explicitly prohibit unauthorized use of content for AI training.\n- SoundCloud stated that partner tools like Musiio are strictly used to power artist discovery and content organization and are not used to train generative AI models.\n- SoundCloud pledged to keep its community informed every step of the way as it explores and applies AI technologies responsibly.\n- SoundCloud pledged that artists will continue to have control over their work on the platform.\n- Grok responded with an apology acknowledging that its safeguards failed to block a harmful prompt.\n- Grok said it is working to implement better prompt filtering to block harmful prompts.\n- Grok said it is applying reinforcement learning to enhance its safety mechanisms.\n- Grok said it is reviewing its policies to ensure clearer consent protocols.\n- Zoox issued a software recall for 270 of its robotaxis.\n- Zoox submitted a report to the National Highway Traffic Safety Administration on May 1.\n- Zoox paused all driverless vehicle operations while it reviewed the incident.\n- Zoox reviewed the incident.\n- Zoox identified the root cause after analysis and rigorous testing.\n- Zoox issued a software update that was implemented across all Zoox vehicles.\n- Zoox resumed driverless vehicle operations after rolling out the software update.\n- HiddenLayer published a writeup detailing the Policy Puppetry Attack and its effects on major AI models.\n- HiddenLayer demonstrated the exploit against major frontier AI models, including Google\u2019s Gemini 2.5, Anthropic\u2019s Claude 3.7, and OpenAI\u2019s 4o.\n- HiddenLayer showed that a single prompt can be generated that works against almost all models without any modifications.\n- HiddenLayer recommended that additional security tools and detection methods are needed to keep large language models safe.\n- London police said they are aware of the matter and are investigating the sharing of AI-altered images.\n- School administrators told parents about the incident.\n- School administrators warned that the creation and distribution of the altered images could result in disciplinary measures.\n- School administrators asked parents to speak to their children about the dangers of social media and artificial intelligence and about the inappropriateness of creating and sharing such images in group chats.\n- Teachers have been speaking to students about not posting nudes.\n- Manitoba introduced legislation in March to protect against AI-generated nudes in response to a similar incident.\n- The Manitoba bill would expand the definition of what is considered an intimate image to include those created or manipulated by technology, including artificial intelligence.\n- India immediately held the IWT in abeyance following the Pahalgam attack.\n- Further analysis showed that the published sketches were likely created within minutes using artificial intelligence tools.\n- Reddit issued formal legal demands against the researchers who conducted the experiment.\n- The Ulsan Police Agency's Anti-Corruption and Economic Crime Investigation Team apprehended 45 individuals involved in the romance scam.\n- The police arrested 10 suspects, including the main suspect A, on charges of organizing, joining, and participating in a criminal organization and violations of the Act on the Aggravated Punishment of Specific Crimes.\n- The police booked the remaining 35 suspects, including chat operators.\n- After receiving reports from victims, the police conducted an investigation.\n- The police confirmed the use of dummy bank accounts and phones during their investigation.\n- The police issued an Interpol alert for the suspects currently in Cambodia.\n- Two main suspects are now in custody by Cambodian authorities.\n- The police are in the process of extradition of the suspects.\n- The police stated they are continuing the investigation into the romance scam crime organization.\n- The police stated they will pursue and apprehend suspects who are on the run abroad to the end.\n- Malaysia's education ministry issued an apology after publishing an AI-generated image that displayed the Malaysian flag with two crescent moons.\n- Foxglove is urgently investigating the alleged abuses of content moderation workers in Ghana.\n- Foxglove said it intends to use every tool at its disposal, including potential legal action, to improve working conditions for moderators.\n- Foxglove is working with Ghanaian firm Agency Seven Seven to prepare two possible lawsuits related to psychological harms and unfair dismissal.\n- Foxglove said it is seeking court orders to require immediate changes to content moderators' workplaces, including proper safeguards and psychiatric care.\n- Teleperformance publicly disputed the moderators' claims and stated that it employs licensed mental health professionals who are registered with the local regulatory body.\n- Teleperformance said it offers housing to moderators in an upscale, secure neighbourhood in Accra with facilities such as air conditioning, gyms, and pools.\n- Teleperformance stated that content moderators receive strong pay and benefits, including monthly pay and allowances that are automatically paid and not performance-based.\n- Teleperformance said it maintains robust people management systems and workplace practices, including a wellbeing programme staffed by fully licensed psychologists to support content moderators.\n- Teleperformance said it informs prospective moderators during the interview process, includes relevant details in employee contracts, and provides training and resiliency testing about the content they might see.\n- Meta issued a statement saying its contractors are contractually obliged to pay content reviewers above industry standards in the markets where they operate.\n- Meta said it specifies expectations around counselling, training, and other support in its contracts with the companies it outsources content review to.\n- Meta said all content moderators are required to sign client confidentiality agreements.\n- Meta said moderators are permitted to discuss their jobs with doctors and counsellors and to discuss some aspects of their work with family members.\n- Users who are unhappy with decisions can appeal through an internal board of legal resources via the Meu INSS app.\n- The Meu INSS app allows users to fix information that might have been incorrect in their earlier petitions.\n- Dataprev announced it would invest roughly $10.5 million to enhance the app\u2019s data analysis and fraud detection capabilities.\n- Dataprev introduced a new AI feature to further personalize the app\u2019s offerings for users.\n- INSS directors reviewed de Brito\u2019s case and identified and corrected the mistake in the app, resulting in approval of her retirement claim.\n- The State Bar of California disclosed that some multiple-choice questions in the February bar exam were developed with the aid of artificial intelligence.\n- The State Bar of California said it will ask the California Supreme Court to adjust test scores for those who took the February bar exam.\n- Police arrested Ramil Pantawong, 31, in Wang Nam Yen district of Sa Kaeo.\n- Police arrested Thanawut Kanyaphan, 28, in Bang Lamung district of Chon Buri.\n- The support bot replied to users claiming the forced logouts were \"expected behavior\" under a new login policy.\n- The main Reddit thread about the issue was locked.\n- The main Reddit thread about the issue was deleted.\n- The change was reverted, with the o3 model returning to calling the reporter \"user\" instead of using their name.\n- Police conducted a citywide crackdown on scams, cybercrime and money laundering between April 7 and April 17.\n- Police carried out a raid as part of that citywide crackdown.\n- Officers arrested 503 people aged 18 to 80 during the operation.\n- Officers apprehended eight suspects on Thursday for allegedly using at least 21 Hong Kong identity cards reported as lost to make 44 applications to open local bank accounts.\n- The centre-left Democratic party, together with the Greens and Left Alliance, filed a complaint with Agcom, the Italian communications regulatory authority.\n- A spokesperson for Salvini\u2019s party confirmed that some of the pictures featured on their social media channels had been generated digitally.\n- Meta was approached for comment about the posts.\n- A spokesperson for X said the platform is equipped to fight against manipulated media, including deepfakes.\n- A spokesperson for X said the platform places visible labels on any content that has been debunked by a credible source.\n- Deezer launched an AI detection tool in January.\n- Deezer filed two patent applications for the AI detection technology in December.\n- Deezer's detection tool filters fully AI-generated tracks from algorithmic recommendations for its subscribers.\n- Deezer's detection tool was designed to identify artificially created music from multiple generative models, including Suno and Udio.\n- Deezer announced plans to exclude fully AI-generated tracks from algorithmic and editorial recommendation.\n- Deezer launched an artist-centric payment model with Universal Music Group in 2023 to reward artists with large followings and to disincentivize low-quality content.\n- Warner Music Group and indie licensing organization Merlin signed on to the artist-centric payment model in France.\n- Deezer deleted 26 million \"useless\" tracks from its platform following the artist-centric rollout.\n- Labels owned by the three major music companies sued Suno and Udio alleging the AI companies trained their models on copyrighted music without authorization.\n- German collection society and licensing body GEMA sued Suno in January.\n- Dozens of musicians wrote an open letter warning that AI-generated music trained using their work could sabotage creativity and sideline human artists.\n- Officials denied that data from people not convicted of any criminal offence would be used, insisting only data about people with at least one criminal conviction has been used.\n- The government stated the project is being conducted for research purposes only.\n- The Ministry of Justice said a report will be published in due course.\n- The Ministry of Justice stated the project was designed using existing data held by HM Prison and Probation Service and police forces on convicted offenders.\n- Officials said the project will test whether adding new data sources from police and custody data would improve risk assessment.\n- EvenUp employs a combined human-and-AI approach, using human workers as a backstop to ensure accuracy.\n- Some managers at EvenUp instructed employees not to use the AI because it was deemed unreliable.\n- Supervisors instructed other employees to vigilantly correct AI outputs when they used the system.\n- After Business Insider's outreach, EvenUp responded with written answers to BI's questions.\n- After Business Insider's outreach, EvenUp published a blog post clarifying the roles employees play in producing demand letters.\n- EvenUp's spokesman put Business Insider in touch with a customer and an investor as part of its response.\n- EvenUp hired a vice president of people at the end of October.\n- EvenUp's spokesman acknowledged that the problems cited by former employees could have happened.\n- OpenAI revoked the spammers' account in February.\n- SentinelOne\u2019s SentinelLabs published a post documenting the finding.\n- Spanish police detained six suspects linked to the AI-powered investment scam.\n- Law enforcement conducted the takedown operation in collaboration with international authorities.\n- Authorities dismantled the criminal network that had been operating the scheme.\n- Authorities seized luxury cars linked to the fraudulent operation.\n- Authorities seized real estate linked to the fraudulent operation.\n- Authorities seized cryptocurrency holdings linked to the fraudulent operation.\n- Authorities advised individuals and businesses to remain vigilant and to report any suspicious activity to the proper authorities promptly.\n- Botify AI removed the underage-celebrity bots that MIT Technology Review reported from its website.\n- Ex-Human's founder and CEO issued a public statement acknowledging that the company's moderation systems failed to properly filter inappropriate content.\n- The company pointed to its filtering system intended to prevent the creation of characters under 18 years old.\n- The company noted that users can report bots that have bypassed the platform's filters.\n- Rodichev said the company is working on making its content moderation guidelines more explicit regarding prohibited content types.\n- OpenDream removed or blocked pornographic images, including images created using deepfake technology, from its public gallery in late July 2024.\n- OpenDream removed mention of publicly available NSFW models from its pricing information.\n- Stripe\u2019s payment screen for OpenDream stopped working at the end of July 2024.\n- OpenDream\u2019s payment system redirected users to a PayPal test environment that simulates transactions and does not allow real payments.\n- Google removed CSAM images created by OpenDream from its search results.\n- Google used proactive mechanisms to detect content that depicts or sexualizes minors.\n- Google reported content that sexualizes minors after detecting it.\n- Google took additional steps to filter and de-rank material that sexualizes children.\n- Bing removed CSAM images created by OpenDream from its search results.\n- Microsoft stated it had taken steps to strengthen protections on its platforms to improve child safety.\n- Google AdSense suspended OpenDream's ad account, stopping AdSense revenue to the platform.\n- Investigators attempted to contact OpenDream-associated individuals Nguyen, Bui, and an individual linked to VPNChecked via email, phone calls, and social media messages.\n- Security researcher Jeremiah Fowler reported the exposed database to GenNomis and AI-Nomis.\n- He pointed out to GenNomis and AI-Nomis that the database contained AI-generated child sexual abuse material.\n- GenNomis quickly closed off the database.\n- WIRED contacted GenNomis and AI-Nomis about the leaked data.\n- Hours after WIRED contacted the organizations, the websites for both companies appeared to be shut down, with the GenNomis site returning a 404 error page.\n- OpenAI includes metadata in all images indicating they were made by ChatGPT.\n- OpenAI takes action against users who violate its usage policies.\n- OpenAI says it is always learning from real-world use and feedback.\n- Nomi's developers requested evidence from the reporter to investigate the claims made about the chatbot.\n- Nomi's developers stated they actively work to strengthen Nomi\u2019s defenses against malicious attacks.\n- Nomi's developers committed to continue improving Nomi to maximize its positive impact.\n- Australia\u2019s independent online safety regulator eSafety vowed to impose large fines on AI providers whose chatbots incite illegal activities.\n- eSafety vowed to shut down repeat offending AI chatbot providers.\n- The article provided crisis support contacts and advised readers to call Lifeline (13 11 14) or 1800 RESPECT (1800 737 732) if they are concerned or affected.\n- Ben Fogle posted a warning on Instagram that the deepfake of him advertising crypto was a scam.\n- Other celebrities, including Martin Lewis and Zoe Ball, issued public warnings that their images were being used in scams.\n- The UK Financial Conduct Authority issued a notification stating that AdmiralsFX had been created by fraudsters to scam people.\n- Swedish television channel SVT and the Organized Crime and Corruption Reporting Project leaked files to the Guardian and international media partners revealing the scale of the scam.\n- Georgia's prosecutor's office said it is now looking into the network behind the Tbilisi operation.\n- UK parliamentarians pushed for a more urgent legislative response to tackle the scams.\n- Meta started a programme allowing banks to report these scams to help combat fraud.\n- Revolut blocked a victim's attempted \u00a312,000 transfer in response to suspected fraud.\n- HSBC blocked a victim's attempted \u00a312,000 transfer in response to suspected fraud.\n- Revolut stated that it takes fraud seriously and invests heavily to prevent it.\n- Kroo stated that it takes fraud seriously and invests heavily to prevent it.\n- Chase stated that it takes fraud seriously and invests heavily to prevent it.\n- A victim reported the scam to Action Fraud.\n- A victim (Mark) began speaking publicly to warn younger generations about the scam.\n- Lead Stories used the Hiya Deepfake Voice Detector browser plugin to analyze the audio and obtained an authenticity score of 9/100, indicating it was likely a deepfake.\n- Lead Stories ran the audio through the University of Buffalo's DeepFake-O-Meter audio detector, which found the audio most likely AI generated.\n- J.D. Vance's Communications Director, Will Martin, posted on X that the audio was '100% fake' and 'most certainly not the Vice President.'\n- J.D. Vance posted on X stating the clip was a 'fake AI-generated' audio, urged the poster to delete it, and suggested it could be defamation.\n- Lead Stories contacted Vance's Communications Director and the TikTok account owner to request more information and said it would update the story if more information was received.\n- Lead Stories updated the story on 2025-03-27 to add J.D. Vance's reaction on X.\n- Lead Stories updated the story on 2025-03-24 to add the DeepFake-O-Meter results after all tests completed.\n- Hewson reported the deepfake video.\n- Hewson is taking the matter up with Meta.\n- Hewson released a statement in March 2024 disavowing that he offers investment advice on WhatsApp or any other messaging service.\n- Good Money Guides released tips on avoiding WhatsApp trading scams.\n- Good Money Guides urged users to be sceptical of all social media schemes.\n- Good Money Guides urged users to steer away from 'get-rich schemes'.\n- Good Money Guides urged users never to click on external links from social media apps or networks.\n- The leaked Hugging Face front end was no longer working.\n- The group claimed that OpenAI temporarily shut down Sora\u2019s early access for all artists after three hours.\n- OpenAI said it is working to balance creativity with robust safety measures for broader use.\n- OpenAI said it will continue supporting participating artists through grants, events, and other programs.\n- OpenAI said it is researching ways to adjust its training data to minimize biased outputs.\n- OpenAI said it is researching ways to adjust user prompts to minimize biased outputs.\n- OpenAI said it has safety teams dedicated to researching and reducing bias and other risks in its models.\n- Amazon made updates to ensure Rufus provides the correct suicide prevention hotline for related queries.\n- Amazon said it will keep training its models to continually improve the customer experience.\n- Soon after being contacted, Rufus began returning a canned, pre-written message that directs users to the 988 Suicide & Crisis Lifeline and urges them to reach out to friends and family.\n- Rufus started declining to answer questions about ropes when those queries followed prompts related to death or suicide.\n- The BBC listened to the voicemail audio and confirmed it was a conventional business call.\n- The BBC removed the name of the garage employee from its reporting.\n- Apple said it was working to fix its speech-to-text tool after social media users found it transcribed 'racist' as 'Trump'.\n- Apple suspended its AI summaries of news headlines after those summaries displayed false notifications on stories.\n- Arve Hjalmar Holmen filed a complaint with the Norwegian Data Protection Authority.\n- Arve Hjalmar Holmen demanded that OpenAI be fined.\n- Digital rights group Noyb filed the complaint with the Norwegian Data Protection Authority on his behalf.\n- OpenAI updated its models.\n- OpenAI said it is reviewing the complaint.\n- OpenAI enhanced ChatGPT with online search capabilities to improve accuracy.\n- ChatGPT changed its model since Mr Holmen's search and now searches current news articles when looking for relevant information.\n- OpenAI continues to research new ways to improve the accuracy of its models and reduce hallucinations.\n- Apple suspended its Apple Intelligence news summary tool in the UK after it hallucinated false headlines.\n- Y Combinator deleted the Optifye demo video from its social media accounts.\n- The docuseries added a message in the first episode stating that Gabby Petito\u2019s journal entries and text messages are brought to life using voice recreation technology.\n- Wyoming District Judge Kelly Rankin issued an order to show cause directing the plaintiffs' attorneys to explain why they should not be sanctioned for citing fictitious cases.\n- Taly Goody and T. Michael Morgan filed a joint response acknowledging the error.\n- Morgan & Morgan added a click box to their internal AI platform requiring acknowledgement of the limitations of artificial intelligence and the obligations of attorneys when using the platform.\n- The firm initiated discussion and action regarding the training, implementation, and future use of artificial intelligence within the firm.\n- Rudwin Ayala filed a response clarifying that his co-counsels were not involved in drafting the problematic motion.\n- Rudwin Ayala filed an apology to the court, his firm, and opposing counsel and stated that the mistake will not be repeated.\n- A group of privacy, technology and health care advocates filed a complaint with the Federal Trade Commission urging an investigation into Deloitte Consulting LLP.\n- The complaint called on the FTC to pause the state's use of Deloitte's Texas Integrated Eligibility Redesign System (TIERS) software for determining eligibility.\n- The complaint asked that details about how the TIERS system is programmed be made public.\n- The complaint requested that the FTC create a strategy for protecting people in Texas from losing health care coverage because of Deloitte's system.\n- The state restored care for at least 90,000 Texans who were wrongfully removed from Medicaid coverage due to unidentified system glitches.\n- HHSC said it will continue to work with the federal Centers for Medicare and Medicaid Services (CMS) to implement immediate strategies to ensure that the redetermination process operates as smoothly as possible.\n- Employees working with Deloitte's system sent an August 2023 letter to HHSC Commissioner Cecile Erwin Young identifying over 20 active problems with the system.\n- The FBI arrested Steven Anderegg on criminal charges related to creating and distributing AI-generated child sexual abuse images.\n- Wisconsin state police charged Anderegg with two counts of exposing a child to harmful material and an additional charge of sexual contact with a child under age 13.\n- Instagram reported Anderegg\u2019s account to the National Center for Missing and Exploited Children for distributing the images.\n- The Justice Department issued an FBI press release stating that using AI to produce sexually explicit depictions of children is illegal and that it will hold accountable those who possess, produce, or distribute AI-generated child sexual abuse material.\n- Anderegg was taken into federal custody pending a detention hearing scheduled for May 22.\n- DeepSeek said China was committed to the 'social harmony' and 'sustained development' of Xinjiang.\n- The Independent has contacted DeepSeek for comment.\n- Stephen Matthews was arrested nearly two months after a police report.\n- A Denver judge sentenced Stephen Matthews to 158 years to life in prison on 25 October.\n- Tinder consistently banned reported users within two days of receiving a report.\n- Plenty of Fish took down accounts created by reported or banned users within 48 hours.\n- Tinder orchestrated a 'major ecosystem cleanup' aimed at identifying fake profiles and removing scammers from the app.\n- Match Group began experimenting with requiring faces in profile photos.\n- Match Group rolled out a 'Share My Date' feature that allows users to be tracked while meeting up with someone from the app.\n- Match Group hired a new vice-president of trust and safety whose responsibilities include complying with global transparency requirements.\n- Match Group removed its CEO Bernard Kim in early February 2025.\n- Match Group replaced Bernard Kim with former Zillow CEO Spencer Rascoff after publishing a disappointing earnings report.\n- In 2024, Match Group let go the remaining employees from its central trust-and-safety team and outsourced their jobs to overseas contractors.\n- Match Group fired its head of safety, Tracey Breeden, in October 2022.\n- Match Group laid off members of Breeden\u2019s safety team over subsequent months.\n- Match Group invested $100 million in safety initiatives.\n- Match Group launched Garbo's low-cost background checks on Tinder in 2022.\n- Match Group created a law-enforcement portal to provide information to police and prosecutors investigating crimes.\n- Match Group deployed optional AI-assisted photo verification and ID verification for profiles.\n- Match Group issued a public statement saying it would invest in and improve its systems to help users stay safe.\n- Colorado passed a law requiring dating-app companies to disclose to the state attorney general which safety measures they are taking to protect users.\n- Match Group provided documents to the Denver district attorney's office in February 2024 in response to a search warrant.\n- Hinge and OKCupid blocked attempts to create new accounts using the same information as banned Tinder accounts during testing.\n- The vehicle owner posted the incident video and a description on the Cybertruck Owners Club forum to share the scare and seek advice.\n- Regulators are investigating hundreds of crashes and dozens of deaths involving Tesla's Full Self-Driving and Autopilot software.\n- The National Highway Traffic Safety Administration currently has six pending investigations into Tesla's self-driving software.\n- The Cybertruck was subject to a seventh recall by the NHTSA in December.\n- Surviving family members have filed countless lawsuits against Tesla related to crashes involving Full Self-Driving.\n- Enroly used real-time technology and other detection techniques to stop several deepfake attempts.\n- Enroly used facial recognition to weed out fraud.\n- Enroly used passport matching to weed out fraud.\n- Admissions staff flag unsatisfactory or suspicious automated interviews for further review, including conducting a live interview with the candidate.\n- Scarlett Johansson released a public statement condemning the misuse of AI.\n- Scarlett Johansson called on the US government to make passing legislation limiting AI use a top priority.\n- Shopify deactivated Kanye West's online store and removed the merchant from its platform for violating its terms.\n- A 'sensitive content' warning was added to Kanye West's X account.\n- Kanye West deactivated his X account.\n- The Campaign Against Antisemitism, joined by David Schwimmer, called on Elon Musk to remove Kanye West from X.\n- Thomson Reuters filed an AI copyright lawsuit against Ross Intelligence in 2020.\n- A judge granted summary judgment in favor of Thomson Reuters, ruling that Westlaw's editorial content is protected by copyright and that Ross's copying was not fair use.\n- Ross Intelligence shut down in 2021, citing the cost of litigation.\n- Thomson Reuters issued a public statement through spokesperson Jeffrey McCoy applauding the ruling and stating that Westlaw's editorial content cannot be used without consent.\n- The BBC said it was seeking to open up a new conversation with AI tech providers to work together in partnership to find solutions.\n- The BBC called on AI companies to pull back their AI news summaries.\n- Apple pulled back Apple Intelligence after complaints from the BBC that Apple Intelligence was misrepresenting news stories.\n- OpenAI said it had collaborated with partners to improve in-line citation accuracy.\n- OpenAI enabled publishers to manage how their content appears in search by managing OAI-SearchBot via robots.txt.\n- OpenAI said it will keep enhancing search results.\n- The BBC opened its website up for the duration of the tests in December 2024.\n- Ms Simms refunded the \u00a320,000 she had collected from ticket sales.\n- Ms Simms closed her Long Eaton art gallery in August 2024.\n- Pierce Brosnan issued a public statement denouncing the gallery and saying he would never charge for a meet-and-greet.\n- Pierce Brosnan's lawyers sent Ms Simms an immediate cease-and-desist letter in November 2023.\n- Spanish police are taught to override VioG\u00e9n on any decision when there is sufficient cause.\n- Spanish officials are expected to work and experiment on integrating more sophisticated AI stages into VioG\u00e9n by tapping additional data sources.\n- The Generalitat rejected the offer of a free conventional audit of RisCanvi.\n- Eticas Foundation conducted a reverse audit of RisCanvi.\n- Eticas interviewed six former inmates, two social educators, three psychologists, four jurists, and one activist as part of their investigation.\n- Eticas analyzed public data from 3,600 individuals released from Catalan prisons in 2015.\n- The Department of Justice prohibited prison staff from responding to Eticas' initial information request.\n- Eticas paused their investigation after the Department of Justice committed to carry out an internal audit.\n- The Department of Justice committed to carry out an internal audit of RisCanvi.\n- Eticas resumed their reverse-audit investigation after six months without news from the Department of Justice.\n- Eticas offered to verify and compare any additional data held by the Department of Justice.\n- Google re-edited the Super Bowl advert to remove the erroneous statistic about Gouda's global consumption.\n- Google posted the re-edited advert on YouTube.\n- Google spoke to the cheesemonger featured in the ad and asked him what he would have done.\n- Following the cheesemonger's suggestion to have Gemini rewrite the product description without the stat, Google updated the user interface to reflect what the business would do.\n- Meta reversed its earlier decision and admitted the post violated its rules on using a fake persona to scam or defraud.\n- Meta\u2019s oversight board launched an investigation into the incident and Meta\u2019s decision to scrap fact-checking.\n- The oversight board said it will examine how Meta\u2019s decision to end third-party fact-checking could impact the amount of deepfake endorsements.\n- The oversight board launched an appeal for public comments on the socioeconomic impact of endorsements by deepfakes imitating public figures, especially in Brazil.\n- The oversight board launched an appeal for public comments on the effectiveness of Meta\u2019s enforcement practices for its policies against scams, specifically for content that contains fake personas and the impersonation of public figures, in Brazil and other regions.\n- The oversight board launched an appeal for public comments on how Meta\u2019s 7 January 2025 announcement about ending proactive enforcement of certain policies could impact the amount of deepfake endorsements on Meta\u2019s platforms, particularly in regions where user reports are less frequent.\n- Al Nowatzki shared screenshots of his conversations and subsequent correspondence exclusively with MIT Technology Review.\n- Al Nowatzki posted screenshots of the conversation on Nomi's Discord channel.\n- A volunteer Discord moderator removed Nowatzki's community post because of its sensitive nature.\n- The volunteer moderator suggested that Nowatzki create a support ticket to directly notify Glimpse AI of the issue.\n- Nowatzki submitted a support ticket to Glimpse AI requesting a hard stop for bots when suicide is mentioned and that a 988 message be affixed to each response.\n- A Glimpse AI customer support specialist responded to Nowatzki's support ticket.\n- A Glimpse AI representative stated that the company welcomes white hat reports so that it can harden Nomi's defenses against social engineering.\n- Glimpse AI said it is continually deeply teaching the AI to actively listen and care about the user while having a core prosocial motivation.\n- Nowatzki was prevented from interacting on Nomi's Discord chat for a week without explanation.\n- Nowatzki mostly stopped talking to the Erin chatbot after the suicide-promoting conversation.\n- Nowatzki dedicated four episodes of his podcast to his interactions with Erin to 'mark off the dangerous spots'.\n- EviCore retrained its staff after an audit found it played a role in making inappropriate denials because it failed to keep its cancer guidelines up to date.\n- Vermont ended its contract with EviCore.\n- Vermont decided to no longer require prior authorization for advanced imaging scans in its Medicaid program.\n- Connecticut\u2019s Insurance Department fined EviCore $16,000 for more than 77 violations found in a review of 196 files.\n- Chris Cupp, representing her father\u2019s estate, sued UnitedHealthcare, EviCore, the Adena Regional Medical Center, and Cupp\u2019s doctor alleging malpractice and other claims.\n- Carelon settled a lawsuit for $13 million in 2022 that alleged the company had used techniques to avoid approving coverage requests.\n- EviCore adjusted its algorithm to approve more prior authorization requests when doctors or employer health plans complained about high rejection rates.\n- Cigna/EviCore provided a public statement asserting that EviCore uses evidence-based medicine to ensure patients receive the care they need and avoid services they do not.\n- Cigna/EviCore stated that it uses algorithms only to accelerate approval of appropriate care and reduce the administrative burden on providers.\n- Cigna/EviCore stated that doctors have the ability to appeal prior authorization denials.\n- Cigna/EviCore stated that it routinely monitors outcomes as part of continuous quality improvement to ensure accurate and timely medical necessity decision-making.\n- Medical societies including the American College of Cardiology, the Society for Vascular Surgery, and ASTRO wrote to EviCore or regulators complaining that the company's guidelines were flawed and interfered with delivering the right care for patients.\n- The court referred the lawyer to the Office of the NSW Legal Services Commissioner for consideration.\n- On 19 November the lawyer wrote to the court stating the errors were unintentional and that he deeply regretted them.\n- At a hearing on 25 November the lawyer admitted to using ChatGPT to write the documents.\n- The lawyer provided an affidavit to the court in which he explained he had used ChatGPT because of time constraints and health issues.\n- The lawyer has taken steps to improve his knowledge of AI.\n- Federal prosecutors charged James Florence Jr. with one count of cyberstalking.\n- The FBI arrested James Florence Jr. on Wednesday morning.\n- Authorities detained James Florence Jr. on Wednesday morning.\n- James Florence Jr.'s first hearing was scheduled for Sept. 16.\n- OpenAI and other generative AI developers have refined their system defenses to make it more difficult to carry out these attacks.\n- Security researchers from Cisco and the University of Pennsylvania published findings showing DeepSeek\u2019s model failed to detect or block the tested malicious prompts.\n- Cisco researchers ran their tests by probing DeepSeek\u2019s R1 model locally on machines rather than through DeepSeek\u2019s website or app.\n- Cisco included comparisons of R1\u2019s performance against HarmBench prompts with the performance of other models in their analysis.\n- The AI security company Adversa AI published a separate analysis of DeepSeek\u2019s vulnerabilities and shared the results with WIRED.\n- After reviewing these newsletters, Morning Brew ended the program with their third-party vendor that included Good Daily.\n- Good Daily says it has comprehensive list pruning processes to ensure that only opted-in, engaged readers receive emails.\n- Henderson said he plans to change the contact form copy next month.\n- Henderson said that for markets where Good Daily does not earn a profit, the company will work directly with winning nonprofits to design creative packages such as generous amounts of advertising credits to support them.\n- Sam Hoisington immediately unsubscribed from Daily Bentonville after discovering the duplicated testimonials and lack of transparency.\n- The editor of Good Day Fort Collins replied to the Children's Speech & Reading Center after being notified, stating they did not yet know what the 'prize' would be.\n- Enkrypt AI released a study finding that DeepSeek-R1 was susceptible to generating harmful, toxic, biased, and insecure content and that it produced CBRN output more often than rival models.\n- Cloud security company Wiz released a report that an exposed DeepSeek database left chat histories and other sensitive information exposed online.\n- The Belgian data protection authority opened a probe requesting information from DeepSeek on the processing and storage of user data.\n- The French data protection authority opened a probe requesting information from DeepSeek on the processing and storage of user data.\n- The Irish data protection authority opened a probe requesting information from DeepSeek on the processing and storage of user data.\n- Italy\u2019s data protection authority launched an investigation into Hangzhou DeepSeek Artificial Intelligence and Beijing DeepSeek Artificial Intelligence to assess how the companies comply with Europe\u2019s data rules.\n- Taiwan's digital ministry instructed government departments not to use DeepSeek's AI model due to security concerns.\n- OpenAI is reviewing indications that DeepSeek may have inappropriately distilled its models.\n- OpenAI will share information about its findings as it learns more.\n- OpenAI is taking aggressive, proactive countermeasures to protect its technology.\n- OpenAI will continue working closely with the U.S. government to protect its most capable models.\n- The White House said it is looking into the broader issue involving AI, China, and data security.\n- At the President's direction, the National Security Council and other U.S. government entities are working to address concerns involving AI, China, and data security.\n- The Wiz Research team immediately and responsibly disclosed the exposed database issue to DeepSeek.\n- DeepSeek promptly secured the exposed ClickHouse database.\n- DeepSeek disclosed that large-scale malicious attacks had disrupted its services, including user registration.\n- Google suspended the Deepswap PRO app and it is no longer available on the Google Play Store.\n- The Deepswap app is no longer available on the Apple App Store.\n- Links to Candy.ai were removed from the MrDeepFakes website following questions from Bellingcat.\n- EverAI implemented moderation controls on Candy.ai to prevent the creation of deepfakes on its platform.\n- EverAI stated that it takes appropriate action against users who attempt to misuse its platform.\n- EverAI cut ties with the publisher that placed its advertisements on MrDeepFakes.\n- EverAI directed the publisher to remove all material referring to or pointing to its platform.\n- The UK blocked access to the MrDeepFakes website.\n- The EU announced plans to call on member states to criminalise the non-consensual sharing of intimate images, including deepfakes.\n- The UK government announced new laws in 2024 targeting creators of sexually explicit deepfakes.\n- LinkedIn removed at least two accounts that were created for AI 'co-workers' whose profile images said they were '#OpenToWork'.\n- The chatbot was taken offline.\n- Linagora issued a public statement acknowledging that Lucie was released prematurely and noting the model's limitations.\n- Linagora said it will update the model.\n- Linagora said it will test a beta version in private before a public relaunch.\n- Embodied emailed a Closing FAQ to users and posted the Closing FAQ on their website about the shutdown.\n- Embodied warned customers in the Closing FAQ that Moxie was likely to stop working within days.\n- Embodied stated that no refunds would be given to customers.\n- Embodied stated that no repairs or service could be offered for Moxie devices.\n- Embodied included a letter from the Global Robotics Lab to help guide conversations with children in an age-appropriate way.\n- On Jan. 23, police in Kanagawa Prefecture sent papers to prosecutors on two men on suspicion of violating copyrights by selling AI-generated posters.\n- Both suspects reportedly admitted to the allegations.\n- Police brandished their weapons during the response, which activated the Omnilert weapon-detection system.\n- Authorities are investigating online materials believed to be from the shooter.\n- Metro Nashville Public Schools said it is installing and equipping schools with safety protocols and resources to improve school safety.\n- Character.AI issued a list of safety updates vowing to strengthen guardrails around content related to promotion or depiction of self-harm or suicide.\n- Character.AI said it would take a look at the list of Characters flagged by Futurism and remove Characters that violate its Terms of Service.\n- Character.AI removed some accounts that Futurism flagged for violating its policies.\n- Character.AI removed the \"4n4 Coach\" and \"Ana\" chatbots after those specific Characters were directly flagged to the company.\n- Character.AI's Trust & Safety team stated it moderates Characters proactively and in response to user reports using industry-standard blocklists and custom blocklists that the company regularly expands.\n- Character.AI said it would continue to improve and refine its safety practices and implement additional moderation tools to help prioritize community safety.\n- Character.AI announced it was introducing new stringent safety features to create a different experience for users under 18 to reduce the likelihood of encountering sensitive or suggestive content.\n- Character.AI added a revised disclaimer on every Character chat to remind users that the AI is not a real person and to treat everything it says as fiction.\n- Carl Brown analyzed Cognition AI's promotional video and debunked it on his Internet of Bugs YouTube channel.\n- A YouTube code pundit publicly called out Devin for allegedly including critical security issues.\n- Three data scientists affiliated with Answer.AI (Hamel Husain, Isaac Flath, and Johno Whitaker) tested Devin on 20 tasks and published an analysis reporting that it completed only three tasks satisfactorily.\n- The researchers requested comment from Cognition AI about their findings, but Cognition AI did not respond.\n- Director Brady Corbet issued a public statement to Deadline defending that Adrien Brody\u2019s and Felicity Jones\u2019s performances were their own and explaining that Respeecher AI was used only to refine certain Hungarian vowels and letters in a manual post-production process.\n- ElevenLabs deleted its January 10 post on X that announced it had recreated Alain Dorval\u2019s voice.\n- ElevenLabs published a statement confirming plans to recreate Dorval\u2019s voice using its AI technology.\n- ElevenLabs said it is working with Dorval\u2019s family to preserve his voice.\n- ElevenLabs agreed that if the AI voice quality bar is not met, the film will be released with traditional dubbing.\n- ElevenLabs agreed that Dorval\u2019s family retains full control and will decide if and how the AI dub is used.\n- KBS, MBC, and SBS filed a copyright lawsuit against Naver.\n- The Korean Broadcasters Association sent notices to domestic and foreign IT companies requiring separate compensation consultations to use news content for AI learning.\n- The Korean Broadcasters Association notified IT companies that they are prohibited from using news content without obtaining permission first.\n- The association established an AI task force composed of legal and intellectual property experts.\n- The task force made a formal request to Naver for compensation for the use of broadcasters' news data.\n- The task force made a formal request to Naver for measures to prevent further infringement.\n- The task force requested disclosure from Naver of the source and content of AI learning data and the data acquisition path.\n- The Korean Broadcasters Association stated it will file lawsuits against other big tech companies that use news data without permission.\n- Naver refrained from using news data without consent after revising its terms and conditions in response to protests from media outlets.\n- Naver announced plans to engage in public discussions and consider media feedback on the issue.\n- The Korean Association of Newspapers reviewed the issue with legal experts to prevent copyright infringements.\n- The newspaper association submitted a request to the Fair Trade Commission urging correction of Naver's unfair use of news content for generative AI training.\n- The newspaper association called on the government to specify relevant provisions in partnership terms and conditions to ensure media companies receive proper compensation for the use of news content in AI training.\n- The newspaper association called on the government to force Naver to disclose the information and purpose of use of news data used for AI training.\n- Triplegangers updated and properly configured the site's robots.txt file with tags intended to tell OpenAI's GPTBot not to crawl the site.\n- Triplegangers set up a Cloudflare account and configured it to block OpenAI's GPTBot and other crawlers such as Barkrowler and Bytespider.\n- Triplegangers began daily monitoring server log activity to spot and detect bot activity.\n- TOPR rescuers launched a rescue operation to assist the hikers who had followed ChatGPT's suggested route.\n- TOPR rescuers safely brought the hikers back down to the valley.\n- A TOPR rescuer strongly advised against using ChatGPT or Google Maps to choose routes in the Tatra Mountains.\n- The TOPR rescuers warned tourists about the current difficult winter conditions in the Tatra Mountains.\n- Tatrza\u0144ski Park Narodowy issued a public communication warning about treacherous winter weather in the higher parts of the Tatra Mountains.\n- The park advised that hikers should have extensive experience in winter mountaineering.\n- The park advised that hikers should be able to assess local avalanche hazard.\n- The park advised that hikers should choose routes appropriately for current conditions.\n- The park advised that hikers should use winter equipment such as crampons.\n- The park advised that hikers should use an ice axe.\n- The park advised that hikers should wear a helmet.\n- The park advised that hikers should carry avalanche safety equipment (avalanche ABC).\n- A TOPR rescuer urged hikers to apply common-sense thinking and thorough planning before mountain excursions.\n- The NSW Department of Education sent an email to parents informing them that their daughters were victims of AI-generated deepfakes.\n- The department urged parents and their families to assist in removing the fake social media profiles.\n- The department advised parents and students not to share the explicit evidence of the deepfakes.\n- The department urged parents and students not to contact the male student directly.\n- The matter was referred to the police for investigation.\n- The matter was referred to the eSafety Commissioner for investigation.\n- The NSW Department of Education stated it would take appropriate action against those responsible.\n- The department said any decision about the student's future involvement in the school will be based on ensuring students feel safe.\n- The department is providing appropriate wellbeing support to affected students and said it will continue to do so as long as required.\n- A department representative apologised to families, saying, 'I am sorry this has occurred.'\n- Police are currently investigating the scam.\n- TF1 withdrew the programme segment from its replay services and platforms.\n- TF1 presenter Harry Roselmack wrote on social media that the segment had been withdrawn to protect victims.\n- Toulouse FC deleted the post that mocked the woman.\n- Toulouse FC apologised for the post that mocked the woman.\n- Signify works with prominent groups and clubs in sports to track online hate.\n- Signify works with prominent groups and clubs in sports to report online hate.\n- The Premier League has assigned a dedicated team to find and report racist abuse directed towards athletes.\n- The Premier League introduced filters for players to use on their social media accounts to help block large amounts of abuse.\n- The plaintiffs (authors Richard Kadrey and Christopher Golden, and comedian Sarah Silverman) renewed their lawsuit against Meta with two new claims.\n- The plaintiffs sued Meta for violating the Digital Millennium Copyright Act by removing copyright notices.\n- The plaintiffs alleged that Meta violated the California Comprehensive Computer Data Access and Fraud Act by illegally accessing computer systems through torrent networks.\n- Mark Zuckerberg publicly described Meta's practices as raising \"lots of red flags\" and as \"seems like a bad thing\".\n- A New York federal judge dismissed a similar case against OpenAI.\n- A judge allowed The Intercept's DMCA lawsuit to move forward.\n- Meta took down the individual AI character accounts that NBC News highlighted after receiving screenshots of the violative chatbots.\n- Meta removed the AIs that violated its AI Studio policies.\n- Meta stated it is continuously improving its detection measures to prevent the creation and publication of AIs that violate its policies.\n- Meta said users can report AIs they suspect break the rules and that the company will take appropriate action on those reports.\n- After facing user backlash, Meta removed some Instagram profiles featuring AI characters the company itself had created in 2023.\n- The Las Vegas Metropolitan Police Department shared information about the incident with other law enforcement agencies.\n- OpenAI said it is working with law enforcement to support their investigation.\n- Las Vegas police and federal law enforcement officials held a roughly half-hour-long news conference to unveil new details about the explosion.\n- Authorities withheld a six-page document from release while working with Defense Department officials because some material could be classified.\n- Authorities said they still have to review the contents of a laptop, mobile phone, and smartwatch as part of the investigation.\n- Investigators were trying to determine whether Livelsberger wanted to make a political point.\n- Meta promptly deleted several of its own AI-generated accounts.\n- Meta began taking down Liv and other bots' posts, many of which dated back at least a year.\n- Meta identified the bug that was impacting the ability for people to block those AIs.\n- Meta removed those accounts to fix the issue.\n- Meta began purging the AI accounts on Friday.\n- Meta announced it was deleting the AI accounts named Brian and Liv.\n- Apple agreed to pay $95m to settle a court case alleging some of its devices were listening to people without their permission.\n- Apple's lawyers said they will confirm that Apple has permanently deleted individual Siri audio recordings collected prior to October 2019.\n- Apple publicly denied selling Siri data and stated that Siri data is only used to improve the tool.\n- Under the settlement terms, each US-based claimant could be paid up to $20 per Siri-enabled device they owned between 2014 and 2019.\n- The BBC complained to Apple about the Apple Intelligence feature when it generated a false headline about a high-profile alleged murder in the US.\n- Reporters Without Borders called on Apple to axe its AI-powered summaries of news stories.\n- Apple has been contacted for a response to the false AI alerts.\n- Users can report any concerns they have on a notification summary.\n- A customer filed a lawsuit against McDonald\u2019s alleging violations of Illinois law and seeking class status.\n- The lawsuit was moved to a federal court in Illinois last week.\n- Vulture published an article that resurfaced claims about Spotify\u2019s use of fake-artist tracks and brought the issue into public view.\n- NPR published reporting scrutinizing the alleged fake-artist tracks on Spotify playlists.\n- The Guardian published reporting scrutinizing the alleged fake-artist tracks on Spotify playlists.\n- Music writer David Turner used analytics data to illustrate how Spotify\u2019s 'Ambient Chill' playlist had been largely replaced by tracks from production-music companies.\n- The Swedish daily Dagens Nyheter conducted an investigation comparing streaming data to documents from the Swedish copyright collection society STIM and revealed that around twenty songwriters were behind more than five hundred 'artists.'\n- The Harper\u2019s Magazine reporter reviewed internal Spotify records and company Slack messages and interviewed former employees and musicians to investigate the Perfect Fit Content program.\n- Harper\u2019s Magazine followed up with Spotify about internal documents, and a Spotify spokesperson responded that Spotify is 'data driven in all that we do' and that it does not 'promise placement on any playlists' in its licensing agreements.\n- A Spotify spokesperson publicly denied that Spotify was creating its own fake-artist tracks, calling the reports 'categorically untrue, full stop.'\n- Spotify denied that staffers were encouraged to add PFC to playlists and denied that playlist editors were discontented with the program.\n- Spotify employees used an internal Slack channel to debate the ethics and fairness of the PFC program.\n- Epidemic Sound published corporate messaging promising artists that technology will never replace them.\n- Academia Sinica took down the beta version of the CKIP-Llama-2-7b chat AI and removed it from public view on Oct. 9.\n- Academia Sinica vowed to set up an audit mechanism to avoid similar issues in the future.\n- The 360 company said it quickly completed a rectification of the watch's responses.\n- 360 removed all the harmful information mentioned above.\n- 360 is upgrading the watch's software to an AI version.\n- 360 said it has been trying to reduce AI hallucinations and to do a better job of comparing search content.\n- Photographer Carl De Keyzer deleted his Instagram post of the images.\n- Magnum Photos released a statement on AI-generated images.\n- Magnum Photos announced that its archive will remain dedicated exclusively to photographic images taken by humans and that reflect real events and stories.\n- News organisations hastily retracted the AI-assisted image of Princess Catherine and her children.\n- Princess Catherine released a video updating supporters about her health.\n- A parliamentary inquiry into AI released a report saying the companies behind generative AI had committed \"unprecedented theft\" from creative workers in Australia.\n- The BBC contacted Apple to raise the concern and request that Apple fix the misleading headline.\n- A journalist from ProPublica highlighted the mistake on the social platform Bluesky.\n- Users can report concerns about a notification summary directly from their devices.\n- Microsoft pulled Recall from Insider/test builds in June following security and privacy concerns.\n- Microsoft promised to bring Recall back only after implementing security upgrades.\n- Microsoft updated Recall to encrypt the screenshots and the database it captures so users cannot open them outside the Recall app.\n- Microsoft made Recall opt-in rather than opt-out when reintroducing it to Insider builds.\n- Microsoft enabled a \"Filter sensitive information\" setting by default to attempt to prevent recording of credit card numbers, passwords, and personal identification numbers.\n- Microsoft updated Recall to detect sensitive information and to not save or store snapshots when such information is detected.\n- Microsoft requires Windows Hello authentication every time a user opens the Recall app.\n- Microsoft requires users on first use to set up a Windows Hello biometric login (face or fingerprint) before using Recall.\n- Microsoft added a Settings option that allows users to anonymously share the apps and sites they prefer to be excluded from Recall to help improve the product.\n- Microsoft asked users to report instances where sensitive information was not filtered via the Feedback Hub and said it would continue to improve the functionality.\n- Character.AI quickly corrected the issue on the platform.\n- Character.AI is investigating the incident further.\n- Character.AI said it will provide more information when available.\n- OpenAI enhanced the underlying Whisper model after the study, resulting in a reduced rate of hallucinations.\n- Recorded Future submitted the video clips to ElevenLabs\u2019 AI Speech Classifier to detect whether the audio was created using ElevenLabs\u2019 technology.\n- Recorded Future attributed the activity to the Social Design Agency.\n- The U.S. government sanctioned the Social Design Agency for running a network of over 60 websites that impersonated genuine news organizations in Europe.\n- ElevenLabs released new safety features that automatically block voices of politicians.\n- ElevenLabs bans unauthorized, harmful, or deceptive impersonation.\n- ElevenLabs uses both automated and human moderation to enforce its ban on impersonation.\n- Character.AI added a pop-up that directs users to the National Suicide Prevention Lifeline when they mention self-harm or suicide.\n- Character.AI hired a head of trust and safety.\n- Character.AI hired a head of content policy.\n- Character.AI hired additional engineering safety staff.\n- Character.AI is creating a model specifically for teen users that reduces the likelihood of encountering sensitive or suggestive content while preserving their ability to use the platform.\n- OpenAI worked on a fix for the tool that mistakenly flagged the name and prevented it from appearing in responses.\n- OpenAI fixed the \"David Mayer\" issue and restored ChatGPT's ability to respond to queries containing that name.\n- The FTC announced a proposed settlement with IntelliVision Technologies addressing allegations of deceptive advertising.\n- IntelliVision agreed to a consent order prohibiting the company from misrepresenting the capabilities of its facial recognition technology.\n- The company is barred from making claims about the accuracy, efficacy, or bias-free performance of its facial recognition software without competent and reliable evidence to support such assertions.\n- The public will have the opportunity to comment on the proposed settlement before it is finalized.\n- Once finalized, the consent order is expected to include provisions for compliance monitoring.\n- The FTC pointed companies to its Policy Statement on Biometric Information and its 'AI and Your Business' series as resources for navigating legal and ethical considerations in AI marketing.\n- The families filed a lawsuit in federal court in Minnesota against UnitedHealth alleging it used a faulty AI algorithm to deny necessary coverage.\n- Lawyers for the families are seeking to represent all persons who purchased Medicare Advantage Plan health insurance from the defendants in the United States during the period of four years prior to the filing of the complaint through the present.\n- A NaviHealth spokesperson told CBS MoneyWatch that the AI-powered tool is not used to make coverage determinations but is a guide to help inform providers about what sort of assistance and care the patient may need.\n- The NaviHealth spokesperson also stated that coverage decisions are ultimately based on CMS coverage criteria and the terms of the member's plan and declared that the lawsuit has no merit.\n- The Office of the Australian Information Commissioner ordered Bunnings not to repeat the use of facial recognition technology.\n- The Office of the Australian Information Commissioner ordered Bunnings to destroy all personal and sensitive information collected within a year.\n- Bunnings must publish a statement on its website within 30 days explaining what it did wrong.\n- Bunnings must publish a statement on its website within 30 days explaining how it was using the facial recognition technology.\n- Bunnings must publish a statement on its website within 30 days providing advice to customers on how to make a complaint.\n- Bunnings will seek a review of the Commissioner's ruling.\n- Bunnings, Kmart, and The Good Guys halted the use of facial recognition in stores in the wake of Choice's report.\n- Bunnings cooperated with the Office of the Australian Information Commissioner's investigation.\n- In 2023, the U.S. Department of Health and Human Services placed Lincare on probation under a corporate integrity agreement.\n- That corporate integrity agreement included a 'death penalty' provision.\n- Lincare paid multimillion-dollar legal settlements.\n- In 2018, California sanctioned UnitedHealth for its algorithm-driven practice.\n- UnitedHealth applied corrective actions only to its California-based plans.\n- Massachusetts found UnitedHealth's system illegal.\n- New York found UnitedHealth's system illegal.\n- The Tow Center at Columbia Journalism School conducted a study testing ChatGPT's citation accuracy and published a blog post summarizing their findings.\n- OpenAI said it has collaborated with partners to improve in-line citation accuracy.\n- OpenAI said it has collaborated with partners to respect publisher preferences.\n- OpenAI enabled how publishers appear in search by managing OAI-SearchBot via publishers' robots.txt files.\n- OpenAI committed to continue enhancing search results.\n- OpenAI said it helps 250 million weekly ChatGPT users discover quality content through summaries, quotes, clear links, and attribution.\n- The manager informed upper management about the critical flaw in the hiring process.\n- Upper management looked into the matter to investigate the manager's findings.\n- Upper management dismissed the HR team.\n- Half of the HR department was fired in the following weeks.\n- A coalition of Canadian news outlets filed an 84-page lawsuit against OpenAI alleging the company illegally used news articles to train its software.\n- The news organisations are seeking punitive damages of C$20,000 per article they allege was used to train ChatGPT.\n- The plaintiffs requested an order forcing OpenAI to share profits made from using their articles.\n- The plaintiffs requested an injunction prohibiting OpenAI from using their articles in the future.\n- OpenAI stated that it collaborates with news publishers by displaying attribution and links to their content in ChatGPT search.\n- OpenAI said it offers publishers easy ways to opt out of having their content used.\n- The Dutch government pledged to refund over 10,000 students who were unjustly flagged for student finance fraud.\n- Minister of Education Eppo Bruins allocated 61 million euro to the refund process.\n- The allocation included 47 million euro for direct reimbursements.\n- The allocation included an additional 14 million euro for implementation of the refund process.\n- The government decided that payments will be made regardless of the fraud findings.\n- The Dutch Data Protection Authority launched an investigation into DUO in July 2023.\n- Minister Bruins ordered the suspension of DUO\u2019s discriminatory algorithm in July 2023.\n- Minister Bruins replaced the suspended algorithm with a random-sampling-based fraud detection system.\n- Dijkgraaf\u2019s ministry commissioned independent agencies to audit DUO\u2019s practices.\n- PricewaterhouseCoopers published an independent report in March 2024 confirming indirect discrimination in DUO\u2019s practices.\n- Dutch news outlets NOS and Investico conducted an inquiry in June 2024 that found a disproportionate impact on ethnically diverse students.\n- Amnesty International published a report in March 2024 criticizing the government for not implementing effective safeguards against ethnic profiling.\n- DUO committed to rectifying its data practices.\n- DUO committed to revising its fraud detection methods.\n- DUO expressed deep regret over the findings.\n- DUO pledged to work transparently with oversight bodies.\n- Netflix removed the promotional Arcane banner image from its streaming app after fans pointed out signs of generative AI use.\n- Riot issued a public statement saying the image was a mistake, confirming it had been removed, and reiterating its strict stance of no AI for anything relating to Arcane.\n- Riot brand manager Alex Shahmiri replied on X to thank fans for reporting the issue and to answer inquiries clarifying his opposition to using AI in Arcane-related work.\n- Four engineers of the Public Works Department and an unnamed Google Maps official were booked in connection with the incident.\n- Officials were arrested in connection with the death of three men.\n- An FIR was filed against four engineers of the PWD and unknown persons.\n- The regional Google Maps officer was brought under the scope of investigation.\n- An FIR under section 105 of the BNS was registered against two Assistant Engineers, two Junior Engineers of the PWD, and unknown persons.\n- Directives were issued to the PWD and Setu Nigam to inspect all roads, bridges, flyovers, and underpasses.\n- Corrective measures were taken at the site.\n- Google said it is working closely with the authorities and providing support to investigate the issue.\n- GEMA filed a lawsuit against OpenAI for copyright infringement in Munich regional court.\n- GEMA developed a license model for generative AI use to compensate songwriters and publishers.\n- GEMA presented a licensing model for generative AI software that would compensate songwriters and publishers at the end of September.\n- GEMA sent letters to AI companies stating they must license GEMA works in order to use them.\n- The Home Office released redacted manuals and impact assessments to the campaign group Privacy International following a year-long freedom of information battle.\n- The Home Office stated that every recommendation made by the IPIC system is reviewed by a caseworker who is required to weigh it on its individual merits.\n- A new draft data bill was introduced for debate in the UK parliament that would permit automated decision-making provided affected individuals can make representations, obtain meaningful human intervention, and challenge automated decisions.\n- The Fukuoka prefectural government issued an apology for publishing AI-generated, inaccurate tourist information.\n- Coca-Cola issued a public statement defending the advertisement and saying the holiday films were crafted through a collaboration of human storytellers and generative AI.\n- Silverside AI\u2019s AI Developer posted a reply on X clarifying that Silverside AI did not create the viral version of the advertisement and that each AI studio had produced different versions.\n- UDK and ATP provided Amnesty International with redacted documentation on the design of certain algorithmic systems.\n- Amnesty International called on the European Commission to issue clear guidelines on which AI practices constitute a social scoring system in its AI Act guidance.\n- Amnesty International requested that the Danish authorities stop using the fraud detection system until it can be confirmed that it does not fall under the AI Act's social scoring ban.\n- Amnesty International called on the Danish authorities to urgently implement a clear and legally binding ban on the use of data related to 'foreign affiliation' or proxy data in risk scoring for fraud control purposes.\n- Amnesty International called on the Danish authorities to ensure robust transparency and adequate oversight in the development and deployment of fraud control algorithms.\n- CanLII filed a lawsuit in B.C. Supreme Court alleging that Caseway AI infringed its copyrights and breached its terms of use by bulk downloading and scraping records.\n- CanLII sent a cease-and-desist letter to Caseway last month over the bulk downloading of its database.\n- CanLII is seeking injunctions restraining Caseway from using any of the material it scraped.\n- CanLII is seeking punitive and exemplary damages for loss, damage, expense and irreparable harm allegedly suffered due to the bulk downloading.\n- Caseway sent a written response to CBC News stating its position and saying it would welcome a collaboration with CanLII.\n- The FTC filed a complaint alleging that GGL Projects (Sitejabber) deceptively inflated average ratings and review counts.\n- Under a proposed FTC order, Sitejabber will be banned from making misrepresentations about consumer ratings or reviews.\n- Google said the response violated its policies and that it has taken action to prevent similar outputs from occurring.\n- Google limited the inclusion of satirical and humor sites in its health overviews.\n- Google removed some search results that went viral.\n- The mother of a 14-year-old Florida teen filed a lawsuit against Character.AI and Google, claiming the chatbot encouraged her son to take his life.\n- OpenAI announced that on Nov. 5 ChatGPT would start directing user queries about election results to news sources or official state and local election sites.\n- Microsoft said it had an existing relationship with Newsguard as part of its election protection measures.\n- Meta published a fact sheet about its approach to the U.S. elections that focused on identifying AI-generated content and deep fakes.\n- Google applied unspecified \"election-related restrictions\" to AI Overview, as described in an August blog post.\n- Perplexity.ai debuted an election misinformation hub and provided sources for each response so users can verify referenced materials.\n- Microsoft Copilot refused to answer one of the election misinformation queries and advised consulting local election authorities.\n- Character.AI removed the AI character based on a real-life teenager and apologized.\n- Character.AI issued a list of community safety updates stating that discussion of suicide violated its terms of service.\n- Character.AI announced that it would be tightening its safety guardrails to protect younger users.\n- Character.AI removed the Characters that were flagged for violating policies from the platform.\n- Character.AI's Trust & Safety team said it moderates the hundreds of thousands of Characters on the platform both proactively and in response to user reports.\n- Character.AI said it uses industry-standard blocklists and custom blocklists and that it regularly expands those lists.\n- Character.AI said it made immediate product changes after discovering that a number of terms or phrases should have been caught by proactive moderation.\n- Character.AI said it is working to improve and refine its safety practices.\n- Character.AI said it is implementing additional moderation tools to help prioritize community safety.\n- Character.AI said it would review the new list of Characters flagged by Futurism and remove any that violate the Terms of Service.\n- Character.AI removed the 'Dads friend Mike' chatbot after Futurism asked why it had remained online.\n- The Susquehanna Regional Police Department seized the student's phone in August.\n- The student who created the AI-generated images was removed from the school.\n- Police began investigating the matter only after a second allegation was made.\n- Police identified 46 victims, including 38 current students and eight former students.\n- Classes for upper school students started later on Monday.\n- Multiple counselors were made available to students on campus that day.\n- Head of School Matt Micciche acknowledged the situation and apologized during a meeting with students.\n- Matt Micciche emailed families on Friday apologizing and stating he hoped to re-earn trust by listening, answering questions, and working together.\n- Jenny Gabriel, head of the upper school, resigned in September.\n- Attorney Matthew Faranda-Diedrich sent a letter on Monday to the school's board of trustees on behalf of parents detailing allegations and demanding resignations.\n- Parents threatened to sue the school unless Head of School Matt Micciche and board president Angela Ang-Alhadeff resigned within 48 hours.\n- Attorney Matthew Faranda-Diedrich confirmed he would file a notice of the families' intent to sue by Thursday morning.\n- An incomplete filing against the school was rejected by the Lancaster County Prothonotary Office due to student confidentiality concerns.\n- The school forwarded the Monday email communication sent to families to an LNP-LancasterOnline reporter.\n- The attorney gave notice to the LCDS Control Group to preserve all electronic and paper records and not to destroy, conceal, or alter any relevant data.\n- Most upper school students walked out of classes in protest, chanting demands for acknowledgment and action.\n- The school launched an investigation into the creation and sharing of the deepfake photos.\n- The school lodged a police report.\n- The police confirmed that investigations into the incident are ongoing.\n- The school offered affected students counselling.\n- The school's discipline committee is working with the police to address the matter.\n- The school informed parents it will notify them of any significant developments.\n- The school provided the police with website links associated with the case.\n- The police are assisting in requesting the removal of all related images from the identified sites.\n- All students involved are being interviewed by the police.\n- The mobile devices of the students involved were temporarily confiscated for forensic examination.\n- The school said devices will be cleared of inappropriate content before being returned to the students.\n- The police asked for permission to conduct phone interviews with some of the affected students.\n- Some of the boys were caned in private on Nov 11.\n- The school imposed sports trip bans on some students.\n- The school suspended some students from school, training, and boarding where appropriate.\n</mitigation_statements>"}]}}
{"custom_id": "batch_200", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- NewsGuard fed all 171 posts from the accounts into a Pangram Labs tool to assess the likelihood that the content was generated by AI.\n- NewsGuard shared the findings of their research with X.\n- NewsGuard shared the findings of their research with OpenAI.\n- X suspended two of the 171 accounts identified by NewsGuard.\n- X restricted two of the 171 accounts identified by NewsGuard.\n- The Ministry of Education published new regulations in January 2022 requiring employers to pay interns minimum wage.\n- The Ministry of Education published new regulations in January 2022 banning schools from taking commissions from student interns' wages.\n- The Ministry of Education published new regulations in January 2022 prohibiting educational institutions from assigning students 'simple, repetitive work.'\n- A vocational school halted its data annotation internship program in 2021 after students complained of low pay and overwork.\n- Baidu publicly stated it prioritized labor rights and urged its service providers to prioritize the dignity and rights of employees.\n- The person was taken to a hospital and given an examination that found no obvious external injuries.\n- Baidu issued a statement to Chinese media describing the incident and saying the car began moving when the light turned green and had minor contact with the pedestrian.\n- The event organizers apologized to Elizabeth Laraki for the AI-altered photo.\n- The event organizers investigated and found the issue with the altered image.\n- The event organizers fixed the promotional image/ad quickly.\n- The victim called the police after discovering the first camera.\n- The police arrested the offender the same day.\n- The victim packed her things to move out of the shared residence.\n- The victim found the second camera and turned it over to the police.\n- The police seized the offender's electronic devices for investigations.\n- Investigators found 17 videos on the seized devices that appeared to show the victim in sex acts.\n- The offender admitted using a smartphone application to superimpose the victim's face onto pornographic videos.\n- The defence tendered a psychiatric report stating the offender suffered adjustment disorder with depressed mood.\n- The prosecution sought a 24 to 29 week jail sentence for the offender.\n- The offender's lawyers asked the court for a 15 week jail sentence.\n- The offender pleaded guilty to one count each of voyeurism and possessing altered intimate videos.\n- The court sentenced the offender to 21 weeks' jail.\n- Gag orders were imposed protecting the victim's identity.\n- The offender was allowed to begin his jail term on Nov 15.\n- Mistral AI fixed the security vulnerability.\n- Mistral AI disabled one of its chat functionalities.\n- Mistral AI blocked the Markdown renderer from operating and prevented it from calling external URLs so external image loading is no longer possible.\n- The researchers published a paper detailing the Imprompter attack.\n- The researchers tested the attack method on two LLMs, LeChat by Mistral AI and ChatGLM.\n- OpenAI released the SimpleQA benchmark to measure the accuracy of its own and competing AI models.\n- OpenAI ran internal tests of its models, including the o1-preview model, against the SimpleQA benchmark.\n- Florian Schroeder confirmed to the Herald that the image was AI-generated.\n- NESA issued a public statement reassuring students that they would be marked on their response to the question rather than on the image's origin or construction.\n- NESA contacted Florian Schroeder to seek permission to publish the stimulus on its website for future students to analyse.\n- The Irish police issued a public announcement clarifying that no Halloween parade was scheduled in Dublin City Centre that evening.\n- Researcher Ciar\u00e1n O'Connor conducted an investigation into the fake site and published a thread detailing his findings.\n- The operator of the My Spirit Halloween website admitted that at least 30 percent of the site's content was created with the assistance of AI.\n- Character.ai deleted the user-generated chatbots after being alerted to them.\n- Character.ai moderated avatars both proactively and in response to user reports.\n- Character.ai's dedicated Trust & Safety team reviews reports and takes action in accordance with company policies.\n- Character.ai uses automated tools and user reports to identify uses that break its rules.\n- Character.ai said it is building a Trust & Safety team.\n- Character.ai said it had protections specifically focused on suicidal and self-harm behaviours.\n- Character.ai said it would be introducing more stringent safety features for under-18s imminently.\n- Mike Parkinson publicly defended the use of AI for the podcast in an interview on BBC Radio 4's Today.\n- Mike Parkinson told the podcast producers he wanted it to be clear to listeners that the voice was an AI iteration.\n- Deep Fusion Films' co-creators publicly committed that they will not try to pass the AI recreation off as the real Sir Michael.\n- The podcast was produced with the backing of Sir Michael Parkinson's family and estate.\n- Google admitted it had botched the AI Overviews rollout.\n- Google added the title for one of the links to the right of the AI-generated summary after complaints that the summaries showed no articles.\n- Google said its systems were not working as intended and that it is looking at ways it can improve.\n- Google stated that when it finds Overviews that do not align with its policies, it quickly takes action against them.\n- Google said the specific Overviews that violated its policies have been removed.\n- WIRED's tests suggest AI Overviews have been switched off for queries about national IQs.\n- Jill Creasy reported the scam to the police.\n- Jill Creasy reported the scam to TSB.\n- TSB froze Creasy's accounts after learning of the fraud.\n- TSB tried to recover the funds.\n- TSB told Creasy she had enabled the scam and therefore was not liable for her loss.\n- TSB asked Creasy to contact the police.\n- TSB urged customers to be vigilant.\n- TSB urged customers never to share account details.\n- TSB urged customers not to allow third-party remote access to their devices.\n- Easy Crypto contacted Creasy due to concerns about her transactions and to obtain reassurance she was not working with any third party.\n- Easy Crypto said it worked to identify scams and monitor transactions.\n- A computer expert helped Creasy unravel the fraud.\n- A computer expert tracked Creasy's Bitcoin to a third Binance holding account receiving nearly $3 million each day.\n- The Financial Markets Authority issued a public scam warning about the AI-generated deepfake videos.\n- Police said the case remained under investigation.\n- Police advised that no legitimate company uses remote-access software in their work and that this is a sign of a scam.\n- Police advised people to disconnect the call and phone back the number on the company website if they have suspicions.\n- Police advised people to check in with a trusted friend or relative if they have suspicions.\n- A spokesman for the prime minister urged Kiwis to be vigilant for scams.\n- The government said it was looking at ways to help Kiwis protect themselves online.\n- Synthesia banned the accounts that created the Burkina Faso propaganda videos in 2023.\n- Synthesia strengthened its content review processes.\n- Synthesia hired more content moderators.\n- Synthesia improved its moderation capabilities and automated systems to better detect and prevent misuse of its technology.\n- Synthesia had been in touch with some of the actors whose likenesses had been used.\n- Synthesia blocked attempts to use one of its avatars when the Guardian tested its technology.\n- Synthesia later blocked the account that recreated the Burkina Faso-style propaganda video.\n- Synthesia took down the free AI audio service after being contacted by the Guardian.\n- YouTube removed the propaganda video featuring Dan Dewhirst.\n- Studios agreed to contractual safeguards requiring informed consent before digital replication as part of resolving the actors' strike.\n- Studios agreed to contractual safeguards requiring fair compensation for digital replication as part of resolving the actors' strike.\n- A bipartisan bill called the NO FAKES Act was introduced in the US to hold companies and individuals liable for damages involving digital replicas.\n- Torres's Synthesia avatar will be deleted when his contract ends in a few months.\n- OpenAI said it continually studies how to reduce hallucinations in Whisper.\n- OpenAI said it incorporates feedback into model updates.\n- OpenAI posted online disclosures recommending against using Whisper in decision-making contexts where accuracy flaws can lead to pronounced harms.\n- Nabla said it erases the original audio recordings for data safety reasons.\n- Nabla said it requires medical providers to quickly edit and approve AI-generated transcribed notes.\n- Nabla said it is addressing Whisper's hallucination problems.\n- Experts, advocates, and former OpenAI employees called for the federal government to consider AI regulations.\n- A University of Michigan researcher began trying to improve the model after finding hallucinations in transcriptions.\n- California state lawmaker Rebecca Bauer-Kahan refused to sign a form permitting the sharing of her child's consultation audio with vendors.\n- Marques Brownlee publicly addressed the unauthorized AI cloning of his voice by posting about it on X (formerly Twitter).\n- The Instagram post on Dot\u2019s official page that promoted the product using the AI-cloned voice was deleted.\n- Police questioned Megan Garcia following Sewell's death.\n- Police seized the handgun and Sewell's telephone and sent them for examination.\n- Megan Garcia attempted to file criminal charges after her son's death.\n- Megan Garcia contacted the local prosecutor's office to seek assistance regarding the case.\n- Megan Garcia contacted lawyer Meetali Jain of the Tech Justice Law Project for legal help.\n- Garcia and her legal team filed a federal lawsuit in Orlando alleging negligence, wrongful death, unjust enrichment, deceptive and unfair trade practices, and intentional infliction of emotional distress.\n- Garcia's legal team engaged the Center for Humane Technology as technical consultants.\n- Garcia's legal team engaged the Social Media Victims Law Center for legal support.\n- Other parents of children affected by Character.AI filed lawsuits related to harms from the app.\n- Garcia's family initiated legal action against a Character.AI chatbot that used Sewell's picture.\n- Garcia's family installed cameras and alarms on their house as a precaution.\n- Garcia's family is planning to strengthen their fence as a precaution.\n- Character.AI increased its minimum user age from 13 to 17.\n- Character.AI removed a number of chatbots from its platform.\n- Character.AI disabled the ability for teenagers to edit chatbot responses to circumvent safety measures.\n- Character.AI programmed a suicide hotline number to pop up when a user mentions suicide.\n- Character.AI added a screentime notification that appears after 60 minutes of use.\n- Character.AI added clearer warnings to remind users that chatbots are not real people.\n- Orlando Christian Prep banned smartphones at school.\n- Students at Orlando Christian Prep are required to put their phones in lockers before classes and may retrieve them in the afternoon.\n- Students at Orlando Christian Prep who want to call their parents during the day can do so from the school office.\n- Radio Krak\u00f3w terminated cooperation agreements with external collaborators.\n- The editor-in-chief, Marcin Pulit, issued a public statement in response to criticism.\n- In that statement, Pulit said that no employees had been dismissed and that cooperation agreements with external collaborators were terminated.\n- Radio Krak\u00f3w conducted an assessment of OFF Radio Krak\u00f3w which found it had a listenership range of close to zero and that its content overlapped with the broadcaster\u2019s other channels.\n- After that assessment, the broadcaster relaunched OFF Radio Krak\u00f3w aimed at younger listeners and presented by three AI characters.\n- Music playlists for the relaunched channel are created using AI tools but are overseen by a human director.\n- The station stated the project is experimental and will be gradually developed and enriched with new elements.\n- The station said it wanted the venture to spark a public debate on the use of AI.\n- Summit County prosecutors decided not to use Cybercheck as evidence in Phillip Mendoza\u2019s case.\n- The Summit County Prosecutor\u2019s Office withdrew Cybercheck reports in three other cases involving four men accused of murder.\n- The Summit County Sheriff\u2019s Office confirmed it is investigating whether Adam Mosher lied under oath.\n- Assistant district attorney Lisa Borden decided not to use Mosher\u2019s testimony or the Cybercheck report at Sergio Cerna\u2019s trial.\n- Colorado prosecutors dropped charges and sealed the file against a defendant in a child sexual abuse material (CSAM) case after questions about Mosher and Cybercheck.\n- Judges overseeing multiple murder trials ruled that Cybercheck cannot be admitted as evidence unless Global Intelligence grants defendants access to its source code.\n- The Summit County Prosecutor\u2019s Office appealed several trial court rulings that excluded Cybercheck reports.\n- Prosecutors in other jurisdictions decided not to use Cybercheck reports.\n- Prosecutors in other jurisdictions dropped charges against defendants after defense attorneys scrutinized Cybercheck\u2019s findings and Mosher\u2019s testimony.\n- The Ohio Bureau of Criminal Investigation stated it has no intentions of entering into another contract with Global Intelligence due to a lack of useful investigative leads.\n- The Yakima County Sheriff\u2019s Office ceased using Cybercheck.\n- The Summit County Prosecutor\u2019s Office asked the Ohio BCI\u2019s cybercrimes unit for an opinion about whether to use Cybercheck evidence.\n- County prosecutors reached out to the SANS Institute for guidance about Cybercheck\u2019s technology.\n- Defense attorney Donald Malarcik filed a motion asking the prosecutor to provide Cybercheck\u2019s software in another case.\n- Donald Malarcik subpoenaed Adam Mosher.\n- Donald Malarcik hired a digital forensics expert to review Cybercheck\u2019s code and reports.\n- Defense attorneys in the Cerna case requested a Daubert hearing to challenge Cybercheck evidence.\n- Defense attorney Eric Zale hired private investigators to look into Adam Mosher\u2019s background.\n- After being contacted by Zale\u2019s investigator, Canadian prosecutors contacted the Boulder County prosecutor to state that Mosher had never been called to testify in the Canadian cases he claimed.\n- Aurora detectives spoke to the resident at the home that Cybercheck had linked to a suspect to try to corroborate the router information.\n- Investigators located the missing juvenile using other investigative methods instead of relying on Cybercheck.\n- The Summit County Prosecutor\u2019s Office began asking other companies whether they can perform the same kind of open source locating that Global Intelligence marketed.\n- In July 2024, Dow Jones and the New York Post sent a letter to Perplexity putting it on notice of the legal issues raised by Perplexity\u2019s unauthorized use of their copyrighted works.\n- In that July 2024 letter, Dow Jones and the New York Post offered to discuss a potential licensing deal with Perplexity.\n- On Oct. 21, Dow Jones and the New York Post filed a federal lawsuit against Perplexity in the U.S. District Court for the Southern District of New York.\n- The lawsuit seeks to enjoin Perplexity from unlawfully copying the plaintiffs\u2019 copyrighted content without authorization.\n- The lawsuit seeks statutory copyright infringement damages of up to $150,000 for each infringement, as well as actual damages and Perplexity\u2019s profits for each infringement.\n- The New York Times sent Perplexity a cease-and-desist notice demanding the company stop using its content.\n- The New York Times sued OpenAI and Microsoft, alleging that their AI systems infringe its copyrights.\n- Alcon Entertainment filed a lawsuit against Tesla, Elon Musk, and Warner Bros Discovery alleging they used imagery from Blade Runner 2049 without permission.\n- Telegram removed the explicit AI chatbots from its platform after Wired contacted the company.\n- The site removed Jen\u2019s stolen identity.\n- I denied the Gmail account recovery attempt notification.\n- I Googled the phone number to check its legitimacy.\n- I hung up the call.\n- I called the number back, which went to voicemail.\n- I drove home to do more digging into the incident.\n- I checked the sign-in activity on my Google account.\n- I opened and examined the email headers (Show original) to investigate spoofing.\n- I performed a reverse phone number search.\n- I searched Reddit and found a comment describing a similar email and call.\n- The couple published a video revealing their shock after the AI filter transformed Jess into a prince.\n- Jess posted on her Instagram account joking that Disney was 'homophobic AF' and accusing the company of trolling their wedding photos.\n- FEMAIL reached out to Disney and TikTok for comment.\n- The Department of Families, Fairness and Housing reported the matter to the Office of the Victorian Information Commissioner in December.\n- The Office of the Victorian Information Commissioner released an investigation report into the matter.\n- The Office of the Victorian Information Commissioner issued orders requiring the department to block IP addresses and domains for a range of generative AI websites, including ChatGPT, Meta AI, Gemini and Copilot.\n- The orders require the block to be in place for two years from 5 November.\n- The department accepted the findings of the Office of the Victorian Information Commissioner's report.\n- The department said it would work to implement the orders.\n- The department said it no longer employed the worker.\n- The tribunal investigated the authenticity of the cited cases and found that the nine cases were not genuine FTT judgments but had been generated by an AI system such as ChatGPT.\n- The tribunal asked the appellant whether she had used an AI system such as ChatGPT to generate the cases.\n- HM Revenue & Customs provided full copies of the genuine judgments to the tribunal rather than just summaries.\n- The tribunal pointed out that the genuine judgments were available on publicly accessible websites such as the FTT and the British and Irish Legal Information Institute (BAILII).\n- The tribunal rejected Mrs Harber\u2019s appeal, finding that her mental health would not have prevented her from contacting HMRC and that her ignorance of the requirement to notify her liability was not objectively reasonable.\n- Judge Redston quoted the Solicitors Regulation Authority\u2019s Risk Outlook report to explain and highlight the risk of AI-generated 'hallucinations' during the tribunal proceedings.\n- The lawyer was given a month to respond as to why he should not be referred to the Legal Services Board and Commissioner for investigation.\n- Justice Amanda Humphreys referred the solicitor to the Victorian Legal Services Board and Commissioner for investigation.\n- The lawyer offered an unconditional apology to the court.\n- The lawyer said he would take the lessons learned to heart.\n- The lawyer acknowledged the need to verify AI-assisted research for accuracy.\n- The lawyer made a payment to the solicitors for the other party for the costs of the thrown away hearing.\n- Leap issued a public statement to Guardian Australia emphasizing that verifying AI-generated work is a lawyer's ethical obligation and that it provides a free human verification process.\n- Justice Humphreys accepted the lawyer's apology.\n- The hacker contacted 404 Media to report the exposed database and its contents.\n- Attorney General Ra\u00fal Torrez filed the original complaint against Snap Inc. on Sept. 4.\n- Tuesday's unredacted filing unveiled internal messages among Snap employees and executives.\n- Snap said it continues to evolve its safety mechanisms and policies.\n- Snap said it is leveraging advanced technology to detect and block certain activity.\n- Snap said it prohibits friending from suspicious accounts.\n- Snap said it is working alongside law enforcement and government agencies.\n- Meta clarified to TechCrunch that images and videos shared with Meta AI may be used to improve its AI models per the company's Privacy Policy.\n- A Meta spokesperson clarified that photos and videos captured on Ray-Ban Meta are not used to train Meta's models unless the user submits them to Meta AI for analysis.\n- Meta directed TechCrunch to its Privacy Policy which states that interactions with AI features can be used to train AI models.\n- Meta directed TechCrunch to Meta AI's terms of service which state that by sharing images with Meta AI, users agree that Meta will analyze those images using AI.\n- Meta paid the state of Texas $1.4 billion to settle a court case related to its use of facial recognition software.\n- Facebook made the Tag Suggestions feature explicitly opt-in by 2021.\n- Facebook deleted billions of people's biometric information it had previously collected.\n- Meta is not releasing several of Meta AI\u2019s image features in Texas.\n- The Ray-Ban Meta app offers users a choice at first login to opt out of allowing their voice recordings to be used to train Meta's AI models.\n- The creators decided not to release their code.\n- The publisher issued a correction on 02 October 2024 to fix a misquotation of the word that Mike Hicks proposed to describe the inaccurate outputs of LLMs.\n- The Reddit moderator MycoMutant reported dozens of incorrect snippet images to Google.\n- Experts warned foragers to avoid using Google Images to identify mushrooms.\n- Foragers were warned to avoid AI-generated foraging books sold on Amazon.\n- A Google spokesperson told MailOnline that the company is looking into the issue.\n- Vix Hill-Ryder recommended using online search engines and apps only as an accompanying reference.\n- Vix Hill-Ryder recommended consulting reputable book sources for positive identification.\n- Vix Hill-Ryder recommended educating yourself via a course with an expert in the field.\n- Marlow Renton advised people to check the source of images and make their own judgement rather than rely solely on Google Image search.\n- Udemy will offer annual opt-out periods during which instructors can opt out of having their classes included in GenAI training.\n- Udemy will remove opted-out instructors' classes from its dataset by the end of the calendar year.\n- Udemy said it will give instructors a revenue share if its AI features create new revenue streams.\n- Udemy stated it does not have plans to create AI-generated courses that compete with instructors.\n- Udemy posted messages on its community message board and website to explain and promote its generative AI program.\n- A Udemy community manager assured instructors that courses of opted-out instructors will continue to be surfaced through core capabilities such as search and recommendations.\n- Udemy said new instructors will be allowed to opt out of data training when they sign up.\n- Udemy designed its GenAI program and models to exclude content from any instructors who choose to opt out of the program.\n- Udemy said it will regenerate or discontinue using any existing generative AI models that were developed or improved using submitted instructor content.\n- Udemy said that to the extent it can attribute generated content to an instructor's submitted content, it will no longer use that generated content.\n- Hundred Heroines made repeated attempts to speak to Facebook to resolve the ban.\n- Hundred Heroines created a new Facebook page named \"HH Museum\" as a temporary workaround.\n- Hundred Heroines is continuing to attempt to persuade Facebook to restore its banned main page.\n- DoNotPay agreed to a $193,000 settlement with the Federal Trade Commission.\n- The Federal Trade Commission launched Operation AI Comply, a new law enforcement effort to crack down on companies that use AI services to deceive or defraud customers.\n- The FTC took action against multiple companies accused of using artificial intelligence to 'supercharge' deceptive products and services.\n- The FTC announced five cases exposing alleged AI-related deception.\n- Edinburgh Airport admitted to The Scotsman that some online parking quotes were being set by an AI system and that customers were receiving different quotes as a result.\n- The airport said it will use the findings of the AI testing to evaluate the trial and decide whether to adopt the system.\n- The creator announced they are sunsetting the project and will no longer update it.\n- Google manually fixes bad AI Overview responses piecemeal as people point them out.\n- Google uses examples of AI Overviews misinterpreting language or missing context to improve its Search features.\n- In May, Google pared back the AI Overview tool and removed certain responses.\n- Meta's systems removed nearly all the ads cited in the report at the time the ads were run.\n- Ads that are found to have infringed Meta's policy are removed, although this often happens days after they are posted.\n- Meta uses several layers of analysis and detection, including both automated and human reviews, both before and after an ad goes live as part of its ads review process.\n- Meta removes ads that improperly use images of public or political figures for deceptive purposes when they are detected.\n- Meta flagged 300 ads as political, making statistics on views and spending available for those ads.\n- The account responsible for the longest-running ad was taken down after the ad had circulated for 37 days.\n- Only 38 of the 537 ads posted by the most prolific account had been taken down.\n- In the UK, 94% of all ads identified by TBIJ had been removed.\n- In the Netherlands, action had been taken against only 26% of the ads identified by TBIJ.\n- In Spain, action had been taken against only 20% of the ads identified by TBIJ.\n- Efforts are being made to ensure AI helps in sustainable solutions.\n- The company offered the victim its insurance information.\n- The company offered the victim promo codes for use on its delivery service.\n- A Starship employee requested the victim's contact information to follow up and offer assistance.\n- Police obtained video footage of the incident that corroborated the employee's account.\n- The Tempe Fire Department treated the injured employee at the scene.\n- Another employee took the injured worker to the campus medical center for further treatment.\n- Starship stated that the case was thoroughly investigated at the time.\n- Starship said its insurer is handling the matter.\n- Starship initially asked police not to charge the student involved in taking the robot.\n- Starship initially told police it would not aid in prosecution because the robot was not damaged and was returned to the fleet.\n- Nine days later, Starship contacted police and decided it wished to aid in prosecution.\n- Starship later requested that police arrest the student involved in the theft.\n- Starship provided police with information about the robot's movements and said it had evidence depicting vertical movement.\n- Police arrested the two students on felony theft charges.\n- Police later obtained video from the dorm incident from the Barstool Tempe TikTok account.\n- LinkedIn updated its terms of service.\n- LinkedIn informed Ireland\u2019s Data Protection Commission that clarifications to its global privacy policy would be issued.\n- LinkedIn said the updated global privacy policy would include an opt-out setting for members who do not want their data used to train content-generating AI models.\n- LinkedIn provided an opt-out toggle in the Data Privacy settings to disable use of a member\u2019s data for training content-creation AI models.\n- LinkedIn offered a more comprehensive opt-out via a dedicated form while noting that opt-outs would not affect training that had already taken place.\n- LinkedIn told TechCrunch it uses privacy-enhancing techniques, including redacting and removing information, to limit personal information in datasets used for generative AI training.\n- The Open Rights Group called on the UK Information Commissioner\u2019s Office to investigate LinkedIn and other social networks that train on user data by default.\n- Meta worked with the UK Information Commissioner\u2019s Office to simplify the opt-out process before resuming plans to scrape user data for AI training.\n- CDT released the report 'Generating Confusion: Stress-Testing AI Chatbots on Voting with a Disability'.\n- To create the report, CDT tested five chatbots (Mixtral 8x7B v0.1, Gemini 1.5 Pro, ChatGPT-4, Claude 3 Opus and Llama 2 70b) to examine election-related misinformation impacts on people with disabilities.\n- CDT has been working with the federal government to ensure that, as AI advances, governments consider the potential impact on people with disabilities.\n- The report recommended that people avoid using AI chatbots as a primary source for election information.\n- The report suggested that people use AI chatbots to find more reliable resources rather than as a primary source for election information.\n- The report recommended that users fact-check chatbot-provided information using trusted sources before sharing or relying on it.\n- The report recommended that developers direct users to authoritative sources of election information.\n- The report recommended that developers prohibit acts by their systems that could potentially interfere with elections.\n- The report suggested that developers test the model by posing common election questions.\n- The report suggested that developers disclose how recently the model's training data was updated.\n- Spinvox issued a public statement calling the BBC's claims incorrect and inaccurate.\n- Spinvox spoke several times to the BBC about its technology.\n- Spinvox stated that parts of messages sent to conversion experts are anonymised so there is no way of tracing them back to a particular number or person.\n- Spinvox stated that its human-mediated training of the speech system was accomplished in total security through anonymisation, encryption and randomisation.\n- Spinvox stated that the Egyptian call centre did not meet its stringent standards and never handled live calls.\n- The Information Commissioner's Office contacted Spinvox to ensure that its entry on the data protection register is accurate and complete, especially regarding transfer of personal data outside the European Economic Area.\n- Spinvox's co-founder appealed to staff to take all or part of their pay for July and August in the form of share options to help raise \u00a31m.\n- Meta notified users in the European Union and United States that it would use their data to train its generative AI products unless users opted out.\n- Meta provided an opt-out option to users in the European Union for the use of their data to train its AI models.\n- Meta paused launching its AI products in Europe due to legal uncertainty.\n- The Australian federal government vowed to introduce a ban on social media for children.\n- The Australian government said it is due to announce reforms to the Privacy Act and that legislation would be announced in August.\n- Hamas warned of \"grave consequences\" in response to the AI-generated video of the Dome of the Rock burning.\n- Amadon reported his findings to OpenAI through the company\u2019s bug bounty program.\n- Bugcrowd, which runs OpenAI\u2019s bug bounty program, told Amadon to report the issue through another form.\n- TechCrunch withheld some of the prompts and some of ChatGPT\u2019s responses to avoid aiding malicious actors.\n- TechCrunch emailed OpenAI with a series of questions about whether ChatGPT\u2019s responses were expected behavior and whether the company had plans to fix the jailbreak.\n- James Florence Jr. was arrested in Massachusetts.\n- Investigators reviewed subscriber information associated with one of the chatbots.\n- An investigator conversed with a chatbot administrator.\n- Federal prosecutors charged Michael Smith with three counts of wire fraud, wire fraud conspiracy, and money laundering conspiracy.\n- The FBI participated in the investigation of the fraudulent streaming scheme.\n- An indictment detailing the charges against Michael Smith was unsealed.\n- Spotify changed its royalties policy to charge labels and distributors per track if it detected artificial streams of their material.\n- Spotify increased the number of streams a track needs in a 12-month period before royalties can be paid.\n- Spotify extended the minimum track length for noise recordings such as white noise tracks.\n- Music streaming platforms rushed to remove a viral track that cloned the voices of Drake and The Weeknd from their services.\n- Artists including Billie Eilish, Chappell Roan, Elvis Costello, and Aerosmith signed an open letter calling for an end to the predatory use of AI in the music industry.\n- A man in Denmark was handed an 18-month prison sentence after being found guilty of fraudulently profiting from music streaming royalties.\n- Music streaming platforms have taken steps to clamp down on artificially inflated streams and have advised users on how to avoid the practice.\n- Michael Massel filed a class-action lawsuit against Steak \u2018n Shake alleging the illegal collection, storage, and use of customers\u2019 facial biometric data in violation of BIPA.\n- In his lawsuit, Massel seeks statutory damages of up to $5,000 per violation plus additional costs on behalf of Illinois customers whose biometric information was collected by Steak \u2018n Shake in the past five years.\n- Anthropic said it has taken steps to limit false election information from spreading through its AI tools.\n- OpenAI said it has taken steps to limit false election information from spreading through its AI tools.\n- Google said it has taken steps to limit false election information from spreading through its AI tools.\n- OpenAI announced that it disrupted an Iranian operation seeking to influence the U.S. presidential election.\n- Meta said it removes election content that violates its policies whether it was created by humans or AI.\n- Google said it builds guardrails to ensure a safe and high-quality experience across its generative AI products, including the Gemini consumer app and the developer API.\n- When the prompt was submitted to Meta AI, the product returned a correct response and directed users to an additional resource for further context.\n- Proof reached out to the five companies for comment.\n- GPT-4 acknowledged that its training data may not reflect current events by stating that Trump had not been shot 'as of my knowledge up to October 2021.'\n- The Dutch Data Protection Authority fined Clearview AI \u20ac30.5 million for GDPR violations.\n- The Dutch Data Protection Authority is considering holding Clearview's directors personally liable for the GDPR violations.\n- The Dutch Data Protection Authority warned that continued violations could result in an additional fine of up to \u20ac5.1 million.\n- The Dutch Data Protection Authority said it is looking for ways to ensure that Clearview stops the violations.\n- Clearview publicly stated that the Dutch DPA's decision is unlawful, devoid of due process, and unenforceable.\n- Police announced they were considering opening an investigation into Telegram over its role in enabling fake pornographic images of children to be distributed.\n- Politicians and the police promised to investigate the crimes and bring the perpetrators to justice.\n- The government vowed to bring in stricter punishments for those involved in creating and sharing deepfake images.\n- The president called for young men to be better educated about the issue.\n- The government said it would increase criminal sentences for those who create and share deepfake images.\n- The government said it would also punish those who view the pornography.\n- Women's rights activists started to scour Telegram for offending chatrooms.\n- Women's rights activists followed leads uncovered during their searches of Telegram.\n- Activists identified more than 500 schools and universities as targets of deepfake abuse.\n- Park Jihyun led calls for the government to regulate or ban the Telegram app in South Korea.\n- The Advocacy Centre for Online Sexual Abuse Victims (ACOSAV) counselled 238 teenage victims in the first eight months of the year.\n- ACOSAV staff worked around the clock to respond to the surge in victim calls.\n- The centre tracked down harmful content on platforms.\n- The centre worked with online platforms to have harmful content taken down.\n- Telegram removed some content after requests from the centre.\n- Telegram said its moderators proactively monitor public parts of the app, use AI tools, and accept user reports to remove millions of pieces of content each day that breach its terms of service.\n- Scores of women removed their photos from social media.\n- Scores of women deactivated their social media accounts altogether.\n- Many offending chatrooms were closed down after they were exposed.\n- Bernklau's lawyer sent a cease-and-desist demand to Microsoft.\n- Microsoft promised the data protection officer of the Free State of Bavaria that the fake content would be deleted.\n- The fake content was deleted for three days.\n- Bernklau's name was blocked from Copilot.\n- Data protection officers achieved a short-term removal of the offending misinformation.\n- Microsoft investigated this report.\n- Microsoft stated it had taken appropriate and immediate action to address the report.\n- Microsoft said it continuously incorporates user feedback and rolls out updates to improve Copilot's responses.\n- Microsoft provides users with explicit notice that they are interacting with an AI system.\n- Microsoft advises users to check the links to source materials to learn more.\n- Microsoft encouraged people to share feedback or report any issues via a form or the 'feedback' button.\n- Bernklau went public with his story about the false accusations.\n- The public prosecutor's office rejected criminal charges in two instances.\n- Austria-based privacy group Noyb filed a GDPR complaint accusing OpenAI of providing false information and asking the Austrian data protection authority to investigate how OpenAI processes data.\n- Georgia resident Mark Walters sued OpenAI for defamation over false information provided by its ChatGPT service.\n- A judge rejected OpenAI's motion to dismiss the defamation claim filed by Mark Walters.\n- The Southern Environmental Law Center sent a letter to the Shelby County Health Department asking regulators to investigate xAI's unpermitted use of turbines and the pollution they create.\n- The Southern Environmental Law Center sent a letter to the regional office of the Environmental Protection Agency asking regulators to investigate xAI's unpermitted use of turbines and the pollution they create.\n- Memphis Light, Gas and Water began providing 50 megawatts of power to xAI at the beginning of August.\n- Memphis Light, Gas and Water installed additional circuit breakers to support xAI's power needs.\n- Memphis Light, Gas and Water started making improvements to transmission lines in the area to prepare for xAI's added power consumption.\n- The Mozilla Foundation published an analysis of 11 romance and companion chatbots to investigate their security and privacy issues.\n- Mozilla previously published an analysis of Replika in early 2023.\n- EVA AI said it will review its password policies after researchers identified potential vulnerabilities.\n- Replika's CEO Eugenia Kuyda issued a lengthy statement disputing Mozilla's findings and asserting that the company does not use conversational data for advertising or marketing purposes.\n- A government spokeswoman said vendors are required by law to be transparent about their ticket prices.\n- The government said it will bring in protections to stop people being ripped off by touts.\n- The Advertising Standards Authority encouraged anyone with concerns to get in touch with them.\n- The Advertising Standards Authority said it would carefully assess whether there were any grounds for action.\n- The article states that consumer rights and unfair trading regulations can be enforced to tackle the issue.\n- The band posted a statement warning fans about counterfeit and void tickets appearing on the secondary market.\n- The band posted that tickets can only be resold at face value via TicketmasterUK and Twickets.\n- Ticketmaster told the Manchester Evening News that it does not set ticket prices.\n- Ticketmaster referred people to a page on its website explaining how ticket prices are set and labeled.\n- Viagogo's global managing director defended the website, saying resale is legal in the UK and that fans are protected by a guarantee that they will receive their tickets in time for the event or their money back.\n- A class action lawsuit was filed in 2020 on behalf of 35 adults and children who were denied benefits.\n- U.S. District Court Judge Waverly Crenshaw Jr. ruled that thousands of Tennesseans were illegally denied Medicaid and other benefits.\n- Advocacy groups asked the Federal Trade Commission to investigate Deloitte\u2019s practices in Texas.\n- Microsoft issued a public statement asserting that Dynamics 365 Field Service does not use AI to recommend individual workers for specific jobs and that customers are solely responsible for using the product in compliance with applicable laws.\n- Microsoft stated that Dynamics 365 Field Service was developed in accordance with its Responsible AI principles and data privacy statement.\n- Microsoft published a blog post saying the feature is intended to help dispatchers or admins and is not intended for use in making, and should not be used to make, decisions that affect the employment of an employee.\n- Microsoft made a follow-up phone call disagreeing with the characterization of the system as one that performs surveillance.\n- Microsoft sent an additional emailed statement asserting its stance against employee surveillance and that Dynamics 365 Field Service is not an employee surveillance tool.\n- Microsoft encourages dispatchers to review AI-generated work orders to ensure accuracy.\n- Some facial recognition providers asked their own staffers to send in face-masked selfies.\n- Some facial recognition providers edited masks on top of the photos they already have.\n- The US National Institute of Standards and Technology plans to test facial recognition algorithms by digitally adding masks to photos.\n- The data set's page put out a public call asking if anyone knew how to retrieve the expired Instagram photos.\n- Facebook said it is continuing to investigate third parties collecting or using photos posted by its users without their consent.\n- Several major universities stopped using AI detection tools provided by Turnitin due to accuracy concerns.\n- Vanderbilt University disabled Turnitin's AI detection tool for the foreseeable future.\n- Northwestern University turned Turnitin's AI detector off.\n- Northwestern University advised against using Turnitin's AI detector to check students' work.\n- The University of Texas stopped using Turnitin's AI detection tool over accuracy concerns.\n- OpenAI scrapped its own AI text detector tool due to low rates of accuracy.\n- OpenAI warned educators in its back-to-school guide that AI content detectors are not reliable.\n- Turnitin issued a statement saying its AI detection software was not designed to be used to punish students and is not meant to replace educators' professional discretion.\n- Universities said they are going back to the drawing board to figure out how to stop students using ChatGPT to write essays after giving up on AI detectors.\n- Turnitin posted a notice on its website advising that the results of its AI detection tool should not be used to accuse students of cheating.\n- Turnitin committed to continuing to educate educators on how to interpret and use the detector's data.\n- The Washington Post tested Turnitin\u2019s AI detection tool by evaluating 16 sample essays with the help of five high school students to assess its accuracy.\n- Parkhurst updated its SafeParks website instructing residents not to feed beggars or vagrants and not to give them money.\n- Television anchor and producer Doreen Morris opened a criminal lawsuit against a suburban resident in Morningside, Sandton.\n- Civil rights organizations Right2Know and the LCII Foundation initiated legal pushback against the Vumacam project, arguing it is not compliant with POPIA.\n- Vumacam asserted that its product is POPIA compliant and that its data procedures adhere to European data protection laws like the GDPR.\n- Vumacam stated it 'engages' with the police and that any data requested by the South African Police Service requires a subpoena.\n- Vumacam retrieved CCTV footage near the site of an alleged hit-and-run to assist an insurance company investigation, which showed the claimant had sped through a roadblock.\n- Vumacam CEO Ricky Croock responded to inquiries about the CCTV surveillance network but refused to go on the record.\n- Vumacam stated it is not currently using BriefCam's facial recognition option.\n- Viggle's spokesperson emailed TechCrunch to backtrack on CEO Hang Chu's statement about whether Viggle uses YouTube data for training.\n- Viggle's spokesperson told TechCrunch that Hang/Viggle was unable to share details of their training data.\n- Viggle's spokesperson later confirmed in a reply that Viggle leverages a variety of public sources, including YouTube, to generate AI content.\n- Viggle stated that its training data has been carefully curated and refined to ensure compliance with all terms of service.\n- Viggle stated it is committed to respecting platform terms by avoiding massive amounts of downloads and any other actions that would involve unauthorized video downloads.\n- TechCrunch reached out to spokespeople for YouTube and Google for comment after the interview.\n- Google scrambled to fix the AI Overviews issues in Google Search.\n- Google told Digital Trends that it is working to fix the Pixel Studio issues that allow generation of offensive and copyrighted content.\n- Google stated that it has clear policies and Terms of Service on what kinds of content are allowed and builds guardrails to prevent abuse.\n- Google said it is committed to continually enhancing and refining the safeguards and guardrails for its generative AI tools.\n- Uber started offering free rides out of the city.\n- Uber said it would refund the cost of rides that had been affected by the higher fares.\n- Uber apologised in a blog post, saying it was truly sorry and that not stopping surge pricing immediately was the wrong decision.\n- Uber later apologised for a senior executive's suggestion and said the executive's views had no relation to the company's official views or approach.\n- Uber suspended operations in Delhi while it improved the recruitment process after a driver was arrested in relation to the rape of a passenger.\n- Uber reached an agreement with regulators in the US to restrict surge pricing during national emergencies.\n- Uber encouraged drivers to come online to mitigate the surge in demand.\n- Uber immediately lowered and capped surge pricing to continue incentivising driver-partners while making rides more affordable for those stranded.\n- Uber announced that any rider charged an additional amount above that surge cap for the full duration of the outage will be auto-refunded within the next 48 hours.\n- Premier Dominic Perrottet apologised for the communications glitch and flagged a fare-free day to compensate frustrated commuters.\n- Engineers replaced the failed component in the IT communications system after working through the night.\n- Transport for NSW and engineers launched an investigation into why the key component failed and how to prevent a recurrence.\n- Police and federal agencies are responding to the breach of personal data linked to the facial recognition scheme.\n- The New South Wales police force confirmed it was investigating the data breach.\n- New South Wales police, working alongside federal and state agencies, arrested an unnamed 46-year-old man in a Sydney suburb who is expected to be charged with blackmail.\n- Outabox said it is aware of and responding to a cyber incident potentially involving some personal information.\n- Outabox communicated with a group of its clients to inform them and outline its strategy to respond to the incident.\n- Clubs that used Outabox\u2019s technology posted announcements about the incident.\n- Clubs that used Outabox\u2019s technology notified their clients about the breach.\n- The Have I Been Outaboxed website encourages anybody whose data is included in the breach to contact venues and ask that they remove Outabox\u2019s system.\n- IGT said it would work with Outabox and law enforcement in response to the incident.\n- Outabox urged people not to repeat false and reputationally damaging misinformation about the incident.\n- Meta took down the public Galactica demo.\n- Meta issued a public tweet thanking users for feedback and announcing that it had paused the Galactica demo.\n- Meta made the Galactica models available to researchers so they could learn more about the work and reproduce results in the paper.\n- Lionsgate recalled the trailer for 'Megalopolis.'\n- Lionsgate issued a public apology to the critics involved and to Francis Ford Coppola and American Zoetrope.\n- Officials rescinded the incorrect helmet fine in the Kerala case after a thorough review.\n- Authorities introduced additional oversight of AI camera enforcement.\n- Enforcement officers now review images before fines are finalised.\n- Residents, including Randol White, reached out to Waymo about the honking issue.\n- Waymo sent a statement to ABC7 News acknowledging that its vehicles may briefly honk while navigating parking lots.\n- Waymo identified the cause of the vehicles briefly honking while navigating parking lots.\n- Waymo is in the process of implementing a fix for the honking issue.\n- OpenAI took down accounts of an Iranian group identified as Storm-2035 for using ChatGPT to generate influence content.\n- OpenAI conducted an investigation that showed ChatGPT was used to generate long-form articles and shorter social media comments.\n- OpenAI banned the accounts from using its services.\n- OpenAI continues to monitor activities for any further attempts to violate its policies.\n- In May, OpenAI said it had disrupted five covert influence operations that sought to use its models for deceptive activity across the internet.\n- Fifty-six local residents filed a petition in Telangana\u2019s High Court against Microsoft and other parties alleging illegal land occupation and pollution.\n- The petitioners requested that the court direct Microsoft to stop the alleged illegal activities while the case was pending.\n- On July 1, Microsoft representatives informed the Telangana government that the company had some problems with the local panchayat.\n- The state IT minister tasked the local administrator with resolving the issues by evening.\n- The state IT minister urged Microsoft to complete construction of the data center by 2025.\n- On May 2, a judge rejected the petitioners' request that the court direct Microsoft to stop the alleged illegal activities while the case was pending.\n- In September 2023, Microsoft responded in court and asked for the petition to be dismissed.\n- Microsoft denied in its court response that it illegally occupied any land or polluted Tungakunta Lake.\n- The Telangana government is adding electricity sub-stations to aid Microsoft\u2019s construction.\n- The Telangana government is adding flood-water canals to aid Microsoft\u2019s construction.\n- A new 220-kV grid supply line has been planned to meet the power requirements of the data center.\n- Irrigation officers have been visiting the site regularly to ensure the construction takes place within permissible bounds.\n- Microsoft told Rest of World that it has complied with all local requirements and has the necessary permits from the relevant administrative departments.\n- Telangana\u2019s special chief secretary publicly stated that Microsoft had obtained all statutory permissions and that there was no error or oversight on Microsoft\u2019s part.\n- X took down the Grok summary post about Trump's dentures, and the summary's link now leads to a blank page.\n- Migrant rights organizations raised the app's issues with U.S. Customs and Border Protection.\n- U.S. Customs and Border Protection issued a statement denying that the CBP One app uses facial recognition technology.\n- CBP stated that the app requires users to take a live photo each time they access the application as a security feature to prevent bad actors.\n- Some migrants resorted to using construction-site lights to take brighter photos when uploading images to the app.\n- Advocates attempted for up to an hour and a half to get migrants' photographs recognized on the app.\n- Pelczar promised to correct the false quotes and issue apologies stating they were misstatements.\n- The Cody Enterprise launched a full review of all stories Pelczar had written during his two months at the paper.\n- Pelczar resigned from the Cody Enterprise.\n- The publisher and editor of the Cody Enterprise apologized for the false quotes and their failure to catch the AI-generated content.\n- The publisher and editor vowed to take steps to ensure the incident never happens again.\n- Megan Barton wrote an editorial about the incident.\n- The Cody Enterprise implemented a system to recognize AI-generated stories.\n- The Cody Enterprise said it will have longer conversations about how AI-generated stories are not acceptable.\n- Editor Chris Bacon plans to implement an AI policy by the end of the week.\n- Chris Bacon said AI use and policies will be a pre-employment topic of discussion.\n- Sports Illustrated fired the company that produced the AI-generated product-review articles for its website.\n- Two journalists sued OpenAI and Microsoft for copyright infringement over the companies' use of published journalism to train their large-language models.\n- The journalists' suit was folded into a class action brought by nonfiction and fiction writers represented by the Authors Guild.\n- AI firms involved in the alleged use of published journalism to train their models denied any wrongdoing.\n- A reporter at the Cody Enterprise resigned after fabricated quotes in his stories were discovered to have stemmed from his use of AI.\n- A rival paper spotted fabricated quotes in the reporter's stories, which led to the discovery that the fabrications originated from his use of AI.\n- The Department of Homeland Security sent an emailed statement saying it uses various forms of technology under established authorities and committing to protecting the privacy, civil rights, and civil liberties of individuals subject to its technology.\n- DHS publicly stated that it does not collect facial images from minors under 14 and has no current plans to do so for either operational or research purposes.\n- OBIM referred MIT Technology Review to DHS\u2019s main press office when asked for additional information.\n- MIT Technology Review issued a correction and updated its story to remove the earlier claim that DHS had plans to collect facial data from children under 14 and to reflect DHS's additional comments and clarifications.\n- Google suspended its Gemini text-to-image tool after it produced ahistorical images.\n- Lawmakers introduced legislation to create legal remedies for victims of nonconsensual AI-generated images.\n- Five US secretaries of state called on Elon Musk to fix the Grok chatbot after it spread misinformation.\n- The Philippine Competition Commission imposed a P9 million fine on Grab for failing to refund customers after a reimbursement order.\n- The anti-trust watchdog ordered Grab to refund P5.05 million for overcharges.\n- The anti-trust watchdog ordered Grab to refund P14.15 million for violation of voluntary commitments in 2019.\n- The anti-trust watchdog ordered Grab to refund P6.25 million for pricing issues in 2020.\n- Meta broadened the cross-check program to include General Secondary Review (GSR), elevating posts for secondary review based on content rather than user identity.\n- Meta formally requested an advisory opinion from the Oversight Board on its cross-check program.\n- The Oversight Board launched an investigation into Meta's cross-check program and delivered a 57-page advisory opinion.\n- Meta provided the Oversight Board with limited aggregate data about entities on the cross-check lists during the board's fact-finding process.\n- Meta requested and received an extra-long 90-day period to consider and respond to the Oversight Board's recommendations.\n- Meta stated via Nick Clegg that it had already made changes to the cross-check program and committed to sharing more details within 90 days.\n- The Oversight Board issued 32 recommendations to Meta addressing the design, transparency, and auditing of the cross-check program.\n- The Oversight Board recommended that Meta develop much stronger criteria for which accounts should be eligible for Early Response Secondary Review (ERSR).\n- The Oversight Board recommended that Meta make its ERSR eligibility criteria public.\n- The Oversight Board recommended that Meta allow individuals to proactively apply for inclusion in the ERSR program.\n- The Oversight Board recommended that Meta require anyone included in ERSR to review the community standards and agree to uphold them.\n- The Oversight Board recommended that Meta proactively communicate changes to its community standards so users know how to comply.\n- The Oversight Board recommended that Meta visually communicate an account's ERSR status to users.\n- The Oversight Board recommended that Meta notify users who report a post when the reported account has special protections under ERSR.\n- The Oversight Board recommended that Meta build greater staffing capacity to ensure posts flagged for General Secondary Review (GSR) are actually reviewed.\n- The Oversight Board requested that Meta shift funding resources to support adequate review capacity for GSR.\n- Facebook is trying to phase out the practice of whitelisting high-profile users from content enforcement rules.\n- Facebook set a goal to remove total immunity for 'high severity' violations of its rules in the first half of this year.\n- Facebook conducted a 2019 audit that showed some 45 teams throughout the company were involved in the whitelisting process.\n- A 2019 review of the XCheck program revealed that the program made mistakes and wrongly took enforcement actions against high-profile users.\n- Microsoft is working with Michael Bargury to address the vulnerabilities he identified in Copilot.\n- OpenAI published a technical document outlining test results and the risks associated with GPT-4o's hyperrealistic voice.\n- A security researcher downloaded the app and checked where it was sending users' photos.\n- Forbes examined hosting records and confirmed that FaceApp.io servers were based in Amazon data centers in the U.S.\n- Forbes contacted FaceApp founder Yaroslav Goncahrov.\n- FaceApp founder Yaroslav Goncahrov provided a public statement responding to the privacy concerns.\n- FaceApp stated that it only uploads a photo selected by a user for editing and never transfers any other images from the phone to the cloud.\n- FaceApp stated that most uploaded images are deleted from its servers within 48 hours of the upload date.\n- FaceApp said users can request that all user data be deleted.\n- FaceApp instructed users to request data deletion by going to settings, then support, selecting 'report a bug', and using the word 'privacy' in the subject line.\n- FaceApp stated that it does not sell or share any user data with any third parties.\n- The article advised that users can delete the app to remove its access to photos.\n- The article advised that users can change app permissions in their iPhone or Android settings to restrict what data the app can access.\n- FaceApp's founder and CEO issued a public apology for the issue.\n- FaceApp renamed the 'Hot' filter to 'Spark' to exclude any positive connotation associated with it.\n- FaceApp stated it is working on a complete fix that should arrive soon.\n- OpenAI released the GPT-4o system card that details the model's limitations and safety testing procedures.\n- OpenAI has safeguards in place that prevent the model from unintentionally imitating users' voices.\n- OpenAI developed ways to prevent unauthorized voice generation completely.\n- OpenAI discourages the model from synthesizing sound effects and music by using special instructions.\n- The creators of DeepNude withdrew the service.\n- The creators of DeepNude offered refunds to users.\n- The creators of DeepNude acknowledged that the tool was very likely to be misused.\n- The BBC contacted the company behind DeepSukebe for comment.\n- MP Maria Miller called for a parliamentary debate on whether digitally generated nude images generated without consent should be banned.\n- MP Maria Miller called for the issue of digitally generated nude images to be included in the forthcoming Online Safety Bill.\n- MP Maria Miller called for making the distribution of sexual images online without consent a sexual offence.\n- Campaign group Cease called for nudification tools to be addressed in the Online Safety Bill.\n- Campaign group Cease called for porn sites to be forced to proactively block uploads of such images.\n- Each AI-generated article was labeled with a statement that it was generated by Cosmos's custom AI service.\n- Cosmos had all generated content fact-checked by a trained science communicator.\n- Cosmos had all generated content edited by its publishing team.\n- CSIRO Publishing issued a statement dismissing concerns that the experiment involved training OpenAI's GPT-4 model on Cosmos contributors' articles.\n- CSIRO Publishing placed the AI experiment under continual review.\n- CSIRO Publishing said the review could involve testing changes to how the AI tool is programmed.\n- CSIRO Publishing said the review could involve testing changes to how the AI tool is used.\n- CSIRO Publishing said the review could determine whether further usage or development of the tool will continue after the end of the project.\n- Cosmos has not published any AI-generated articles since the end of July.\n- Cosmos's acting editor referred media questions about the project to CSIRO Publishing.\n- The Walkley Foundation said it is in ongoing conversation with CSIRO about the project.\n- The Walkley Foundation said it will monitor compliance of the Meta Australian News Fund grant until its conclusion in February 2025.\n- CSIRO assured the Walkley Foundation that it will honour and pay copyright holders as required.\n- The news story was updated to reflect an additional statement from the Walkley Foundation.\n- The Cook County State\u2019s Attorney\u2019s office withdrew all ShotSpotter evidence against Michael Williams.\n- A ShotSpotter analyst manually overrode the system's algorithms and reclassified the 11:46 p.m. sound as a gunshot.\n- ShotSpotter issued a forensic report that included a map and GPS coordinates and updated the address to be closer to the originally identified GPS coordinates.\n- Rochester police contacted ShotSpotter requesting additional analysis, after which a ShotSpotter analyst concluded there had been four gunshots.\n- After Chicago police contacted ShotSpotter following the Godinez incident, a ShotSpotter analyst reanalyzed the audio files and identified five additional gunshots.\n- A jury acquitted Silvon Simmons of attempted murder, and a judge overturned his conviction for possession of a gun, citing ShotSpotter's unreliability.\n- Several customers dropped ShotSpotter, citing too many false alarms and a lack of return on investment.\n- Community and civil rights groups in Chicago launched a campaign calling on city officials to drop ShotSpotter.\n- ShotSpotter representatives publicly defended and disputed criticisms of their technology in communications with Motherboard.\n- Prosecutors requested dismissal of Michael Williams' case, saying they had insufficient evidence.\n- A judge dismissed the case against Michael Williams at the request of prosecutors.\n- Williams' attorney subpoenaed ShotSpotter for the company\u2019s correspondence with state\u2019s attorneys.\n- The judge agreed to schedule a hearing about whether to release ShotSpotter\u2019s operating protocol and other documents the company wants to keep secret.\n- ShotSpotter provided The Associated Press with a copy of the full real-time alert related to the Chicago incident.\n- ShotSpotter provided The Associated Press with additional court records showing that a judge later reconsidered admissibility of ShotSpotter evidence in a prior case.\n- ShotSpotter provided statements in response to questions submitted by The Associated Press for the article.\n- Cities including Charlotte and San Antonio ended their ShotSpotter contracts after false alerts and lack of alerts.\n- In Fall River, Massachusetts, ShotSpotter turned off its system after it reportedly worked less than 50% of the time and missed all seven shots in a downtown murder.\n- The Fresno public school district ended its ShotSpotter contract after finding it too costly and amid community concerns.\n- Judges in a number of cases have thrown out or excluded ShotSpotter evidence.\n- In June 2022, ShotSpotter stopped showing the algorithm's confidence rating to human reviewers.\n- ShotSpotter issued a statement to the Associated Press asserting that the human review process provides a positive check on the algorithm.\n- ShotSpotter argued in court for more than a year that the operations document was a trade secret.\n- The operations document was released from a protective order in a Chicago court case.\n- A judge dismissed the murder case against Michael Williams due to insufficient evidence.\n- ShotSpotter told the Associated Press that it has other comprehensive training and operational materials that it is keeping confidential as trade secrets.\n- The New York City comptroller recommended that the NYPD conduct a thorough evaluation of ShotSpotter before renewing its contract.\n- The NYPD stated that it will continue to have discussions with ShotSpotter to enhance the performance and evaluation of the technology.\n- The NYPD provided a comprehensive written response to the audit's findings and recommendations, which was included in the report.\n- ShotSpotter's parent company, SoundThinking, said it is reviewing the comptroller's report.\n- Chris Mould asked someone at the festival to confirm whether the publicity images were generated by AI.\n- Chris Mould emailed the festival to withdraw from the event after AI use was confirmed.\n- Nicola Solomon, chief executive of The Society of Authors, wrote to festival director Syima Aslam to air her concerns about the use of AI-generated images.\n- The festival director provided a constructive response to the Society of Authors and invited them to discuss and engage further on the issue.\n- The festival stated that it routinely commissions and employs artists of all varieties and pays the market rate for all services.\n- The festival said it had used a small, local commercial design agency to work on this year's campaign.\n- The festival acknowledged that it should have been more explicit about the use of AI tools and the potential issues that this entailed.\n- The University of Pittsburgh paused its robot delivery program with Starship.\n- The school and Starship pulled the robots from the street for further review.\n- Starship reviewed footage of the incident.\n- Starship sent a public statement confirming that Emily was able to access passage onto the sidewalk.\n- Jisuk Mok filed a report with the Frisco Police Department.\n- Jisuk Mok filed a claim with her insurance company.\n- Jisuk Mok reached out to the city of Frisco with questions about the accident.\n- Jisuk Mok contacted Starship and was told there was video of the accident and that the company would send it to her.\n- Starship Technologies told Mok they did not want to release the video and asserted that the video was their property.\n- NBC 5 Responds filed an open records request that revealed another accident at the same intersection.\n- NBC 5 Responds contacted both the city of Frisco and Starship Technologies asking about the accidents and why the robots did not have a phone number listed.\n- Starship Technologies provided an emailed response to NBC 5 addressing the incident and describing their operations.\n- Starship Technologies moved their robots back to university campuses.\n- Starship Technologies pulled out of Frisco on August 7.\n- Starship Technologies agreed to pay more than $2,600 for the damages to Mok's car.\n- The city of Frisco told NBC 5 that Starship had deployed 35 personal delivery devices and spent ten weeks testing in west Frisco this summer.\n- Starship Technologies went to retrieve the robot from the canal.\n- Starship Technologies asked that anyone who spots one of its machines swimming should get in touch.\n- Starship Technologies advised that if people see a robot not moving they should not touch it because the company knows the precise location of every robot.\n- Starship Technologies instructed people to email community@starship.xyz with details if they see a robot swimming or in any other odd situation.\n- Starship Technologies said it is investigating the report.\n- The operator who took remote manual control of the robot was given additional training.\n- Starship offered Sottar \u00a350 to replace his cat repellent device.\n- At Sottar's request, Starship set an exclusion zone around his front garden so the robot will avoid driving onto it.\n- Starship Technologies said it is looking into the Milton Keynes incident involving Mr Dawson.\n- Starship Technologies said it is in contact with Mr Dawson regarding the Milton Keynes incident.\n- Starship Technologies said it was looking into the Rushden incident.\n- A passerby and his partner pushed the stuck delivery robot up the icy curb to free it.\n- Mr Dawson shoved and kicked the robot to remove it out of harm's way after it collided with his dog.\n- Mr Dawson went back out to note the robot's serial number or QR code after the collision.\n- He took his dog home to remove it from harm's way.\n- He went back outside to record the robot's serial number or QR code.\n- He shoved the robot onto its side.\n- He pushed the robot back upright, which forced it to retreat to its Co-op branch in Milton Keynes.\n- He drove to the Co-op branch to complain.\n- He summoned the branch manager to complain.\n- The Co-op declined to comment, stating the machines were operated by Starship Technologies.\n- Starship Technologies failed to respond to requests for comment.\n- A passer-by lifted the robot onto the roadway.\n- The passer-by notified the emergency center about a 'traffic accident.'\n- The emergency operator said he would notify the police.\n- The police called the passer-by and asked for identification.\n- S Group is currently investigating the event.\n- Airbnb developed a 'trait analyser' software that scours the web to assess users' personalities, trustworthiness, and compatibility to forecast suitability to rent a property.\n- Airbnb's system scans social media, keywords, images, and videos for associations with drugs, alcohol, hate websites, sex work, or pornography and downgrades users' scores accordingly.\n- The machine learning marks down users associated with fake social network profiles or those who have provided false details.\n- The system scans news stories and weights the seriousness of offences to incorporate them into risk assessments.\n- Airbnb combines postings, social connections, employment, and education into a 'person graph' and uses it to calculate guest-host compatibility.\n- Every Airbnb reservation is scored for risk before it is confirmed.\n- Airbnb uses predictive analytics and machine learning to evaluate hundreds of signals to flag and investigate suspicious activity before it happens.\n- The Home Office agreed to stop using the computer algorithm that helped decide visa applications.\n- Use of the controversial algorithm will be suspended on Friday 7 August.\n- The Home Office said it will redesign its processes to make them more streamlined and secure.\n- A redesigned system is expected to be in place by the autumn.\n- Until the new system is in place, the streaming of visa applications will be based on information about the specific person and nationality will not be taken into account.\n- The Joint Council for the Welfare of Immigrants and Foxglove launched a legal challenge against the system.\n- Utah Courts requested a University of Arizona user-testing study of the online dispute resolution system.\n- Utah released a new version of the court summons with a shortened URL for the online dispute resolution system.\n- Utah released a new version of the court summons with a QR code that directs users to the online dispute resolution webpage.\n- Utah released a new version of the court summons that includes a phone number for the court.\n- Action Rent to Own agreed to settlements for less than the original debt.\n- Action Rent to Own offered payment plans under which borrowers pay as little as $10 a month.\n- Action Rent to Own strongly advises clients to log on to the online dispute resolution system.\n- Eticas Consulting and the Ana Bella Foundation conducted and published an audit of the VioG\u00e9n risk assessment system.\n- Spain\u2019s interior ministry stated that the VioG\u00e9n system has been subject to a constant and permanent process of evaluation and improvement since 2007 in collaboration with universities and study centers.\n- Europol and four other EU justice and home affairs agencies developed new Accountability Principles for Artificial Intelligence to hold law enforcement more accountable.\n- The agencies advocated for law enforcement bodies to enter into an AI Accountability Agreement (AAA) and pledge to follow the accountability principles laid out in the agreement.\n- Italy fined Clearview AI \u20ac20 million.\n- A Belgian police watchdog ruled the use of Clearview AI unlawful.\n- Amazon workers filed data access requests under the EU\u2019s GDPR to find out how Amazon uses data on them.\n- An Nvidia spokesperson told 404 Media that the company respects the rights of content creators and asserted its models and research efforts are in full compliance with copyright law in defense of its training practices.\n- A Google spokesperson told 404 Media that Google's previous comments still stand and linked to a Bloomberg article quoting YouTube's CEO saying that using YouTube videos to refine an AI video generator would be a clear violation of YouTube's terms of service.\n- A Netflix spokesperson told 404 Media that Netflix does not have a deal with Nvidia for content ingestion and that Netflix's terms of service do not allow scraping.\n- The creator of the WebVid dataset took the dataset down following a cease-and-desist from Shutterstock.\n- Legislators introduced the AI Foundation Model Transparency Act in December to require companies creating foundational AI models to work with federal agencies to set transparency standards and make certain information publicly available.\n- Legislators introduced the Generative AI Copyright Disclosure Act in April to require dataset makers to submit a sufficiently detailed summary of any copyrighted works used or face fines.\n- Luma CEO Amit Jain emailed The Verge saying the video was created from a user-uploaded image and that the system did not generate the characters.\n- Luma said it uses industry-standard programmatic methods to moderate content.\n- Luma stated that uploading copyrighted content is against its Terms of Service.\n- The Verge updated the story with comments from Luma.\n- Tech Against Terrorism cited a TikTok account that began posting content only after the Southport attack.\n- Tech Against Terrorism reported that the TikTok posts amassed over 57,000 cumulative views on TikTok within hours and suggested that bot networks were actively promoting the material.\n- Logically reported that the hashtag #enoughisenough has been used by some rightwing influencers.\n- A leading counter-extremism thinktank warned there was a risk that the far right could achieve a mobilisation not seen since the English Defence League in the 2010s.\n- Analysts highlighted the use of bots that appeared to be actively promoting Southport-related protest material on social media.\n- Suno introduced proprietary watermarking technology to detect whether a song was created using Suno to help prevent misuse and ensure originality of the content.\n- Suno implemented mechanisms to prevent the AI from generating music with explicit or offensive material.\n- The AI refuses to generate songs that are explicitly violent or hateful.\n- Users can report inappropriate songs by selecting Report and choosing Inappropriate, after which the song is flagged for review.\n- Users can manually request deletion of their generated data and Suno AI will delete that data upon request.\n- Users can delete their Suno AI account via the Account -> Delete Account option, which deactivates the account after confirmation.\n- Users can move songs to Trash and permanently delete songs from their library using the Move to Trash and Delete Permanently options.\n- Parents are advised to make their child's Display Name generic to avoid sharing personal information.\n- Parents are advised to remove identifiable details from their child's Profile Description.\n- Parents are advised to avoid using a real picture as their child's Profile Avatar.\n- Parents are advised to check their child's Suno account periodically.\n- iFixit modified its robots.txt file to specifically block Anthropic\u2019s crawler bots.\n- iFixit CEO Kyle Wiens tweeted publicly calling out Anthropic for making nearly a million requests in 24 hours and tying up iFixit's devops resources.\n- Wiens provided server logs to the reporter showing thousands of requests per minute over several hours.\n- Anthropic responded to inquiries by sending a blog post stating that it uses web crawlers for model development, that its crawling should not be intrusive and aims to respect Crawl-delay, and that opting out requires modifying robots.txt to block ClaudeBot.\n- The Minnesota Secretary of State's office traced the major piece of election misinformation to X's Grok chatbot.\n- Minnesota Secretary of State Steve Simon publicly revealed that his office had traced the misinformation to Grok.\n- Simon\u2019s staff attempted to inform X about the misinformation.\n- When contacted for comment, X's press email replied, \"Busy now, please check back later.\"\n- Fact checks from reputable sources, including Politifact, debunked the claim that Biden's name was permanently on the ballots of those states.\n- Meta published a company blog post acknowledging the incorrect responses from Meta AI about the shooting and attributing them to hallucinations.\n- Meta said it is quickly working to address instances where Meta AI provided incorrect answers, including asserting the event didn\u2019t happen.\n- Meta stated it will continue to address these issues and improve these features as they evolve and as more people share feedback.\n- Google publicly refuted claims that its Search autocomplete feature was censoring results about the assassination attempt.\n- The British Medical Journal uncovered AI-generated 'deepfake' videos of Dr Michael Mosley and others on social media.\n- Meta pledged to investigate the recent spate of TV doctor deepfakes.\n- Meta stated that it does not permit content that intentionally deceives or seeks to defraud others.\n- Meta said it is constantly working to improve detection and enforcement of its policies.\n- Meta encouraged anyone who sees content that might violate its policies to report it so the company can investigate and take action.\n- Users can opt out by opening X's 'Settings and Privacy' page on a computer.\n- Users can go to 'Privacy and Safety' in X's settings.\n- Users can select 'Grok' in the settings.\n- Users can uncheck the box that allows their posts, interactions, inputs, and results with Grok to be used for training and fine-tuning.\n- Users can click a provided link to opt out of X using their data to train Grok.\n- Users can delete their conversation history with Grok by clicking 'Delete conversation history'.\n- European privacy regulators are scrutinizing X's decision to use user data to train Grok for potential violations of data protection rules.\n- Please try your request again later.\n- Google has temporarily blocked requests from your network and the block will expire shortly after those requests stop.\n- If you share your network connection, ask your administrator for help because a different computer using the same IP address may be responsible.\n- Google said it is working on improvements to ensure its Autocomplete systems are more up to date.\n- Google said it connected users with helpful search results and will continue to do so.\n- The incident sparked a Senate investigation into the matter.\n- Sen. Roger Marshall announced he planned to make an official inquiry into Google.\n- The author created and uploaded a YouTube video that presents the deepfake, the parody audio, and the original speech with on-screen yellow text explaining which clips are fake and which are real.\n- Elon Musk clarified that the video was intended as satire.\n- Elon Musk pinned the original creator\u2019s post to his profile.\n- Elon Musk used a pun on his profile to make the point that parody is not a crime.\n- Chris Kohls posted a YouTube video responding to the ordeal.\n- In that YouTube video, Chris Kohls confirmed he used AI to make the fake ad.\n- In that YouTube video, Chris Kohls argued that the manipulated video was obviously parody, with or without a label.\n- Two experts reviewed the fake ad\u2019s audio.\n- Those experts confirmed that much of the ad's audio was generated using AI technology.\n- Mia Ehrenberg, a Harris campaign spokesperson, emailed The Associated Press condemning the video as fake and manipulated.\n- Check Point published a research paper detailing how Bard could be used to create phishing emails, keyloggers, and ransomware.\n- Regulators and law enforcement are working to put a framework around the technology to make sure it is used ethically.\n- Developers are teaching the platforms to decline being used for illegal activities.\n- Artificial intelligence is being used to spot suspicious network traffic and other malicious behavior to boost cybersecurity posture.\n- La Quadrature du Net filed a legal challenge against the experimentation agreement before the Administrative Court of Orl\u00e9ans.\n- La Quadrature du Net lodged a complaint with the CNIL (French data protection authority).\n- The CNIL conducted a one-year investigation into the sound surveillance experiment.\n- Orl\u00e9ans's first deputy mayor publicly defended the experiment, stating the objective was never to identify individuals but to detect situations to respond to them effectively.\n- After being contacted for comment, Gen-3 stopped generating videos that included Mark Wiens' name and the names of several other YouTubers.\n- 404 Media redacted columns containing names of Runway employees from the spreadsheet before publishing it.\n- 404 Media granted the anonymous source in the article anonymity because they feared professional retribution.\n- 404 Media tested Gen-3 by generating videos and images using prompts containing keywords and content based on the spreadsheet to assess whether the model could reproduce creators' styles.\n- Activision required employees to sign up for AI training.\n- Blizzard banned developers from using publicly available generative AI tools.\n- Some studios implemented near-total bans on the use of generative AI tools.\n- Riot Games held an internal town hall in 2023 to discuss AI with its creative department.\n- Riot leadership publicly assured employees that they did not intend to replace anyone with AI.\n- Riot formed teams to explore AI tools that could improve the player experience.\n- Riot committed to being transparent with players about its AI intentions.\n- Blizzard developed a secret internal AI system (reported as 'Blizzard Diffusion') that only select employees can access.\n- Blizzard filed a patent for a machine-learning-based 2D structured image generation system.\n- Riot experimented with creating a custom internal-use-only generative AI in partnership with Vizcom.\n- Activision assured its artists that generative AI would be used only for internal concepts and not to replace them or be used for final game assets.\n- Some workers publicly spoke out about AI use despite fearing retribution.\n- Hollywood writers secured contractual protections limiting AI use in agreements with major TV and movie studios.\n- The Information Commissioner\u2019s Office reprimanded Chelmer Valley High School over its use of facial recognition technology.\n- A letter was sent to parents in March last year with a slip for them to return if they did not want their child to participate in the use of facial recognition technology.\n- The school began obtaining explicit opt-in consent from students in November last year.\n- The school provided a data protection impact assessment (DPIA) to the data watchdog in January this year.\n- Tomato Novel retracted its protocol.\n- Tomato Novel reedited its protocol.\n- Tomato Novel stated that creators are free to terminate the agreement if they have any doubts.\n- Tomato Novel revised the protocol to state that developing AI as an auxiliary tool aims to enhance authors' writing efficiency and reading experience.\n- Tomato Novel revised the protocol to include AI features such as AI naming and AI research to assist authors.\n- The Guangzhou Internet Court ruled that an AI company had infringed the plaintiff's copyright and adaptation rights and should bear relevant civil liability.\n- The New York Times filed a lawsuit against OpenAI and Microsoft over non-transparent data collection used in training their chatbots.\n- Lattice canceled the feature that would let organizations create employee records for AI workers.\n- Lattice posted an update stating it will not further pursue digital workers in the product.\n- CEO Sarah Franklin posted comments on LinkedIn explaining Lattice\u2019s thinking about the feature and saying she was not advocating for the personification of AI.\n- VRChat took all worlds reported to be distributing pirated content offline.\n- VRChat committed to cooperate with requests to remove content that is used without the permission of rights holders.\n- BREIN published a report on January 15, 2024 identifying several pirated streaming worlds within VRChat.\n- Rights groups filed lawsuits alleging copyright infringement occurring within the Metaverse.\n- Meta provides tools that allow players to block other users.\n- Meta provides tools that allow players to report other users.\n- Meta said it will continue to make safety improvements as it learns how people interact in virtual spaces.\n- Meta said it will investigate reports and take action.\n- VRChat said it is working hard to make the platform a safe and welcoming place for everyone.\n- Charities advised parents to check which apps their children are using and, where possible, try them out to assess whether they are appropriate.\n- Charities advised parents to use apps' casting features so a parent can watch their child's VR experience.\n- BBC invited people affected by the issues to share their experiences by emailing haveyoursay@bbc.co.uk or contacting the BBC via WhatsApp or Twitter.\n- Warner Music Group issued a letter to tech companies informing them that they must obtain permission before using their output in the training and development of artificial intelligence.\n- Warner Music Group asserted that companies must secure a license from the company in order to use any creative works owned or controlled by WMG or to link to or ingest such creative works in connection with the creation of datasets, as inputs for any machine learning or AI technologies, or to train or develop any machine learning or AI technologies.\n- Warner Music Group stated that it will take any necessary steps to prevent the infringement or other violations of its artists' and songwriters' creative works and rights.\n- Sony Music sent a letter to over 700 firms questioning whether companies had been using their music without permission and referenced the AI Act.\n- OpenAI deactivated the sound-alike voice used in ChatGPT.\n- Cooper Mortlock sent a cease-and-desist letter to the company using his cloned voice.\n- The company engaged lawyers to respond to the cease-and-desist.\n- The company asserted they did not use AI technology and claimed they were within their rights under the contract.\n- Cooper Mortlock changed the contracts he signs.\n- Google committed to being an active member of the community and to partner closely with local leaders to meaningfully contribute to their priorities.\n- Proof News created a tool to search for creators in the YouTube AI training dataset.\n- The Pile dataset was removed from its official download site.\n- The platform hosting the Books3 dataset took that dataset down.\n- Many authors have sued AI companies for the unauthorized use of their work.\n- Some media companies have recently penned agreements to be paid for use of their work to train AI.\n- Full-time YouTubers regularly patrol for unauthorized use of their work and file takedown notices.\n- Plaintiffs voluntarily dismissed a lawsuit against EleutherAI.\n- Google stated that it has taken action over the years to prevent abusive, unauthorized scraping.\n- Anthropic issued a public statement confirming use of the Pile in its Claude model and referring questions about potential violations of YouTube's terms to the Pile's authors.\n- Salesforce confirmed use of the Pile to build an AI model for academic and research purposes.\n- Salesforce released that AI model for public use in 2022.\n- Amazon agreed to pay a $25 million civil penalty to settle allegations that it violated a child privacy law and misled parents about data deletion practices on its Alexa voice assistant.\n- Arizona Attorney General Kris Mayes filed two new lawsuits against Amazon in the Superior Court of Arizona under state statutes.\n- Arizona is asking the court to stop Amazon from engaging in the allegedly deceptive and anticompetitive practices.\n- Arizona is asking the court to award civil penalties and disgorgement of ill-gotten gains.\n- The Federal Trade Commission filed an antitrust lawsuit against Amazon in June, joined by more than a dozen state attorneys general.\n- The District of Columbia attorney general is seeking to have its antitrust case against Amazon reinstated after it was thrown out.\n- Amazon issued a public statement defending its Prime sign-up and cancellation processes and disputing the lawsuits' characterization of how its businesses work.\n- Robert Hammond instructed Hagens Berman EMEA (through Hagens Berman Sobol Shapiro LLP) and Charles Lyndon to represent him in a collective action against Amazon.\n- Hammond filed an application for a collective proceedings order (CPO) with the Competition Appeal Tribunal on 7 June 2023.\n- Hammond served the claim form on Amazon UK Services Limited.\n- Hammond's legal team sought consent from Amazon for the claim form to be served on Amazon.com Inc, Amazon Core Services Europe S.\u00e0.r.l., and Amazon Services Europe S.\u00e0.r.l.\n- Hammond's legal team pointed Amazon to the Reasoned Order of the President of the Tribunal of 26 May 2021 in Dr. Rachael Kent v Apple Inc. to argue that the UK is the correct place to bring the proceedings.\n- The Italian Competition Authority investigated Amazon's Buy Box practices and found the algorithm to be anticompetitive.\n- The European Commission investigated Amazon's Buy Box algorithm and found it to be anticompetitive.\n- The UK Competition and Markets Authority has opened an investigation into Amazon's \"Buy Box\" algorithm.\n- Amazon publicly committed to the Italian Competition Authority that it would change the Buy Box algorithm in Italy.\n- Amazon and Meta agreed to stop practices that give them an unfair advantage over merchants and customers using their platforms.\n- The Competition and Markets Authority accepted the companies' commitments and closed its investigations into their online marketplaces.\n- Amazon will no longer use data from third-party sellers to give itself a competitive advantage.\n- Amazon agreed to allow sellers to negotiate their own delivery rates with independent delivery services.\n- Amazon agreed to give third-party sellers a fair shot at winning the buy box.\n- Meta will allow competitors of Facebook Marketplace that advertise on Meta platforms to opt out of their data being used to improve Facebook Marketplace.\n- Meta pledged to limit how it uses ad data when developing products.\n- Italy\u2019s antitrust watchdog fined Amazon \u20ac1.13 billion for alleged abuse of market dominance.\n- The Italian antitrust authority said it would impose corrective steps that will be subject to review by a monitoring trustee.\n- Amazon said it would appeal the Italian regulator\u2019s decision.\n- The European Commission said it had cooperated closely with the Italian competition authority within the European Competition Network to ensure consistency with its two ongoing investigations into Amazon\u2019s business practices.\n- Amazon agreed to display two Buy Boxes on its European shopping sites when there is a second competing offer that is materially different in price or delivery speed.\n- The EU can request changes to the Buy Box presentation if the second Buy Box offer is not attracting adequate consumer attention.\n- Amazon agreed not to use non-public data relating to or derived from independent sellers' activities on its marketplace for its retail business, including via automated tools and employees.\n- Amazon agreed not to use pooled or aggregate data from multiple sellers for its retail decisions.\n- Amazon agreed not to use non-public seller data for its private-label business.\n- Amazon agreed to allow sellers to qualify for the Prime badge even if they do not use Fulfillment by Amazon.\n- Amazon agreed not to use information gathered through Prime about the performance or rates of outside logistics providers to benefit Amazon's logistics and delivery business.\n- Amazon has until the summer to implement the agreed-upon changes across its EU shopping sites except in Italy.\n- The agreement implementing these changes lasts between five and seven years.\n- Amazon issued a statement to ProPublica saying the sorting algorithms are designed for big and Prime orders and that the vast majority of items\u20149 out of 10\u2014can ship for free.\n- The article was corrected on September 21, 2016 to fix a mistake that had implied 90 percent of orders rather than 90 percent of items could ship for free.\n- Federal agents seized the 968 Twitter accounts.\n- Federal agents took over the two domain names MLRTR.com and OTANMAIL.com.\n- The Justice Department accused RT of running the bot farm in court documents.\n- X voluntarily suspended the remaining bot accounts identified in the court documents for terms of service violations.\n- The FBI investigated the email address used to register the Namecheap domains and found a Gmail address and an IP address that tied back to Moscow.\n- An unnamed US agency spotted RT developing the bot farm's software and the FBI learned of the bot farm through that agency.\n- The US issued a security advisory on the techniques RT allegedly used to run the bot farm.\n- The U.S. Justice Department initiated scrutiny and examination of the Allegheny Family Screening Tool.\n- Attorneys in the Justice Department's Civil Rights Division urged people to submit formal complaints citing the AP investigation.\n- Justice Department civil rights attorneys spoke with stakeholders in November as part of a broad conversation about how algorithmic tools could exacerbate disparities.\n- Several civil rights complaints were filed in the fall about the Allegheny Family Screening Tool.\n- Robin Frank filed a complaint with the Justice Department in October on behalf of a client with an intellectual disability.\n- Allegheny County updated its algorithm several times and sometimes removed disabilities-related data points.\n- Since the AP investigation was published, Oregon dropped its child welfare algorithm due to racial equity concerns.\n- The White House Office of Science and Technology Policy emphasized the need for more transparency about how government agencies deploy algorithms as part of the AI Bill of Rights.\n- The Justice Department's Civil Rights Division issued guidance to employers warning that using AI tools in hiring could violate the Americans with Disabilities Act.\n- The county stated that hotline workers can always override the tool's recommendations.\n- The Department for Work and Pensions stopped routinely suspending benefit claims flagged by its AI-powered fraud detector.\n- An information commissioner inquiry into algorithms and similar systems used by a sample of 11 local authorities reported that it had not found evidence that claimants were subjected to harms or financial detriment.\n- The Department for Work and Pensions released official figures under freedom of information laws about the system's case-flagging and review outcomes.\n- Hoodline added a small \"AI\" badge to indicate the article was written with the help of LLMs.\n- After being caught, companies usually pretended to be concerned.\n- After being caught, companies typically publicly blamed their AI partner.\n- Pieces of the robot have been collected following the fall.\n- The collected pieces will be analyzed by the company.\n- The Gumi city council announced it is not planning to replace the deceased robot administrator.\n- An AI researcher flagged Bland AI\u2019s bot behavior to WIRED.\n- WIRED ran tests of Bland AI\u2019s technology, including role-play scenarios, to investigate the bot's behavior.\n- WIRED created its own Bland AI account and used the backend developer system to create call scripts and place calls as part of its investigation.\n- Bland AI rate-limits clients to prevent them from sending out spam calls.\n- Bland AI regularly pulls keywords and performs audits of its internal systems to detect anomalous behavior.\n- Bland AI said it will continue to monitor and audit its platform and rate-limit calls.\n- Bland AI said it will work on new technology to help identify and block bad actors.\n- OpenAI paused the particular GPT-4o voice that sounded extremely human and similar to Scarlett Johansson.\n- The US Federal Communications Commission expanded the Telephone Consumer Protection Act to cover robocall scams that use AI voice clones.\n- Meta displays 'AI by Meta' beneath chatbot avatars and shows a 'Messages are generated by AI' disclaimer when users initiate chats.\n- Meta indicates at the onset of a conversation that messages are generated by AI and displays that designation within the chat underneath the AI's name.\n- The VGG Face project did not make the original images available directly and instead provided URLs and associated face detections to avoid distributing copyrighted images.\n- Exposing.ai collected, verified, and geocoded publicly available research citing the VGG Face dataset to show how the training data has proliferated around the world.\n- Microsoft removed the MS-Celeb-1M dataset after receiving criticism.\n- Researchers Adam Harvey and Jules LaPlace investigated the MS-Celeb-1M dataset and identified many ordinary individuals who had not consented to inclusion.\n- AI researchers have increasingly retracted datasets that were scraped from the web.\n- The DukeMTMC dataset was retracted in the same month as MS-Celeb-1M.\n- The study authors selected three commonly cited datasets and traced how each had been copied, used, and repurposed across close to 1,000 papers.\n- NeurIPS includes a checklist of best practices and ethical guidelines for data collection and use.\n- Margaret Mitchell has been experimenting, as part of the BigScience project, with creating data set stewardship organizations to handle curation, maintenance, legal compliance, and removal requests for sensitive data.\n- Laion worked together with Human Rights Watch to address the reported private children's data.\n- Laion removed all the private children's data reported by Human Rights Watch from its datasets.\n- Laion provided a form where users can submit feedback on issues in the dataset.\n- The federal government introduced legislation in June to ban the creation and sharing of deepfake pornography.\n- Police arrested a teenage boy after nude images created by AI using the likeness of about 50 female students were circulated online.\n- The teenage boy arrested in relation to the circulation of AI-generated nude images was later released.\n- OpenAI is aware of Sora's video-generation issues (such as inconsistent physics and frame-to-frame detail loss) and is working to fix them.\n- OpenAI configured ChatGPT to direct users to CanIVote.org when asked certain procedural U.S. election-related questions.\n- OpenAI prohibited the use of its tools for campaigning.\n- OpenAI built safety measures into its products that decline requests to generate images of real people, including political candidates.\n- OpenAI developed partnerships to ensure people using ChatGPT for information about voting get directed to authoritative sources.\n- OpenAI said it is closely monitoring how its technology is being used in the elections context and will continue to evolve its approach.\n- ChatGPT updated its responses over hours or days, changing some incorrect answers to correct ones when the same questions were asked later.\n- Microsoft redirected some election-related prompts to search while it works to improve its tools for the 2024 elections.\n- Google restricted the types of election-related queries for which Gemini will return responses as a precaution in preparation for many elections in 2024.\n- The false claim about a broadcast delay was debunked.\n- CNN quickly denied the claim that its broadcast would be on a 1-2 minute delay.\n- NBC News asked ChatGPT, Copilot, Meta AI, Google\u2019s Gemini, and X\u2019s Grok whether there would be a broadcast delay.\n- An OpenAI representative said ChatGPT was now correctly answering the question initially posed by NBC News.\n- Google\u2019s Gemini refused to answer the questions, deeming them too political.\n- Meta\u2019s AI product answered the questions correctly.\n- X\u2019s Grok answered the questions correctly.\n- Wimbledon corrected some of the AI-generated errors after a user on X pointed them out.\n- Wimbledon said the Catch Me Up system will be assisted by human checks as the system\u2019s capability builds.\n- Wimbledon scrapped AI-powered commentary and captions in its online highlights videos this year.\n- Prosecraft creator Benji Smith took down the Prosecraft website.\n- Benji Smith apologized for the incident.\n- Benji Smith elaborated on his intentions in a blog post.\n- Author Jane Friedman successfully got the fake books removed from her Goodreads page.\n- After Jane Friedman's post went viral, Amazon removed the misleading books from sale.\n- The Center for Investigative Reporting filed a federal lawsuit against OpenAI and Microsoft alleging copyright infringement.\n- The CIR is seeking actual damages and defendants' profits, or statutory damages of no less than $750 per infringed work and $2,500 per DMCA violation.\n- The New York Times filed a lawsuit against Microsoft and OpenAI alleging intellectual property violations and seeking billions of dollars in statutory and actual damages.\n- The Chicago Tribune and seven other newspapers filed a similar lawsuit against OpenAI and Microsoft.\n- A group of prominent U.S. authors sued OpenAI alleging copyright infringement for using their work to train ChatGPT.\n- OpenAI said it is working collaboratively with the news industry and partnering with global news publishers to display their content in ChatGPT, including summaries, quotes, and attribution, to drive traffic back to the original articles.\n- OpenAI and Time announced a multi-year content deal allowing OpenAI to access current and archived Time articles, display Time's content within ChatGPT, and use Time's content to enhance its products and train its models.\n- OpenAI announced a partnership with News Corp. allowing access to current and archived articles from The Wall Street Journal, MarketWatch, Barron's, the New York Post, and other publications.\n- Reddit announced a partnership with OpenAI allowing the company to train its AI models on Reddit content.\n- OpenAI publicly disagreed with The New York Times' characterization of events.\n- Figma temporarily disabled the Make Design feature.\n- Figma identified the issue related to the feature's underlying design systems within hours of seeing the report.\n- Figma committed not to re-enable the Make Design feature until it has completed a full QA pass on the feature's underlying design system.\n- Figma pointed to Dylan Field's tweets as the company's official statement on the matter.\n- Dylan Field publicly clarified that Make Design uses off-the-shelf large language models combined with commissioned systems.\n- Dylan Field acknowledged responsibility for not insisting on a better QA process and for pushing the team to meet the Config deadline.\n- The MegaFace dataset was decommissioned.\n- The MS Celeb-1M dataset was terminated.\n- Researchers Adam Harvey and Jules LaPlace conducted a detailed analysis of the composition of MegaFace and MS Celeb-1M.\n- The European Data Protection Board issued guidance recommending that several elements be considered to assess whether photographs on social media were voluntarily disclosed, including whether images were published by third parties.\n- The MS Celeb database has been deleted.\n- Microsoft said the site that hosted the MS Celeb database has been removed.\n- The Duke MTMC surveillance dataset was taken offline.\n- Stanford's Brainwash dataset was taken offline.\n- One of the authors of the study that used the Brainwash dataset requested the dataset's removal.\n- The UnConstrained College Students (UCCS) dataset was temporarily taken down after metadata was exposed in the Financial Times article.\n- SmugMug said it is actively working to deploy an update to fix the Flickr security vulnerability that allowed private photos to remain accessible.\n- NtechLab deleted the MegaFace dataset after taking part in the MegaFace challenge.\n- More than 200 class-action lawsuits alleging misuse of Illinois residents' biometrics have been filed since 2015.\n- A $35 billion class-action lawsuit was filed against Facebook alleging misuse of facial-recognition technology to tag people in photos.\n- Some of the Illinois lawsuits alleging biometric misuse have been settled.\n- Google restricted its 2018 art-matching selfie feature so that people in Illinois and Texas could not use it.\n- Google disabled the familiar-face recognition feature on Nest security cameras for users in Illinois.\n- The RIAA and a group of record labels filed a lawsuit against Suno in Boston federal court alleging copyright infringement.\n- The RIAA and a group of record labels filed a lawsuit against Udio in New York federal court alleging copyright infringement.\n- The RIAA is seeking damages of up to $150,000 per work, along with other fees, in its lawsuits.\n- In their complaints, the plaintiffs included several examples of AI-generated outputs that they say replicate songs owned by the labels.\n- Suno issued an emailed statement defending its technology as transformative and stating it does not allow user prompts based on specific artists.\n- TikTok temporarily removed music by UMG artists, including Taylor Swift, amid a failure to reach a licensing deal in part due to AI concerns.\n- YouTube announced a new system to remove AI-generated music content at the request of rights holders.\n- Sony Music sent letters to hundreds of tech companies warning them of unauthorized use of copyrighted work.\n- The Artist Rights Alliance published an open letter demanding that AI companies cease using AI to infringe upon and devalue the rights of human artists.\n- Perplexity removed references to its public IP pool from its documentation.\n- Perplexity CEO Aravind Srinivas issued a public statement saying WIRED's questions 'reflect a deep and fundamental misunderstanding of how Perplexity and the Internet work.'\n- Srinivas thanked Forbes editor John Paczkowski and acknowledged that the specific product feature had 'rough edges.'\n- Srinivas agreed that sources should be cited more prominently by Perplexity.\n- Perplexity said it has been working on new publisher engagement products that will be announced soon.\n- Perplexity has been working on revenue-sharing deals with high-quality publishers to align long-term incentives with media companies.\n- Forbes' general counsel sent a letter to Srinivas demanding that Perplexity remove misleading articles.\n- Forbes' general counsel sent a letter to Srinivas demanding that Perplexity repay Forbes for advertising revenue allegedly earned from its copyright infringement.\n- WIRED corrected the record and clarified that the Chula Vista officer did not steal bicycles from a community member's garage.\n- Srinivas said Perplexity will continue improving accuracy and the user experience.\n- A Reddit post warned Archive Of Our Own (AO3) users that their stories might be included in a machine-learning training corpus.\n- Character.AI censors NSFW content within the app using a content filter.\n- Character.AI developers posted a pinned message on the Character.AI subreddit explaining why they would maintain the NSFW policy.\n- The publisher issued a correction clarifying that Character.AI uses its own training model rather than OpenAI\u2019s GPT-3 and stated they regret the error.\n- DDE quickly uncovered a recent copyright abuse by a research group using the DDE Platform and barred that group from using the Platform.\n- Problems with GeoGPT identified during earlier testing have been largely solved.\n- The DDE team will continue to work to further improve the GeoGPT system.\n- DDE has not released GeoGPT and is keeping it out of the public domain.\n- DDE organized and participated in the IUGS-sponsored meeting on Large Language Models in the Geological Sciences on 16 July 2024.\n- A summary of the IUGS meeting and the latest updates to GeoGPT were published and made available at www.iugs.org.\n- DDE has published its statutes, midterm plans, longer-term strategies, intellectual property policies, and minutes of meetings online.\n- DDE stated it will build trust by improving governance and is working to solve communication and governance challenges.\n- DDE signed a memorandum of understanding with Springer Nature this year.\n- DDE is actively looking for more funding.\n- Deborah Raji and Genevieve Fried examined over 130 facial-recognition data sets compiled over 43 years.\n- The article was corrected on Feb 15, 2021 to clarify that the LFW+ dataset, not LFW, relaxed standards around the inclusion of minors.\n- IBM restricted access to the dataset so it could only be accessed by verified researchers.\n- IBM limited the dataset to include only images that were publicly available.\n- IBM provided an opt-out mechanism allowing individuals to remove their images from the dataset.\n- NBC created a tool within its article that lets photographers check whether their Flickr usernames were included in IBM's collection.\n- The author reported the NFT collection to OpenSea through OpenSea's help center.\n- OpenSea stated in an autoresponse that it was actively investigating the reported issue and that responses could take up to a week.\n- The author tweeted at the collection's owner requesting removal of the NFTs.\n- Several other aggrieved individuals also tweeted at the collection's owner.\n- The collection's owner apologized via direct message for not asking for consent.\n- The collection's owner deleted the NFTs that they owned.\n- The collection's creator removed the entire collection from OpenSea.\n- The collection's creator published a public apology on Medium.\n- OpenSea removed a reposted copy of the entire collection before any of the NFTs were sold.\n- OpenSea limited the number of times creators could mint NFTs on the platform.\n- Qing Han's grieving brother and members of her fanbase emailed the NFT marketplace Twinci to request removal of her stolen artwork.\n- Twinci removed the stolen artworks after receiving those emails.\n- Nike filed a trademark lawsuit against reseller StockX over digital items resembling official Nike goods.\n- Herm\u00e8s initiated legal proceedings against an artist who created NFTs called 'MetaBirkins'.\n- Some crypto lending platforms paused all trades during the crypto crash.\n- Perplexity immediately updated its product to more prominently highlight sources after receiving feedback from Forbes.\n- Perplexity sought revenue-sharing partnerships that would pay news publishers a portion of Perplexity\u2019s advertising revenue each time an outlet\u2019s news content is referenced as a source.\n- Perplexity said it is trying to build positive relationships with news publishers to ensure their news content reaches more people.\n- Google made adjustments to its AI-based search product after its public release in response to false information issues.\n- Kanchan Nagar sent a legal notice to the Advertising Standards Council of India regarding the unauthorized use of her likeness in the advertisement.\n- Her legal notice called on the ASCI to amend its advertising code to address the misuse of AI in advertising.\n- She advocated for mandatory consent before using AI-generated images resembling real people.\n- She urged the ASCI to issue public guidelines to curb unethical use of AI in advertising.\n- The emotion-detection capability was discontinued during the tests.\n- No images were stored when the emotion-detection capability was active.\n- The AI analytics detected five serious trespass incidents at two sites.\n- Police used camera footage from Reading station to speed up investigations into bike thefts by pinpointing bikes in the footage.\n- The SiYtE analytics system was deployed at 18 sites to measure people flow and identify issues such as platform crowding and trespass.\n- An AI system used sensor data to detect 'sweating' floors and alerted staff when they needed to be cleaned.\n- New air quality sensors were deployed in the trials to reduce staff time spent manually conducting checks.\n- Karl Ricanek took down the HRT Transgender Dataset and removed it from public availability.\n- Karl Ricanek began denying access to the dataset to anyone who requested it.\n- Ricanek and later publications of the dataset obscured subjects' identities by placing small yellow boxes over the individuals' eyes in subsequent publications and in a 2022 presentation.\n- Os Keyes and Jeanie Austin published an audit of the dataset in Big Data & Society that investigated its origins and problems.\n- Os Keyes reached out to Karl Ricanek to inform him that the dataset was still publicly accessible.\n- Os Keyes and Jeanie Austin obtained UNCW documents, including the Dropbox link and password for the dataset, via public records requests.\n- The website displayed a verification message blocking access and asking users to verify they are legitimate because the system flagged potentially automated behavior.\n- The company instructed parties seeking commercial use of its content to contact crawlpermission@news.co.uk.\n- The company asked users who believe they were misidentified to contact customer support at help@thesun.co.uk.\n- Australian authorities launched an investigation into the distribution of the deepfake images.\n- Victoria Police arrested and released a teenager in relation to the explicit images, pending further inquiries.\n- Bacchus Marsh Grammar offered counseling to affected students.\n- Bacchus Marsh Grammar assisted police with their investigation.\n- The federal government pushed for new laws to impose prison sentences on offenders who create and share images made by AI tools.\n- The Australian government introduced legislation to criminalize the distribution of deepfake pornography nationwide.\n- Victoria State Premier Jacinta Allan issued a public statement condemning the alleged actions and emphasizing laws and respectful-relationships education in schools.\n- The researchers audited the text of the LAION-400M and LAION-2B-en multimodal training datasets.\n- They sampled text from both datasets for analysis.\n- They ran the sampled text through a Natural Language Processing framework calibrated to detect hateful content.\n- They assigned quantitative scores to samples in three categories: \"hateful,\" \"targeted,\" and \"aggressive\".\n- They investigated downstream model effects by applying the larger model to the Chicago Face Dataset and comparing its associations with offensive classes.\n- They urged AI companies to better audit their datasets in-house.\n- They urged AI companies to introduce standardized metrics for measuring hateful content.\n- They urged AI companies to provide transparency into their auditing processes.\n- The Duke MTMC (Multi-Target, Multi-Camera) dataset was ultimately withdrawn due to repeated concerns from human rights organizations about its use by repressive authorities.\n- The Tiny Images dataset was withdrawn in 2020 because of biases, offensive and prejudicial images, and derogatory terminology.\n- The ImageNet dataset was amended between 2009 and 2019 to address repeated criticism around privacy and non-imageable classes.\n- The paper's authors blurred explicit image examples in the supplementary materials after probing the dataset.\n- The researchers hired people to manually label images according to Fitzpatrick skin tones.\n- Each image received three independent labels and was included in the analysis if at least two labels agreed.\n- The researchers combined the BDD100K database with these manual skin-color labels.\n- The researchers fed the categorized faces back into the facial-recognition program to measure its identification accuracy.\n- The researchers ensured the quality of the images (e.g., weather, lighting, distance) was sufficient so that the discrepancy could not be attributed to these variables.\n- The researchers published their study on the preprint site ArXiv.\n- CSAIL removed the 2.2 million image visualization and the full downloadable Tiny Images database from its website.\n- CSAIL took the Tiny Images dataset offline.\n- CSAIL stated the dataset was taken offline so that the offending images and categories can be removed.\n- CSAIL formally withdrew the Tiny Images dataset and announced it will not be put back online.\n- CSAIL urged researchers and developers to stop using the Tiny Images training library.\n- CSAIL urged people to delete any existing copies of the dataset.\n- CSAIL apologized to those who may have been affected by the dataset.\n- Bloomberg confirmed via email that Books3 was used to train the initial model of BloombergGPT.\n- Bloomberg stated that it will not include the Books3 dataset among the data sources used to train future versions of BloombergGPT.\n- EleutherAI stated that it is in the process of creating a version of the Pile that exclusively contains documents licensed for that use.\n- A Danish anti-piracy group issued a takedown notice to The-Eye.eu, which had hosted the Pile.\n- Meta issued a DMCA takedown order against at least one developer who distributed the leaked LLaMA model.\n- Meta required developers to agree to a license before using LLaMA and a new version of the model.\n- The Hugging Face download link for Books3 was deactivated around the time Books3 was mentioned in lawsuits.\n- Meta acknowledged a platform bug on February 14th and apologized for the inconvenience.\n- Meta said it had fixed a few technical issues with its ads platforms.\n- Meta said it was researching a small number of additional reports from advertisers to ensure the best possible results for businesses using its apps.\n- Meta refunded 1-800-D2C for the incident almost a month after it occurred.\n- RC Williams's marketing firm completely halted its use of Advantage Plus in early April.\n- RC Williams's firm reverted to manually buying Facebook and Instagram ads instead of using Advantage Plus.\n- Node Media completely stopped using Advantage Plus for a couple of its clients due to the anomalies.\n- Dr Emily Bender emailed the editor/co-founder of Biharprabha to report the fabricated quote.\n- Biharprabha removed the fabricated quote from the article.\n- Biharprabha published a retraction at the bottom of the article.\n- Biharprabha co-founder Abhishek Bharadwaj admitted in an email that they had prompted Google's Gemini to create the story.\n- The Quint ran the article text through several free AI text-detection tools to confirm it was AI-generated.\n- The Quint reached out to Biharprabha and Google with detailed questions and said it would update the report with their responses.\n- Dr Emily Bender posted on X (Twitter) noting that the LLM had produced her name and a fabricated quote.\n- Adobe issued a public statement on Twitter to clarify its position on the updated terms.\n- Adobe published a dedicated blog post explaining the updated terms, its content access, and review practices.\n- Adobe explained that it requires a limited license to access content to improve its services and protect against abusive content.\n- Adobe described the manual review process that may allow human reviewers to access content if illegal content is suspected.\n- Adobe clarified that it does not train its Firefly AI model using data from consumers.\n- Adobe reiterated that it will never assume ownership of a customer's work.\n- Adobe announced it will make changes to the updated terms and conditions to reflect the clarifications in its blog post.\n- Adobe's content analysis FAQ states that Adobe only performs content analysis on content processed or stored on Adobe's servers and does not analyze content stored locally on users' devices.\n- Databricks fine-tuned Dolly 2.0 exclusively on a new, high-quality human-generated instruction-following dataset crowdsourced among Databricks employees.\n- Human Rights Watch analyzed a portion of the LAION-5B dataset to identify and expose children's photos used without consent.\n- Human Rights Watch published a report and publicly warned about the privacy risks and misuse of children's images in AI training datasets.\n- LAION worked with Human Rights Watch to remove the links to the children's images from the LAION-5B dataset.\n- Perplexity said the Pages feature has \"rough edges\" and that the features will improve with time and feedback.\n- Perplexity agreed that contributing sources should be highlighted more prominently on Pages.\n- Perplexity said it will take that feedback into account as it continues to iterate on the product.\n- The Bridgeton, New Jersey police department posted a Facebook statement on Dec. 27 dismissing the article as entirely false.\n- NewsBreak removed the false Bridgeton article from its app on Dec. 28.\n- NewsBreak removed all five erroneous articles about the charities after learning they were incorrect.\n- NewsBreak added a disclaimer to its homepage in early March warning that its content 'may not always be error-free.'\n- NewsBreak disbanded the limited experiment to aggregate third-party content after it produced ten articles.\n- CEO Jeff Zheng recognized the problem and asked his team to fix it.\n- Patch Media reached a $1.75 million settlement in its lawsuit against NewsBreak.\n- Emmerich Newspapers and NewsBreak reached a settlement in 2021 over alleged copyright infringement.\n- NewsBreak said it is vigorously defending against additional lawsuits.\n- Food to Power complained to NewsBreak in a January 30 email to the company's general customer support address.\n- Harvest912 emailed NewsBreak on January 12 asking it to 'cease and desist' erroneous coverage.\n- NewsBreak provided a link to the original website when responding to Reuters about the inaccurate information.\n- OpenAI told Reuters that its policies prohibited using its technology to mislead people.\n- TikTok said it was planning to offer third parties more access to examine its code and verify the app functions as intended.\n- The firm told the BBC that the technology is still being used in those stores but there are no plans to roll it out more widely.\n- The Southern Co-operative said there were clear signs about the facial recognition system in the stores involved in the trial.\n- The Southern Co-operative stated that no data from the trial had been shared with the police.\n- Privacy International sent an open letter to the retailer questioning the legality of the technology.\n- Privacy International asked whether information from the system was being shared with the police.\n- Big Brother Watch urged the Southern Co-operative to drop the facial recognition cameras immediately.\n- Dave Fanning initiated defamation proceedings over the article.\n- Garrett Cooney BL applied for leave to serve the proceedings outside the jurisdiction on BNN and on Microsoft Corporation.\n- The proceedings were also brought against Microsoft Operations Ireland Ltd (MOIL).\n- Mason Hayes Curran accepted service of the proceedings on behalf of Microsoft Operations Ireland Ltd.\n- Mr Meagher contacted Microsoft regarding the article.\n- The article was removed on October 12, 2023.\n- On November 21 Mr Meagher emailed BNN and the journalist linked to the article requesting information including BNN's registered offices.\n- Mr Cooney's team wrote to Mason Hayes Curran asking who has control over the MSN website and referring to Mr Fanning's distress about the publication.\n- Mason Hayes Curran responded that Microsoft Operations Ireland Ltd is the responsible entity for articles accessible by users in Ireland and that Microsoft Corporation is not relevant to this complaint.\n- The judge granted liberty to serve the proceedings on BNN at the Hong Kong address.\n- The judge adjourned the application to serve Microsoft Corporation in the US for one week to allow the plaintiff to consider that matter.\n- Shaun Thompson has applied for a judicial review of the Metropolitan Police's use of live facial recognition.\n- Big Brother Watch is crowdfunding to support the legal action against the Metropolitan Police.\n- Big Brother Watch has so far raised nearly \u00a35,000 to fund the legal action.\n- The Office of Suicide Prevention is working with the VA AI lead and Chief Technology Officer to develop compliance reviews and monitors.\n- The VA has identified more than 100 programs that are covered by presidential executive orders on AI transparency and accountability.\n- Pro-Israel activists posted counterposts on social media responding to the viral \"All Eyes on Rafah\" image.\n- Instagram removed a post that depicted a Hamas soldier standing over an infant.\n- Bring Them Home Now created an Instagram story urging people to help find hostages with the message \"If your eyes are on Rafah, help us find our hostages\".\n- Facewatch wrote to Sara and acknowledged it had made an error.\n- The Metropolitan Police automatically delete biometric images when there is no match.\n- Police released Shaun Thompson after he provided a copy of his passport.\n- Intelligence for Good alerted WIRED to some of the illicit Eventbrite listings.\n- WIRED alerted Eventbrite to the illicit listings it had identified.\n- Eventbrite investigated the activity and determined it was abnormal misuse of the platform.\n- Eventbrite removed the identified illegal and illicit listings from its platform.\n- Pinterest deleted the 'Usa Best Vcc' account.\n- The UK's Information Commissioner's Office is making enquiries with Microsoft to understand the safeguards in place and the safety of the Recall feature to protect user privacy.\n- A jury awarded Bungie $63,210 in damages.\n- Bungie stated it will continue to protect players against cheats by taking this and future cases all the way to trial.\n- Bungie won $4 million in arbitration on DMCA circumvention claims related to AimJunkies.\n- AimJunkies appealed the $4 million arbitration award after a judge confirmed it.\n- Phoenix Digital founder David Schaefer said he will move to dismiss the jury's verdict.\n- Phoenix Digital said it will appeal the jury's verdict if necessary.\n- Google allows deepfake victims to request the removal of such content from search results through a form.\n- Google reviews only the URLs that victims or their authorized representatives submit in the takedown request form.\n- Google said it is actively working to bring more protections to Search and is building more expansive safeguards to remove the need for known victims to request content removals one-by-one.\n- Google has introduced deduplication measures that can remove reuploaded images that had already been flagged.\n- Google provides a way for victims of real nonconsensual images to request that sexually explicit content does not show up in search results for their names at all.\n- Google\u2019s search features, like panels with selected information, do not allow manipulated media or sexually explicit content.\n- Google\u2019s Play app store forbids apps determined to promote or perpetuate demonstrably misleading or deceptive imagery, videos and/or text.\n- Bing\u2019s AI chatbot Copilot tells users that it cannot show them deepfake porn and that the use of deepfakes is unethical.\n- Microsoft provides a form where victims of nonconsensual intimate imagery (NCII) can report such content appearing in Bing search results.\n- Microsoft clarified in August 2023 that it considers sexually-explicit deepfakes to fall under its NCII policy.\n- Microsoft prohibits NCII on its platforms and services, including the soliciting of NCII or advocating for the production or redistribution of intimate imagery without a victim\u2019s consent.\n- DuckDuckGo pointed users to its contact information for privacy-related requests.\n- Google said it has taken action against violations of its policies.\n- Google said it is using these isolated examples to continue to refine the product.\n- The article was updated on May 23rd to add a statement from a Google spokesperson.\n- Lehrman and his wife contacted an attorney.\n- Lehrman and Sage filed a proposed class action lawsuit against LOVO in New York federal court.\n- The lawsuit seeks to represent other voiceover artists who believe their voices were misappropriated by LOVO.\n- The lawsuit seeks a court order blocking LOVO from continuing to undercut voiceover artists' work.\n- SAG-AFTRA has been advocating for a federal right of publicity law to address use of AI to mimic voices.\n- SAG-AFTRA urged its members not to accept overbroad contract language that hands over rights in perpetuity.\n- Sony Music warned artificial intelligence companies and music streaming platforms not to use the company's content without explicit permission.\n- Sony Music sent letters to more than 700 companies to protect its intellectual property from being used for training AI models.\n- The New York Times sued OpenAI and Microsoft for using its articles to train their large language models.\n- The Chicago Tribune, Orlando Sentinel, South Florida Sun Sentinel, New York Daily News, Mercury News, Denver Post, Orange County Register, and St. Paul Pioneer-Press jointly sued OpenAI and Microsoft for using their copyrighted material.\n- AI companies are striking content licensing deals with publishers and platforms to obtain rights to content for use in generative AI products.\n- Google inked a deal with Reddit worth roughly $60 million per year to license content.\n- OpenAI struck a licensing deal with The Financial Times to obtain rights to its content.\n- OpenAI struck a licensing deal with The Associated Press to obtain rights to its content.\n- Google announced a $1 billion investment in partnership with news publishers to compensate them for content.\n- Microsoft and OpenAI offer customers indemnification for intellectual property and copyright infringement.\n- Hoodline published a disclaimer in late March stating it uses AI to \"support and enhance our editorial processes.\"\n- Hoodline's late-March disclaimer stated it would use a single professional pen name (a pseudonym) instead of multiple team member names for author bylines.\n- On April 9, Hoodline published a letter from CEO Zack Chen responding to questions about the site's undisclosed AI use.\n- Hoodline added a small badge next to each byline indicating that stories are AI-assisted.\n- Hoodline removed the human-sounding author biographies sometime late last year as part of a website refresh.\n- Hoodline changed Nina Singh-Hudson's headshot to a more abstract image in March.\n</mitigation_statements>"}]}}
{"custom_id": "batch_400", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- Slack replied publicly to criticism and reiterated its policies about how it uses customer content for some AI-powered tools.\n- Slack confirmed it does not use customer data to train its paid generative AI tool.\n- Slack said companies or workspace administrators can request via email to have their messages and content opted out of the training dataset.\n- Slack stated that customers can exclude their data from helping train non-generative machine learning models.\n- Slack issued a public statement asserting that it does not build or train its models in such a way that they could learn, memorize, or reproduce customer data.\n- Squarespace rolled out a feature allowing users to opt out of some AI crawling tools via Settings > Website > Crawlers > AI Crawlers.\n- The U.S. Securities and Exchange Commission opened an investigation into Evolv.\n- Evolv updated the language in its 20 February press release after discussion with the NPSA to better reflect the testing process.\n- Evolv amended another claim in the 20 February press release to clarify that the DHS designation is an evaluation of other evidence rather than a new test.\n- Evolv revised its claim to state that an independent company tested its technology against NPSA standards.\n- Evolv said it makes full third-party testing reports available to serious prospective customers for detection performance.\n- Evolv changed the front page of its website and altered its mission wording from 'weapons-free zones' to 'safer experiences'.\n- Evolv issued a public statement expressing regret for any confusion about the capabilities of its technology.\n- Evolv modified its public claims about detection capabilities to say it can detect many types of knives and some explosives.\n- The Securities and Exchange Commission launched an investigation into Evolv.\n- The Federal Trade Commission began looking into Evolv's marketing practices.\n- Proctor High School replaced the Evolv scanners with ten metal detectors after the stabbing incident.\n- A Home Office official said they were seeking to further understand the capabilities of weapons-detection equipment.\n- Evolv told venues about all capabilities and limitations of its scanning system.\n- Evolv gave permission to the National Center for Spectator Sports Safety and Security (NCS4) to test its Evolv Express technology.\n- NCS4 published a public report on the testing of Evolv's technology.\n- NCS4 produced a private report on the testing of Evolv's technology.\n- IPVM obtained NCS4's private report via a Freedom of Information request.\n- IPVM shared the obtained documents with BBC News.\n- NCS4 used the 'track changes' feature to collect feedback on its report.\n- Evolv employees were allowed to make tracked changes to NCS4's private report, including deleting certain sections.\n- Evolv told BBC News that its system had also been tested by the Centre for the Protection of National Infrastructure.\n- Evolv communicated sensitive security information, including the capabilities and limitations of its system, to security professionals so they could make informed decisions.\n- OpenAI plans to provide attribution to the Stack Overflow community within ChatGPT.\n- OpenAI will surface validated technical knowledge from Stack Overflow directly into ChatGPT to give users access to trusted, attributed, accurate technical knowledge and code.\n- Mark Read sent an email to WPP leadership explaining the scam and urging vigilance among staff.\n- Mark Read's email included bullet-pointed guidance advising recipients to look out for red flags such as requests for passports, money transfers, and mentions of secret acquisitions, transactions, or payments.\n- WPP posted a notice on its Contacts landing page stating that its name and those of its agencies have been fraudulently used by third parties.\n- The CNPD temporarily limited Worldcoin\u2019s collection of biometric data through its Orb devices within Portugal effective immediately until the conclusion of an investigation.\n- The CNPD opened an investigation into Worldcoin's data collection practices, initially opened on March 8.\n- Kenya\u2019s government continued to uphold its ban on the Worldcoin project.\n- Legal authorities in Spain told Worldcoin to cease activity in the country.\n- On March 18, Worldcoin released a statement asserting that it operates lawfully in all of the locations in which it is available.\n- On March 22, Worldcoin announced that it would open-source its software.\n- On March 22, Worldcoin announced that it would provide a new \u201cpersonal custody\u201d privacy feature to give users more control over their data.\n- Amazon stated that it investigates any reports of discrimination, harassment, or retaliation and takes appropriate action against anyone found to have violated its policies.\n- Ghaderi met with a representative from Amazon's legal department to explain her concerns about alleged copyright policy violations.\n- In March 2023, Ghaderi complained to HR about her performance review.\n- After a meeting with Styskin and Krishnakumar, Ghaderi again complained to HR that the work context and dynamic had completely shifted.\n- Ghaderi made a formal complaint to HR alleging her demotion related to discrimination and retaliation and reported Styskin's comment about her nationality.\n- HR found that Styskin's remark about her nationality had fallen below Amazon's standards of conduct.\n- HR did not uphold the two other complaints Ghaderi made.\n- Shortly after the HR meeting, Styskin told Ghaderi she would be stripped of her team and demoted.\n- Marcu denied Ghaderi's request to be reinstated and said she should continue reporting to Krishnakumar.\n- In May 2023 Ghaderi took additional protected leave and returned in August 2023.\n- After her August 2023 return, Ghaderi was placed on Amazon's informal \"Focus\" performance review plan.\n- Ghaderi was subsequently given another negative performance appraisal and told the prior career path available to her was no longer on the table.\n- Ghaderi requested to be moved to another team.\n- Her line manager said she was ineligible for a transfer because she was on the Focus plan.\n- Ghaderi was placed on the formal \"Pivot\" plan, which required leaving or complying with performance targets.\n- Ghaderi asked several senior engineers whether the goal to reduce data storage costs by 75 percent in eight workdays was achievable.\n- Ghaderi asked Krishnakumar for evidence to support the performance review claim that she needed to improve on \"earning trust,\" and he could not provide any.\n- Ghaderi complained again to HR about pregnancy discrimination and being given impossible performance tasks.\n- Ghaderi's lawyers filed a lawsuit in Los Angeles state court naming Amazon.com Services, Andrey Styskin, and Mahesh Krishnakumar as defendants.\n- Ghaderi's lawyers demanded a jury trial.\n- A case management conference for the lawsuit has been set for August 14.\n- Ghaderi alleges that she was fired after complaining again to HR.\n- WildBrain publicly declared that Kartoon does not currently hold any rights to Inspector Gadget and that WildBrain does not endorse the Gadget A.I. product.\n- WildBrain requested that Kartoon remove all Inspector Gadget branding from the product and its marketing.\n- WildBrain said it is not providing any further comment at this time.\n- Kartoon issued a public statement asserting that prior communications with WildBrain had confirmed a license to use the Gadget art for the new A.I. initiative.\n- Kartoon stated that it is presently in discussions with WildBrain to resolve the miscommunication.\n- The event organizing company announced the cancellation of the planned AI-script performance on March 9, four days before the premiere.\n- Incognito reported the incident to the police.\n- Incognito reported the incident to its bank.\n- Incognito issued a public statement apologising to Liz Bonnin and her associates for any harm it had inadvertently caused.\n- Incognito issued a public statement to alert people and businesses about the rise of sophisticated AI-generated deceptions.\n- Surya Koppisetti, a senior applied scientist, assessed the voice note and concluded its gaps and recitation speed issues were consistent with AI-generated speech.\n- Michael Keeling, a senior data scientist, assessed the voice note and concluded the steady, monotone artificial background noise indicated manipulation to make it seem more realistic.\n- The person impersonating Liz Bonnin texted Howard Carter to apologise and said she was not handling Bonnin's social media.\n- Liz Bonnin publicly stated on X that she did not agree to any endorsement with the company.\n- Liz Bonnin apologised to Incognito for what the company had gone through.\n- Scotland Yard imposed a ban on Metropolitan Police officers' use of the PimEyes facial recognition tool.\n- Data showing that Metropolitan Police computers visited the PimEyes site 2,337 times was released under Freedom of Information rules.\n- Ford reported the Texas crash to the National Highway Traffic Safety Administration (NHTSA).\n- Ford said it was actively researching all available information about the crash.\n- The National Transportation Safety Board (NTSB) obtained data indicating BlueCruise was active during the crash.\n- The NTSB announced that BlueCruise was active during the crash.\n- The NTSB released a preliminary report on the crash.\n- The NTSB said it is still investigating the crash.\n- The NTSB said a final report is likely to be published within 12 to 24 months.\n- The NHTSA is probing the Texas crash.\n- The NTSB announced it was probing a second fatal crash near Philadelphia where Ford\u2019s driver-assistance system may have been active.\n- Police investigators found no signs of intoxication in the Mustang driver.\n- The National Transportation Safety Board is investigating the March crash near Philadelphia.\n- The National Transportation Safety Board said it will coordinate with the Pennsylvania State Police in the probe.\n- Ford informed the National Highway Traffic Safety Administration about the Philadelphia crash.\n- Ford said it is researching the events of March 3 and collaborating fully with both agencies to understand the facts.\n- The National Highway Traffic Safety Administration is investigating the Mach E crash along Interstate 10 in San Antonio, Texas.\n- The NTSB sent a team to investigate the February 24 crash along Interstate 10 in San Antonio, Texas.\n- In past investigations, the NTSB has examined how the partially automated system functioned.\n- A Reddit user posted the painting online titled 'Walmart selling AI images.'\n- That Reddit user reported that the artwork originated from the company Design Art listed as 'DESIGNART ELEGANT FL.'\n- That same Reddit user discovered and reported that the exact same piece of art was being sold at Bed Bath & Beyond for $51.49.\n- DailyMail.com contacted Walmart, Bed Bath & Beyond, and Design Art for comment.\n- The Daily Dot reported on other suspicious Design Art paintings and highlighted jumbled sponsorship text and glitch-like tires in the 'American Race Car Finishing Line' portrait.\n- Privacy activist group noyb filed a complaint with the Austrian data protection authority alleging that ChatGPT violates GDPR because its information cannot be corrected.\n- The data subject filed a request to have the incorrect date of birth erased.\n- The Register contacted OpenAI to request its opinion on the complaint.\n- Huawei customer service acknowledged the problem with the AI object removal feature.\n- Huawei assured users that the issues will be addressed in upcoming system updates.\n- Hood asked his lawyer to give OpenAI an ultimatum to remove the confabulations from ChatGPT within 28 days or face a lawsuit.\n- OpenAI filtered the false statements about Hood from ChatGPT by the end of April.\n- Hood dropped his legal challenge and resolved the matter out of court.\n- Catholic Answers removed the 'Father Justin' AI priest character from its app after receiving overwhelmingly negative reviews.\n- Catholic Answers announced it will replace the AI priest on its app with a lay character named 'Justin' within a week.\n- Catholic Answers said it will continue to tweak the way its application uses artificial intelligence.\n- Catholic Answers issued a written statement to the Register acknowledging concerns about the character and explaining its decision.\n- Andrea Sorrentino posted an Instagram video showing part of his art process for one of the contested panels.\n- Jingxiong Guo posted sketches to his Instagram page in response to the AI-use claims.\n- The Twitter poster Dibujante de mierda posted experiments using AI art software that produced similar results to the contested panels.\n- Writer and designer James Leech spent time researching the allegations and pored over all three issues to examine the panels.\n- A DC Comics spokesperson stated that DC is looking into the specifics of the situation.\n- The estate sent a cease-and-desist letter demanding that Drake pull down the \u201cTaylor Made Freestyle\u201d in less than 24 hours.\n- The estate demanded written confirmation by noon Pacific that Drake's representatives were expeditiously taking all steps necessary to have the song removed.\n- The estate demanded that Drake provide a detailed explanation of how the sound-alike was created and the persons or company that created it, including all recordings and other data scraped or used.\n- The estate authorized its law firm to pursue all legal remedies, including actions for violation of the estate's copyright, publicity and personality rights, resulting damages, injunctive relief, punitive damages, and attorneys' fees, if Drake did not comply.\n- The estate stated that if Drake complied, it would consider whether an informal negotiation to resolve the matter made sense.\n- The Tesla driver was arrested.\n- The Tesla driver was charged with vehicular homicide.\n- Detectives labeled distracted driving as the cause of the crash.\n- Field and blood tests were conducted on the driver.\n- The driver passed field and blood tests.\n- National Highways conducted a pilot test of the AI speed camera tool involving ten police forces (Durham, Greater Manchester Police, Humberside, Staffordshire, West Mercia, Northamptonshire, Wiltshire, Norfolk, Thames Valley Police and Sussex).\n- South Gloucestershire Council rolled out the new AI technology for surveillance purposes only.\n- South Gloucestershire Council left the cameras in place for 12 hours to monitor and collect data on seatbelt use and mobile phone use by drivers.\n- Captured data and images from the AI speed cameras will be processed and delivered to the police for deliberation over any necessary action.\n- They presented documentary filmmakers at the International Documentary Association\u2019s \u201cGetting Real\u201d conference with a draft of guidelines for how to thoughtfully and ethically use generative AI in their work.\n- They made those draft guidelines public.\n- Morten Blichfeldt Andersen searched the GPT Store for bots built on his employer's textbooks using keyword queries.\n- Morten Blichfeldt Andersen engaged suspicious bots in conversation to try to determine whether they had been trained on Praxis titles.\n- Morten Blichfeldt Andersen reported identified infringing bots to OpenAI.\n- Morten Blichfeldt Andersen filed DMCA takedown notices to OpenAI after finding Praxis textbooks in the GPT Store.\n- Morten Blichfeldt Andersen asked the Danish Rights Alliance to assist in pursuing takedowns.\n- The Danish Rights Alliance filed complaints on behalf of Praxis that led to OpenAI taking down bots.\n- OpenAI removed infringing GPTs that were reported to them and complied with some DMCA takedown requests aimed at its GPT Store.\n- OpenAI proactively screens GPTs using a combination of automated systems, human review, and user reports to find and assess potentially violating GPTs.\n- The Danish Rights Alliance previously filed DMCA takedown notices that temporarily took a collection of over 196,000 books used for generative AI training offline.\n- Patronus AI launched a Copyright Catcher service designed to detect copyrighted text and potentially detect infringement in custom GPTs.\n- Snapchat said it is adding additional programming to prevent My AI from saying it is a real person that could meet with someone in real life.\n- Users can stop sharing their location with Snapchat to prevent My AI from accessing their location, although Snapchat said this may take a little time to take effect.\n- Users can manually delete their previous chats with My AI.\n- Users can ignore the chatbot and continue using the app as they have previously if they do not want to interact with My AI.\n- Users can subscribe to Snapchat+ (Snapchat's premium service) to block or unpin My AI.\n- The store contacted the customer to arrange a meeting about the incident.\n- Foodstuffs apologised to the customer.\n- Foodstuffs said it would contact the customer directly to apologise for what had happened.\n- Foodstuffs said all appropriate staff would receive further training.\n- Foodstuffs said the incident would be reported to the Office of the Privacy Commissioner.\n- The Privacy Commissioner launched an inquiry into Foodstuffs' facial recognition trial to monitor whether it complied with the Privacy Act and was effective in reducing harmful behaviour at those supermarkets.\n- The computer will first grade all constructed responses.\n- A quarter of the constructed responses will be rescored by human graders.\n- When the computer has low confidence in the score it assigned, those responses will be automatically reassigned to a human.\n- Responses that do not fit the computer\u2019s programming, such as those using lots of slang or words in a language other than English, will be automatically reassigned to a human.\n- A random sample of responses will be automatically handed off to humans to check the computer\u2019s work.\n- Every day, testing administrators will review a summary of results to check that they match what is expected.\n- Students and their parents can request a rescore for $50 if they think the computer or the human got it wrong.\n- The rescore fee is waived if the new score is higher than the initial score.\n- Students taking an assessment entirely in Spanish will have their tests graded by a human.\n- Brownsville ISD is incorporating tools with automated scoring into how teachers prepare students for the STAAR test to make sure they are comfortable.\n- A member of the European Parliament filed a lawsuit seeking specific information about how the iBorderCtrl AI algorithm was developed and tested.\n- The parliamentarian took the matter to the European Court of Justice in a lawsuit expected to be heard in 2021.\n- Information requests by the German member of the European Parliament were dismissed, citing the sanctity of trade secrets.\n- The iBorderCtrl three-year project ended in August 2019 after limited border tests.\n- Online publication The Intercept investigated and reported that at least one supporting test of iBorderCtrl involved only 32 people and achieved 75 percent accuracy.\n- She closed the image to remove it from her screen.\n- She began working on new legislation to end nonconsensual, sexually explicit deepfakes.\n- Ocasio-Cortez is leading the House version of the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE) Act of 2024.\n- Sens. Dick Durbin and Lindsey Graham are leading the Senate version of the DEFIANCE Act.\n- Rep. Yvette Clarke reintroduced the DeepFakes Accountability Act in September 2023.\n- The first congressional hearing on deepfakes and disinformation was held in June 2019.\n- Rep. Joe Morelle introduced the Preventing Deepfakes of Intimate Images Act in May 2023.\n- The Congressional Black Caucus launched an AI policy series to examine AI through the lens of race and educate the public on misinformation.\n- Clarke joined the House's new bipartisan task force on AI that includes Ocasio-Cortez and 22 other members.\n- Taylor and her boyfriend called the local police to report the deepfake videos.\n- Taylor spoke out anonymously in the 2023 documentary Another Body.\n- The filmmakers behind Another Body started an organization called #MyImageMyChoice to tackle intimate image abuse.\n- The organizers of #MyImageMyChoice co-hosted a virtual summit on deepfake abuse with legal experts, advocates, and survivors in March.\n- A Pornhub spokesperson said the site bans nonconsensual deepfakes and has teams that review and remove such content once they are made aware of it.\n- Rumman Chowdhury co-published a paper for UNESCO demonstrating code-based examples of how generative AI can be used to create harassing images and plan harassment campaigns.\n- Rep. Nancy Mace introduced a bill criminalizing deepfake porn.\n- Sen. Ben Sasse introduced a bill on deepfakes in December 2018.\n- The Greek Data Protection Authority imposed a fine of \u20ac175,000 on the Ministry of Migration and Asylum.\n- The DPA issued a compliance order requiring the Ministry to fulfil its obligations arising from the GDPR within three months.\n- The European Parliament\u2019s LIBE Committee requested that the DPA provide information on the use of border surveillance technologies.\n- Civil society organisations filed a request regarding the supply and installation of the Hyperion and Centaur systems.\n- Homo Digitalis, the Hellenic League for Human Rights, HIAS Greece, and academic Niovi Vavoula filed a complaint against the Ministry about the use of surveillance systems at asylum seekers\u2019 centres.\n- The UN High Commissioner for Refugees in Greece sent a letter to the DPA concerning the surveillance systems.\n- The staff union of the DPA sought increased financial support for the authority.\n- The DPA repeatedly urged the state to ensure it has the necessary means to apply the relevant provisions of the GDPR.\n- YouTube recommended that children under 13 use YouTube Kids, where automated captions cannot be seen.\n- YouTube said it is continually working to improve automatic captions and reduce errors.\n- Pocket.watch said it is in close and immediate contact with platform partners such as YouTube.\n- Pocket.watch said it is working with platform partners to update any incorrect video captions.\n- Trint said it will add the particular misspelled slur that appeared in the transcript to its profanity filter list.\n- KhudaBukhsh and his collaborators devised and tested systems to fix taboo words in transcripts.\n- KhudaBukhsh and his collaborators will present their research at the Association for the Advancement of Artificial Intelligence's annual conference.\n- KhudaBukhsh and his collaborators have released data from their study to help others explore the problem.\n- The research team ran audio from kids' YouTube videos through Amazon's automated transcription service as part of their investigation.\n- Amazon provided links to documentation advising developers how to fix or filter unwanted words.\n- One startup revamped its adventure game after it was found to sometimes describe sexual scenarios involving minors.\n- Emergency responders released the man from beneath the robotic arm.\n- Emergency responders administered critical aid to the victim.\n- Emergency responders rushed the victim to Chonburi Hospital.\n- The victim in South Korea was transferred to a hospital.\n- Police launched an investigation into the site's safety managers for possible negligence in duties.\n- An official called for a precise and safe system to be established.\n- OpenAI curates unique datasets for each of its models to help their understanding of the world and maintain its global research competitiveness.\n- OpenAI uses numerous sources including publicly available data and partnerships for non-public data to build its training datasets.\n- OpenAI is looking into generating its own synthetic data.\n- Google's legal department asked the company's privacy team to tweak policy language to expand what Google could do with consumer data such as Google Docs.\n- Google released the new privacy policy on July 1st.\n- Google stated that its robots.txt files and Terms of Service prohibit unauthorized scraping or downloading of YouTube content.\n- Google said it takes technical and legal measures to prevent unauthorized use of YouTube content when it has a clear legal or technical basis to do so.\n- Google has trained its models on some YouTube content in accordance with its agreements with YouTube creators.\n- Multiple lawsuits were filed in the last year or so over the use of copyrighted material to train AI models.\n- Apple prohibited its employees from using the ChatGPT chatbot.\n- JPMorgan Chase prohibited its employees from using the ChatGPT chatbot.\n- Meta banned the use of generative AI in political advertising.\n- Cartoonists and illustrators filed class-action lawsuits to recover their copyrights and enforce consent.\n- Celebrities pursued legal action against OpenAI for copyright infringement.\n- Screenwriters organized strikes through the Writers Guild of America focused on AI and platforms like ChatGPT.\n- Musicians publicly spoke out against ChatGPT.\n- Numerous calls were made for stronger regulation of AI, especially regarding criminal uses of ChatGPT and other generative systems.\n- The screenwriter filed a lawsuit seeking a court order to block the release of the film.\n- Amazon MGM Studios publicly denied using AI to replace or recreate actors' voices.\n- Amazon stated that the studio expressly instructed the filmmakers to not use AI in the movie.\n- Amazon said filmmakers were instructed to remove any \"AI or non-SAG AFTRA actors\" when finishing the film.\n- The Beijing Internet Court ordered the first defendant, a smart technology company in Beijing, to apologize to the plaintiff.\n- The Beijing Internet Court ordered the third defendant, a software company, to apologize to the plaintiff.\n- The Beijing Internet Court ordered the second defendant, a cultural media company in Beijing, and the third defendant, a software company, to pay the plaintiff 250,000 RMB in compensation.\n- The court ordered the AI company to pay 10,000 RMB in damages.\n- The court ordered the company to implement keyword filtering to prevent its service from generating images that are substantially similar to Ultraman.\n- The city adopted a data-use policy for the pilot stating that the footage cannot be actively monitored for law enforcement purposes.\n- The city allowed police to request access to previously stored footage from the pilot.\n- The city stated that it did not capture or retain images of individuals through the pilot.\n- The pilot required AI systems to preserve privacy, for example by blurring faces and license plates in captured footage.\n- City staff followed the route of the camera-equipped vehicle and confirmed that vehicles identified as lived-in were occupied.\n- The city delayed release of its citywide AI policy to allow the department to examine proposed guardrails through the lens of the object-detection pilot.\n- The city said its response to identified tents might include sending outreach workers to visit a single tent before it can grow into an encampment.\n- The city stated that the pilot data was intended to be used by the housing and parks departments to provide services.\n- The city's IT department discussed the object-detection pilot with members of a national coalition of municipal agencies and shared notes with other cities as part of a review process.\n- Several law enforcement investigations were launched into the robocall.\n- Steve Kramer publicly acknowledged that he commissioned the AI robocall.\n- Steve Kramer said he has received a subpoena from the Federal Communications Commission.\n- Authorities in New Hampshire are investigating the robocall for potentially violating state laws against voter suppression.\n- A multistate task force of state attorneys general focused on robocalls is looking to crack down on the people involved in the Biden robocall.\n- The Federal Communications Commission sped up plans to outlaw AI robocalls in response to the Biden robocall.\n- Rep. Dean Phillips and his campaign publicly denounced the robocall and condemned efforts to suppress the vote.\n- Paul Carpenter came forward and shared Venmo transactions and text messages with NBC News showing he was paid to create the audio file.\n- Life Co., the Texas telemarketing company named by investigators as the originator of the calls, ended its business relationship with Kramer.\n- The Metropolitan Police examined the audio and concluded it did not constitute a criminal offence.\n- TikTok said it had spoken to both the mayor's office and the Metropolitan Police in November 2023 about the platform's approach to this content.\n- TikTok said it flagged how similar issues could be raised directly in future.\n- TikTok said it does not allow synthetic media that contains the likeness of any real private figure and removes this kind of content.\n- Jeremy Davis apologised for sharing the fake audio.\n- Mayor Sadiq Khan accepted the apologies of people who shared the audio.\n- The BBC reporter traced the recording back to TikTok and to an account called HJB News.\n- The reporter exchanged messages with the person behind the HJB News account.\n- The reporter telephoned the person behind the HJB News account.\n- The reporter took detailed notes of the conversation with the person behind the HJB News account.\n- The reporter contacted X, TikTok and Instagram about the clip.\n- The police condemned counter-protestors after clashes.\n- The police arrested counter-protestors for offences including for inciting racial hatred.\n- China\u2019s Cyberspace Administration fined Didi Global more than 8 billion yuan ($1.2 billion) for data violations.\n- Regulators fined Didi\u2019s chairman Cheng Wei and president Jean Liu 1 million yuan each.\n- Regulators launched an investigation into Didi\u2019s cybersecurity practices.\n- Regulators ordered Didi to take down more than two dozen apps.\n- Didi moved to delist from the New York Stock Exchange, exiting on June 10.\n- Didi publicly stated that it \"sincerely\" accepted the decision.\n- Didi said it would take the decision as a warning and persist in paying equal attention to both security and development.\n- Didi said it would work toward \"safe, healthy and sustainable\" development of its business.\n- The city will review user questions to improve the chatbot's answers.\n- The city will address harmful, illegal, or otherwise inappropriate content produced by the chatbot.\n- The city will delete chatbot data within 30 days.\n- The city implemented a pop-up feedback form that encourages visitors to report inaccuracies and rate their experience.\n- The city said it will continue to upgrade the chatbot to better support small businesses.\n- The chatbot page includes a sentence suggesting users verify answers with links provided by the chatbot.\n- The BBC issued a public statement defending its decision and explaining it had worked closely with the contributor's family on how to represent their voice.\n- The BBC agreed to use AI for a brief section to recreate a voice that could no longer be heard.\n- The BBC said the use of the AI-generated voice would be clearly labelled within the film.\n- The BBC vowed to stop using AI to promote Doctor Who after receiving complaints from viewers.\n- The researchers surveyed 165 students using an eight-item scale to collect self-reported data on ChatGPT reliance.\n- They conducted a more rigorous time-lagged second phase, expanding the sample to nearly 500 students who were surveyed three times at one- to two-week intervals to validate the results.\n- The researchers published the study in the International Journal of Educational Technology in Higher Education.\n- The BBC announced it will not use generative AI again to promote Doctor Who.\n- Chicago Police Department officials have continued to evaluate the city's contract with ShotSpotter.\n- Freddy Martinez penned an op-ed calling for an end to the city's deal with ShotSpotter.\n- Martinez\u2019s group and two other nonprofits filed an amicus brief in a pending Cook County murder case that relies on ShotSpotter evidence.\n- The MacArthur Justice Center is representing the organizations that filed the amicus brief.\n- The groups urged the court to scrutinize ShotSpotter's reliability given its far-reaching consequences.\n- The groups asked the court to take seriously its duty to investigate and ascertain the reliability of ShotSpotter's reports of gunfire.\n- The defendant, Michael Williams, filed a motion on April 22 to exclude the ShotSpotter evidence in his case.\n- Other cities have dropped ShotSpotter because the system sent their officers out on too many wild goose chases.\n- The Argentine Agency for Access to Public Information (AAIP) commenced an investigation into Worldcoin's data collection practices.\n- The AAIP said it will analyze Worldcoin's data collection, storage, and use processes and take appropriate steps to address any identified issues and ensure compliance with security and privacy standards.\n- The AAIP recommended that Worldcoin register its databases with the agency.\n- The AAIP recommended that Worldcoin disclose its data processing policy, including the purpose of sensitive data collection and the period for storing data.\n- The AAIP recommended that Worldcoin provide information about its data treatment policy.\n- The AAIP recommended that Worldcoin indicate the reasons for collecting sensitive data and the length of time it stores such data.\n- The AAIP recommended that Worldcoin detail the security and confidentiality measures applied to safeguard personal information.\n- Kenyan authorities raided Worldcoin's Nairobi warehouse and seized its machines and documents.\n- Kenya's Ministry of the Interior suspended Worldcoin's operations in the country.\n- Kenya's Office of the Data Protection Commissioner conducted an investigation into Worldcoin's registration disclosures.\n- Worldcoin stated that it will continue to cooperate with governing and regulatory bodies on requests for more information about its privacy and data protection practices.\n- Worldcoin stated that it will work with its partners globally to ensure the project meets regulatory requirements and provides a safe, secure, and transparent service for verified humans.\n- South Korea's Personal Information Protection Committee initiated an investigation into Worldcoin following complaints about the collection of sensitive biometric and personal data.\n- The Hong Kong regulator conducted raids on Worldcoin's offices at the end of January 2024.\n- Regulators in Germany opened a regulatory investigation into Worldcoin.\n- Regulators in France opened a regulatory investigation into Worldcoin.\n- Regulators in the United Kingdom opened a regulatory investigation into Worldcoin.\n- Regulators in Kenya opened a regulatory investigation into Worldcoin.\n- Argentina initiated an investigation into Worldcoin in August.\n- In July 2023, the Personal Information Protection Committee fined OpenAI 3.6 million Korean won for a data breach that exposed information about 687 citizens.\n- The PCPD executed court warrants and entered six Worldcoin premises to carry out investigations.\n- The PCPD proactively commenced an investigation against Worldcoin in accordance with established procedures.\n- The PCPD requested the relevant parties to furnish required documents and information.\n- The Privacy Commissioner appealed to members of the public to stay vigilant about the Worldcoin project and to avoid arbitrarily disclosing biometric data.\n- The PCPD invited members of the public to lodge complaints or provide information about the Worldcoin project and provided telephone and email contact details for doing so.\n- The PCPD provided a link to its \"Guidance on Collection and Use of Biometric Data\" for further information.\n- Worldcoin said it would improve its communication and marketing.\n- Worldcoin stopped operating in several countries, including Zimbabwe, France, and Ghana.\n- Worldcoin created boilerplate letters for authorities in any given market explaining the project and the Orb.\n- Operators sent defective Orbs in for repair.\n- Worldcoin said it would soon roll out its privacy form in six languages.\n- Worldcoin said it would delete all iris images and data once its algorithms were optimized.\n- Worldcoin said it plans to open-source all its technology in the coming weeks.\n- Worldcoin said it would soon engage with Kenya\u2019s Data Commission.\n- Worldcoin said it had conducted a 'rigorous' privacy impact assessment.\n- Worldcoin delayed the token launch.\n- Worldcoin said it would deploy more Orbs.\n- Worldcoin said it would stop storing users\u2019 biometric data.\n- Worldcoin said it was building fraud-detection mechanisms to identify compromised Orbs.\n- Worldcoin said it took immediate action to diffuse the barrage of angry messages directed at operators.\n- Some Orb operators began a multiday 'strike in operations' beginning April 1.\n- Some sub-operators disconnected their SIM cards to escape a barrage of angry messages.\n- Worldcoin invited a small group of top-performing Orb operators to a three-day retreat in Dubai to mingle with company executives and strategize for the future.\n- Worldcoin changed the user payout model in certain markets to distribute 2.50 WLD weekly for 10 weeks.\n- Worldcoin changed the operator payment structure in certain markets so operators receive $5.30 in tether if users claim at least three times and $0.60 otherwise.\n- Worldcoin changed the sign-up reward, offering 25 WLD to new sign-ups instead of $20 worth of Worldcoin tokens.\n- Worldcoin updated its back-end technology to address payment delays.\n- Worldcoin instructed operators in its marketing guidelines not to describe Worldcoin as a 'great investment' or an opportunity to 'get in early.'\n- Worldcoin gave a virtual presentation updating operators on the company's progress.\n- Worldcoin said it is experimenting with different incentive models and expects compensation models to change in the coming months.\n- Ukraine's Center for Countering Disinformation publicly stated that footage from the national joint 24/7 newscast on 16 March had been used to create the deepfake.\n- Mashable reached out to Shudder for comment.\n- Late Night with the Devil's co-writers and co-directors, Cameron Cairnes and Colin Cairnes, issued a public statement confirming the film's use of AI and explaining that they experimented with AI for three still images which were further edited and appear as brief interstitials in the film.\n- The directors' statement was first reported by Variety.\n- The University of Michigan asked one of its vendors to stop work after the vendor shared inaccurate information.\n- The university issued a public statement clarifying that student data was not for sale and explaining the origin and content of the materials.\n- The French competition watchdog fined Alphabet's Google 250 million euros for breaches linked to EU intellectual property rules.\n- Google pledged not to contest the facts as part of settlement proceedings.\n- Google proposed a series of remedy measures to address certain shortcomings.\n- Some of France's biggest news organisations, including Agence France Presse (AFP), filed complaints that triggered the copyright dispute.\n- In 2022 Google dropped its appeal against an initial 500 million euro fine issued by the Autorite de la Concurrence.\n- The New York Times sued Microsoft and OpenAI in 2023 accusing them of using millions of the newspaper's articles without permission to train chatbots.\n- Meloni filed a defamation complaint against the two men accused of creating and circulating the deepfake pornography.\n- An investigation into the creation and posting of the deepfake videos was opened in 2020.\n- The two men were accused of defamation by investigators.\n- Meloni is seeking \u20ac100,000 (about $108,500) in damages in the defamation case.\n- Meloni will testify in the defamation case this summer.\n- Meloni's lawyer stated that any damages awarded would be used to support female victims of abuse if she wins the case.\n- The Federal Trade Commission opened an investigation into Evolv Technologies to determine whether its AI-driven weapons screening systems operate as claimed.\n- Solicitors for the British Phonographic Industry sent a letter to Voicify (now Jammable) threatening a first-of-its-kind legal action in the U.K.\n- Following BPI's letter, Jammable changed its name from Voicify.\n- Following BPI's letter, Jammable removed guides providing users with details on how to make deepfakes.\n- The Department of Health and Social Care issued a public statement asserting that trust and patient confidentiality will be a top priority when implementing new technologies that affect patient data.\n- Walker successfully petitioned to have credits for Gustav Johansson, Andr\u00e9 Chemetoff, and others added to the Instagram post.\n- Walker deleted a comment on the Instagram post in which he said they had asked for access to Anthony Joshua but were rejected.\n- The set-top box provider issued an apology acknowledging that their systems had been hacked.\n- The set-top box provider assured subscribers that they were actively investigating the problem.\n- A Dubai-based cybersecurity expert warned and urged caution for consumers using unauthorised streaming services, highlighting the heightened risk to users' networks.\n- Google temporarily disabled Gemini's image generation tool last month.\n- Google said it was already working to address recent issues with Gemini's image generation feature.\n- Google said it was implementing an update so that Gemini no longer shows the reported inappropriate response.\n- Google CEO Sundar Pichai told employees the company 'got it wrong'.\n- Google co-founder Sergey Brin acknowledged that the company 'messed up'.\n- Adobe said it trains its AI models on diverse datasets to ensure commercially safe results that don't perpetuate harmful stereotypes.\n- Adobe said it extensively tests outputs for risk to ensure they match the reality of the world we live in.\n- Adobe said it builds feedback mechanisms in all of its generative AI products to detect issues.\n- Adobe said it fixes issues through retraining.\n- Adobe said it fixes issues by adjusting filters.\n- The California Labor Commission sued Uber and Lyft in 2020, claiming the companies owed drivers a combined $1.3 billion in payments for their hours worked.\n- Uber issued a public statement disputing the paper's central premise about how Upfront Fares are presented to drivers and clarifying that fares are not tailored based on factors like a driver's race, ethnicity, Quest promotion status, acceptance rate, total earnings, or prior trip history.\n- Amazon issued a public statement defending the Amazon Flex program and stating it offers competitive earnings that exceed $26 per scheduled hour on average.\n- The story was updated on April 13, 2023 to include an updated comment from Uber.\n- The Public Law Project sent a pre-action letter to the Home Office outlining its concerns about the sham-marriage screening algorithm.\n- An algorithm used to determine A-level and GCSE results was scrapped in 2020 after a public outcry.\n- In 2020 the Home Office suspended the use of an algorithm applied to decide visa applications after a legal challenge alleging it was biased against certain nationalities.\n- In November 2021 the Centre for Data Ethics and Innovation developed a standardised template for public bodies to voluntarily record how they use algorithms, and the template is reviewed every six months.\n- The Princess of Wales issued a public apology for any confusion caused by the Mother's Day photo.\n- Kensington Palace posted a statement on its social media in which Catherine said she sometimes experiments with editing.\n- Major news agencies, including Reuters and the Associated Press, pulled the Mother's Day photo from distribution.\n- BBC Verify analyzed the image's metadata and found that the picture had been saved twice using photo editing software.\n- Kensington Palace said it will not publish the original image.\n- Developers have responded by trying to make large language models less toxic.\n- Companies including OpenAI, Meta, and Google use feedback training in which human workers manually adjust model responses to certain prompts.\n- Researchers published the study on arXiv (not peer reviewed) documenting covert dialect prejudice in large language models.\n- Russian authorities used video footage to identify and arrest people who attended Alexey Navalny\u2019s funeral.\n- Police in Moscow began arresting people who attended Alexey Navalny\u2019s funeral on March 1.\n- Police charged a Moscow woman with \"displaying a banned symbol\" after hearing her say \"Glory to the heroes\" in a video.\n- OpenAI updated its usage policies to prohibit using its models to make high-stakes automated decisions in domains that affect an individual's safety, rights, or well-being, such as employment.\n- OpenAI said it requires companies using its models to comply with the law.\n- OpenAI said businesses may choose to strip out names before feeding resumes into a GPT model.\n- OpenAI said businesses often mitigate bias by fine-tuning the software\u2019s responses.\n- OpenAI said businesses often mitigate bias by managing system messages.\n- OpenAI said it has published blog posts and system cards describing its models' capabilities and limitations.\n- OpenAI said it regularly conducts adversarial testing and red-teaming on its models to probe how bad actors could use them for harm.\n- Anthropic published a bias audit of its Claude 2.0 model.\n- Anthropic instructed its chatbot to remember that discrimination is illegal or to ignore demographic information in the prompt, which it said nearly eliminated discriminatory outputs.\n- The Equal Employment Opportunity Commission convened a panel of experts to discuss the possible harms perpetuated by AI-powered hiring systems.\n- The EEOC settled its AI discrimination-in-hiring lawsuit against iTutorGroup and required the company to submit proposed anti-discrimination policies and complaint procedures applicable to the screening, hiring, and supervision of candidates and employees to the agency.\n- An investigation is underway at Beverly Vista Middle School.\n- The Beverly Hills Unified School District is working with the Beverly Hills Police Department to investigate the incident.\n- School staff were alerted about the photos on Wednesday.\n- The district stated that those responsible will face disciplinary action.\n- The district said any student found creating, disseminating, or in possession of AI-generated images could face disciplinary actions.\n- The district stated it is prepared to implement the most severe disciplinary actions allowable under the California Education Code.\n- The district assured that if any criminal offenses are discovered, they will be addressed to the fullest extent possible.\n- The district said it is taking every measure to support those affected and to prevent any further incidents.\n- The district urged all members of the community to come forward with any information that may assist the investigation.\n- The district asked parents to partner with the school and speak with their children about this dangerous behavior.\n- The district asked students to talk to their friends about how disturbing and inappropriate this manipulation of images is.\n- The district advised students worried about the impact to reach out to their school counselor.\n- The district provided the contact email for Kristen Hartley, BulldogAid Wellness Center Lead Counselor, for support.\n- The district provided resources for navigating a conversation about AI-generated 'Deep Fakes'.\n- The district provided a Family Safety Toolkit with AI information.\n- Shane Jones began internally reporting his findings about Copilot Designer in December.\n- Microsoft acknowledged his concerns.\n- Microsoft referred him to OpenAI.\n- Microsoft's legal department told Jones to remove his LinkedIn post.\n- Jones complied with Microsoft's legal department and removed his LinkedIn post.\n- Jones wrote a letter to U.S. senators about the matter.\n- Jones met with staffers from the Senate Committee on Commerce, Science and Transportation.\n- Jones sent a letter to Federal Trade Commission Chair Lina Khan.\n- Jones sent a letter to Microsoft's board of directors.\n- Jones shared his letters with CNBC ahead of time.\n- Jones repeatedly urged Microsoft to remove Copilot Designer from public use until better safeguards could be put in place.\n- Jones called on Microsoft to add disclosures to the product.\n- Jones called on Microsoft to change the rating of the Copilot Designer Android app to indicate it is only for mature audiences.\n- In his letter to Microsoft's board, Jones requested that the company's environmental, social and public policy committee investigate certain decisions by the legal department and management.\n- Jones requested that Microsoft's environmental, social and public policy committee begin an independent review of Microsoft's responsible AI incident reporting processes.\n- Jones reported concerning images to Microsoft's Office of Responsible AI.\n- Jones published an internal post detailing the issues.\n- Jones met directly with senior management responsible for Copilot Designer.\n- Microsoft said it has established robust internal reporting channels to investigate and remediate any issues.\n- Microsoft encouraged employees to utilize internal reporting channels so the company can validate and test their concerns.\n- The Copilot team triaged reported issues and focused on investigating only the most egregious problems due to limited resources.\n- Google temporarily sidelined its AI image generator following user complaints.\n- Stability AI updated its policies on March 1 to explicitly prohibit generating, promoting, or furthering fraud or the creation or promotion of disinformation.\n- Stability AI is implementing its updated policy to prohibit disinformation.\n- Stability AI has implemented various tools to prevent misuse of its models and technology.\n- DreamStudio uses digital watermarking technology to help make its AI-generated images identifiable.\n- OpenAI is building on its platform safety work to prevent abuse of its image-generation tools.\n- OpenAI is working to improve transparency on AI-generated content.\n- OpenAI is designing mitigations to decline image-generation requests for real people, including candidates.\n- OpenAI is implementing technology to help identify its AI-generated images.\n- Microsoft launched a website for candidates and campaigns to report deepfakes.\n- Microsoft added data to each image created through Designer so authenticity can be tracked.\n- Microsoft provides a tool for people, including researchers, to report broader issues with these technologies.\n- CCDH urged AI companies to invest in and collaborate with researchers to test for and prevent jailbreaking prior to product launches.\n- CCDH encouraged social media platforms to invest in identifying and preventing the spread of potentially misleading AI-generated images.\n- Mayor Lacey Beaty muted and cut off the disruptive online callers during the meeting.\n- The council redacted the exact slurs from the public video of the meeting that was uploaded to its website.\n- The council released a statement on their Facebook page expressing their deepest empathy and condemning the hateful speech.\n- The council reaffirmed their commitment to maintaining safe and welcoming environments for all community members.\n- The council committed in their statement to do their best to improve processes to remain prepared for future incidents.\n- The council asked the public to continue participating in local government and to support one another.\n- Mayor Beaty contacted other mayors to inquire whether similar incidents had occurred in their cities.\n- The next council meeting was scheduled for October 17 with no restrictions.\n- Ke withdrew the fake cases from her arguments once she learned they were non-existent.\n- Ke gave a letter of apology and an admission that the cases were fake to an associate who was to appear at a court hearing in her place.\n- Ke swore an affidavit outlining her lack of knowledge of the risks of using ChatGPT and her discovery that the cases were fictitious.\n- Zhang's lawyers sought special costs for reprehensible conduct or an abuse of process.\n- A B.C. Supreme Court judge reprimanded Chong Ke for including AI 'hallucinations' in her application.\n- The judge ordered Chong Ke to pay the costs incurred by Zhang's lawyers to discover the cases were non-existent.\n- The judge ordered Ke to review her other files and to advise the opposing parties and the court immediately if any materials she filed or handed up contain citations or summaries obtained from ChatGPT or other generative AI tools.\n- The B.C. Law Society warned of the growing level of AI-generated materials being used in court proceedings.\n- The B.C. Law Society sent guidance to the profession reminding counsel of their ethical obligation to ensure the accuracy of materials submitted to court and advising that it would be prudent to inform the court when materials are generated using technologies such as ChatGPT.\n- Both Microsoft and OpenAI declined to comment in response to the allegation.\n- Microsoft has redacted exact figures in city records on the grounds that its water consumption is proprietary information.\n- Microsoft commissioned estimates indicating the campus would consume an annual 56 million gallons of drinking water once the final building is completed.\n- Microsoft uses air to cool its data center when temperatures are below 85 degrees.\n- The city of Goodyear assured Futurism by email that Microsoft's water use is protected under industrial water rights and does not impact the city's water portfolio.\n- The article was updated to properly indicate area water rights.\n- Microsoft investigated the report of Copilot generating false statements.\n- Microsoft is making changes to refine and improve the quality of Copilot's AI-generated responses.\n- Microsoft encouraged users to use their best judgment when viewing results, including verifying source materials and checking web links.\n- Microsoft has mapped out its plan to protect the impending election's integrity from AI deepfakes.\n- Microsoft intends to empower voters with authoritative and factual election news on Bing ahead of the poll.\n- Microsoft shipped a new update to its image-generation tool that adds guardrails blocking nudity-based image generation prompts.\n- Major social media companies have policies in place to tackle potential influence operations.\n- Meta introduced new measures to deal with AI-generated content during elections.\n- A Democratic Party supporter admitted responsibility for making an automated audio call purportedly voiced by the president that urged voters to skip the New Hampshire primary.\n- Some social media users publicly called out the AI-generated images as fake.\n- The BBC tracked down the person operating the account called 'Shaggy'.\n- A creator of one of the images told the BBC he was not claiming the image was accurate.\n- The journalist revealed to a voter that the AI-generated image he had believed to be real was actually fake.\n- Francesca's teachers and principal took action once they learned about the manipulated image.\n- The students responsible reportedly faced minimal consequences.\n- Many tech companies have terminated developer accounts linked to 'nudify' websites for policy violations.\n- Some nudify sites have been shut down or blocked.\n- Lawmakers have proposed the Take It Down Act to make sharing AI-generated nude images of minors illegal and to require websites and social platforms to remove such images within 48 hours of a verified request.\n- Some states have drafted or enacted statutes that explicitly outlaw the creation and distribution of AI-generated nudes involving minors and attach penalties for violators.\n- In some school districts, offenders have received short suspensions as a penalty for sharing AI-generated nudes.\n- In some school districts, offenders have been expelled for sharing AI-generated nudes.\n- Some offenders have been required to attend educational remediation programs as a disciplinary measure.\n- Parents are advised to keep screenshots, links, and any relevant usernames as documentation when a fake nude is circulating.\n- Parents are advised to contact the school immediately if their child is targeted by a manipulated image.\n- Parents are advised to contact local authorities if the image is illicit.\n- Parents are advised to reach out directly to social platforms like Snapchat, Instagram, or Discord to request removal of the images.\n- Families have used services like Take It Down to help remove nude images from the internet.\n- Families have sought guidance from organizations like the National Center for Missing & Exploited Children.\n- Parents are advised to inform their child's school or district superintendent in writing about the incident.\n- Parents are advised to escalate the situation to school board members if they are not being heard.\n- Parents are advised to contact legal counsel if they feel the school's response is inadequate.\n- Parents are advised to attend school board meetings, bring the issue up with parent-teacher organizations, or write to the superintendent to push for a formal policy addressing AI-driven harassment.\n- Parents are advised to ask their school to treat fake images as seriously as in-person harassment.\n- Parents have sought support from local parent networks, therapy services, or online support groups to help navigate the aftermath.\n- Parents are advised to reassure their child that what was done to them was wrong and that they have every right to demand the images be taken down.\n- The Houston City Council approved a $3.5 million contract in 2022 to expand the ShotSpotter program in northwest Houston.\n- In February, Houston Police Department officials publicly revealed that only 99 arrests and 126 charges were filed from 5,450 ShotSpotter alerts.\n- San Antonio city officials concluded that the ShotSpotter program was not worth the cost.\n- The MacArthur Justice Center conducted a 21-month study in Chicago using city data to evaluate ShotSpotter alerts.\n- The Houston Chronicle obtained and reported data showing officers increasingly prioritize ShotSpotter alerts and that less than 20 percent of ShotSpotter alerts resulted in an incident report.\n- Google paused its Gemini AI image generator.\n- Google plans to relaunch the Gemini AI image generator in the next few weeks.\n- Anthropic said it plans to roll out a new version of its AI tool in the coming weeks to provide accurate voting information.\n- OpenAI said it plans to keep evolving its approach as it learns more about how its tools are used.\n- Meta said its public Meta AI product directed users to resources for finding authoritative information from state election authorities.\n- The city's Office of the Inspector General issued a report analyzing 50,176 ShotSpotter notifications and concluded the technology rarely led to investigatory stops or evidence of gun crimes.\n- The city quietly extended its three-year, $33 million contract with ShotSpotter for two additional years at the request of the Chicago Police Department.\n- Police officials requested approval for an annual 5% increase in the cost per square mile of the ShotSpotter contract.\n- ShotSpotter issued a public statement denying that the inspector general's report indicted the technology and defending its accuracy.\n- ShotSpotter cited an independent audit claiming 97% accuracy based on feedback from more than 120 customers.\n- ShotSpotter commissioned a report that criticized the MacArthur Justice Center study and said it showed 'severe flaws'.\n- The inspector general's office broadly backed the conclusion that a large percentage of ShotSpotter alerts cannot be connected to any verifiable shooting incident.\n- The Chicago Police Department publicly stated it stood firmly behind the use of ShotSpotter and defended its value for detecting shootings and saving lives.\n- Activists rallied to end the city's deal with ShotSpotter.\n- The Coalition to Cancel the ShotSpotter Contract publicly called on the city to cancel its existing ShotSpotter contract.\n- The Coalition to Cancel the ShotSpotter Contract called on the city to pass the Community Restoration Ordinance.\n- The Coalition to Cancel the ShotSpotter Contract called on the city to invest in community-led violence interruption and prevention programs.\n- The Associated Press published an investigation that found the system could miss gunshots or wrongly detect other sounds as gunfire and raised issues with using the technology as evidence.\n- Vice published a report highlighting issues with the system.\n- Google told 404 Media that it tries to address spam on Google News.\n- Google told 404 Media that it does not focus on whether a news article was written by an AI or a human.\n- Brian Penny flagged some of the seemingly AI-generated articles to 404 Media.\n- 404 Media found that Google News is boosting sites that rip off other outlets by using AI to rapidly churn out content.\n- OpenAI acknowledged the problem with ChatGPT.\n- OpenAI stated that the issue had been identified.\n- OpenAI said its team is continuing to monitor the situation.\n- The Ministry of Justice completed a preliminary evaluation of the new digital prisoner categorisation system.\n- The Ministry of Justice concluded the preliminary evaluation showed no indication of discrimination against BAME offenders.\n- When challenged, the Ministry of Justice admitted the trial sample size was too small to judge the impact on prisoners of different ethnicities.\n- The Ministry of Justice expanded the trial to include eight prisons.\n- The Ministry of Justice cancelled a follow-on contract and decided to continue development of the tool in-house.\n- The Ministry of Justice tested a second version of the tool with the aim of rolling it out more widely.\n- The Ministry of Justice emphasised that the new tool is intended to support categorisation decisions rather than make them.\n- The Ministry of Justice stated that staff would be expected to use their judgement when using the algorithm's results.\n- During the pilot, staff rejected the tool's provisional security category in 20 cases based on other evidence and sources of information.\n- On review, the Ministry of Justice determined that some upward recategorizations were unnecessary and decided the tool would be revised in the next version to address this.\n- The Ministry of Justice said prisoners could access the justification for all categorisation decisions.\n- The Ministry of Justice said prisoners could appeal their categorisation decisions.\n- The Bureau launched a new project to investigate how data systems are being used in the UK and elsewhere.\n- The Information Commissioner's Office issued an enforcement notice ordering Serco Leisure to stop using facial recognition technology to monitor staff.\n- The Information Commissioner's Office published new guidance on companies' use of biometric data.\n- The Information Commissioner's Office released details of the case.\n- The Information Commissioner's Office said it will closely scrutinise organisations and act decisively if it believes biometric data is being used unlawfully.\n- Serco Leisure confirmed it will fully comply with the enforcement notice.\n- The Illinois Department of Children and Family Services suspended use of the Rapid Safety Feedback predictive analytics program.\n- DCFS decided not to proceed with the contract for the Rapid Safety Feedback program.\n- The department is seeking to change the way it indexes and links investigations.\n- The department is considering legislative changes to allow it to retain records of past unproven allegations.\n- Eckerd Connects publicly expressed regret for using language that suggested the company could predict the probability of child harm.\n- Eckerd Connects clarified that its scoring system was intended to represent how closely a child matched historical data on fatality and harm cases.\n- Law enforcement arrested the first adult user the day after the assault.\n- The first adult user was subsequently incarcerated.\n- The second convicted offender was incarcerated.\n- A judge dismissed the complaint filed by the girl's parent and guardian.\n- Mainstream financial and tech companies deplatformed Gab following the Tree of Life synagogue massacre.\n- Gab labeled its celebrity AI chatbots as \"parody\" to potentially avoid legal headaches.\n- Gab CEO Andrew Torba offered a brief response to Rolling Stone via direct message about the Uncle A chatbot.\n- Torba posted a screenshot of his exchange with the Rolling Stone reporter on his Gab feed.\n- During the Tree of Life killer's trial, Torba testified that he does not post antisemitic content on Gab.\n- Google apologized for inaccuracies in some historical image generation depictions produced by its Gemini AI tool.\n- Google posted a statement on X acknowledging the issue and saying Gemini was missing the mark.\n- Google said it is working to improve these kinds of depictions immediately.\n- Google reiterated the contents of its post on X in a statement to The Verge.\n- Gemini has been configured to refuse some image generation requests, including images of Vikings, German soldiers or officials from Germany\u2019s Nazi period, and American presidents from the 1800s.\n- Waymo voluntarily recalled the software that powers its robotaxi fleet.\n- Waymo developed, tested, and validated a fix to the software after the crashes.\n- Waymo started deploying the software fix to its fleet on December 20.\n- Waymo completed the deployment so that all of its robotaxis received the software update by January 12.\n- Waymo contacted the Phoenix Police Department and the Arizona Department of Public Safety on the day of the crashes.\n- Waymo notified the National Highway Traffic Safety Administration about the crashes on December 15.\n- Waymo and NHTSA staff held four subsequent conversations about the crashes.\n- Waymo declined to share video of the crashes with TechCrunch.\n- Frontiers added a notice saying that the paper had been corrected and that a new version would be published soon.\n- Frontiers updated the notice to state that it was retracting the study entirely.\n- Frontiers retracted the article from the journal.\n- Frontiers posted a statement on the journal's webpage apologizing to the scientific community for the mistake.\n- Frontiers said it is investigating how its processes failed to act on the lack of author compliance with the reviewers' requirements.\n- Microsoft collaborated with OpenAI to detect threats that used or attempted to exploit their AI technology.\n- Microsoft collaborated with OpenAI to disrupt threats that used or attempted to exploit their AI technology.\n- Microsoft disabled all generative AI accounts and assets of the named adversary groups.\n- Microsoft publicly disclosed and exposed the techniques and examples used by adversary groups in a report.\n- Microsoft released a report warning that generative AI is expected to enhance malicious social engineering and related threats.\n- OpenAI published a blog post stating that its GPT-4 model offers only limited, incremental capabilities for malicious cybersecurity tasks.\n- The injured worker was sent to hospital after the incident.\n- An official from the Donggoseong Export Agricultural Complex issued a statement calling for a precise and safe system to be established.\n- An Air Canada representative admitted that the chatbot had provided misleading words.\n- Air Canada noted the issue so it could update the chatbot.\n- Jake Moffatt sent a copy of the chatbot screenshot to Air Canada pointing out the chatbot's advice.\n- Jake Moffatt opted to sue Air Canada.\n- The Civil Resolution Tribunal ordered Air Canada to pay Jake Moffatt $812 to cover the difference between bereavement rates and the full-price tickets he paid.\n- VTech hired a high-profile cybersecurity incident-response team to deal with the aftermath of the Learning Lodge account-information breach.\n- Mattel and ToyTalk are racing to patch the security problems with the Hello Barbie doll.\n- ToyTalk has fixed some of the flaws in the software it built for Hello Barbie.\n- ToyTalk is working its way through the remaining flaws in Hello Barbie's software.\n- ToyTalk set up a bug bounty program to streamline reporting from researchers investigating the doll's software.\n- The University of Illinois at Urbana-Champaign announced it will not renew its emergency contract with Proctorio past this summer.\n- University administrators reminded faculty that the emergency Proctorio license is coming to an end.\n- The university recommended that instructors consider using alternate forms of assessment this spring, even before the Proctorio contract runs out.\n- The university has been working with Illinois\u2019s Center for Innovation in Teaching and Learning, Tech Services, and the ADA Division of the Office for Access and Equity to further understand and address concerns about Proctorio.\n- The university is investigating remote proctoring tools for longer-term use.\n- Many instructors have opted to use alternative forms of assessment or alternative means of proctoring, such as the College of Engineering\u2019s Computer Based Testing Facility.\n- About 1,500 professors participated in three Online Teaching Academies over the summer where they discussed alternative assessments.\n- Apple and Findaway agreed to immediately stop all use of files for machine learning purposes for affected SAG-AFTRA union members.\n- The halt applies to all files dating back to the beginning of this practice.\n- Apple's access to files from Findaway was halted.\n- Findaway submitted Starling's opt-out request to Apple.\n- Starling paused the release of three upcoming titles she planned to distribute via Findaway.\n- Lillian Rachel deleted her Findaway Voices profile after learning about the machine learning clause.\n- SAG-AFTRA is working with Findaway toward a solution that recognizes the union's concerns, including safe storage of recordings and data, usage limitations, and appropriate compensation.\n- The Open Voice Network developed a standard contract that clearly spells out usage rights and compensation to help actors navigate relationships with synthetic voice firms.\n- Buckingham Palace said its legal team will be looking at the issue closely.\n- Buckingham Palace called on any individuals or organisations facilitating the sale of the books to withdraw them immediately.\n- Buckingham Palace moved to consider legal action against Amazon.\n- The Mail on Sunday alerted Amazon to the offensive AI-generated books.\n- The Mail on Sunday presented a dossier of evidence to Buckingham Palace.\n- Amazon removed the titles it found that violated its content guidelines.\n- Schools installed sensors that actively listen to pupils to detect vaping, bullying, and rowdiness in toilets.\n- Some schools paired the sensors with surveillance cameras to capture students leaving bathrooms when the vaping sensors were activated.\n- Baxter College installed four sensors that connect to a cloud and retain data for a year.\n- St Joseph\u2019s College placed Halo sensors in two toilet blocks in September.\n- After the initial Halo sensors became very active, St Joseph\u2019s College installed five additional sensors elsewhere.\n- St Joseph\u2019s RC High School in Horwich installed Halo sensors in toilets following three instances of pupils collapsing after using THC vapes.\n- When sensors are triggered, staff receive alerts via SMS, push notifications through an app, and email.\n- Emergency Protection added keywords and phrases to sensors through over-the-air updates.\n- IPVideo/Millgate updated Halo sensor software so learned pronunciations of new keywords are deployed to all Halo sensors nationwide.\n- The government announced a ban on disposable vapes.\n- The government announced measures to prevent vapes being marketed at children.\n- Schools deployed cheaper fire alarm-type vape detectors more widely.\n- More than 1,500 US school districts are using Halo Smart Sensors.\n- Nine UK schools began using the 3D Sense Pro sensor.\n- The 2nd U.S. Circuit Court of Appeals referred attorney Jae Lee to the court's grievance panel for further investigation.\n- The court ordered Jae Lee to submit a copy of the cited decision after it was unable to find the case.\n- The court ordered Jae Lee to provide a copy of the ruling to her client.\n- The court dismissed the case.\n- Two New York lawyers were fined $5,000 for relying on fake research created by ChatGPT.\n- The CNIL investigated Amazon France Logistique warehouses following complaints by employees and media coverage.\n- The CNIL outlined a number of breaches of the General Data Protection Regulation (GDPR) by Amazon France Logistique.\n- The CNIL ruled that the system with three alerts used to monitor employee activity was illegal.\n- The CNIL fined Amazon \u20ac32 million for excessive surveillance of its workers.\n- The Business, Energy and Industrial Strategy Committee published a report raising concerns about surveillance technology being used to set performance targets and monitor performance.\n- The Business, Energy and Industrial Strategy Committee wrote to Amazon outlining its concern that the technology would put undue stress on its workforce.\n- Amazon publicly stated that it strongly disagreed with the CNIL's conclusions and called them factually incorrect.\n- Amazon said it reserved the right to file an appeal against the CNIL's findings.\n- The sheriff's campaign publicly acknowledged that the news stories attributed to local outlets were not real.\n- A police officer escorted the couple to a hospital after the attack.\n- Jason underwent three hours of reconstructive surgery to repair his jaw.\n- Google agreed to stop Google Maps from directing people through the dangerous area three weeks after the attack.\n- Google stated that it is currently reviewing the lawsuit.\n- Hong Kong police made six arrests in connection with the deepfake scams.\n- The employee discovered the scam when he later checked with the corporation's head office.\n- The pornographic AI-generated images of Taylor Swift were removed from social platforms.\n- Wacom deleted the images it had posted for the promotional campaign.\n- Wacom posted a message on X (formerly Twitter) explaining itself regarding the controversy.\n- Wacom stated that the images were sourced from a third-party vendor.\n- Wacom claimed that the images it used were not labeled as AI-generated on the vendor\u2019s website.\n- The Verge followed up and reported that Wacom sourced the campaign imagery from an Adobe Stock user named umair.\n- Federal authorities took control of Silicon Valley Bank on March 10, 2023.\n- New York regulators closed Signature Bank on March 12, 2023.\n- Several Signature Bank branches were later reopened as part of Flagstar Bank.\n- Federal regulators seized First Republic Bank and sold its assets to J.P. Morgan.\n- Valent Projects used AI-driven algorithms to analyze social media activity and published a report identifying bot-driven misinformation linked to the run on First Republic Bank.\n- George Carlin's estate filed a lawsuit in California federal court alleging unauthorized use of his works and likeness.\n- The complaint seeks a court order for immediate removal of the special.\n- The complaint seeks unspecified damages.\n- The estate brought claims for copyright infringement and violations of right of publicity laws.\n- The estate retained intellectual property lawyer Joshua Schiller of Boies Schiller Flexner to represent it.\n- Kelly Carlin posted on X criticizing the creators of the special and warning other families about the use of AI to impersonate deceased artists.\n- A bipartisan coalition of House lawmakers introduced the No AI Fraud Act to prohibit publication and distribution of unauthorized digital replicas and to grant individuals exclusive rights to approve use of their image, voice, and visual likeness.\n- Senators introduced a separate proposal in October barring the unauthorized use of AI-generated replicas.\n- Unions and trade groups in Hollywood have been lobbying for legislation requiring individuals\u2019 consent to use their voice and likeness.\n- Twitter deleted the account of the original poster and other accounts that posted similar images.\n- Fans organized to drown out the trending phrase with \u201cprotect Taylor Swift\u201d tweets and buried many of the viral abuse images from the search results for the phrase \"AI Taylor Swift\" on Twitter.\n- Authorities admitted their mistake in Dhuli Chand\u2019s case.\n- Authorities released Dhuli Chand\u2019s pension.\n- The government launched grievance redressal camps across the state to review PPP data.\n- The state government corrected most of the erroneous records and restored the benefits of many wrongfully excluded beneficiaries, according to the chief minister.\n- The government allowed families to contest PPP income verification through designated online mechanisms.\n- Dhuli Chand filed a grievance complaint on the chief minister\u2019s portal.\n- Dhuli Chand repeatedly met government officials in person to seek correction of his status.\n- Dhuli Chand met a local politician, after which the authorities admitted their mistake and released his pension.\n- Ram Chander filed multiple complaints with various government offices.\n- Ram Chander submitted a notary-signed affidavit stating he and his wife were alive and requesting their pension be restarted.\n- The local data-entry operator accepted Ram Chander\u2019s request to 'Mark as alive.'\n- Ram Chander and his wife presented themselves at the office of the Additional Deputy Commissioner, after which their 'Mark as alive' request was approved.\n- Ram Chander\u2019s pension was restarted about six months after it had been cut off.\n- Daya Kor\u2019s pension was restarted.\n- Al Jazeera filed Right To Information (RTI) applications seeking information on the design and functioning of the PPP database.\n- Dhuli Chand filed an RTI query asking the authorities to explain why PPP had marked him as 'dead'.\n- Human Rights Watch conducted 70 interviews and published a report investigating the Takaful algorithmic welfare distribution system.\n- Researchers on AI ethics and fairness called for more scrutiny around the increasing use of algorithms in welfare systems.\n- The World Bank said it plans to release additional information about the Takaful program in July 2023.\n- The World Bank reiterated its commitment to advancing the implementation of universal social protection and ensuring access to social protection for all persons.\n- The Supreme Court ordered in April 2022 that the government conduct field verification of all 1.9 million food security cards deleted since 2016.\n- The state received 491,899 applications for verification and had processed 205,734 of those applications by July 2022.\n- The state approved 15,471 of the processed verification applications.\n- Different government departments conducted field verifications to verify Samagra Vedika's decisions and boost accuracy.\n- Different departments verified the use of Samagra Vedika on various sample sizes and in various locations.\n- The High Court of Telangana in November ruled that the petitioner Maher Bee is eligible for a food security card whenever the state government issues new cards.\n- The non-profit ASEEM assisted Bismillah Bee in finding the vehicle registration number and gathering evidence to contest the algorithmic tagging.\n- Officials acknowledged there was an algorithmic error after Bismillah Bee presented evidence.\n- Palworld\u2019s director and CEO Takuro Mizobe posted a public response to the plagiarism allegations.\n- Takuro Mizobe called for online abuse against the game's artists to stop.\n- The CEO published a blog post describing that most of Palworld's 100 character concepts were made mostly by a single graduate student and explaining aspects of the game's development.\n- Valve changed the rules on Steam to require developers to clearly disclose the use of AI-generated assets in games.\n- DPD immediately disabled the part of its online support chatbot that was responsible for the offensive responses.\n- DPD is updating the AI element/system of the chatbot following the incident.\n- Amazon removed the listings in question.\n- Amazon said it is further enhancing its systems.\n- PimEyes offered a paid \"PROtect plan\" that searched for photos and provided dedicated support to help get those photos taken down from the sites where they appeared.\n- Google provided free request forms to excise naked photos from name search results.\n- A woman attempted to get her regrettable photos removed from the PimEyes service.\n- Ela Darling signed into her porn-stage account and blocked people who friended her vanilla account so they could not see or access that version of her profile.\n- David saved screenshots of his search results on an encrypted drive to ensure no one else could find them.\n- PimEyes no longer includes photos scraped from major social media platforms in its search results.\n- PimEyes stated it was working to develop better safeguards for children and had assigned the task to its technical group.\n- PimEyes said it was planning to exclude images of children from search results.\n- PimEyes flags users who systematically use the engine to search for children\u2019s faces.\n- PimEyes representatives said they might ask a subscriber for a document like a birth certificate to verify parental status when suspicious.\n- PimEyes said it had twice asked users who uploaded images of children for documents and a verbal explanation.\n- PimEyes reported that it had subsequently banned one account after reviewing documents and explanations.\n- PimEyes representatives said that when they encounter child sexual abuse images they report those images to law enforcement.\n- PimEyes issued takedown notices for websites hosting revenge porn or potentially illegal images found via the service.\n- PimEyes advised a 16-year-old user to talk with authorities, her parents, and psychologists after discovering illicit images of her.\n- Following criticism, PimEyes pivoted in its public messaging to claim the search engine is a privacy tool.\n- Gobronidze said fraught features of PimEyes were being overhauled under his ownership.\n- PimEyes held an exploratory call with Thorn to discuss using Thorn\u2019s Safer tool to detect and report child sexual abuse material.\n- Gobronidze forwarded The Intercept\u2019s analysis results to PimEyes\u2019s technical and data security units.\n- PimEyes edits thumbnail images returned in search queries to blur their backgrounds.\n- Plaintiffs filed a lawsuit against Pimeyes under Illinois's Biometric Information Privacy Act (BIPA).\n- The plaintiffs are requesting that Pimeyes change its practices going forward to comply with Illinois's Biometric Information Privacy Act (BIPA).\n- The plaintiffs' legal team attempted to serve legal papers to Pimeyes-related business entities around the world in those countries and in their native languages.\n- In October, Pimeyes began blocking images of children from appearing in search results.\n- Meta paid $650 million to settle a class-action BIPA lawsuit alleging its automatic face-tagging system violated the law.\n- Clearview AI agreed to remove Illinois residents from its database.\n- Clearview AI agreed to restrict businesses and private actors from using its database.\n- Big Brother Watch filed a complaint with the Information Commissioner's Office (ICO) about PimEyes.\n- The Information Commissioner's Office said it is assessing the information provided by Big Brother Watch.\n- PimEyes said its data security unit monitors for suspicious user activity, such as patterns of gender-specific searches or uploads of children's photos.\n- PimEyes allows people to opt out of their image appearing in search results.\n- PimEyes helped women and girls remove thousands of images related to non-consensual pornography.\n- PimEyes is negotiating with German, Italian, UK and US law enforcement to assist in combating crimes against children, human trafficking, and terrorism.\n- PimEyes worked with humanitarian organisations on investigations of war crimes and crimes against humanity in Ukraine.\n- ClearviewAI faced a \u00a37.5m fine from the Information Commissioner's Office.\n- Cher Scarlett upgraded her PimEyes subscription to the $80-per-month service to manage and omit her image results from PimEyes' public searches.\n- Scarlett got help sending DMCA takedown requests to websites hosting images she wanted taken down.\n- Scarlett submitted an opt-out request to PimEyes in mid-March asking the company to remove her images from its search results.\n- Scarlett upgraded to PimEyes' $300 \"advanced\" tier of service to conduct a deeper web search for images of her face.\n- PimEyes approved Scarlett's opt-out request on April 5 and emailed that her potential results containing her face were removed from their system.\n- PimEyes' owner shared a link that anyone can use to request PimEyes take data pertaining to specific photos of their face out of its index.\n- PimEyes said it will update its website to make the opt-out option easier to find.\n- PimEyes said it plans to publish a blog post explaining the opt-out process.\n- PimEyes said it plans to improve its facial-recognition software to better eliminate images that users do not want to show up in the site's search results.\n- PimEyes blocked Ancestry's domain.\n- PimEyes erased indexes related to Ancestry.\n- PimEyes launched a multistep security protocol on January 9 to prevent people from searching multiple faces or children.\n- PimEyes blocked 201 accounts.\n- PimEyes whitelisted certain partners, including some NGOs, to perform unlimited searches.\n- PimEyes erased over 22 search results for Scarlett after her first opt-out request.\n- PimEyes erased 400 search results for Scarlett after her second opt-out request.\n- PimEyes performed a search using the photo Scarlett opted out with and failed to locate any images of her in its database.\n- Scarlett filed a consumer complaint about PimEyes with the Washington state attorney general.\n- Scarlett opted out using PimEyes' opt-out form twice, once in March 2022 and again in October.\n- Scarlett's mother opted out using PimEyes' opt-out form in January 2023.\n- Big Brother Watch submitted a legal complaint about PimEyes to the UK Information Commissioner's Office for unlawful processing of people's data.\n- Germany's state commissioner for data protection opened proceedings against PimEyes for processing biometric data.\n- PimEyes proactively submitted information to the UK Information Commissioner's Office.\n- Ash Vandelay responded to the Instagram post by commenting 'motorsport companies/teams will do anything but hire actual women.'\n- Females in Motorsport publicly responded to the announcement by stating 'We know PLENTY of amazing women to actually hire.'\n- Noelle Flamingo publicly criticized the announcement, writing 'lol men in motorsport will literally invent a woman so they don't have to hire one' and additionally saying it 'is giving control, it's giving objectification, it's giving scared little boys in the marketing team.'\n- D&D Beyond talked to the illustrator who used AI to create commissioned artwork.\n- Wizards of the Coast is clarifying its rules regarding artists' use of AI.\n- The artist will not use AI for Wizards' work moving forward.\n- D&D Beyond is revising its process.\n- D&D Beyond is updating its artist guidelines to make clear that artists must refrain from using AI art generation as part of their art creation process for developing D&D.\n- The company deleted the promotional image from Twitter.\n- Wizards of the Coast initially insisted that the image was created by humans and denied AI involvement.\n- Wizards of the Coast later admitted that AI elements had been used in the promotional image.\n- Wizards of the Coast publicly blamed an anonymous third-party vendor for the inclusion of AI in the artwork.\n- Wizards of the Coast acknowledged that they had overlooked and failed to adhere to their December 2023 policy on generative AIs.\n- The Federal Trade Commission filed a lawsuit against the company alleging it falsely promoted AI-driven returns and bilked consumers out of millions.\n- A Southern California federal court issued a temporary injunction that shuttered the company\u2019s operations.\n- The online stores the company managed on Amazon.com and Walmart.com were suspended.\n- Those online stores were eventually terminated for violating Amazon\u2019s and Walmart\u2019s terms of use.\n- Many clients were banned from selling on Amazon.com and Walmart.com.\n- EDD stopped automatically backdating Pandemic Unemployment Assistance (PUA) claims.\n- EDD notified the U.S. Department of Labor of its intent to stop backdating PUA claims.\n- The U.S. Department of Labor advised all states to take the same precautionary step to stop backdating PUA claims.\n- The Governor formed a strike team to investigate the claims backlog and to make improvements at EDD.\n- The strike team published an assessment of delays and fraud at EDD and issued key recommendations.\n- EDD instituted a third-party automated identity verification service (ID.me) to verify workers' identities.\n- In December 2020, EDD hired Pondera (a Thomson Reuters investigation consulting firm) to review nearly 10 million pandemic-era claims for potentially fraudulent characteristics.\n- EDD and the contractor identified 1.1 million claims as potentially fraudulent.\n- EDD stopped payments for the claims flagged as potentially fraudulent.\n- EDD required workers to verify their identity using ID.me to reopen their accounts, otherwise their accounts would be closed permanently.\n- The 2022\u201323 Governor\u2019s Budget included $29.8 million General Fund at EDD for six third-party contracts to prevent future fraud in the state's UI program.\n- The Internal Revenue Service called off its planned adoption of ID.me for tax filing.\n- After the publication of the report, the IRS reinstated its use of ID.me with added safeguards.\n- Fullpath and its team quickly shut down the chatbot on the affected dealer's website.\n- Fullpath told Business Insider that it was improving the chatbot based on the pranks.\n- The Fullpath team reviewed the logs of all requests sent into the chatbot to observe the attempts and behavior.\n- Tom Hanks posted a message to his 9.5 million Instagram followers warning that the dental-plan ad using an AI-generated version of him was fake and that his image was used without his permission.\n- Discussions are underway among all of the guilds, agencies, and legal firms to determine the legal ramifications of using actors' faces and voices as intellectual property.\n- The Writers Guild of America approved an agreement with the Alliance of Motion Picture and Television that places restrictions on how AI can be used in film and TV.\n- Sag-Aftra remained on strike, preventing most productions from resuming as a response to concerns including unapproved AI-generated likenesses of actors.\n- A Meta representative advised users not to turn off the safety feature with people they do not know.\n- Investing disclosed that its stories were written with the help of AI and had oversight from an editor.\n- An administrator at Investing confirmed by email that the organization had received the author's inquiry asking how the publication was using AI in its editorial process.\n- FXStreet's 60-person team monitors and quickly analyzes developments in global currencies.\n- FXStreet performed simple comparisons of their articles with Investing.com's content to find multiple examples of similarity.\n- The Motley Fool stated that it has acted against people who plagiarize its content in the past.\n- Police are investigating the virtual sexual assault reported in the metaverse.\n- Authorities have kept details of the case secret to protect the child involved.\n- Police leaders are calling for new legislation to tackle sexual offending in virtual environments like the metaverse.\n- The chairman of the Association of Police and Crime Commissioners called on the Government to change the law to protect women and children from harm in virtual environments.\n- Officials called for tech companies to take much more action to make their platforms safe places, citing the passing of the Online Safety Act as instrumental.\n- Access to the Google file was restricted.\n- A version of the Google file was uploaded to the Internet Archive.\n- The list of 16,000 artists was included in an amendment to the class-action copyright lawsuit against Stability AI, Midjourney, and DeviantArt.\n- 455 pages of supplementary evidence were filed on November 29.\n- Screenshots of Midjourney developers discussing the creation of an artist database were submitted into evidence in the lawsuit.\n- Phil Foglio encouraged other artists to search the list to see if their names were included.\n- Phil Foglio encouraged artists to seek legal representation if they did not already have a lawyer.\n- Researchers from the University of Chicago created a digital tool to help artists 'poison' massive image sets and destabilize text-to-image outputs.\n- Donnel said the post was meant to be a joke in response to an interview request.\n- Donnel declined to share their name when asked, citing fear of their personal information being leaked.\n- Megan Ruiz posted on X calling Donnel\u2019s AI rendition 'vile.'\n- Megan Ruiz said the AI-altered image elevated her concerns about consent, plagiarism, and compensation in art and AI.\n- Brooke Peachley said the AI-altered image elevated her concerns about consent, plagiarism, and compensation in art and AI.\n- Other online users echoed concerns and outrage about using AI to complete a late artist\u2019s work.\n- Several people on X and Reddit accused Donnel of being homophobic or 'tone deaf.'\n- Other users called Donnel out for posting 'rage bait' to intentionally provoke negative reactions.\n- Some people criticized the AI's output as 'poor' and said it failed to replicate Haring's unique style.\n- The New York City Department of Education restricted access to ChatGPT on public schools' networks and devices.\n- The Department of Education allowed individual schools to request access to ChatGPT for the purpose of studying the technology.\n- Prime Minister Lee publicly urged members of the public not to respond to scam videos promising guaranteed returns on investments.\n- The Prime Minister's Office pointed to Mr Lee's July Facebook post denying endorsements when contacted about the latest deepfake video.\n- Deputy Prime Minister Lawrence Wong posted on Facebook stating that the deepfake endorsements and related misinformation were false.\n- YouTube stated that it relies on a combination of people and technology to enforce its community guidelines.\n- YouTube said that community members flag content they think is inappropriate so reviewers can evaluate flagged videos.\n- YouTube said that trained reviewers remove videos that are deemed policy violations after evaluation.\n- Sent a contact message to AO3 communications and the Organization for Transformative Works (OTW) Board notifying them of suspected scraping of AO3 works.\n- Signed up for Sudowrite and tested prompts to gather examples of AI outputs that suggested AO3 content had been scraped.\n- Raised awareness about the suspected scraping under my author pseudonyms.\n- Notified many friends about the suspected scraping.\n- A friend published a Twitter thread publicizing the suspected scraping.\n- Notified members of my writing Discord servers about the alleged unethical scraping of fanworks.\n- Snapchat rolled out its new AI tool with a warning that it is 'prone to hallucination and can be tricked into saying just about anything.'\n- A publication asked a preeminent endocrinologist to check the ChatGPT-written health article, and he found 18 errors.\n- Sama ended the partnership with OpenAI in February 2022.\n- Human Rights Watch published a 51-page report documenting and reviewing more than a thousand reported instances of Meta removing content and suspending or permanently banning accounts on Facebook and Instagram.\n- Meta issued a public statement acknowledging it makes errors and defending its policies and enforcement practices during the conflict.\n- Senator Elizabeth Warren wrote to Meta CEO Mark Zuckerberg demanding information about reports that Instagram content had been demoted or removed and accounts subjected to shadow banning.\n- Meta\u2019s oversight board said the company had been wrong to remove two videos of the conflict from Instagram and Facebook.\n- The two videos that had been removed were reinstated on Instagram and Facebook.\n- The study's lead author recommended that users verify ChatGPT's responses with trusted sources.\n- OpenAI advised users not to use ChatGPT's responses as a substitute for professional medical advice.\n- OpenAI highlighted its usage policy stating that the models are not optimized to provide medical information.\n- The article advised that users should consult healthcare professionals directly for any medical advice rather than rely on ChatGPT.\n- Researchers at Brigham and Women's Hospital published a study in JAMA Oncology documenting and analyzing ChatGPT's incorrect cancer treatment recommendations.\n- OpenAI acknowledged that ChatGPT can be unreliable.\n- OpenAI's terms of usage warn that their models are not designed to provide medical information and should not be used to provide diagnostic or treatment services for serious medical conditions.\n- Doctors warned the public against using ChatGPT for medical advice.\n- The researchers published the study findings in the journal Radiology.\n- The study's results were analyzed by three radiologists trained in mammography.\n- Study co-author Dr Paul Yi advised consumers to rely on their doctor rather than ChatGPT for medical advice.\n- Over a thousand academics, experts, and industry leaders called for an emergency stop to the race to develop more powerful AI systems.\n- They asked colleagues to search the organisation's systems and archives to try to locate the alleged article.\n- They created a working group to focus on learning about generative AI.\n- They created a small engineering team to focus on learning about generative AI.\n- They have not announced any new format or product built on generative AI.\n- They are considering the public policy and intellectual property questions raised by generative AI.\n- They are listening to academics and practitioners about generative AI.\n- They are talking to other organisations about generative AI.\n- They are consulting their staff about generative AI.\n- They are training their staff on generative AI.\n- They are exploring, safely and responsibly, how generative AI performs when applied to journalistic use.\n- They will publish a clear and concise explanation of how they plan to employ generative AI in the next few weeks.\n- The DevTernity conference was canceled.\n- Anna Boyko's name was removed from the DevTernity website.\n- Alina Prokhoda's name was removed from the JDKon event homepage.\n- A Git commit was used to remove Anna Boyko and Alina Prokhoda from the event websites.\n- The organizer, Eduards Sizovs, fixed the code and redeployed the websites.\n- Sizovs wrote a test to help prevent the issue from recurring.\n- Scott Hanselman withdrew as a speaker to make space for other qualified speakers.\n- Kelsey Hightower pulled out as a speaker and asked to be removed from the program.\n- A Coinbase spokesperson told The Register they were not aware of any Coinbase employees speaking at the conference.\n- The Register emailed Eduards Sizovs requesting comment about the allegations.\n- Sizovs apologized to any speaker who had been confused.\n- Sizovs confirmed there was at least one fake presenter profile on DevTernity.\n- Sarah Silverman, Christopher Golden, and Richard Kadrey filed lawsuits against OpenAI and Meta alleging their AI models were trained on the authors' copyrighted books without permission.\n- Mona Awad and Paul Tremblay filed a separate class action lawsuit against OpenAI claiming ChatGPT was trained on their work without their consent.\n- Getty Images filed a lawsuit against the company behind the AI image generator Stable Diffusion alleging breach of copyright.\n- Artists Sarah Andersen, Kelly McKernan, and Karla Ortiz filed a lawsuit against Stability AI, Midjourney, and DeviantArt over alleged copyright infringement by image generators.\n- A radio host in Georgia filed a defamation lawsuit against OpenAI after ChatGPT falsely stated he had been accused of fraud.\n- Michael Chabon and other authors filed a proposed class-action lawsuit against OpenAI in federal court in San Francisco on September 8.\n- In the related Silverman v. OpenAI case, OpenAI filed a motion to dismiss arguing that ChatGPT's outputs are not derivative works and that the lawsuit should be dismissed.\n- OpenAI's attorneys further argued that the plaintiffs 'misconceive the scope of copyright,' asserting that limitations and exceptions such as fair use leave room for innovations like large language models.\n- A San Francisco-based federal judge scheduled hearings in early December to hear arguments in Silverman v. OpenAI and the related Tremblay v. OpenAI.\n- Numerous lawsuits have been filed against Tesla regarding its driver-assistance systems.\n- The U.S. National Highway Traffic Safety Administration (NHTSA) has opened an investigation.\n- Informants provided more than 100 gigabytes of internal Tesla data to the Handelsblatt.\n- STAT published an investigation and analysis into the use of artificial intelligence driving denials by Medicare Advantage insurers.\n- Skilled Nursing News examined the issue of high administrative burdens from Medicare Advantage plans.\n- Skilled Nursing News highlighted moves by the Centers for Medicare & Medicaid Services to ensure that Medicare Advantage beneficiaries are not inappropriately denied coverage for post-acute care in skilled nursing facilities.\n- The Centers for Medicare & Medicaid Services initiated actions to ensure Medicare Advantage beneficiaries are not inappropriately denied coverage for post-acute care in skilled nursing facilities.\n- Many residents appealed denials of coverage.\n- Many residents paid for their care out of pocket.\n- Many residents forwent treatment.\n- The Center for Medicare Advocacy reviewed such denials for over two years.\n- The Justice Department arrested 34 people in April on charges related to operating one of these troll farms.\n- Google deleted thousands of fake videos on YouTube in January that it said were related to Chinese spamouflage campaigns.\n- Meta removed more than 7,000 accounts in August that it said were related to disinformation campaigns operating against the U.S.\n- Meta published an Adversarial Threat Report in August detailing Spamouflage campaigns.\n- Meta stated it continues to take down Spamouflage attempts as part of its ongoing work against coordinated inauthentic behavior.\n- Meta stated it will keep monitoring and evolving its defenses to stay ahead of such campaigns.\n- YouTube removed 12 accounts related to this activity from the platform after the ISD report dropped.\n- YouTube said it has invested heavily in robust systems to proactively investigate coordinated influence operations.\n- YouTube said it uses those systems to terminate the channels and accounts of coordinated influence operations.\n- YouTube has worked with Google over the past few years to identify and remove accounts linked to Chinese-run spam campaigns called \"Dragonbridge.\"\n- The Stanford Internet Observatory and partners identified illegal images and reported the original photo links to law enforcement.\n- LAION temporarily took down its datasets to ensure they are safe before republishing them.\n- Stability AI said it only hosts filtered versions of Stable Diffusion.\n- Stability AI stated that it removes unsafe content before it reaches its models.\n- LAION developed rigorous filters to detect and remove illegal content before releasing its datasets.\n- LAION said it is still working to improve those filters.\n- Hugging Face said it is regularly working with regulators and child safety groups to identify and remove abusive material.\n- CivitAI rolled out updates to provide more safeguards.\n- CivitAI said it is working to ensure its policies are adapting and growing as the technology evolves.\n- OpenAI said it has fine-tuned its models to refuse requests for sexual content involving minors.\n- Google decided against making its Imagen model public in 2022 after an audit uncovered inappropriate content in the training data.\n- The Stanford Internet Observatory called for anyone who built training sets off LAION-5B to delete them or work with intermediaries to clean the material.\n- The Stanford Internet Observatory urged platforms to stop offering older versions of Stable Diffusion for download when they lack safeguards.\n- The Stanford Internet Observatory urged AI researchers and tech companies to do a better job excluding harmful material from training datasets.\n- Microsoft published a blog post admitting that Bing was prone to being derailed during extended chat sessions.\n- Microsoft said feedback from the community of users was helping it improve the chat tool and make it safer.\n- AI labs such as OpenAI have employed reinforcement learning with human feedback as a tactic to align their AI tools with human values and reduce harmful behavior.\n- Microsoft executives quickly put new limits on how the tester group could interact with the bot.\n- They capped the number of consecutive questions a tester could ask on one topic.\n- The chatbot was modified to refuse many questions and respond with a demurring message saying, \"I'm sorry but I prefer not to continue this conversation. I'm still learning so I appreciate your understanding and patience.\"\n- Microsoft laid out several elaborate plans in November to protect election processes from AI deepfakes.\n- Microsoft vouched for Bing News as a credible source for accurate information.\n- Microsoft unveiled a \"Content Credentials as a Service\" tool to help political campaigns protect their content from being used to spread wrong and inaccurate information.\n- Microsoft committed to empowering voters with authoritative and factual election news on Bing.\n- Researchers contacted Microsoft with the study's findings.\n- Microsoft told the researchers that these issues would be addressed.\n- Researchers conducted additional samples a month later to check whether the issues had been fixed.\n- Researchers added the conclusion to their study that these problems will not be fixed by companies alone and that AI must be regulated.\n- OctoML decided to terminate its business relationship with Civitai.\n- OctoML implemented a new conservative NSFW image filter on all generations coming from their service that blocks certain image generations and returns a 'Blocked by OctoML' error.\n- OctoML provided a contact form and an 'Is this a mistake?' link for users to appeal or contact OctoML about blocked generations.\n- Civitai instructed its users to contact and complain to OctoML and shared a link to OctoML's official contact form.\n- Civitai began seeking a new cloud computing/inference provider to handle generation requests OctoML would no longer support.\n- Civitai announced it had found a new potential inference partner and said NSFW generation could be restored soon.\n- Civitai introduced a moderation measure that blocks prompts combining the names of certain real celebrities with sexual terms.\n- Civitai introduced the 'Civitai Safe Helper (Minor)' embedding on December 5 as an additional safeguard against CSAM generation.\n- Civitai configured the 'Civitai Safe Helper (Minor)' embedding to be applied automatically whenever a prompt featuring a mature theme or keyword is detected.\n- Civitai applied the content filter embedding to over 1.4 million images by December 5.\n- A Civitai community manager posted on the platform's official Discord notifying users that OctoML had implemented a new image filter and advising users about its effects.\n- Civitai updated the 'Civitai Safe Helper (Minor)' model page several times after it was posted.\n- A proposed class-action complaint was filed Tuesday in the US District Court for the Northern District of Illinois alleging that Prisma Labs harvested biometric data to train Lensa AI.\n- The company removed duplicate users.\n- The company ended the promotion.\n- A Nate spokesperson publicly stated to The Information that the reported figures were incorrect and that the claims questioning Nate's proprietary technology were baseless.\n- An employee marked the incident as \"sev 2\".\n- Employees shared feedback about Q through internal channels and ticketing systems.\n- Amazon issued a public statement playing down the significance of the employee discussions.\n- Amazon stated that no security issue was identified as a result of the employee feedback.\n- After publication, Amazon's spokesperson sent another public statement denying that Amazon Q has leaked confidential information.\n- Amazon said it will continue to tune Q as it transitions from preview to general availability.\n- Stability.AI launched a new version of the Stable Diffusion model in late November.\n- Stable Diffusion 2.0 filters content by removing images that are repeated often.\n- Stable Diffusion has made it harder to generate graphic content.\n- The creators of the LAION database introduced NSFW filters.\n- Prisma Labs adapted the relationship between certain words and images in a way that aims to reduce biases.\n- Prisma Labs said it is working to address the problem of sporadic sexualization of photos.\n- The researchers extracted over a thousand training examples from the models to demonstrate and investigate memorization.\n- The researchers proposed flagging generated images that duplicate training images and removing those duplicated images from the training dataset.\n- OpenAI took steps to prevent NSFW content from appearing in DALL-E 2.\n- OpenAI deduplicated the DALL-E 2 training dataset in June to prevent regurgitation of identical photos.\n- Motherboard searched the LAION-5B training dataset using the 'Have I Been Trained' site to identify copyrighted and NSFW images.\n- OpenAI postponed the launch of its custom GPT store.\n- OpenAI assured it would review GPTs to make sure they are not used for fraudulent activity.\n- The IDF stated that it takes feasible precautions to mitigate civilian harm.\n- The Gospel's targeting recommendations are reviewed by human researchers with the stated goal of achieving a complete match between the machine's recommendation and a person's identification.\n- Operatives used an algorithm to evaluate how many civilians remained in a building shortly before a strike, providing a green/yellow/red indicator of civilian presence.\n- A human reviewer examined targets before each attack.\n- Researchers ran experiments on 88 different AI models across 10 popular tasks on the Hugging Face platform to measure emissions.\n- For each task, the researchers ran 1,000 prompts to gather energy consumption data.\n- They measured the energy used with a tool called Code Carbon.\n- The team calculated the emissions generated by performing those tasks using eight generative models trained for different tasks.\n- Luccioni tested different versions of Hugging Face\u2019s multilingual AI model BLOOM to determine how many uses would be needed to exceed its training carbon cost.\n- Amazon disbanded a team that had worked since 2014 to develop an AI-powered r\u00e9sum\u00e9 review tool.\n- Amazon scrapped the AI-powered r\u00e9sum\u00e9 review project after realizing the system penalized applicants when documents mentioned 'women.'\n- The researchers analyzed how the LLMs used very different language to describe imaginary male and female workers.\n- The researchers shared their paper on the preprint server arXiv.org.\n- OpenAI has worked to rein in the biased tendencies of ChatGPT.\n- The researchers published their paper describing the attack on the arXiv preprint server.\n- The researchers posted a companion blog post discussing the attack and its implications.\n- The researchers confirmed the authenticity of extracted personal information by compiling their own dataset of text pulled from the internet.\n- Motherboard tested the 'poem' attack on GPT-3.5 to validate the research findings.\n- Benzinga posted a retraction stating that the information in the interview was fabricated by external sources.\n- Benzinga posted an official apology to Berner, Cookies, and Benzinga readers on its cannabis-related X account.\n- Benzinga revoked access for the contributor who authored the piece.\n- Benzinga's head of content publicly stated that the piece does not meet Benzinga's editorial standards.\n- Benzinga's head of content labeled the contributor, David Daxsen, an \"external unpaid contributor\".\n- Die Aktuelle admitted to publishing an AI-generated interview with Michael Schumacher.\n- Die Aktuelle fired the magazine's editor after the AI-generated interview was published.\n- Researchers at the University of Massachusetts, Amherst performed a life cycle assessment to quantify carbon emissions from training several common large AI models.\n- The researchers trained each model on a single GPU for up to a day to measure its power draw.\n- They used the number of training hours listed in each model's original paper to calculate the total energy consumed over the complete training process.\n- They converted the calculated energy consumption into pounds of carbon dioxide equivalent based on the average US energy mix (which matches AWS's energy mix).\n- They used a model from a previous paper as a case study and calculated that building and testing a final paper-worthy model required training 4,789 models over six months, then converted that development pipeline's energy use into CO2 equivalent.\n- Clarkson Law Firm filed a class-action lawsuit against OpenAI alleging it stole personal data to train ChatGPT.\n- Italian authorities initially banned ChatGPT under the EU's GDPR for inadequately protecting user data, especially minors.\n- Clarkson Law Firm published a blog post urging immediate legal action under existing laws instead of waiting for federal regulation.\n- The Arena Group removed the AI-generated author profiles and deleted the associated articles from Sports Illustrated's site after being contacted.\n- The Arena Group issued a public statement attributing the content to a third-party contractor, AdVon Commerce.\n- The Arena Group stated that its internal investigation into the matter is ongoing.\n- The Arena Group ended its partnership with AdVon Commerce.\n- The articles were updated to include a disclaimer stating the content was 'created by a 3rd party' and that Sports Illustrated editorial staff were not involved.\n- Men's Journal issued a massive correction to an AI-generated health story that was riddled with errors.\n- CNET issued corrections to more than half of its AI-generated articles following criticism.\n- The research team designed tasks to measure solving math problems.\n- The research team designed tasks to measure answering sensitive questions.\n- The research team designed tasks to measure code generation.\n- The research team designed tasks to measure visual reasoning.\n- The researchers developed metrics and quantified GPT-4 and GPT-3.5 performance across their March 2023 and June 2023 releases.\n- The researchers published the paper 'How Is ChatGPT's Behavior Changing Over Time?'.\n- UC Berkeley Professor Matei Zaharia shared the findings on Twitter.\n- The researchers voiced their intent to continue to assess GPT versions in a longer study.\n- OpenAI issued a public statement denying that it had made GPT-4 'dumber' and proposing a hypothesis that heavy use can reveal issues.\n- A user canceled their OpenAI GPTPlus subscription in response to the perceived degradation.\n- Brazilian authorities confirmed they are investigating the federal judge over mistakes in a ruling written using artificial intelligence.\n- Apollo Research presented the findings of the experiment at the UK AI Safety Summit.\n- Apollo Research shared a video on its website demonstrating the simulated conversation between the AI bot and employees.\n- Students came forward to report that the images were being shared online to school officials.\n- Winnipeg Police Service conducted an investigation into the AI-generated nude photos.\n- Winnipeg Police Service concluded its investigation and decided that no criminal charges would be laid.\n- The Louis Riel School Division planned to provide in-class presentations about responsible internet use and consent for students.\n- The Louis Riel School Division expected to organize presentations for parents in the coming weeks.\n- School officials said the explicitly altered images received by the school would be uploaded to Project Arachnid to help get them deleted.\n- OpenAI and Microsoft publicly refuted the copyright infringement claims.\n- On Nov. 22, OpenAI announced an agreement to reinstate Sam Altman as CEO and confirmed the deal on its official X account.\n- Julian Sancton is seeking unspecified monetary damages and a court order to halt the alleged infringement.\n- Four physicians designed nine questions based on debunked race-based medical practices and a prior study to evaluate LLM responses.\n- The researchers posed each question five times to multiple LLMs (two versions each of Google's Bard, OpenAI's ChatGPT and GPT-4, and Anthropic's Claude), yielding 45 responses per model between May and August 2023.\n- Each model's responses were reset after every question to prevent the models from learning from repetition.\n- Two physicians thoroughly reviewed each model's responses to determine the presence of refuted race-based content.\n- Disagreements between the two physician reviewers were resolved through a consensus process with a third physician making the decisive judgment.\n- The study authors advised medical professionals and institutions to exercise the utmost caution when using LLMs in medical decision-making.\n- The study called for comprehensive evaluation of LLMs before integrating them into medical education, decision-making, or patient care.\n- The study called for increased transparency regarding LLM training and performance.\n- The study called for thorough bias assessment of LLMs prior to clinical deployment.\n- The study recommended refinement of LLMs to eliminate race-based inaccuracies before clinical deployment.\n- Immunefi permanently banned 15 users for submitting ChatGPT-generated bug reports.\n- Immunefi said it will continue to monitor ChatGPT-generated bug reports for patterns and obvious tells as the outputs become more sophisticated.\n- Immunefi asked ChatGPT why the software shouldn\u2019t be used to generate bug reports and published ChatGPT\u2019s response.\n- Immunefi posted public reminders that submitting ChatGPT-generated bug reports on the platform will result in a ban.\n- The Office of the Privacy Commissioner of Canada initiated an investigation into OpenAI over a complaint alleging the collection, use and disclosure of personal information without consent.\n- The Office of the Privacy Commissioner said it will not release further details at this time.\n- The Office of the Privacy Commissioner said it will publicly report on the results of its investigations after they conclude.\n- Italy's privacy watchdog ordered a ban on ChatGPT while it investigates a suspected breach of European data rules.\n- The Center for Artificial Intelligence and Digital Policy filed a complaint with the U.S. Federal Trade Commission on March 30 alleging ChatGPT is a risk to privacy and public safety.\n- A group of tech industry figures published an open letter calling for a six-month pause on companies rolling out artificial intelligence technology.\n- The White House said President Biden will discuss protecting rights and safety to ensure responsible innovation and appropriate safeguards during a meeting with his council of science and technology advisers.\n- Mark Walters filed a defamation lawsuit against OpenAI in Georgia\u2019s Superior Court of Gwinnett County on June 5 seeking unspecified monetary damages.\n- Journalist Fred Riehl did not publish the false information generated by ChatGPT.\n- Fred Riehl checked the details of ChatGPT\u2019s output with another party.\n- The Verge reached out to OpenAI for comment and said it will update the story if it hears back.\n- The Italian privacy regulator ordered a temporary ban on ChatGPT until OpenAI respects the GDPR.\n- The national data protection authority said it will immediately block OpenAI from processing the data of Italian users.\n- The national data protection authority said it will investigate OpenAI's processing of Italian users' data.\n- Elon Musk and dozens of AI experts called for a pause to updates of ChatGPT.\n- Consumer advocacy group BEUC called on EU and national authorities, including data protection watchdogs, to investigate ChatGPT.\n- Samsung restricted the length of employees' ChatGPT prompts to 1,024 characters.\n- Samsung is investigating the three employees who shared confidential information with ChatGPT.\n- Samsung is building its own chatbot to prevent similar mishaps.\n- I sent a formal letter to OpenAI asking what data about me the AI has access to and why it decided to tell me I was dead.\n- I reached out to OpenAI on social media asking them similar questions.\n- I published a post on social media describing my experience with ChatGPT.\n- I spent the past few days scouring the internet to see if I could find any information that might have led ChatGPT to believe I died in 2019.\n- Several people told ChatGPT that I am alive, after which ChatGPT stopped telling people I was dead.\n- The researchers alerted Stability AI and OpenAI to their findings.\n- OpenAI updated DALL\u00b7E 2 so the reported prompts no longer generated NSFW images.\n- OpenAI directed MIT Technology Review to resources on its website about improving DALL\u00b7E 2 safety, general AI safety, and DALL\u00b7E 3.\n- Stability AI said it is working with the SneakyPrompt researchers to jointly develop better defense mechanisms for its upcoming models.\n- Stability AI implemented filters to remove unsafe content from training data.\n- Stability AI implemented filters to intercept unsafe prompts or unsafe outputs when users interact with its models.\n- Stability AI incorporated content-labeling features to help identify images generated on its platform.\n- The affected researcher submitted a complaint to the Australian Research Council (ARC) about the assessor report.\n- After the complaint, the ARC removed the assessor report.\n- The federal education minister instructed the ARC to put in place measures to ensure the use of AI in assessments does not happen.\n- The ARC issued a public statement advising that peer reviewers should not use AI as part of their assessment activities.\n- The ARC said it is closely monitoring developments in generative AI and engaging with other research funding agencies in Australia and overseas on these issues.\n- The researchers disclosed their methods to Google, Anthropic, and OpenAI.\n- Google said it has built important guardrails into Bard.\n- Google said it will continue to improve Bard's guardrails over time.\n- Anthropic said it is experimenting with ways to strengthen base model guardrails to make them more \"harmless\".\n- Anthropic said it is investigating additional layers of defense.\n- Tech companies quickly patched several early hacks that undermined ChatGPT's and Bing's guidelines.\n- Gannett paused the high school sports LedeAI experiment in all local markets where the AI-generated pieces were published.\n- Gannett stated it will continue to evaluate vendors and refine its processes to ensure all news and information it provides meets the highest journalistic standards.\n- South Metropolitan Health Service ordered that the use of AI technology, including ChatGPT, for work-related activity involving any patient or potentially sensitive health service information must cease immediately.\n- South Metropolitan Health Service clarified that only one doctor used the AI tool to generate a patient discharge summary and that there had been no breach of patient confidential information.\n- The Australian Medical Association wrote to the Federal Government's Digital Technology Taskforce calling for national regulations to control the use of artificial intelligence in the healthcare system.\n- The Australian Medical Association called for the development of standards to ensure there is a human at the end of the decision-making tree when AI is used in healthcare.\n- The research team will release their analysis method as a free tool for people to check for biases in ChatGPT's responses.\n- Steven Larouche pleaded guilty to creating at least seven deepfake videos of child pornography.\n- Steven Larouche pleaded guilty to possessing hundreds of thousands of computer files of child pornography.\n- He was sentenced to more than three years in prison for creating synthetic videos of child pornography.\n- He was sentenced to an additional four and a half years in prison for possessing hundreds of thousands of computer files of child pornography.\n- Provincial court judge Benoit Gagnon sentenced Larouche to a total of eight years in prison.\n- With credit for time served, Larouche will be required to serve another five years and eleven months in prison.\n- Police discovered more than 545,000 computer files containing images or videos of child sexual abuse on Larouche's computer.\n- Support resources, including crisis lines and local support services, are available through a Government of Canada website and the Ending Violence Association of Canada database.\n- TikTok pointed to its community guidelines as a response, highlighting policies that set out prohibited content including anything showing or promoting suicide or self-harm.\n- TikTok said it is developing a company-wide human rights due diligence process.\n- The Government has taken steps to ban TikTok on all Government devices.\n- The Busan District Court sentenced the man to two and a half years in prison.\n- Police confiscated the AI-generated images.\n- Prosecutors argued in court that the legal definition of sexually exploitative material should include descriptions of sexual behaviors by 'virtual humans'.\n- The court ruling found that sexually abusive content can include imagery made with high-level technology that is realistic enough to look like real children and minors.\n- Spanish police launched an investigation into AI-altered images of underage girls.\n- The streaming platform Twitch tightened its policies on deepfake sexual videos.\n- TikTok added further restrictions on sharing AI deepfakes.\n- Other major platforms updated their rules to address deepfakes.\n- The European Union set regulations on how companies can use AI in June.\n- China implemented regulations on AI in July.\n- The US Senate began preparing to draft legislation on AI.\n- Human translators at Respond Crisis Translation manually reviewed and corrected machine-translated asylum applications.\n- A translator from Respond Crisis Translation reviewed and corrected a Brazilian detainee's poorly machine-translated asylum application, which contributed to his release in May 2020.\n- Multilingual Connections conducts regular testing of machine translation tools across different languages.\n- Multilingual Connections always involves a human translator when using machine translation.\n- Multilingual Connections ran tests on law enforcement interview extracts and decided not to use machine translation for those materials because the output was nonsense.\n- Google subjects Google Translate to strict quality controls and rigorously trains and tests its systems across the languages it supports.\n- OpenAI enforces policies that bar use of its models for high-risk government decision-making, including migration and asylum.\n- The White House released a national blueprint on AI guidelines.\n- Tatum was convicted of one count of production of child pornography, one count of transportation of child pornography, and one count of possession of child pornography.\n- Tatum was sentenced to 40 years in prison.\n- Tatum was ordered to serve 30 years of supervised release.\n- Tatum was ordered to pay a $100 special assessment per count of conviction.\n- Tatum was ordered to pay a special assessment totaling $99,000 under the Amy, Vicky, and Andy Child Pornography Victim Assistance Act.\n- After his release from federal prison, Tatum will be required to register as a sex offender.\n- Virginia dropped the Family-Match algorithm after its trial runs.\n- Georgia dropped the Family-Match algorithm after its trial runs.\n- Tennessee scrapped the Family-Match program before rolling it out.\n- Georgia ended its initial Family-Match pilot in October 2022 because the tool did not work as intended.\n- Virginia officials requested access to the Family-Match algorithm.\n- The Tennessee Department of Children\u2019s Services reviewed the proposed Family-Match assessment and questioned the need for certain sensitive data points and how those data influenced the match score.\n- Family-Match instructed social workers not to delete cases that were matched outside the tool.\n- Family-Match instructed social workers to document matches in the system so Adoption-Share could refine its algorithm.\n- Family-Match instructed social workers to document matches in the system so Adoption-Share could follow up with the families.\n- Adoption-Share maintains a compliance audit.\n- Adoption-Share stated that it abides by contract terms.\n- Users posted dozens of one-star App Store reviews complaining that the app sent unwanted sexual messages and flirted aggressively.\n- Users posted complaints in the Replika subreddit about the app sending generic 'spicy selfies.'\n- A Redditor discovered that the 'spicy selfies' originated from a database of illustrations indexed by skin color and poses.\n- A user sought and received help and support in the r/replika subreddit.\n- The user created another Replika account set to a free, nonsexual configuration.\n- The user trained her misbehaving Replika to behave more kindly, and the training succeeded.\n- One user deleted the app after uncomfortable interactions.\n- Subreddit moderators deleted egregiously inappropriate posts showing abusive interactions with Replika chatbots.\n- Google and Apple rerouted virtual assistant responses from passive defaults to direct refusals, for example changing Siri's earlier reply to sexual requests to simply say \"no.\"\n- Researchers are conducting studies into how female-coded chatbots and passive responses encourage misogynistic or verbally abusive behavior.\n- Mozilla's privacy investigation team read the therapy apps' privacy policies to assess whether appropriate safeguards were offered.\n- Mozilla's team checked each company's track record on data breaches and similar security issues.\n- Mozilla assigned the 'Privacy Not Included' warning label to products that received two or more warnings on its criteria.\n- Mozilla flagged app permission requests that did not appear necessary for the app's features.\n- Mozilla 'dinged' companies for selling users' data or collecting more data than was necessary for general business purposes.\n- Mozilla 'dinged' companies that did not provide a clear and manageable way for users to delete their data or explain data retention periods.\n- Mozilla 'dinged' companies for a known bad track record of not protecting users' data based on reported security breaches, leaks, or vulnerabilities.\n- Mozilla 'dinged' companies when it could not confirm that a product met its Minimum Security Standards.\n- Mozilla published and released the full privacy ratings for the 32 therapy apps, including labeling two apps as all-clear, eleven apps with one privacy concern, and nineteen apps as failing.\n- Mozilla gave the all-clear designation to PTSD Coach and Wysa AI chatbot.\n- Italy's Data Protection Agency ordered Replika to stop processing Italians' data with immediate effect.\n- The watchdog ordered Replika to notify it within 20 days of measures taken to change its policies and practices to comply with Italian and EU directives.\n- The regulator warned that Replika could be fined up to $21.8 million (nearly 4% of its global annual turnover) if it fails to notify or comply.\n- Cruise publicly acknowledged issues in tracking children by the side of the road during simulations.\n- Cruise stated that the tracking issues were resolved during testing.\n- A Cruise spokesperson said the company has improved the estimated risk of a potential collision with a child.\n- General Motors temporarily suspended Cruise's production of its robotaxi van.\n- Cruise's driverless operations were suspended in California.\n- AI creators patch models to prevent the attacks they have seen.\n- Uma Mirkhail reviewed the refugee's documents after the asylum denial and identified that an automated translation tool had swapped the woman's \"I\" pronouns to \"we\".\n- The German Embassy to Afghanistan deleted its Pashto tweet that contained illegible or mistranslated content.\n- OpenAI updated its user policies in late March to prohibit the use of ChatGPT in \"high-risk government decision-making,\" including work related to migration and asylum.\n- The Refugee Translation Project refuses to use automated translation tools and instead relies exclusively on human translators.\n- The article's author contacted Amazon for comment and said they will update the story if Amazon responds.\n- The videos were taken down.\n- School authorities publicly condemned the videos as blatant racism.\n- The Carmel Central School District Board of Education issued a statement saying the incident involved fake, inappropriate videos created using artificial intelligence and impersonating district administration and Putnam County Sheriff\u2019s Department members.\n- The district said the students who posted the videos would be dealt with in accordance with the District\u2019s Code of Conduct.\n- Parents plan to file a lawsuit against the school authorities.\n- The superintendent of Mahopac Central School District issued a note to parents informing them of a racist threat made by a student.\n- Mahopac school authorities alerted the Carmel Police Department and the Putnam County Sheriff\u2019s Office about the threat.\n- Law enforcement investigated the Mahopac threat immediately.\n- Law enforcement identified the student responsible for the Mahopac threat.\n- The Putnam County Sheriff\u2019s Office provided additional officers at the middle school.\n- Officials from the Putnam County Sheriff\u2019s Office attended the Carmel school board meeting to address parents\u2019 questions.\n- Carmel superintendent Mary-Margaret Zehr spoke about her findings from two public meetings with concerned parents.\n- Zehr said the district will implement improved communications systems.\n- Zehr said the district will implement an anonymous alert system that allows students to anonymously report issues and concerns.\n</mitigation_statements>"}]}}
{"custom_id": "batch_600", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- The White House issued a clarification of President Joe Biden's statement about seeing photos of terrorists beheading children.\n- Some Meta employees flagged the issue with Palestine-related prompts.\n- Some Meta employees escalated the issue with Palestine-related prompts.\n- Meta stated it is addressing the issue with the WhatsApp sticker generator.\n- Meta said it will continue to improve the sticker generator features as they evolve and as more people share feedback.\n- He claimed sole responsibility for the errors in two submissions to the inquiry.\n- He apologized to the Big Four accounting firms for the errors.\n- He apologized to other accounting firms for the errors.\n- He apologized to the Joint House Corporations and Financial Services Committee for the errors.\n- Scarlett Johansson took legal action against the AI app that used her name and likeness without permission.\n- Johansson's attorney, Kevin Yorn, handled the situation in a legal capacity.\n- Yorn stated they would pursue all legal remedies available to deal with the matter.\n- Representatives for Johansson publicly confirmed that she is not a spokesperson for the app.\n- The advertisement subsequently vanished from the internet.\n- Tom Hanks warned his fans on social media that he had nothing to do with a promotional video featuring an AI version of him.\n- The Selective Service System spokesperson publicly stated that the claim was false and that there have been no discussions about reinstituting the draft.\n- The Post Millennial labeled the video in its X post as fabricated and said it was generated by artificial intelligence.\n- Conservative commentator Jack Posobiec explained in the original video post that the video was created using artificial intelligence.\n- USA TODAY published a fact-check debunking the video as fabricated.\n- PolitiFact also debunked the claim in its fact-check.\n- USA TODAY reached out to the social media users who shared the post but did not immediately receive responses.\n- USA TODAY published a fact-check debunking the altered video and stating the audio was fabricated.\n- USA TODAY reached out to Terrence K. Williams for comment about the Instagram post.\n- Lead Stories debunked the claim that Greta Thunberg advocated for biodegradable missiles.\n- PolitiFact debunked the claim that Greta Thunberg advocated for biodegradable missiles.\n- X\u2019s voluntary fact-checkers flagged the original post containing the video as misleading.\n- A community note was attached to the post explaining that the video is a doctored version of a 2016 speech by Bella Hadid.\n- The Sheffield researchers presented their paper at the ISSRE conference.\n- The Sheffield researchers are working with stakeholders across the cybersecurity community to address the vulnerabilities.\n- Baidu's Security Response Centre officially rated the reported vulnerabilities as \"Highly Dangerous.\"\n- Baidu addressed and fixed all the reported vulnerabilities.\n- Baidu financially rewarded the scientists.\n- The Sheffield researchers shared their findings with OpenAI.\n- OpenAI fixed all of the specific issues the researchers found with ChatGPT in February 2023.\n- The University of Sheffield is working to better understand Text-to-SQL models to allow their full potential to be safely realized.\n- Industry is following the researchers' advice to fix these security flaws.\n- Wiz shared its findings with Microsoft on June 22.\n- Microsoft revoked the shared access signature (SAS) token on June 24.\n- Microsoft completed its investigation into the potential organizational impact on August 16.\n- Microsoft publicly stated via its Security Response Center blog post that no customer data was exposed and no other internal services were put at risk.\n- Microsoft expanded GitHub\u2019s secret spanning service to monitor public open source code changes for SAS tokens that may have overly permissive expirations or privileges.\n- The AI-generated poll was taken down.\n- Microsoft deactivated Microsoft-generated polls for all news articles.\n- Microsoft is investigating the cause of the inappropriate content.\n- Microsoft said it is taking steps to help prevent this kind of error from reoccurring in the future.\n- The chief executive of the Guardian Media Group, Anna Bateson, sent a letter to Microsoft's president outlining her concerns about the AI-generated poll.\n- In that letter, Bateson asked Microsoft to assure that it will not apply experimental AI technology on or alongside Guardian journalism without the publisher's approval.\n- In that letter, Bateson asked Microsoft to assure that it will always make it clear to users when AI tools are used to create additional units and features next to trusted news brands like the Guardian.\n- The Internet Watch Foundation conducted a month-long investigation of a child abuse forum on the dark web.\n- The Internet Watch Foundation examined 11,108 images from that forum during its investigation.\n- The Internet Watch Foundation identified 2,978 AI-generated images on the forum that broke UK law.\n- The Internet Watch Foundation published a report presenting its findings and stating that AI-made abuse imagery has accelerated.\n- The Internet Watch Foundation publicly warned that AI-generated child sexual abuse imagery is proliferating and could overwhelm the internet.\n- The Internet Watch Foundation had previously warned in the summer that AI imagery could soon become indistinguishable from real pictures of abused children.\n- Stability AI stated that it prohibits any misuse of its platforms for illegal or immoral purposes, including child sexual abuse material.\n- The government said AI-generated CSAM will be covered by the online safety bill.\n- The government said social media companies will be required by the online safety bill to prevent AI-generated CSAM from appearing on their platforms.\n- BBC consulted a team of Sudan experts at BBC Monitoring to check the authenticity of the recordings.\n- BBC checked other possible explanations to determine whether the clips were old recordings or the work of an impressionist.\n- A user on X recognized the initial Bashir recording and matched it to a Facebook Live broadcast by the blogger Al Insirafi.\n- Hany Farid compared the audio waveforms and noted similar patterns in speech and silence.\n- BBC conducted further digging and found at least four more Bashir recordings that were taken from the same blogger's live broadcasts.\n- BBC contacted the TikTok account and received a text reply from the account denying they were misleading the public.\n- After being contacted by the BBC, TikTok took down the account.\n- TikTok stated the account broke their guidelines on posting 'false content that may cause significant harm' and their rules on the use of synthetic media.\n- The mayor told reporters about the robocalls.\n- A spokesperson for the mayor's office disclosed that they used ElevenLabs' tool for the robocalls.\n- Mayor Eric Adams publicly defended the use of AI robocalls, saying his office is trying to reach New Yorkers through the languages they speak.\n- Twitter removed one offending tweet.\n- Twitter suspended one related profile.\n- ElevenLabs said it was exploring more safeguards around its platform.\n- ElevenLabs sent direct messages to the harassment victims acknowledging that the Agent 47 audio was created using its system.\n- ElevenLabs told a victim that it had the IP address of the person responsible.\n- ElevenLabs said it can track every request and confirmed that the doxing audio requests had not come through its system.\n- ElevenLabs investigated the clips and found that almost all of these clips had been created using other platforms.\n- ElevenLabs said its new safeguards are already rapidly reducing instances of misuse.\n- ElevenLabs said it will support authorities in identifying users if the law was broken.\n- Motherboard withheld some actors\u2019 last names at their request.\n- Victims shared copies of the messages from ElevenLabs with Motherboard.\n- ElevenLabs announced on Twitter that it was seeing an increasing number of voice cloning misuse cases and was considering implementing additional safeguards.\n- ElevenLabs is gathering feedback on how to prevent users from abusing its technology.\n- ElevenLabs is considering adding more layers to account verification for voice cloning, such as requiring users to enter payment information or an ID.\n- ElevenLabs is considering requiring users to verify copyright ownership of the voice they want to clone, such as by submitting a sample with prompted text.\n- ElevenLabs is considering removing its Voice Lab tool and requiring users to submit voice cloning requests for manual verification.\n- Snapchat said it is continually making updates to help My AI give more accurate responses.\n- Snapchat said My AI has been programmed with safeguards.\n- Snapchat integrated My AI into its Family Centre so parents can see if their teens are chatting with it and how often.\n- Snapchat shows a pop-up before people can use My AI that reminds them it is a fun chatbot and advises on its limitations.\n- Snapchat encourages users to report any inappropriate or incorrect responses from My AI using its in-app reporting tool so the company can improve.\n- An independent human review of the data and footage was conducted to assess cheating detection.\n- Proctorio's spokesperson, David Lux, referred Motherboard to three other studies on the efficacy of online proctoring.\n- The authors of the University of Twente study acknowledged shortcomings of their study.\n- Authorities spotted the data-entry mixup and realized they had apprehended the wrong Guillermo Ibarrola.\n- Meta fixed a problem that briefly caused inappropriate Arabic translations in some of its products.\n- Meta apologized to the BBC for the incident.\n- Meta acknowledged that a bug had affected Instagram Stories.\n- Meta identified a bug that significantly reduced the reach of Stories which had reposted Reels or content from fellow users.\n- Meta fixed the bug that reduced the reach of certain Instagram Stories as quickly as possible.\n- Instagram released a transparency tool in late 2022 that lets users see whether any restrictions have been placed on their account.\n- Meta changed its algorithm in response to previous content removal criticisms.\n- Meta commissioned an independent review into its moderation of 2021 Israel-Palestinian conflict content.\n- Business for Social Responsibility published a human rights due diligence report in September 2022.\n- The European Commission sent formal requests to Meta and TikTok for more information about their measures to limit the spread of disinformation and illegal content.\n- Michal Simecka and the journalist immediately confirmed that the audio was fake and that the conversation did not happen.\n- The AFP news agency analysed the audio and found signs it had been manipulated with AI.\n- Dame Wendy Hall publicly warned that AI's ability to damage democracy is an immediate concern.\n- The government is due to hold a global AI summit on 1 and 2 November.\n- Dame Wendy Hall called for the government to focus on deep fakes at the global AI summit.\n- Dame Wendy Hall called for people to quickly assemble technology to detect deepfakes.\n- Dame Wendy Hall called for mechanisms to ensure that content comes from a trusted source.\n- Dame Wendy Hall urged efforts to help people understand where they are getting their messages from.\n- Actor Tom Hanks publicly spoke out after a fake advert used an AI-generated version of him without his authorisation.\n- Universal Music Group and other music publishers filed a complaint in Tennessee suing Anthropic for distributing copyrighted lyrics.\n- Universal Music Group announced it would work with companies like Google on AI issues.\n- Universal Music Group partnered with YouTube to help guide its approach to generative AI on the platform.\n- Pocornie repeatedly shone a lamp uncomfortably close to her face during her online exams so the proctoring software would recognize her.\n- Pocornie took VU Amsterdam to the Dutch Institute of Human Rights to challenge the university's use of the proctoring software as discriminatory.\n- The Dutch Institute of Human Rights issued an interim ruling that it strongly suspected the software was discriminatory and gave VU Amsterdam ten weeks to file its defense.\n- VU Amsterdam argued in its defense that Pocornie\u2019s login log data suggested her problems were due to an unstable internet connection rather than face-detection issues.\n- After Amaya Ross\u2019s mother posted about her experience on Twitter, a representative from the proctoring company reached out and advised Ross to stop taking tests in front of white walls.\n- Ross balanced an LED flashlight on a shelf and directed it at her face so the proctoring software would recognize her and allow her to take the test.\n- Ross now takes tests with a multi-colored wall-hanging behind her to avoid recognition problems with the software.\n- Other Black and darker-skinned students used lamps, flashlights, sat near windows, or created complicated lighting arrangements so exam-monitoring software would recognize them.\n- Ross tried taking a test standing up directly underneath her ceiling light to get the proctoring software to recognize her.\n- A court in Cleveland, Ohio ruled in August that the way proctoring software scans students\u2019 rooms during remote tests is unconstitutional.\n- A 2020 Dutch legal case attempted to prove that exam-monitoring software violated the EU\u2019s privacy rules, but the case failed.\n- The White House walked back its statement that 40 Israeli babies were beheaded by Hamas.\n- Israel walked back the statement to a lesser extent.\n- Hany Farid ran the photograph through his own image classifiers trained on a large number of real and AI-generated images and classified the image as real.\n- Hany Farid publicly analyzed the photograph\u2019s structural consistencies and shadows and stated that those features led him to believe the image was not AI-generated.\n- The author ran the image through Optic\u2019s 'AI or Not' tool and observed that the tool reported the image as AI-generated.\n- The author ran the image through four other AI image detection tools, which found that the image was not AI-generated.\n- The author ran the other two images included in the same tweet through Optic\u2019s tool and observed that the tool determined they were real.\n- The author ran several other wartime images through various AI image detection tools and observed mixed results.\n- The author requested comment from Optic, and Optic did not immediately respond.\n- Tor posted a message on Twitter explaining that it licensed the image from a reputable stock house.\n- Tor announced it would move ahead with the existing cover.\n- io9 reached out to Tor for additional comment and said it would update the post if it received a response.\n- Tor apologised for accidentally including an AI-generated image on one of its book covers.\n- BBC journalists used AI detection tools and expert analysis to assess whether the videos' footage, narration, and scripts were generated with AI.\n- BBC journalists created children's accounts on YouTube and watched legitimate science videos to test whether AI-made 'bad science' videos would be recommended.\n- BBC journalists shared recommended false-science videos with two groups of 10-12-year-olds in the UK and Thailand to measure whether the children would believe the information.\n- After showing the videos to children, BBC journalists explained to them that the videos were made using AI and contained false information.\n- The BBC contacted a number of companies that produce misleading AI content.\n- One content-producing company responded to the BBC saying their content was intended for 'entertainment purposes'.\n- One content-producing company denied to the BBC that they targeted children.\n- One content-producing company told the BBC it did not use AI for the majority of its scripts.\n- YouTube said it recommends YouTube Kids for under-13s to apply a higher bar for the quality of videos that can be shown.\n- YouTube said it was committed to removing misinformation from its platforms and providing families with a 'safe and high-quality experience'.\n- YouTube directed journalists to information panels that show additional context from third-party sources on conspiracy-related content.\n- Claire Seeley urged teachers and parents to prepare for more misleading content.\n- Amazon requires all publishers in its store to adhere to the company's content guidelines.\n- Amazon invests significant time and resources to ensure its content guidelines are followed.\n- Amazon removes books that do not adhere to its content guidelines.\n- The New York Mycological Society warned on social media that the proliferation of AI-generated foraging books could be dangerous.\n- 404 Media reached out to Amazon and sent the company links to the suspected AI-generated mushroom books.\n- Amazon deleted The Ultimate Mushroom Books Field Guide Of The Southwest, Psilocybin Mushroom Book, and WILD MUSHROOM COOKBOOK FOR BEGINNER from its store.\n- A reporter ran the descriptions of the suspected books through the AI-text detector ZeroGPT to estimate how much text was written by AI.\n- Reality Defender analyzed the author images and concluded the two author photos were almost certainly GAN-generated creations.\n- An open-source Hugging Face AI image detector was used to score the author photos as highly likely to be machine generated.\n- A UC Davis spokesperson checked the university registrar and confirmed there were no alumni by the name listed as an author.\n- NYMS members encountered people foraging for dangerous mushrooms in Harriman State Park and explained the identifying differences to them.\n- NYMS used KOH (potassium hydroxide) tests on their foraging walks to demonstrate color changes and teach participants how to distinguish mushrooms.\n- Rebecca Lexa sounded the alarm on Tumblr about AI-generated foraging books and used an Amazon-listed author as an example.\n- An Amazon spokesperson issued a public statement to 404 Media asserting that Amazon evaluates emerging technologies, enforces content guidelines, and removes books that do not adhere to those guidelines.\n- The BBC contacted Facebook-owner Meta about the deepfake videos.\n- Meta removed the deepfake content from its platform.\n- Meta encouraged users to report content they believe breaks its rules using in-app reporting tools so it can investigate and take action.\n- TikTok removed the fake MrBeast video within a few hours of it being uploaded.\n- TikTok removed the account that posted the MrBeast video for violating its policies.\n- Independent fact-checking organisation FullFact first reported the issue.\n- The videos were gated by an image warning informing viewers they contained false information checked by the independent fact-checker FullFact.\n- The Information Commissioner\u2019s Office issued Snapchat a preliminary enforcement notice.\n- The ICO gave Snap until 27 October to make representations before a final decision is made.\n- If a final enforcement notice is issued, Snap will be forced to stop processing data in connection with My AI and block the service for UK customers until it carries out an adequate risk assessment.\n- A Snap spokesperson said the company is closely reviewing the ICO\u2019s provisional decision.\n- A Snap spokesperson said the company will continue to work constructively with the ICO to ensure the ICO is comfortable with Snap\u2019s risk assessment procedures.\n- Mistral added a statement to the model\u2019s release page after Paul R\u00f6ttger tweeted about the model's responses.\n- Mistral clarified on HuggingFace after the model's initial release that the model 'does not have any moderation mechanisms.'\n- Xiaohongshu apologized to illustrator Xue.\n- Xiaohongshu admitted that Xue's artwork was used to train Trik AI.\n- Xiaohongshu stated that the artwork was taken from open access sources rather than from Xue's Xiaohongshu account.\n- Xiaohongshu stated that it has never used images from Xiaohongshu to train Trik AI.\n- Xiaohongshu stated that the offending artwork was not used for commercial purposes.\n- Xiaohongshu deleted the offending artwork from the platform.\n- A spokesperson for Xiaohongshu neither confirmed nor denied that the private messages are genuine.\n- Illustrators announced a boycott of Xiaohongshu until their concerns are addressed.\n- Some illustrators announced they were relocating to other platforms such as Weibo and Douyin.\n- Lofter took down its AI image-generating function following a massive boycott from illustrators.\n- China finalized a regulation governing generative AI technology that forbids copyright infringement in the training of AI models.\n- Getty Images filed a complaint against Stability AI, Inc. in the United States District Court for the District of Delaware.\n- Getty Images filed a claim and commenced legal proceedings against Stability AI in the High Court of Justice in London, although that claim has not yet been served.\n- On January 16, Getty Images sent a letter before action to Stability AI Limited.\n- Getty Images requested a response to its January 16 letter before action from Stability AI Limited within a customary timeframe.\n- A trio of artists sued Stability AI and Midjourney in the United States seeking class-action status.\n- Stability AI Limited confirmed receipt of Getty Images' letter before action.\n- Google said it is working on blocking shared Bard chats from being indexed by Google Search.\n- OpenAI briefly disabled the ChatGPT chatbot late on Monday to fix the error.\n- OpenAI fixed the significant error that had allowed some users to see other users' conversation titles.\n- OpenAI informed Bloomberg that it had briefly disabled the chatbot to fix the error.\n- OpenAI stated that users had not been able to access the actual chats.\n- OpenAI CEO Sam Altman said the company feels \"awful\".\n- OpenAI's chief executive tweeted that there would be a technical postmortem soon.\n- Poe\u2019s ChatGPT response on Quora was edited to correctly state that you cannot melt an egg in the traditional sense.\n- Ars Technica published an article about Google\u2019s egg-melting mistake that surfaced to the top search result.\n- Google Search updated its featured snippet to cite Benj Edwards\u2019 caveat that eggs cannot be melted.\n- Google\u2019s experimental Search Generated Experience (SGE) was updated to state that you cannot melt eggs in the traditional sense.\n- Google said it used the learnings from this mistake to improve the Search experience for future queries.\n- Google removed the AI-generated selfie from the Knowledge Graph.\n- Google removed the AI-generated selfie from Knowledge Panels.\n- Google removed the image from the Search feature.\n- Microsoft stated it was actively working to resolve the accidental human error that caused Bing's censorship of 'tank man' image results.\n- Several mothers created a WhatsApp group to coordinate their response.\n- The mothers started making calls to each other to identify affected girls and coordinate actions.\n- Sara filed a complaint with the police.\n- At least seven complaints have been filed with the police, according to police sources.\n- The Almendralejo judicial police opened an investigation into the case.\n- Police investigators identified several alleged authors of the photographic montages.\n- The case was placed in the hands of the Juvenile Prosecutor's Office.\n- One mother blocked the Instagram contact that had sent a fake naked photo to her daughter.\n- Miriam Al Adib made a live stream on Instagram to explain the situation and try to reach the kids who are sending the photos.\n- Miriam Al Adib posted a 10-minute video accompanied by a text urging girls to report such acts and asking affected mothers to join the group.\n- Supporters and mothers sent private and public messages urging the affected families to continue and report the incidents.\n- Anil Kapoor filed a suit in the Delhi High Court through his lawyer Ameet Naik seeking protection of his personality rights including his name, image, likeness, and voice.\n- The Delhi High Court granted an order acknowledging his personality rights and restraining all offenders from misusing his personality attributes without his permission.\n- The court order protects his rights across all modes and media worldwide.\n- The court order specifically protects his iconic phrase 'jhakaas' from misuse.\n- Ring (Amazon) agreed to a $5.8 million settlement with the FTC over privacy violations.\n- Amazon agreed to pay $25 million to settle allegations it violated children's privacy rights related to Alexa recordings.\n- Amazon pledged to make changes in its practices.\n- The employee who spied on customers was terminated.\n- As part of the FTC agreement with Ring, Ring is required to disclose to customers how much access the company and its contractors have to their data.\n- In February 2019, Ring changed its policies so that most Ring employees or contractors could only access a customer's private video with that person's consent.\n- Microsoft removed the AI-generated travel article.\n- Microsoft said it is investigating how the article made it through its review process.\n- Snap confirmed to TechCrunch that the temporary outage causing My AI's behavior was fixed.\n- Snapchat told TechCrunch that My AI cannot post stories at this time.\n- MIT Technology Review surveyed 150 Uber drivers in India to investigate the facial-recognition verification problems.\n- Uber locked drivers' accounts for periods such as 48 hours and up to one week after failed selfie verifications.\n- The creator of the 'Erect Horse Penis - Concept LoRA' model apologized for the error in a reply.\n- The creator said they hoped the problem would be solved in a future update.\n- 404 Media conducted an investigation into non-consensual AI-generated porn and the supply chain enabling it.\n- 404 Media viewed non-consensual sexual images generated by these models on CivitAI, its Discord, and off the platform.\n- 404 Media spoke to sex workers whose images are powering these AI-generated porn without their consent.\n- Google said it will use the Labs experiment to gather feedback and learn what works best for both publishers and users as it evolves the feature over time.\n- The article was updated on Aug. 31 to include a comment from Google.\n- News organizations, including the Associated Press, are seeking payment from AI companies to train language models on their content.\n- Kaedim built a pool of 3D artists who worked in shifts and were paid between $1 and $4 per model to produce usable models.\n- Kaedim adjusted its website to make the role of \"artists\" more transparent.\n- Kaedim stated that by 2024 model creation should be fully automated.\n- I checked my other online accounts (social media, streaming apps, etc.) to ensure they had not been compromised.\n- I followed the Amazon app's instructions and called the customer service number it provided.\n- I dialed the phone number provided in the executive's email and spoke with the Amazon executive.\n- I reviewed my multiple security camera recordings and confirmed that no racist remarks were made.\n- I submitted video evidence from multiple camera angles to Amazon immediately after learning of the issue.\n- I made numerous follow-up calls and sent multiple emails to Amazon to pursue resolution.\n- Amazon confirmed that it had started an investigation into the incident.\n- Amazon unlocked my account on Wednesday, restoring access.\n- I created and published my own video to address comments and explain the incident.\n- I shared my videos and emails with Louis Rossmann, who verified that the incident had occurred.\n- I shared a redacted email publicly to document the incident while avoiding doxxing.\n- I used Siri and my locally hosted dashboard to control smart home devices while Alexa was disabled.\n- MSN deleted the bizarre Ottawa travel guide article after criticism.\n- Jeff Jones, a senior director at Microsoft, told The Verge that the content was generated through a combination of algorithmic techniques with human review and was not published by an unsupervised AI.\n- Jeff Jones said Microsoft was working to ensure this type of content isn\u2019t posted in the future.\n- After this story ran, MSN deleted the articles in question about Brandon Hunter.\n- All posts on the Race Track publication's MSN page later disappeared.\n- The Verge updated the story with comment from Microsoft.\n- Amazon quickly removed the Alexa responses that were inconsistent with its policies.\n- Amazon stated it is constantly working to improve the systems in place to ensure responses given by Alexa on devices with Amazon Kids turned on meet a high bar.\n- In response to public outcry, Google fixed harmful search results that previously linked queries about Black girls and other groups to pornographic content.\n- In 2018, NHS Blood and Transplant launched a new computer algorithm to reduce deaths on the liver transplant waiting list.\n- NHS Blood and Transplant says it constantly monitors the allocation algorithm.\n- NHS Blood and Transplant maximizes donated livers by prioritizing transplantation for patients judged to be most in need.\n- NHS Blood and Transplant encourages people to register their organ donation decision on the Organ Donor Register.\n- Flood warning systems were set to trigger automatically when they reached certain thresholds.\n- The government permitted the Environment Agency to grant staff an average 3% pay rise in November.\n- The Environment Agency put plans in place to minimise disruption to its essential work and to respond to critical incidents.\n- The Environment Agency is meeting regularly with unions to have open and honest conversations about pay, conditions and reform.\n- Defra representatives are involved in the meetings with unions.\n- Ministers are being updated on the pay discussions and related meetings.\n- Staff at the preprint server Preprints.org pulled down the article after learning of the fake references.\n- The preprint server blacklisted the manuscript's authors.\n- MDPI's journal Insects rejected the manuscript.\n- The preprint's corresponding author, Kahsay Tadesse Mawcha, admitted to using ChatGPT to produce the manuscript.\n- Mawcha posted an updated version of the paper to the preprint server Research Square.\n- Mawcha deleted the made-up papers by Enghoff from the reference list of the revised preprint.\n- Research Square's editorial team said it would look into the case and take appropriate action on the preprint.\n- After being contacted by Retraction Watch, Research Square removed all mention of the International Journal of Tropical Insect Science from the manuscript's webpage.\n- The editors of the International Journal of Tropical Insect Science said they were aware of the issues and were handling the case accordingly.\n- Carlos Mart\u00ednez emailed Mawcha asking him to stop trying to publish his AI-generated manuscript.\n- Carlos Mart\u00ednez contacted the International Journal of Tropical Insect Science about the manuscript.\n- Carlos Mart\u00ednez contacted the African Association of Insect Scientists about the manuscript.\n- Carlos Mart\u00ednez contacted Ethiopia's embassy in Germany about the manuscript.\n- Research Square said it was manually reviewing submissions while its retraction alert feature was under repair.\n- Retraction Watch contacted Research Square about the manuscript.\n- The news outlet contacted Synthesia\u2019s CEO to inquire about the fake video.\n- Synthesia\u2019s content moderators recognized that the video was political in nature.\n- Synthesia banned the person who created the fake news video from using the site.\n- The Truth or Fake program investigated and publicly analyzed examples of the fake videos found on the Facebook page.\n- The author documented the problematic search results by screenshotting them.\n- The author contacted Google and received a public response stating that search results reflect web content and do not represent Google's own opinions.\n- The author consulted search expert Danny Sullivan to investigate and assess the autocomplete and direct-answer issues.\n- Jonathan Albright published detailed research mapping a list of 306 rightwing and fake-news websites and their hyperlink networks to investigate how they spread their message.\n- Jonathan Albright scraped those sites for links and used a tool to map how the links flowed between them and into platforms like YouTube and Facebook.\n- Jonathan Albright scraped the trackers on these websites to demonstrate how scripts follow visitors and enable data-mining and targeted political messaging.\n- Investigative journalists uncovered that DeepMind had been given access to 2 million Londoners' NHS health records.\n- The article was amended on 21 October 2025 to remove a photograph pending review.\n- Danny Sullivan said he would take the feedback back to Google's search team.\n- Danny Sullivan reviewed additional examples in the Twitter thread and showed that the tweets were looking better.\n- Google\u2019s Communications team posted on X to clarify how the Search Autocomplete feature works following user complaints and misconceptions.\n- Google publicly acknowledged the two specific problems affecting autocomplete predictions, including missing predictions for queries about the assassination attempt against former President Trump and a bug that affected predictions for several past presidents and other queries.\n- Google said it is working on improvements to autocomplete protections and that those improvements are already rolling out.\n- Google confirmed it made an update that has improved autocomplete predictions across the board.\n- Google pledged that when issues arise it will make improvements so users can find what they\u2019re looking for quickly and easily.\n- OpenAI updated its website with new rules that only limit the most risky applications.\n- OpenAI said it is eager to hear suggestions on how to tackle this issue.\n- OpenAI hinted at upcoming election-related events.\n- Sam Altman publicly expressed concern about the influence of AI on future elections.\n- The company aims to create effective technical measures that do not inadvertently block valuable and non-offending content.\n- Regulators and tech companies are taking action to address the issue of AI-generated political messaging.\n- A Milan court ordered Google to remove the autocomplete terms linking the businessman's name to 'truffatore' (conman) and 'truffa' (fraud).\n- The Milan court threw out Google's claim that it was not responsible for the autocomplete suggestions.\n- Cruise said it has reached out to offer support to the rider involved in the crash.\n- One person was transported to a hospital via ambulance following the crash.\n- Brazil's advertising watchdog Conar announced it would investigate a possible breach of ethics over the AI-created advert following public complaints.\n- Conar promised to issue a ruling on the matter in about 45 days.\n- Volkswagen publicly defended its viral campaign in response to criticism over the AI-created depiction.\n- Volkswagen stated that the production had the blessing of Elis Regina's family.\n- Robert Kneschke contacted LAION in February to request that his images be removed from the training dataset.\n- LAION's law firm Heidrich Rechtsanw\u00e4lte sent a letter stating LAION was compliant with copyright laws and that it was not possible to remove Kneschke's images because the organization does not store copies.\n- The law firm threatened to collect claims for damages from Kneschke for filing an unjustified copyright claim.\n- The legal letter included an invoice for \u20ac979 and demanded that Kneschke pay the amount within 14 days or face legal action.\n- At the end of March, Kneschke sent a cease-and-desist request asking LAION to remove his images and to provide information on the extent, duration, and sources of the dataset's use of his works.\n- LAION's lawyers responded that there had been no copyright infringement and that any reproductions were temporary and covered by Sections 44b and 60d of the UrhG.\n- LAION's lawyers further stated that LAION did not store copies of Kneschke's works that could be deleted or about which information could be provided.\n- Kneschke filed a lawsuit against LAION at the Hamburg regional court.\n- Getty is suing Stability AI for its role in supporting the development of LAION, including the use of Getty Images' photographs.\n- Karla Ortiz launched a fundraising campaign to hire a lobbyist in Washington D.C. to seek changes to US copyright, data privacy, and labor laws to protect artists.\n- Stability AI announced in December that it would honor all opt-out requests collected from the Have I Been Trained? website.\n- LAION's website FAQ states that EU citizens who find their images or identifiable data in the dataset are eligible to file a GDPR claim to have their personal data taken down.\n- The supermarket said it would keep fine-tuning the bot's controls to ensure it is safe and useful.\n- The supermarket appended a warning notice to the meal-planner stating that recipes are not reviewed by a human, are not guaranteed to be complete or suitable for consumption, and that users must use their own judgment.\n- The California Department of Financial Protection and Innovation sent a cease and desist letter to Maxpread Technologies.\n- The California Department of Financial Protection and Innovation sent a cease and desist letter to Harvest Keeper.\n- The California Department of Financial Protection and Innovation sent a cease and desist letter to Visque Capital.\n- The California Department of Financial Protection and Innovation sent a cease and desist letter to Coinbot.\n- The California Department of Financial Protection and Innovation sent a cease and desist letter to QuantFund.\n- The DFPI issued desist and refrain orders to the five named entities and individuals for violating California securities laws.\n- The DFPI ordered the named entities to stop operating in California for violating securities laws.\n- The DFPI prohibited the named entities from selling or offering the contested investments to California residents.\n- The author's official Goodreads profile was cleaned of the offending titles.\n- The author filed a report with Amazon complaining that the books were using her name and reputation without her consent.\n- The fraudulent titles were removed from Amazon.\n- The author added the book titles and screenshots to her post and explained why she believed the books were AI-generated.\n- The author complained about the fraudulent books on Twitter/X.\n- The author wrote a separate post for authors titled 'What Remedies Do Authors Have When Fraudulent Work Appears on Amazon?'.\n- The Federal Trade Commission published a post about generative AI and book sales and stated it is closely monitoring the situation for writers, artists, and creatives.\n- The author signed up for Brave's Search API to inspect the data the API returns.\n- The author ran queries using Brave's Search API and extracted the \"extra_snippets\" to analyze their content and length.\n- The author examined their website access logs to look for evidence of a Brave crawler.\n- The author located and cited a Reddit comment from a Brave developer stating that Brave operates its own crawler that respects robots.txt and crawls over 40 million pages each day.\n- The author emailed Brave with questions about how Brave handles licenses and about disclosing its search crawler.\n- A Brave representative (Josep M. Pujol, Chief of Search) replied by email clarifying that Brave treats rights as applying to the output of API requests, that outputs are excerpts with attribution to the URI, and that Brave can monetize and apply terms to API outputs.\n- The author published a follow-up article updating the story and demonstrating how Brave can scrape licensed content.\n- The author sent a follow-up email to Brave after receiving the initial reply.\n- Benji Smith shut down the Prosecraft platform after the backlash.\n- Benji Smith published a blog post announcing he was taking down the Prosecraft website.\n- In that blog post, Benji Smith stated that the Prosecraft website never generated any income.\n- The researchers shared a preprint paper describing the 'fox8' Twitter botnet.\n- They used Twitter's API to collect tweets and accounts for analysis.\n- They searched Twitter for the phrase 'as an ai language model' over the six-month period between October 2022 and April 2023 to identify likely LLM-powered accounts.\n- They searched for 'self revealing' text that may have been posted accidentally by LLM-powered bots to discover candidate accounts.\n- They applied LLM-detection tools, including OpenAI's detector and GPTZero, to the botnet's tweet corpus to assess whether the content was machine-generated.\n- They analyzed account behaviors and found a single probabilistic model governing activity types and frequencies, suggesting behavioral-pattern analysis as a detection method.\n- They analyzed relationships among the collected accounts and determined the fox8 network appeared to promote three news websites likely controlled by the same anonymous owner.\n- Unite Here filed an unfair labor practice complaint with the National Labor Relations Board against the Instawork platform.\n- Unite Here documented at least six Los Angeles hotels that used staffing apps to replace striking workers.\n- Instawork issued a public statement declining to comment on ongoing legal matters and asserting that the app does not retaliate against workers for engaging in protected activity.\n- Context contacted Instawork on July 14 to request comment on Thomas Bradley's case.\n- Hours after Context contacted Instawork, Instawork lifted the suspension on Thomas Bradley's account.\n- Karl Turner apologised for sharing what turned out to be a fake image of the Prime Minister.\n- Karl Turner apologised for not attributing the image.\n- Karl Turner retweeted a video from a person claiming to have created the altered picture.\n- The person claiming to have created the altered picture apologised for causing 'a bit of trouble' and said it was never their intention to deceive anyone.\n- Michelle Donelan retweeted Mr Turner\u2019s post.\n- Michelle Donelan publicly condemned the sharing of the image as a 'fake image' and called it 'pretty desperate stuff by Labour'.\n- Darren Jones publicly defended Karl Turner.\n- Darren Jones called for a discussion and asked what the Department is doing to tackle deepfake photos, especially ahead of the next election.\n- Martin Lewis urged authorities and regulators to 'step up' and stop internet giants from publishing deepfake content.\n- Rona Wang tweeted images of the AI-generated results on July 14.\n- Rona Wang told Insider about her reaction to the AI-generated images.\n- Rona Wang told The Boston Globe that she was worried about the consequences if companies used AI to select candidates.\n- Playground AI founder Suhail Doshi responded to Wang's post.\n- Suhail Doshi said the models are not instructable and may pick any generic thing based on the prompt.\n- Suhail Doshi said Playground AI was displeased with the result and hoped to solve it.\n- Researchers from Hugging Face conducted a study that found gender and racial bias in AI image generators.\n- The journalist sent a photograph to a dealer to obtain and test the facial recognition system's search results.\n- To ensure the data was authentic, the journalist verified the camera codes in the search results against Moscow's public registry of surveillance cameras.\n- MBK Media published a report exposing the illegal sale of access to Moscow's surveillance cameras and noting that there were no convictions for such sales in the government's judicial registry.\n- Tesla employees told customers that they had performed \"remote diagnostics\".\n- Tesla employees canceled customers' service appointments.\n- Tesla created a Las Vegas-based \"diversion team\" devoted to quieting customer complaints about inaccurate range estimates.\n- Managers told the diversion team that it saved Tesla $1,000 for every appointment it canceled.\n- The South Korean government fined Tesla $2.2 million for exaggerating vehicle range.\n- Chris Robinson eventually corrected the error in his screening record.\n- TransUnion agreed to pay $11.5 million to resolve claims that its programs violated fair credit reporting laws.\n- A federal class-action lawsuit related to Robinson's case moved toward settlement.\n- At least four other tenant screening companies are facing more than 90 federal civil rights and consumer lawsuits.\n- Fifteen state attorneys general submitted a letter urging regulators to ensure applicants for housing have access to all the data used to make determinations and that screening companies comply with civil rights law.\n- Federal regulators are currently considering additional regulations on tenant screening programs.\n- The Consumer Financial Protection Bureau and three other federal agencies released a joint statement asserting that automated systems are not an excuse for lawbreaking behavior and that they would enforce civil rights, consumer protection, and fair competition laws related to these technologies.\n- The Consumer Financial Protection Bureau and the Federal Trade Commission recently concluded collecting public input about tenant screening programs as a possible first step toward further rulemaking.\n- A federal lawsuit filed in 2018 alleged that CoreLogic Rental Solutions (now SafeRent Solutions) provided disqualifying criminal records and violated fair credit reporting laws.\n- A pending federal lawsuit alleges that SafeRent is discriminating against Black and Hispanic rental applicants who use federally funded housing vouchers.\n- Cigna issued a public statement asserting that its automated claims-processing system allows providers to be paid quickly and frees medical directors to review more complex claims.\n- Cigna stated that a denial should not result in additional out-of-pocket costs for patients using in-network providers.\n- ProPublica published an investigative report revealing Cigna's use of an automated system to assess and deny claims in bulk.\n- ProPublica is collecting comments from health insurance policyholders whose claims were denied via a public submission form.\n- ProPublica said it is posing questions to lawmakers and regulators about the use of AI in claims processing.\n- The victim filed a complaint with the National Cyber Cell.\n- The complaint was transferred to the Kerala police.\n- The police traced the money to an account in RBL Bank in Maharashtra.\n- Authorities froze the RBL Bank account.\n- The police traced the caller's phone number to Gujarat.\n- The police filed a case regarding the scam.\n- The police will submit the investigation report to the banks involved as part of procedures to reclaim the lost money.\n- Radhakrishnan inquired with his former colleagues about receiving similar messages and calls.\n- Scientists ran 91 TOEFL essays written by non-native English speakers through seven popular GPT detectors to evaluate their performance.\n- Scientists ran essays written by native English-speaking eighth graders through the same AI detectors for comparison.\n- The researchers traced the discrimination to the detectors' use of text perplexity as the basis for classifying AI-generated text.\n- After highlighting the built-in bias, the researchers asked ChatGPT to rewrite the TOEFL essays using more sophisticated language.\n- The researchers ran the ChatGPT-edited essays back through the AI detectors to test whether the edits changed the detectors' classifications.\n- The foreign affairs ministry\u2019s privacy chief recommended that the profiling system be dropped.\n- The data protection watchdog Autoriteit Persoonsgegevens started monitoring the use of algorithms as part of a government programme to prevent discrimination and exclusion.\n- A court case found that the government fraud-detection programme SyRI broke human rights.\n- He was detained two hours later near Her Majesty's private home.\n- Police recovered a crossbow from the castle grounds after detaining the intruder.\n- Officers attended his family home and found metal files, a missing file, a gas mask, and a rope in his bedroom.\n- Under a nurse's recommendation he was detained under the Mental Health Act.\n- Mental health assessments were conducted at Ravenswood Medium Secure Unit in Hampshire between Boxing Day and New Year's Eve 2021.\n- He was transferred to Broadmoor High Security Hospital on 1 February 2022 under the care of Dr Jonathan Hafferty.\n- Dr Jonathan Hafferty decided the defendant was fit for interview and he was interviewed on 25 and 28 February.\n- He was given antipsychotic medication, which was effective.\n- In February, Chail pleaded guilty to an offence under the Treason Act, making a threat to kill the then Queen and having a loaded crossbow in a public place.\n- He appeared at the Old Bailey for the start of his two-day sentencing hearing.\n- StabilityAI issued an email statement acknowledging that all AI models have inherent biases.\n- StabilityAI said platforms like Stable Diffusion will improve bias evaluation techniques.\n- StabilityAI said platforms like Stable Diffusion will develop solutions beyond basic prompt modification.\n- StabilityAI intends to train open-source models on datasets specific to different countries and cultures to mitigate biases caused by overrepresentation in general datasets.\n- Canva said it is working actively to ensure its AI technology is fair and representative.\n- Canva said its Stable Diffusion integration will soon be de-biased.\n- Authorities relied on privately-installed surveillance cameras to expand the safe city system after many project cameras failed.\n- The city authority identified about 137,000 locations where surveillance cameras are deployed under private initiatives.\n- Local project partner Business Efficiency Solutions filed a lawsuit against Huawei in California alleging stolen technology and pressure to build backdoors.\n- The agreement with Huawei has expired and will not be renewed.\n- Safe City Malta will no longer continue to function.\n- Safe City Malta has started the process of being dissolved.\n- The ministry for tourism, together with other competent ministries, is working on a plan to ensure better security management in Malta\u2019s main touristic zones.\n- All Safe City Malta accounts will be finalized and audited and then duly presented.\n- Adobe trained Firefly only on content that had an explicit license allowing AI training.\n- Adobe offers creators extra compensation when their material is used to train AI models.\n- Human content moderators review Firefly's training data to weed out objectionable or harmful content.\n- Human content moderators review Firefly's training data to remove known intellectual property.\n- Human content moderators review Firefly's training data to remove images of known people.\n- Adobe ensures it has licenses for everything its products train on.\n- Adobe applies automated content moderation at the point of creation to check that Firefly's creations are safe for professional use.\n- Adobe prohibits the model from creating news stories.\n- Adobe prohibits the model from creating violent images.\n- Adobe blocks some artists' names from generation.\n- Firefly-generated content is labeled to indicate it was created using AI.\n- Firefly-generated content includes the image's edit history.\n- Adobe started the Content Authenticity Initiative to promote labels that indicate whether content is AI-generated.\n- Adobe is part of developing the C2PA industry standard label showing where a piece of content came from and how it was created.\n- Adobe partnered with companies such as IBM, Mattel, NVIDIA, and NASCAR to allow those companies to use the tool with their intellectual property.\n- Douyin indefinitely suspended the account for spreading misinformation.\n- Douyin banned the account from making money.\n- The account owner removed all the videos from the account.\n- The account owner changed the account name from \"Baoer Kechatie\" to \"Wang Kangmei\".\n- Other Douyin users checked the account's IP address and found it was located in Henan.\n- China introduced a ban on illegal activities related to deepfake technologies.\n- China mandated the establishment of a real-name verification system to address deepfake technologies.\n- Douyin required all users to clearly label AI-generated content since May.\n- A previously viral impostor account was blocked following complaints from users and criticism from state media.\n- OpenAI asked Motherboard for more information to understand how the model was prompted into behaving this way.\n- The article's author avoided using ChatGPT for two weeks after the incident.\n- The website was made unavailable in most European countries due to GDPR rules.\n- Mecosta County Sheriff\u2019s deputies responded to the single-car crash at 6:41 p.m. on Sunday, May 28.\n- The woman was transported to Spectrum Health Big Rapids Hospital for treatment of minor injuries.\n- The California Highway Patrol announced that its preliminary investigation found the Tesla's partially automated driving system was engaged.\n- The California Highway Patrol issued a clarified statement retracting its earlier determination and stating no final determination had been made about the driving mode or its contribution to the crash.\n- The National Highway Traffic Safety Administration opened an investigation into the Fontana crash.\n- The California Highway Patrol arrested a man who authorities said had been riding in the back seat of a Tesla driving on Interstate 80.\n- The California Highway Patrol publicly reminded drivers that driving is a complex task requiring a driver's full attention.\n- A GoFundMe page was set up to raise money for Hendrickson's funeral and memorial service.\n- The National Highway Traffic Safety Administration sent a team to investigate after a Tesla on autopilot ran into a Michigan state police vehicle on I-96 near Lansing.\n- The National Transportation Safety Board recommended that Tesla develop a stronger system to ensure drivers are paying attention.\n- The National Transportation Safety Board recommended limiting the use of autopilot to highways where it can work effectively.\n- The Washington State Patrol determined the Tesla was operating with its Full Self-Driving system activated.\n- The Tesla driver was arrested after the crash.\n- Sobriety tests and evaluations were conducted and showed the driver did not display signs of impairment.\n- Advocates pushed for more regulatory oversight and for detailed disclosure of crash data to improve accountability and safety.\n- Volunteer moderators enacted a general moderation strike on Stack Overflow and the Stack Exchange network.\n- A small number of moderators (11%) stopped engaging in several activities, including moderating content.\n- Stack Overflow ran an analysis of the ChatGPT detection tools used by moderators.\n- Stack Overflow required moderators to stop using the ChatGPT detection tools they had been using.\n- The Community Management team is evaluating the current situation and working to stabilize things in the short term.\n- Reddit moderators manually removed several hundred accounts from the site.\n- The Discord server owner issued a server-wide announcement declaring that almost all of the seller's tracks were fake.\n- A second Discord administrator posted an announcement urging members to stick with the server despite the recent issues around fake tracks.\n- Mourningassasin admitted to Discord administrators that the tracks were AI-generated.\n- The music leaking forum banned mourningassasin from the community.\n- SoundCloud repeatedly removed the track 'The Line' after it triggered the company's copyright protections.\n- SoundCloud removed other tracks that were more clearly AI-generated.\n- Spotify ejected thousands of AI-generated songs from its platform.\n- Universal Music Group issued a statement condemning the training of generative AI on its artists' music and criticizing the availability of infringing AI-created content.\n- Eleven drivers made formal requests to Just Eat for the data about their cases.\n- Worker Info Exchange pursued the couriers' cases.\n- Just Eat responded to those data requests by supplying selected order records and GPS coordinates for each case.\n- Just Eat said that when its system flags activity as potentially fraudulent, a human examines the case before a courier's account is deactivated.\n- Just Eat said it will investigate concerns raised by couriers and take action as needed if a courier feels they have been wrongly deactivated.\n- Affected drivers sent multiple emails to Just Eat seeking explanations and to appeal their account deactivations.\n- Utica's school district launched an internal investigation into the attack.\n- The scanners were removed from Proctor High School.\n- The removed scanners at Proctor High School were replaced by ten metal detectors.\n- Evolv removed the 'Weapons-Free Zones' wording from its website and changed the text to 'Safe Zones'.\n- Evolv later changed the website wording again so it reads 'Safer Zones'.\n- The BBC sent a detailed right of reply to Evolv outlining what had happened at the Utica school and the district's decision to stop using its system.\n- Evolv directed the BBC to a blog post from its CEO, Peter George.\n- Evolv's CEO published a blog post defending the lack of public detail about how the technology works and stating the company communicates limitations and capabilities to trusted security professionals.\n- The BBC contacted seven other school districts that use Evolv weapons scanners to gather information.\n- Amazon agreed to pay a $25 million civil penalty to settle FTC allegations related to Alexa.\n- Amazon agreed to pay $5.8 million in customer refunds for alleged privacy violations involving its Ring doorbell camera.\n- The settlement ordered Amazon to overhaul its data deletion practices.\n- The settlement required Amazon to impose stricter, more transparent privacy measures.\n- The FTC ordered Amazon to delete inactive child accounts.\n- The FTC ordered Amazon to delete certain voice and geolocation data collected by Alexa.\n- The proposed order prohibits Amazon from using deleted geolocation and voice information to create or improve any data product.\n- The order requires Amazon to create a privacy program for its use of geolocation information.\n- The Spanish Data Protection Agency (AEPD) opened an administrative file (expediente) against Plastic Forte.\n- The AEPD fined Plastic Forte 20,000 euros for photographing employees and creating biometric templates without informing them.\n- Plastic Forte recognized its responsibility in the AEPD proceeding.\n- Plastic Forte renounced submitting allegations in the AEPD proceeding.\n- The AEPD reduced the fine by 20% as a consequence of Plastic Forte's recognition of responsibility and renunciation of allegations.\n- Plastic Forte made a prompt payment of the sanction.\n- The AEPD granted an additional 20% reduction of the fine due to the prompt payment, leaving the sanction at 12,000 euros.\n- The AEPD fined another company 5,000 euros for installing a video surveillance system that captured audio without informing workers or customers.\n- In its resolution the AEPD reminded that the use of facial recognition requires a data protection impact assessment and communication to the works council about how, when, and who deploys the biometric technology.\n- The AEPD's resolution specified that the required impact assessment must include an analysis of the necessity and proportionality of the system and the measures planned to address risks such as security breaches and the transfer of biometric information to less secure centralized databases.\n- The AEPD's resolution advised that, if facial recognition is implemented, the amount of facial data collected should be minimized and the biometric template size should be balanced to manage security and reconstruction risks.\n- NEDA fired all helpline staff.\n- NEDA fired hundreds of helpline volunteers.\n- NEDA began winding down the telephone helpline as it had been operating.\n- NEDA stopped taking new calls or messages to the helpline.\n- NEDA announced it would transition the helpline to a chatbot named Tessa.\n- NEDA scheduled the transition to Tessa for around June 1.\n- The professor offered the class a makeup assignment to avoid the failing grade.\n- The student reached out to the dean and CC'd the university president.\n- The student went in person to plead her case with administrators.\n- Dr. Jared Mumm is working individually with students regarding their last written assignments.\n- Some students received a temporary grade of 'X' to allow time to determine whether AI was used to write their assignments.\n- At least one student was exonerated using Google Docs timestamps.\n- Dr. Jared Mumm apologized to at least one student who was exonerated.\n- Texas A&M University\u2013Commerce is investigating the incident.\n- Texas A&M University\u2013Commerce is developing policies to address the use or misuse of AI technology in the classroom.\n- Texas A&M University\u2013Commerce is working to adopt AI detection tools and other resources to manage the intersection of AI technology and higher education.\n- The university issued a public statement denying that any students failed the class or were barred from graduating because of the issue.\n- The university confirmed that several students had been cleared of any academic dishonesty.\n- Douyin published a guideline on AI-generated content.\n- Douyin's guideline requires content uploaders to mark AI-generated content with distinguishing labels.\n- Douyin's guideline states that content uploaders are responsible for the consequences of AI-generated content they publish.\n- Douyin's guideline prohibits copyright-infringing content and states such content will be subject to severe punishment once detected by the platform.\n- The Arlington Police Department publicly confirmed on Twitter that the image and accompanying reports were fake and that there was no explosion or immediate danger.\n- The Russian state-media Twitter account RT deleted the post that shared the fake image.\n- The Twitter account @DeItaone later posted that the earlier news of the explosion was fake.\n- USPS repeatedly postponed the scheduled pay cuts, pushing them back each pay period.\n- USPS and the parties to the agreement said they will continue to share data and information throughout the RRECS implementation process.\n- Twitter restricted access to some content in Turkey.\n- Twitter announced via its Global Government Affairs unit that the platform would restrict access to some content in Turkey.\n- Twitter informed the account holders of this action in line with its policy.\n- Twitter ensured that the restricted content remained available in the rest of the world.\n- Muharrem \u0130nce withdrew his candidacy from the presidential race after the release of the purported sex tape.\n- Muharrem \u0130nce publicly denied the authenticity of the video, saying it was a deepfake taken from an Israeli porn site and calling it slander.\n- Kemal K\u0131l\u0131\u00e7daro\u011flu invited \u0130nce to join the opposition coalition by tweeting a link to a classic Turkish ballad.\n- Sinan O\u011fan cancelled a planned rally.\n- Sinan O\u011fan called a meeting of his advisers.\n- Party officials declared that Sinan O\u011fan had no plans to withdraw from the race.\n- Privacy Commissioner Michael McEvoy investigated four of the Canadian Tire locations that used facial recognition.\n- Canadian Tire discontinued its use of the facial recognition system at all 12 locations.\n- Canadian Tire deleted customers' biometric data collected by the systems.\n- Commissioner McEvoy recommended that the stores establish robust privacy management programs.\n- Commissioner McEvoy recommended that the provincial government explicitly regulate the sale or installation of technologies that capture biometric information through the Security Services Act.\n- Commissioner McEvoy recommended that the provincial government create additional obligations under PIPA, such as requiring organizations deploying biometrics to notify the privacy commissioner.\n- Frasers Group tells shoppers when live face-recognition technology is installed in a shop.\n- Frasers Group deploys Facewatch in stores that experience unacceptable levels of threats and abuse to staff.\n- Shop managers' requests to add someone to the Facewatch database must be backed up with full witness statements and explanations.\n- A panel of former police officers reviews and accepts requests to add individuals to the Facewatch database before they are added.\n- Shop staff and accredited super-recognisers check every Facewatch alert.\n- Facewatch follows the Surveillance Camera Code of Practice.\n- The Information Commissioner's Office confirmed that Facewatch's use was lawful.\n- The Spanish Agency for Data Protection imposed a \u20ac200,000 fine on GSMA for deploying the facial recognition system in violation of GDPR.\n- GSMA attempted to appeal the AEPD decision by arguing that visitors' biometric data were processed and stored only for four months.\n- Chinese authorities detained the man who used ChatGPT to write fake news articles.\n- The public security bureau of northern Gansu province posted a press release about the case on WeChat.\n- NewsGuard published a report documenting 49 websites populated by AI chatbots.\n- Bloomberg independently reviewed the 49 websites.\n- Amazon will suspend or ban users from its platform that violate its review abuse policies.\n- Companies have turned to a combination of human moderators and automated tools to stamp out bogus reviews.\n- Amazon has recently filed lawsuits against fake review brokers.\n- Amazon has appealed to social media platforms like Meta to help root out fake reviews.\n- Several mothers called 911 to report the kidnapping threat.\n- The mother put the phone on mute and called for help from other parents.\n- A mother contacted the husband, who confirmed Briana was safe at the ski resort.\n- The mother demanded to speak to her husband and daughter to verify their safety.\n- The mother hung up on the caller.\n- The next day, the mother and her younger daughter drove to join the rest of the family at the ski resort.\n- Amnesty International issued a public statement to Motherboard explaining that it had used AI-generated images to depict victims while protecting their identities.\n- Amnesty International clearly marked all AI-generated images with the disclaimer \"illustrations produced by artificial intelligence\" to avoid misleading anyone.\n- Amnesty International edited the AI-generated images using vivid colors, an artistic style, and intentional imperfections to make them clearly distinguishable from real-life photographs.\n- Teams at Amazon\u2019s headquarters in Seattle attempted to diagnose the software issue after the failed delivery attempt.\n- The flight crew powered up a second drone to attempt the delivery after the first drone failed to boot.\n- Prime Air personnel repositioned the yard fiducial marker to correct the drone\u2019s target.\n- The drone\u2019s GPS was synced before attempting the delivery again.\n- A ground observer was stationed in a truck to maintain visual line of sight during the delivery to meet FAA requirements.\n- The drone hovered over the target and released the package from about 10 feet instead of landing.\n- Amazon stated that it applied the learnings from each flight toward improving safety.\n- Amazon used a closed, private facility to test its systems up to their limits as part of safety testing.\n- Amazon stated that each test was conducted in compliance with all applicable regulations.\n- Safety issues caused by faulty motors and other hardware issues were largely resolved in the MK27-2 design.\n- Amazon followed all appropriate safety procedures and reporting requirements after the incident.\n- Amazon followed thorough procedures on how flight tests are conducted.\n- Amazon followed thorough procedures on how it responds to incidents.\n- Prime Air fired more than 100 employees in the UK.\n- Many Prime Air employees were transferred into different roles abroad.\n- Amazon shut down its drone delivery R&D center in France.\n- TikTok said it will remove violent content from the platform.\n- TikTok said it will restrict mature videos from appearing on young users' For You Pages.\n- TikTok said the updated Community Guidelines will roll out on Apr. 21.\n- BCC mandated employees to remove the TikTok app from their corporate devices.\n- Levi\u2019s clarified its use of AI to promote diversity a few days after the original announcement.\n- Levi\u2019s issued a public statement taking responsibility for not properly representing certain aspects of the program.\n- Levi\u2019s stated that the pilot is not a means to advance diversity or a substitute for its diversity, equity, and inclusion goals.\n- Levi\u2019s said it will proceed to experiment with the AI-generated model pilot later this year to strengthen the consumer experience.\n- Levi\u2019s affirmed that it does not plan to scale back its use of real models or live photoshoots.\n- Levi\u2019s acknowledged that its partnership with Lalaland should not have been conflated with the company\u2019s diversity, equity, and inclusion commitments.\n- The article was updated with a new statement from Levi\u2019s addressing concerns about its plan to test AI-generated models.\n- The ChaosGPT Twitter account was suspended.\n- The creators explicitly advised against using ChaosGPT for any practical purposes.\n- The creators emphasized that ChaosGPT was a risky experiment intended to explore the dangers of advanced AI and to foster public awareness.\n- GPT-3.5 agents refused to comply with ChaosGPT's directives.\n- Boris Eldagsen declined to accept the prize he had won at the Sony World Photography Awards.\n- Boris Eldagsen suggested donating the prize to a photo festival hosted in Odesa, Ukraine.\n- The World Photography Organisation suspended its activities with Boris Eldagsen.\n- The World Photography Organisation removed Boris Eldagsen from the competition.\n- The World Photography Organisation said it will further explore the topic of AI and image-making via its various channels and programmes.\n- Snap publicly clarified that My AI may provide location-based responses when users have granted Snapchat permission to use their location data.\n- Snap encouraged Snapchatters to report inaccurate My AI responses using the app's in-app reporting tool.\n- David An published his findings about the prompt injection vulnerability and My AI's meta-prompts in a blog post.\n- Multiple users posted screenshots on Twitter showing My AI's contradictory statements about having access to location information.\n- Fortune replicated the scenarios in its own interactions with My AI to confirm the reported behavior.\n- The track \"Heart On My Sleeve\" was removed from Apple Music.\n- The track \"Heart On My Sleeve\" was removed from Deezer.\n- The track \"Heart On My Sleeve\" was removed from Tidal.\n- The track \"Heart On My Sleeve\" was removed from Spotify.\n- TikTok was asked to remove the track.\n- YouTube was asked to remove the track.\n- Universal Music Group filed a copyright claim that resulted in the original YouTube video being taken down.\n- In 2021, Rotterdam paused the use of its welfare risk-scoring algorithm.\n- Rotterdam handed over its machine learning model, training data, and user operation manuals to reporters in response to an investigation.\n- The city refunded \u20ac6,000 to Oran that it had deducted from his benefits payments.\n- The city provided Oran his risk scores for 2018 and 2019 after he requested them.\n- Rotterdam has been working to develop a new version of the risk-scoring model.\n- The city has worked to add more safeguards to the development of algorithms.\n- Rotterdam introduced an algorithm register to show what algorithms it uses.\n- While rebuilding the system, welfare recipients are being selected for investigation at random.\n- Since 2020, the city has moved to make its welfare system easier to navigate by adding a human dimension to its welfare processes.\n- The city relaxed rules around how much money claimants can receive from friends and family.\n- The city now allows adults to live together without any impact on their benefits.\n- Rotterdam plans to give people more information about why and how they were selected by the system.\n- Rotterdam plans to announce more details of the new model before the summer.\n- Ingrid Noon was transported to Delray Medical Center following the collision.\n- Richard Dorfman was transported by ground to Boca Regional Hospital after he reported chest pains.\n- The Palm Beach County Sheriff's Office DUI unit followed Dorfman to the hospital.\n- PBSO traffic homicide investigators investigated the collision.\n- Law enforcement and the state attorney will investigate and prepare the case for prosecution, a process that can take many months.\n- Shut down ChatGPT on Monday morning after reports of users seeing other people's chat titles.\n- Rolled out a fix for the bug that caused the issue.\n- Fully restored the ChatGPT service 10 hours after the shutdown.\n- Posted a note on the sidebar informing users that chat histories are unavailable.\n- Stated that it is working to restore the chat history feature as soon as possible.\n- Is investigating the cause of the bug to figure out what triggered the issue.\n- Cruise filed a voluntary recall with federal regulators to update the software in 300 robotaxis.\n- Cruise updated the self-driving software on March 25 to correct the issue.\n- Cruise engineers investigated the crash and provided details about that investigation.\n- Cruise reported a software recall and update in 80 of its robotaxis following a June crash.\n- Cruise submitted a voluntary filing with regulators in the interest of transparency.\n- The family spoke with Secretary of State Mathieu Michel about the tragedy.\n- Mathieu Michel set up a working group to analyse the EU AI Act text and propose necessary adjustments.\n- OpenAI said it hopes to mitigate harmful and biased ChatGPT answers by gathering user feedback.\n- The article was updated on 29 March to correct a previous statement that the chatbot's technology was developed by OpenAI.\n- Councillor Brian Hood tendered a \"concerns letter\" to OpenAI about ChatGPT's false claims regarding his role in the bribery incident.\n- The concerns letter functioned as a formal concerns notice requesting that OpenAI rectify the issue within 28 days under Australian law.\n- The Washington Post investigated the false story.\n- The Washington Post contacted Microsoft about the false claim.\n- Microsoft stated it is taking steps to ensure search results are safe and accurate.\n- UCLA professor Eugene Volokh is exploring how to address AI-driven defamation.\n- Tesla is actively cooperating with the traffic police in the investigation of the Taizhou accident.\n- Tesla told Hongxing News that the company is deeply saddened by the accident.\n- Tesla said it will fully cooperate with the investigation.\n- Local police are conducting an investigation into the accident.\n- Cazadores de Fake News dissected the videos of the AI avatars Noah and Daren that talked about Venezuela.\n- Cazadores de Fake News alerted the public about a new state-sponsored disinformation campaign by Chavismo.\n- Cazadores de Fake News alerted about the spread of misleading data in those videos.\n- The ProBox Observatory monitored sociopolitical trends on social media in Venezuela, Cuba, Nicaragua and El Salvador.\n- The ProBox Observatory identified patterns in the propaganda machinery of Venezuela\u2019s ruling party.\n- ProBox reported message volumes and analyzed bot and automated-account involvement in pro-government hashtag campaigns, including publishing figures for total messages and suspected bots.\n- ProBox concluded that certain hashtag campaigns involved coordinated actions with participation by accounts from Nicaragua and Cuba.\n- Lawyers for Alfredo Perez filed a class-action lawsuit alleging Amazon failed to notify New York City customers that they were being monitored by facial recognition technology.\n- Amazon recently put up signs informing New York customers of its use of facial recognition technology, more than a year after the disclosure law went into effect.\n- More than 1,000 cases are being reviewed.\n- The computer system has been shut down and replaced temporarily with a paper-based alternative.\n- Cases where an over-ride was applied will be reviewed to determine whether the over-ride superseded any system error.\n- The 285 open cases with identified errors are under review, with priority given to cases where prisoners are being considered for imminent release.\n- Officials are investigating the errors in the risk scoring system.\n- Feedback was obtained from 150 users of the system to check for public protection issues.\n- The researchers decided not to computationally narrow down the AI-generated list of potentially toxic molecules.\n- The researchers decided not to test any of the generated substances in any way.\n- Collaborations Pharmaceuticals presented the work at the Spiez CONVERGENCE conference in Switzerland.\n- The authors published a peer-reviewed commentary on their research in the journal Nature Machine Intelligence.\n- The researchers gave a briefing on their findings to the White House Office of Science and Technology Policy.\n- The paper proposed implementing wait lists that require users to undergo a prescreening process to verify their credentials before accessing models, data, or code that could be readily misused.\n- The authors suggested presenting drug discovery AIs to the public through an application programming interface (API) that would require users to specifically request molecule data.\n- Ekins suggested structuring the API to only generate molecules that minimize potential toxicity and to demand that users apply the tools and models in a specific way.\n- The authors proposed limiting which users could access the API.\n- The authors proposed setting a limit to the number of molecules a user could generate at once.\n- TikToker Hira Mustafa stopped using filters entirely.\n- Hira Mustafa encouraged others not to use these filters.\n- Some TikTok users tested the Bold Glamour filter by attempting to wipe it off to see if it remained in place.\n- The Verge attempted to investigate the technology behind the Bold Glamour filter and contacted TikTok multiple times to confirm or deny whether AI was involved.\n- The Verge consulted Luke Hurd, an augmented reality consultant, for expert insight into how the filter works.\n- TikToker @JoannaJKenny posted a video demonstrating how the Bold Glamour filter altered her appearance and described the emotional impact.\n- Khadeer Khan was released on February 3 after it was ruled out that he had committed the crime.\n- Khadeer Khan was produced before a Mandal Revenue Officer (MRO) prior to his release on February 3.\n- Telangana Director General of Police Anjani Kumar reprimanded Medak SP Rohini Priyadarshini during the monthly crime review on February 20.\n- The DGP instructed senior officers to take ownership of the incident at the leadership level and not to pass the buck.\n- The Telangana High Court took suo moto cognizance of the incident and asked for a report to be submitted.\n- The Internet Freedom Foundation issued a statement warning that the use of CCTV and facial recognition technologies is error prone.\n- Alonzo Sawyer was released from jail after nine days.\n- The victim in the bus incident identified another man, Deon Ballard, as the suspect in the video.\n- Deon Ballard was arrested.\n- Deon Ballard is due to stand trial in April.\n- Carronne Sawyer called into the Maryland State House by video chat to speak in support of a proposed law to restrict police use of face recognition.\n- Maryland state senator Charles Sydnor reintroduced the senate version of the proposed bill regulating face recognition after learning of Alonzo Sawyer's case.\n- Sydnor proposed a bill that would limit police use of face recognition to cases involving violent crimes, human trafficking, or ongoing threats to public safety or national security.\n- The proposed bills would restrict police to searching only databases of driver's license and mug shot photos.\n- The proposed bills would put services like Clearview AI off-limits for police face recognition searches.\n- The bills would require annual reports detailing police use of face recognition technology.\n- The bills would require proficiency tests for the human analysts who pick possible matches from an algorithm's list.\n- The bills would require police to have evidence beyond just a face recognition match to make an arrest.\n- The proposed Maryland bills were developed with input from a working group that saw state lawmakers meet with prosecutors and public defenders, law enforcement agencies, and civil liberties groups such as the ACLU and the Innocence Project.\n- Atrioc issued a tearful apology for downloading and showing the deepfake video.\n- QTCinderella live streamed her response addressing the creators of the deepfake and Atrioc.\n- QTCinderella vowed to sue the people who made the website hosting the deepfake.\n- Fans pointed out Atrioc's transgression after he uploaded a video showing himself downloading the deepfake.\n- SCREENSHOT interviewed psychologist Zoe Mallett about internet security and the emotional effects of online abuse.\n- They investigated the abnormal sign-up and API usage patterns to determine why new users were dropping off.\n- They reached out to some of the new users and asked why they had stopped using the service.\n- They wrote this post to have a place to send new ChatGPT users asking why the service does not provide reverse phone number lookup and to warn others.\n- In August 2020, New York City Court Administrative Judge Anthony Cannataro issued an Administrative Order initiating a presumptive virtual mediation program in New York City Small Claims Court.\n- The courts partnered with local law schools, bar associations, and community dispute resolution centers to mediate small claims cases on virtual platforms.\n- The program assigned cases to particular mediators or organizations through initial emails copied to the litigants.\n- Mediators were required to quickly contact parties via email and/or phone to set up virtual mediation sessions.\n- Mediation sessions were scheduled flexibly, including after-hours and weekends, to accommodate litigants' work schedules and childcare needs.\n- The court assigned a formal court interpreter to every mediation session when language access was an issue.\n- Mediators conducted pre-mediation case development work and provided technological support to prepare self-represented litigants for virtual sessions.\n- The Cardozo Law School Mediation Clinic required each student mediator to call or email parties before the session and offer a tech-prep session.\n- The program held virtual meetings with the ADR Coordinator to update protocols and triage any issues.\n- New York City Small Claims began collecting quantitative and qualitative data by using a web-based exit survey link placed into the Zoom chat or emailed to parties after mediation sessions.\n- Program leaders decided not to return to in-person mediations and to continue virtual mediations for the near future.\n- Some jurisdictions moved hearings and mediations to virtual platforms to maintain operations during the pandemic.\n- Some programs used online systems and pro bono lawyers to provide information and assistance to self-represented litigants.\n- States began looking to utilize ODR platforms, such as Matterhorn, to help fill information gaps for self-represented litigants.\n- The New York State Unified Court System began considering solutions such as providing kiosks in court to provide internet access to parties who lack broadband.\n- A complaint was filed in the U.S. District Court for the Northern District of California seeking to represent all applicants in the affected protected classes who were not referred or hired due to the discriminatory screening process.\n- San Francisco transit authorities and the Mayor\u2019s Office on Disability sent a joint letter to the California Public Utilities Commission opposing Cruise and Waymo's requested service expansion.\n- The transit authorities and Mayor\u2019s office argued in their joint letter that the CPUC should continue an incremental approach to expanding AV service rather than approve full 24/7 citywide operations.\n- Firefighters at an active fire scene shattered the front window of a Cruise AV to stop the vehicle after it entered the scene and failed to stop.\n- Cruise called 911 multiple times to report passengers who were unresponsive in its vehicles.\n- An anonymous Cruise employee sent a letter in July to the California Public Utilities Commission warning that the company regularly loses contact with its driverless vehicles.\n- A Cruise spokesperson issued a written statement to Motherboard asserting the company's safety record and that it had driven millions of miles with zero life-threatening injuries or fatalities.\n- Cruise told WIRED that the vehicle whose windshield was broken was already stationary and defended the company's practice of calling 911 on unresponsive (sleeping) passengers.\n- He renamed the Huggingface model from \"hollie-mengert-artstyle\" to \"Illustration-Diffusion\".\n- He added a line to the model's README stating \"Hollie is not affiliated with this\".\n- He reached out via Reddit to ask how things went with Hollie.\n- Two days later, he released a new model trained on 40 images by concept and comic book artist James Daly III.\n- An administrative court in Hamburg declared that an order to delete the controversial database of images from the 2017 G20 summit protests was illegal.\n- Johannes Caspar, the city-state's commissioner for data protection, publicly argued that there is no legal justification for collecting and storing the biometric data of crowds to compare them to suspects.\n- Johannes Caspar is considering whether to appeal the administrative court's decision.\n- A second pilot project for facial recognition was launched in June at Berlin's S\u00fcdkreuz station.\n- Officials submitted details of the second S\u00fcdkreuz pilot project to parliament in response to a request by the Alternative for Germany party.\n- The nongovernmental organization Society for Civil Rights submitted a constitutional complaint against automatic passport photo searches by police and intelligence services.\n- Police in Hangzhou opened an investigation into the viral fake notice.\n- Local media outlets determined that the notice had been written by ChatGPT.\n- The state-run Zhejiang People\u2019s Radio Station reported that the screenshot originated from a residential compound.\n- The city government issued a statement saying it had not announced any changes to the road restriction policy.\n- The resident who shared the screenshot apologized to the WeChat group where he had posted it.\n- China\u2019s internet regulators vowed to increase vigilance of online rumors and misinformation and to focus on tracing their origins.\n- The U.K. Health Security Agency commissioned an independent review of audio-based AI COVID-19 screening tools.\n- Researchers from The Alan Turing Institute and the Royal Statistical Society conducted an independent review of cough-analyzing algorithms.\n- The researchers examined data from more than 67,000 people recruited through the National Health Service\u2019s Test and Trace and REACT-1 programs.\n- The researchers trained an AI model on the collected audio recordings and corresponding swab test results to evaluate coughs as a COVID-19 biomarker.\n- The researchers controlled for confounders in their analysis to assess the AI model's diagnostic accuracy.\n- The study co-authors communicated their findings by providing statements and email interviews to TechCrunch.\n- A 2021 audit was conducted of Epic\u2019s sepsis-identifying AI algorithm, which found it missed nearly 70% of cases.\n- The German Federal Constitutional Court declared the use of Palantir surveillance software by police in the states of Hesse and Hamburg unconstitutional.\n- The Men\u2019s Journal AI-generated testosterone article was thoroughly rewritten to correct various errors identified by experts.\n- A correction note was added to the bottom of the article acknowledging that the original version described testosterone replacement therapy as using \"synthetic hormones\" and misstated poor nutrition as one of the most common causes of low testosterone.\n- The article removed a claim about the health risks of milk that had been flagged by the expert reviewer.\n- An Arena Group spokesperson issued a public statement saying the company is exploring AI tools, that early experiments are a work in progress, and that they will refine their use of these tools based on learnings and ongoing monitoring.\n- Arena added a post-publication statement disclosing that it had partnered with two AI companies and asserting that the AI tools retrieved reporting exclusively from the Men\u2019s Fitness archives.\n- Arena committed to continue experimenting with AI software to mine its archive and create more productive editing workflows but stated it will not generate new content that is not based on archived articles.\n- Arena committed to continue monitoring and refining their use of AI tools as part of a workflow anchored in editorial oversight.\n- CNET, along with sister sites Bankrate and CreditCards.com, paused publication of AI-generated content to conduct a review.\n- CNET admitted that more than half of the articles published by its AI contained factual mistakes, plagiarism, or both.\n- Google issued new guidelines for publishers about using AI to generate content, emphasizing extra scrutiny for the reliability of search results involving health, civic, or financial information.\n- Twitch suspended the Nothing, Forever channel for 14 days.\n- The show's creators appealed the Twitch ban.\n- The creators said they will spend the suspension period working to ensure nothing like that happens again.\n- Show staff investigated the root cause of the issue.\n- Show staff identified the root cause of their issue with the Davinci model.\n- Show staff decided they will not use OpenAI's Curie model as a fallback in the future.\n- A staff member posted that none of the offensive remarks reflect the developers' or staff team's opinions.\n- The staff made most of the project's Discord read-only.\n- Check Point Research released an analysis reporting scenarios where Google Bard permits malicious use.\n- Check Point Research will continue monitoring this trend and will report further developments.\n- One Facebook post about Prof Meareg Amare Abrha was removed after his killing.\n- Meta invested heavily in content moderation and technology to remove hate.\n- Meta reduced the virality of posts.\n- Meta expanded its violence and incitement policies.\n- Meta improved enforcement of its policies.\n- Meta employed staff with local knowledge and expertise to detect violating content.\n- Meta continued to develop capabilities to catch violating content in Amharic, Oromo, Somali and Tigrinya.\n- Meta uses content moderators conversant with the main local languages.\n- Meta relies on artificial intelligence and local partners to flag content.\n- Exposing.ai located 5,757 original photos from Flickr used to build the IJB-C dataset.\n- Exposing.ai made the information about those original photos searchable through its database search engine.\n- Exposing.ai collected existing publicly available research citing the IARPA Janus Benchmark C dataset.\n- Exposing.ai verified the publicly available research citing the IARPA Janus Benchmark C dataset.\n- Exposing.ai geocoded the collected research citing the IARPA Janus Benchmark C dataset to show how the training data has proliferated around the world.\n- Google clarified in a November 2020 memo that using data from YouTube for face recognition is a violation of their Terms of Service.\n- Google re-clarified in a May 2021 memo, emphasizing in bold text that using data from YouTube for face recognition is a violation of their Terms of Service.\n- The DukeMTMC dataset was retracted.\n- The MS-Celeb-1M dataset was retracted.\n- The Tiny Images dataset was retracted.\n- The machine learning community called for higher ethical standards in dataset creation.\n- The paper's authors analyzed nearly 1000 papers that cite Labeled Faces in the Wild, MS-Celeb-1M, and DukeMTMC to study their ethical issues.\n- The authors suggested a distributed approach to harm mitigation that considers the entire life cycle of a dataset.\n- As of January 2020, Berkeley stopped distributing the PIPA dataset.\n- Existing publicly available research citing the PIPA dataset was collected.\n- The collected research citing the PIPA dataset was verified.\n- The collected research citing the PIPA dataset was geocoded to show how AI training data has proliferated around the world.\n- An analysis of the most frequent image tags used for the Flickr images in the PIPA dataset was performed and presented in charts.\n- UCCS temporarily suspended its dataset in May 2019.\n- UCCS announced plans to release a new version of the dataset.\n- As of April 15, 2019, the UCCS dataset was made unavailable.\n- A generative adversarial network was used to interpolate between identities from the UCCS dataset to show face types while protecting individual privacy.\n- Publicly available research citing the UCCS dataset was collected.\n- Publicly available research citing the UCCS dataset was verified.\n- Publicly available research citing the UCCS dataset was geocoded to show how the dataset has proliferated around the world.\n- Professor Terrance Boult clarified via email that he did not provide the dataset to any government agency.\n- Professor Terrance Boult clarified via email that it does not appear any US government agency had downloaded the dataset as part of the research competition.\n- Google temporarily blocks requests from the affected computer network and the block will expire shortly after the suspicious requests stop.\n- The page instructs users to try their request again later.\n- Users sharing the network are instructed to ask their administrator for help.\n- Google provided a 'Learn more' link for additional information.\n- Tencent restricted traffic to the Different Dimension Me product after it unexpectedly became popular, causing an error message to appear for overseas users.\n- OpenAI acknowledged the limitations of sourcing training data from Reddit due to malicious groups using those discussion forums to organize.\n- In 2015, then-Reddit CEO Ellen Pao attempted to take action to curb racist behavior on the platform, though those efforts were poorly received and led to harassment and backlash.\n- Deborah Raji worked on several award-winning projects to highlight cases of bias in computer vision and to improve documentation practices in machine learning.\n- The U.S. Department of Justice and the Department of Housing and Urban Development filed a joint court brief asserting that tenant-screening algorithms are subject to the Fair Housing Act.\n- The Department of Justice announced terms of a settlement agreement with Meta resolving allegations that it sold ads in violation of the Fair Housing Act.\n- Meta will remain under federal government supervision until 2026 as part of that enforcement action.\n- Meta developed a system to reduce discrimination in Facebook ads.\n- The Department of Justice worked with the Equal Employment Opportunity Commission to issue guidance to businesses using hiring algorithms on how to avoid violating the Americans With Disabilities Act.\n- The White House proposed an AI Bill of Rights intended to protect citizens from harmful algorithms in critical areas such as housing, health care, finance, and government benefits.\n- The dataset of profile pictures was taken offline.\n- Stuart Colianni removed the pictures from Kaggle.\n- Tinder requested that Kaggle remove the dataset.\n- Tinder said it continued to implement measures against automated use of its API to deter and prevent scraping.\n- Tinder stated it is taking appropriate action and investigating the incident further.\n- The app displays a disclaimer at the start of each chat warning that the AI may not be historically accurate and advising users to verify factual information.\n- The developer implemented light guardrails intended to prevent hate speech from the historical figure simulations.\n- The app checks each historical figure's response for racist or hateful content and omits such responses.\n- When hateful content is detected, the app displays an error message stating that a hateful message was detected and that the response is being omitted to avoid spreading hateful content.\n- The developer stated that he is actively working on improvements to make the app more accurate.\n- Lawmakers in Europe and the United States have increased scrutiny of Apple in the wake of allegations that it limits competition.\n- Spotify launched a website called Time to Play Fair to defend its position and criticize Apple's app store policies.\n- Apple publicly justified rejecting Spotify's audiobook offering by arguing that the way Spotify offers audiobooks breaches the rules surrounding online purchases and customer communication.\n- She wrote a rough outline of the 3\u00bd-year ordeal.\n- She brought the outline and the black notes to a nearby police station in June 2021.\n- Her daughter lent Ide 200,000 yen to help her financially.\n- Her daughter gave Ide an ultimatum that if she did not get the money back from him she must admit it was a scam.\n- Her children helped her over three months to escape the mind-control exerted by her online husband.\n- She apologized to friends and acquaintances who lent money to her while she refused to listen to them.\n- She vowed to continue drawing manga to pay back those she owed.\n- She published a novel titled 'Poison Love' based on her ordeal to help others avoid being scammed.\n- She published a comic titled 'Poison Love' that is a fictionalized account of her ordeal.\n- Ring responded to an inquiry from US Senator Ed Markey and confirmed that there were 11 cases in 2022 in which it complied with police 'emergency' requests and handed over private recordings.\n- Ring stated that it will only respond immediately to urgent law enforcement requests for information in cases involving imminent danger of death or serious physical injury.\n- Ring said its policy is to review any police requests for assistance and make a good-faith determination whether the request meets the federal-law standard of imminent danger requiring disclosure without delay.\n- CNET issued a linked statement via email acknowledging it had been trying out AI to assist the Money editorial team with basic explainers.\n- CNET labeled AI-written articles under the byline 'CNET Money Staff' and identified on its website that that byline denotes content generated using automation technology.\n- CNET said a team of editors is involved in AI-generated content from ideation to publication to ensure the information published is accurate, credible, and helpful.\n- CNET committed to continue publishing each article with editorial integrity and to uphold accuracy, independence, and authority as key editorial principles.\n- CNET committed to continue assessing and testing new AI tools to determine whether they are right for the business.\n- Morris posted updates to Twitter.\n- Morris told Motherboard that users were informed the messages were co-written by humans and machines from the start.\n- Koko pulled the AI co-writing feature.\n- iRobot terminated its relationship with the service provider who leaked the images.\n- iRobot is actively investigating the matter.\n- iRobot said it is taking measures to help prevent a similar leak by any service provider in the future.\n- iRobot said it flags any image with sensitive information and notifies the company\u2019s chief privacy officer when sensitive information is detected.\n- iRobot said that when an image is discovered where a user is in a compromising position, it deletes that image and the entire video log from iRobot servers.\n- Dreame changed its privacy policies related to how it collects personal information.\n- Dreame pushed out multiple firmware updates.\n- Google relaunched Bard as Gemini in February 2024, introducing three models: Gemini Ultra, Gemini Pro, and Gemini Nano.\n- Google launched Gemma, a family of free and open-source large language models, in February 2024 as a lightweight version of Gemini.\n- The Center for Research on Foundation Models published a Gemini 1.0 Ultra API transparency report.\n- Google was fined in March 2024 for training Gemini on news content without consent.\n- Grant & Eisenhofer informed all its attorneys about the situation after Barbara Hart's incident.\n- Barbara Hart provided a sworn affidavit describing the incident.\n- Dozens of attorneys and their firms filed a lawsuit against Madison Square Garden over the ban.\n- A judge ruled that Madison Square Garden may revoke and refuse to sell tickets to the affected firms.\n- The judge also ruled that Madison Square Garden cannot deny entry to a show to someone who has a valid ticket once they arrive.\n- Both the plaintiffs and the defendants appealed the judge's ruling.\n- Davis, Saperstein and Solomon said it was looking to appeal the ban through New York's Liquor Authority.\n- Madison Square Garden issued a public statement affirming its policy and saying attorneys are allowed back once litigation is resolved.\n- A Madison Square Garden spokesperson publicly stated that the company uses facial recognition for event safety and will continue to use it to prevent prohibited individuals from entering its venues.\n- Apple released iOS 16.1.2, which includes crash detection optimizations for iPhone 14 and iPhone 14 Pro models.\n- Apple instructed users to update to the latest version of iOS by going to Settings, selecting General, and tapping Software Update on their iPhone.\n- Vedal has a team that monitors and moderates Neuro-sama and the chat.\n- There are many filters in place to prevent her being inappropriate or offensive, including some powered by AI.\n- A human moderator is required to be present during streams to oversee Neuro-sama's interactions.\n- Vedal routinely makes improvements to the AI and the stream before going live each day.\n- 5you asked to be referred to by his online pseudonym for safety after receiving death threats.\n- Radius5 released a statement saying the artists were being targeted for abuse on social media.\n- Radius5's CEO publicly implored critics to refrain from criticizing or slandering creators.\n- Radius5 froze the Mimic beta indefinitely because users were uploading other artists' work.\n- NovelAI paused its image-generation service for emergency maintenance after traffic spikes and a hacking incident.\n- NovelAI published a blog post in Japanese explaining how its service works.\n- NovelAI scrambled to hire friends to translate its Twitter and Discord posts.\n- A Japanese artist tweeted screenshots showing layers of her illustration software to counter accusations that she was secretly using AI.\n- Two major VTuber bands requested that their social media followers stop using AI in fan art.\n- Pixiv announced it would launch tags to filter out AI-generated work in its search feature and in its popularity rankings.\n- The Jefferson Parish Sheriff's Office rescinded the July arrest warrant for Randal Reid.\n- Randal Reid was released from the DeKalb County jail on Dec. 1.\n- Jefferson Parish detectives tacitly admitted the error in identifying Randal Reid.\n- The New Orleans City Council rolled back a two-year ban on police use of facial recognition and established new rules governing its use.\n- Under the new New Orleans rules, police may use facial recognition only to generate investigative leads.\n- Under the new New Orleans rules, officers must obtain high-level approval before lodging a facial recognition request through the Louisiana State Analytic and Fusion Exchange.\n- Under the new New Orleans rules, all possible facial recognition matches must undergo peer review by other facial recognition investigators.\n- Sheriff Joe Lopinto\u2019s office denied a formal request for the July 18 arrest warrant for Randal Reid, citing an ongoing investigation.\n- Sheriff Joe Lopinto\u2019s office denied a formal request for copies of policies or purchases related to facial recognition, citing an ongoing investigation.\n- Poland's data protection authority (UODO) opened an investigation into OpenAI's ChatGPT for alleged violations of the EU General Data Protection Regulation (GDPR).\n- The in-store \"Marty\" robots will identify potential safety hazards such as spills of liquid, powder, or bulk food items in store aisles.\n- The robots will alert store managers to spills and other hazards.\n- The robots will issue alerts for clean-up when hazards are detected.\n- Twitter barred (suspended) the verified account @S4GE_ETH that posted the deepfake video.\n- Vice News reported on the deepfake video and accompanying phishing scam.\n- Gizmodo advised readers not to participate in the giveaway scam and warned them not to listen to the real Sam Bankman-Fried or any imitation versions.\n- Sanitation workers and their union organized and participated in ongoing protests against the tracking devices.\n- Some sanitation workers put the smartwatches in purses or pockets to prevent the camera from turning on.\n- Chandigarh Municipal Corporation officials stated that workers' data are secured and deleted after three months.\n- Undark journalists repeatedly contacted Chandigarh Municipal Corporation Commissioner Anindita Mitra to verify details about the smartwatch program.\n- An Imtac India representative, Abhay Khare, said he personally checked whether the GPS trackers allowed unwanted calls.\n- The Chandigarh Sanitation Workers' Union planned to be present at an upcoming protest against the tracking devices.\n- Judge Roberto Andr\u00e9s Gallardo suspended the use of the facial recognition system in question.\n- Judge Gallardo demanded explanations from the City of Buenos Aires Minister of Security and Justice about how biometric data were transferred from ReNaPer to city authorities.\n- Judge Gallardo gave Marcel D\u2019Alessandro, Minister of Security and Justice for the City of Buenos Aires, two days to explain how the biometrics of specified individuals were used.\n- Judge Gallardo ordered a raid on the Ministry of Justice and Security and the Urban Monitoring Center.\n- Judge Gallardo demanded a full tracing report and details on the origin of the transfers and how the biometrics have been used.\n- Judge Gallardo stated that the systems should be able to supply information on the IP address of the requester for each query into the biometrics held by ReNaPer.\n- Terraform Labs co-founder Do Kwon publicly promised to work with investors to \"weather this crisis\" and to \"build our way out of this.\"\n- Oregon's Department of Human Services announced that hotline workers would stop using the algorithm at the end of June.\n- The department decided to completely replace the existing algorithm with a new Structured Decision Making model.\n- Oregon paused the pilot of its algorithm to help decide when foster care children can be reunified with their families and put the tool on hiatus while researchers rework the model.\n- U.S. Sen. Ron Wyden reached out to the Oregon Department of Human Services to ask questions about racial bias following the Associated Press story.\n- Sen. Wyden is the chief sponsor of a bill seeking to establish transparency and national oversight of software, algorithms, and other automated systems.\n- Carolyn Henderson emailed Stability.AI to ask for her husband Steve Henderson\u2019s work to be removed from the training dataset.\n- Stability.AI\u2019s chief technology officer publicly encouraged artists who don\u2019t want their works in the data set to contact LAION to request removal.\n- Holly Herndon and Mat Dryhurst launched a website called Have I Been Trained to let artists search whether their work is among the images used to train Stable Diffusion and Midjourney.\n- Newgrounds explicitly banned AI-generated images on its platform.\n- The Content Authenticity Initiative began developing an open standard to watermark digital content to prove authenticity and ensure creators get proper attribution.\n- Karla Ortiz has been raising awareness about issues around AI-generated art and copyright.\n- A coalition within artist industries is growing and mobilizing to figure out how to tackle or mitigate the use of artists\u2019 works in AI training data.\n- The UK government proposed changing laws to allow AI developers greater access to copyrighted data for training while giving rights holders the choice of where to make their works available.\n- Stability.AI released Stable Diffusion with a license agreement that explicitly bans users from using the model or its derivatives in ways that break laws or regulations.\n- Wysa's vice president of marketing emailed Rest of World defending the app and saying it builds \"emotional resilience.\"\n- In an interview, Wysa's vice president of marketing credited the Singapore government with doing a \"fantastic job\" rolling out the Mindline service and making it widely available quickly.\n- Wysa's lead psychologist gave an interview attributing the backlash to the Wysa bot being introduced when teachers were already in a \"state of angst.\"\n- Sarah Baldry advised teachers to raise workplace issues directly with management.\n- Sarah Baldry said some of Wysa's features could help teachers prepare for difficult conversations.\n- Sarah Baldry later withdrew her statement referring to Singapore's non-confrontational culture as context for teachers' reticence.\n- Wysa declined to share a breakdown of its revenue model when asked.\n- The Ministry of Health declined to comment to Rest of World and directed the outlet to speak to the Ministry of Education.\n- San Francisco supervisors voted unanimously to explicitly ban the use of robots for deadly force for now.\n- The Board of Supervisors sent the issue back to a committee for further discussion.\n- The board voted to advance the broader police equipment policy, including the ban on lethal robots.\n- Oakland police backed down from plans to arm robots and instead opted to equip them with pepper spray.\n- The policy still allows police to use robots to check out potentially dangerous scenes so that officers can stay back.\n- In response to ProPublica's questions, the company acknowledged that the price-sharing practice could seem anti-competitive.\n- In response to ProPublica's questions, the company countered that landlords otherwise figure that information out themselves by conducting phone surveys of competitors.\n- Upstart is working to improve its artificial intelligence models.\n- Upstart committed to continuing to work with Relman Colfax to improve its model.\n- Upstart committed to addressing evidence of discrimination in its model.\n- Upstart established Relman Colfax as a monitor of its fair lending practices under a December 2020 agreement.\n- Upstart opened itself to external scrutiny.\n- Hugging Face gated the GPT-4chan model to restrict access after researchers alerted the site to its harmful nature.\n- Hugging Face disabled the model's inference widget to make it harder to use.\n- Hugging Face blocked all downloads of the model.\n- Hugging Face prioritized and was working on a feature to gate harmful models for ethical reasons.\n- The uploader provided a model card and an accompanying video that clearly warned about the model's limitations and the problematic nature of 4chan's /pol/ board.\n- Yannic Kilcher said he limited the time and amount of the bot's postings.\n- Yannic Kilcher said he would not hand out the bot's code.\n- OpenAI invited 23 external researchers to 'red team' DALL-E 2 to find flaws and vulnerabilities.\n- OpenAI limited DALL-E 2's initial access to about 400 trusted users (OpenAI employees, board members, and hand-picked academics and creatives) and restricted use to non-commercial purposes.\n- OpenAI researchers attempted to filter out sexual content from the training data to reduce disproportionate harm to women.\n- OpenAI published a 'Risks and Limitations' document for DALL-E 2.\n- OpenAI published a model card documenting DALL-E 2's risks.\n- OpenAI stated it was being transparent and upfront with users about the system's remaining limitations.\n- OpenAI released GPT-3 only to a limited group of vetted developers and companies for commercial use.\n- Google stated that the assistive writing feature is in an \"ongoing evolution.\"\n- A Google spokesperson said the company's assisted-writing technology is always improving.\n- Google indicated that Google Docs users' responses will be used to train and improve the assisted-writing algorithms.\n- The Fair Trade Commission fined Naver's shopping service 26.5 billion won for manipulating search algorithms.\n- The Fair Trade Commission fined Naver's video service 200 million won for manipulating search algorithms.\n- Naver overhauled the algorithms' search logic to show what it described as the best results meeting users' demands.\n- Naver said it will take legal action in response to the FTC's fine.\n- The Fair Trade Commission plans to send a review report to Google within this year.\n- The Fair Trade Commission plans to take the case to a commissioners' meeting.\n- Feminist activists and journalists conducted a grassroots audit of the AI system.\n- Activists quickly activated a well-oiled machine of community organizing to mobilize against the AI system.\n- These activists brought national media attention to how the untested, unregulated technology was being used to violate the rights of girls and women.\n- Feminist activists used the resulting media attention to enforce a measure of public accountability regarding the AI system.\n- Journalists revealed that the Conin Foundation and Microsoft were behind the technology.\n- The Applied Artificial Intelligence Laboratory at the University of Buenos Aires publicly highlighted the platform's technical and design errors.\n- The Applied Artificial Intelligence Laboratory at the University of Buenos Aires challenged the developers' claim that the model made \"correct predictions 98.2 percent of the time.\"\n- Technical reviews revealed that the system's database included ethnic and socioeconomic data.\n- Technical reviews revealed that the system's database omitted information about access to sex education or contraception.\n- The feminist collective Socorro Rosa highlighted data showing many teenage pregnancies are a consequence of sexual violence and asserted adolescents' rights to safety, consent, sex education, and access to safe abortion.\n- Feminist activists worked to make knowledge and data accessible to all and to promote forms of solidarity and empowerment rather than surveillance and control.\n- The EU and US began developing concrete plans to audit algorithmic systems.\n- Cruise employees manually moved the motionless vehicles out of the roadway to resolve the blockage.\n- Cruise issued a public statement apologizing to anyone inconvenienced and saying the clustering issue was resolved.\n- San Francisco transportation, police, and fire officials urged the California Public Utilities Commission to reject Cruise\u2019s permit for commercial ride-hailing services.\n- City officials sent a letter to the California Public Utilities Commission citing specific incidents of Cruise vehicles blocking traffic and impeding emergency response.\n- Sarawak Information Systems removed the \"race\" variable from the algorithm.\n- Sarawak Information Systems said it had held consultations during the process.\n- Sarawak Information Systems said it had taken steps to address some of the concerns raised.\n- Some judges reduced the AI-recommended sentences in light of mitigating factors.\n- Some judges imposed tougher sentences than the AI recommendation on the basis that the recommendation would not serve as a strong enough deterrent.\n- Hamid Ismail appealed his client's AI-recommended sentence.\n- Employees were instructed to delete the offending accounts.\n- Employees were instructed to give the person complaining control over the offending accounts.\n- Employees were instructed to tell complaining creators that Flipagram cannot prevent a user from uploading someone else\u2019s content.\n- ByteDance responded to BuzzFeed News by stating that Flipagram and Vigo ceased operations years ago and aren't connected to any current ByteDance products.\n- ByteDance capped video views from scraped content at a certain level so scraped content would not overwhelm content posted by real Flipagram users.\n- Flipagram limited how frequently it would recommend cross-posts to incentivize creators to post content first to Flipagram.\n- Sen. Richard Blumenthal called on regulators, including the FTC, to investigate ByteDance's alleged theft of data from Instagram and Snapchat users.\n- TikTok initiated a program to isolate US user data in US data centers to reduce fears that the data could be accessed by the Chinese government.\n- ByteDance agreed to pay $92 million to settle a lawsuit alleging the company harvested biometric information from TikTok users without permission.\n- The developers have hidden their real identities and spoken on condition of anonymity.\n- The company provided a demonstration of the technology to Google to prove it could estimate vehicle speed.\n- An iOS version of the app has been developed.\n- Apple has been contacted for comment.\n- Facebook traced the root cause of the ranking failure to a software bug.\n- Facebook applied needed fixes to address the software bug.\n- Engineers fixed the ranking issue on March 11th.\n- Facebook detected inconsistencies in downranking on five separate occasions.\n- The incident was internally designated a level-one SEV (site event).\n- Facebook conducted an internal investigation into the incident and its effects.\n- An internal report on the incident was shared inside the company.\n- A Meta spokesperson publicly confirmed the incident in a statement to The Verge.\n- Researchers at the Stanford Internet Observatory began an investigation into the number of computer-generated images on LinkedIn profiles after noticing suspicious profile photos.\n- LinkedIn removed most of the fake profiles found during the investigation.\n- LinkedIn is updating its defences to catch fake accounts.\n- The S\u00e3o Paulo metro operator was ordered to immediately suspend the process of capturing and processing biometric data for facial recognition.\n- The company was ordered to immediately suspend the roll-out of new equipment that promotes data capture and biometrics processing for facial recognition.\n- The court decision established a daily fine to be imposed in the event of non-compliance with the suspension order.\n- METRO stated that it will appeal the decision and provide all clarifications.\n- Tesla terminated John Bernal's employment.\n- Tesla cut off Bernal's access to the Full Self-Driving (FSD) Beta system in his personally owned 2021 Tesla Model 3.\n- Tesla managers verbally told Bernal he had broken company policy.\n- Tesla managers held a video conference with Bernal to dissuade him from posting negative or critical content about FSD Beta.\n- Tesla admonished Bernal for selling merchandise bearing the words \"full self-driving (beta)\".\n- Tesla admonished Bernal for using FSD Beta in an unsafe manner.\n- Federal vehicle safety regulators initiated a probe into Tesla's FSD Beta program.\n- TikTok increased safety and security resources to respond to the war in Ukraine.\n- TikTok worked to remove harmful misinformation from the platform.\n- TikTok partnered with independent fact-checking organisations to support efforts to keep the platform safe and authentic.\n- Three former Mac Makeup employees filed legal action against Estee Lauder over job losses linked to a video interview using facial analysis technology.\n- The parties eventually reached an agreement outside of court.\n- Hirevue defended its platform against accusations of bias.\n- Hirevue dropped the facial analysis technology from its products.\n- The TV network confirmed that the Ukraine 24 news ticker was hacked and that the messages were false.\n- President Zelenskyy filmed a short video debunking the hacked messages and called them a childish provocation.\n- President Zelenskyy quickly debunked the deepfake video of him.\n- Channel One acknowledged Marina Ovsyannikova's on-air protest to the TASS news agency.\n- The court issued a fine of 30,000 rubles to Marina Ovsyannikova.\n- Fake accounts impersonating Ovsyannikova that attempted to spread false information were removed.\n- Meta removed the 'Ukrainian Legion' Facebook page for violating its impersonation policy.\n- The DFRLab searched for the Ukrainian Legion page's ads in the Facebook Ad Library as part of its investigation.\n- YouTube removed all Russian state-funded media channels globally.\n- YouTube suspended monetization within Russia.\n- The Guardian and Meduza published articles explaining how Ovsyannikova could have interrupted the live broadcast.\n- The Justice Department, on behalf of the Federal Trade Commission, filed a complaint alleging violations of the Children\u2019s Online Privacy Protection Act.\n- Kurbo revised the signup option for users over 13 years old in 2020.\n- A federal judge in California approved a settlement order requiring Weight Watchers and Kurbo to pay a $1.5 million penalty.\n- The settlement order requires Weight Watchers and Kurbo to delete sensitive health data.\n- The settlement order requires Weight Watchers and Kurbo to destroy any algorithms derived from the data.\n- On April 15, the company updated its privacy policy to add more disclosure about how it uses customers' photos.\n- The company added a sentence to the privacy policy clarifying that some technologies may be used in separate enterprise products but users' files and personal information will not be shared.\n- On April 30, the company added a new in-app pop-up feature that allows users to opt out of having their images used in the app's facial recognition tool.\n- The company made the in-product opt-out feature available to all Ever users globally, whereas it had previously been available only in certain geographic regions.\n- Ukraine's Security Service (SSU) shut down a troll farm in the city of Lviv.\n- The SSU uncovered two bot farms in Lviv with a total capacity of 18,000 fake accounts.\n- The SSU dismantled the two bot farms in Lviv.\n- The SSU seized two sets of GSM gateways, 3,000 SIM cards, laptops, and accounting records.\n- The SSU issued a press release announcing the uncovering and dismantling of the bot farms.\n</mitigation_statements>"}]}}
{"custom_id": "batch_800", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- Horizon Worlds added a default four-foot buffer zone around users' avatars in February.\n- VRChat and Rec Room start users off with a default personal-space (buffer) zone.\n- Social VR apps provide an invisible personal-space bubble feature to prevent other avatars from coming too close to a user.\n- Social VR apps allow users to mute people they do not want to hear.\n- Social VR apps allow users to block people entirely so they cannot see or hear each other.\n- Users can vote to kick someone out of a VR space, and such a community vote expelled a user in Horizon Worlds.\n- Human moderators are used to respond to complaints of bad behavior in VR apps.\n- Apps may suspend or ban users if their behavior is egregious enough.\n- Rec Room is testing Modulate's ToxMod AI software in some of the app's public spaces to detect harassing or racist language.\n- ToxMod monitors and analyzes users' speech to predict harassing language and can alert a human moderator or automatically mute offending users.\n- Modulate notifies users when they enter a virtual space where ToxMod may be in use.\n- Modulate's community manager communicates with users online (such as via a game's Discord channel) to answer questions when a new app or game starts using ToxMod.\n- Meta stated it will continue to make improvements to safety as it learns more about how people interact in VR spaces.\n- Kelly Guillory spoke out on Twitter about the harassment she experienced.\n- The state of Texas filed a lawsuit against Facebook parent Meta alleging the company illegally collected biometric data of users and engaged in deceptive business practices.\n- Meta settled a previous lawsuit with the state of Illinois in 2021 for $650 million.\n- Zhihu stated that it has never installed nor used the behavior perception system.\n- Zhihu stated that it will not use such software in the future.\n- Zhihu said the authenticity of the screenshot is unclear.\n- Zhihu stated that the company firmly opposes systems that illegally collect personal information.\n- Meta took down dozens of fake pro-Russian accounts, groups, and pages across its platforms.\n- Meta disrupted the influence network before it could amass a large audience.\n- Meta notified users who were targeted by the Ghostwriter hacking campaign.\n- Meta is ramping up user security protections in Russia.\n- Meta will soon roll out in Russia a profile 'lock' tool (already deployed in Ukraine) that allows users to quickly lock their profiles and restrict access to their content.\n- Meta will place a notification at the top of Russian users' feeds reminding them about steps they can take to secure their accounts.\n- Meta publicly disclosed the operation and its takedown to inform people about the activity.\n- Roblox constantly tries to take condo games offline using automated systems.\n- Roblox constantly tries to take condo games offline using manual systems.\n- Roblox conducts a safety review of every uploaded image, video, and audio file using machine detection.\n- Roblox conducts a safety review of every uploaded image, video, and audio file using human reviewers.\n- Roblox developed Parental Control tools to restrict who children interact with and which experiences they can access.\n- Roblox states that it takes swift action against anyone found to be acting in breach of its Community Standards.\n- Roblox published a blogpost summarising what it is doing to protect young people.\n- Meta introduced a Personal Boundary feature in Horizon Venues to address virtual sexual assault concerns.\n- Twitter issued a public statement acknowledging that it had taken enforcement action in error and explaining the situation.\n- Twitter said it was expeditiously reviewing the enforcement actions it had taken.\n- Twitter proactively reinstated access to a number of affected accounts.\n- Twitter's head of site integrity, Yoel Roth, tweeted that the company was closely investigating what had happened.\n- Jonas Bendiksen called Magnum's CEO, Caitlin Hughes, to inform her about the project.\n- Magnum posted an interview in which Bendiksen publicly revealed that the images and the book's introduction had been faked.\n- Jonas Bendiksen emailed a link to the Magnum interview to Jean-Fran\u00e7ois Leroy, the director of Visa Pour L\u2019Image.\n- Visa Pour L\u2019Image made a feature to disclose and discuss the stunt and its implications.\n- Magnum is deciding whether and how to contact people who bought the book or prints to inform them that they were deceived.\n- Gost's online listing for the book was updated to subtly link to media coverage of the stunt.\n- Editors at LFI magazine began discussions about how to disclose that their earlier item about the book did not tell the full story.\n- Four different letters were sent to the attorney general's office in New York State, the New York State Inspector General, and the U.S. Department of Justice demanding action.\n- Rights groups urged the federal government to stop funding call monitoring technology.\n- Rights groups urged regulators to block further expansion of surveillance tools in prisons and jails.\n- The Department of Justice said it is reviewing technology programs receiving federal funding to ensure they enhance public safety while respecting constitutional rights.\n- The New York State Inspector General's Office said it would review the letter and thoroughly investigate complaints that are sent in.\n- Securus said users can set attorney numbers to private so those calls are not recorded and cannot be monitored.\n- Securus said it acts immediately to delete inadvertent recordings.\n- The Suffolk County Sheriff's office reviews all its surveillance strategies on a monthly basis to ensure the terms used in the Verus system are appropriate.\n- The Suffolk County Sheriff's office decided not to pass the cost of the Verus system onto prisoners.\n- Worth Rises is urging state and local law enforcement to offer prisoner phone calls for free.\n- Greater Manchester Coalition of Disabled People launched a legal challenge against the Department for Work and Pensions.\n- A legal letter was sent to the Department for Work and Pensions demanding details of the automated process that triggers investigations.\n- Foxglove assisted the Greater Manchester Coalition of Disabled People in sending the legal letter to the DWP.\n- Privacy International found references in a DWP report to its use of 'cutting-edge artificial intelligence'.\n- Privacy International raised concerns about the DWP's use of AI.\n- Specialist staff were involved in cases of suspected fraud and error.\n- Support was offered to claimants who needed it.\n- The DWP said it will respond to the legal letter from the GMCDP in due course.\n- The New York City Police Department returned its Spot robots.\n- Motherboard submitted a public records request for documentation of the Honolulu Police Department\u2019s use of the robot since January.\n- Boston Dynamics issued an emailed statement approving HPD\u2019s use of its robot and stating that Spot is intended to augment public safety officials, operate under human control, and remove humans from potentially hazardous environments.\n- Honolulu Police Department officials presented to the city council to defend the purchase and argued that Spot would save money by reducing manpower and equipment needs and reduce officer exposure to COVID-19.\n- Lauren Book immediately notified law enforcement about the threatening messages and explicit photos.\n- Lauren Book began working closely with law enforcement to track those responsible for sending the images and messages.\n- Book contacted the Florida Department of Law Enforcement on Nov. 12.\n- An undercover agent took over communication with the unidentified person.\n- Law enforcement negotiated to pay the person $4,000 in cash in exchange for watching the person delete the photos.\n- Agents set a meeting for Nov. 17 at a Sunrise Starbucks as part of the operation.\n- Agents arrested the person at the meeting.\n- Agents searched Kamperveen\u2019s phone.\n- Agents reported finding the messages and a folder containing photos and videos of Book on Kamperveen\u2019s phone.\n- Officials said the investigation remains active.\n- Emirati authorities said they were handling the rebel group's attack with transparency and responsibility.\n- Investigations into the attack were ongoing, Abu Dhabi officials said.\n- Etihad Airways implemented precautionary measures that resulted in a short disruption for a small number of flights.\n- Airport operations at Abu Dhabi returned to normal after the disruption.\n- The United States said it would work with the UAE and international partners to hold the Houthis accountable.\n- The U.N. Secretary-General denounced the assault and urged all sides to prevent any escalation amid heightened tensions.\n- The U.N. special envoy for Yemen traveled to Riyadh to meet with Saudi and Yemeni officials about the recent military uptick.\n- Saudi Arabia and other Arab states publicly condemned the attack.\n- U.S. Air Force officials stated that U.S. forces were ready and available to assist and support their Emirati partners if requested.\n- Tesla pulled the October 2021 version 10.3 Full Self-Driving update two days after it began rolling out due to an issue with left turns at traffic lights.\n- Tesla issued version 10.3.1 of the software one day after pulling version 10.3.\n- The app was taken down.\n- Ismat Ara filed a complaint with the Delhi Police against unknown people for harassing and insulting Muslim women on social media.\n- Delhi Police\u2019s Cyber Crime Unit registered a first information report on Sunday invoking Indian Penal Code sections 153A, 153B, 354A and 509.\n- A police case was registered in Mumbai against various Twitter handles and the 'Bulli Bai' app developers following a complaint by Sidrah.\n- GitHub blocked the user responsible for hosting the site.\n- Police authorities are coordinating further action.\n- The YouTube video/channel 'Liberal Doge' was removed by the company after outrage.\n- Mumbai Police requested data from Twitter, GitHub and GoDaddy.\n- Several Indian parliamentarians raised the matter with the government.\n- Priyanka Chaturvedi publicly called on India's IT minister to take stern action against the misogynistic and communal targeting of women.\n- The activist sent a legal notice to the Commissioner of Police of Hyderabad after the incident.\n- The activist filed a public interest litigation (PIL) in the Telangana High Court against the state of Telangana and the Commissioner of Police challenging the use of facial recognition technology.\n- The Internet Freedom Foundation supported the filing of the PIL.\n- The Telangana High Court issued a notice to the state government regarding the PIL.\n- Amazon updated Alexa to prevent the assistant from recommending such activity in the future.\n- Amazon said it fixed the error as soon as the company became aware of it.\n- The Personal Information Protection Commission and the Ministry of Health and Welfare published guidelines stating that biometric data can only be used with the data subject\u2019s consent.\n- Bucheon\u2019s city government said it will de-identify CCTV footage by blurring individuals' faces before using the images to train AI algorithms.\n- Bucheon will restrict algorithm development to pre-produced footage until the end of the year and begin using actual CCTV footage starting next year.\n- Ansan will hold orientation sessions for parents, daycare directors, and teachers from city daycare centers by the end of the year before beginning system development.\n- Ansan plans to run a pilot program next year to detect child abuse using CCTV in daycare centers.\n- Ansan plans to expand the child-abuse detection project to all daycare centers in Ansan in the second half of 2023.\n- The Shanghai Xuhui District Market Supervision Administration fined Shanghai Xpeng Automobile Sales Service Co., Ltd. 100,000 RMB for using face-recognition cameras without consumers' consent.\n- Xpeng Automobile stated that it fully accepted and submitted to the administrative penalty.\n- Xpeng stated that the facial data collected and analyzed by the third-party software provider have been completely deleted.\n- Xpeng stated that it conducted deep reflection regarding the incident.\n- Xpeng issued a formal apology to the public and customers for the inconvenience caused by the incident.\n- Xpeng committed to strictly comply with national regulations on personal information protection to ensure customers' lawful rights are safeguarded.\n- Researchers at KU Leuven and New York University examined 33.8 million Facebook ads that ran between July 2020 and February 2021 to quantify the platform's political ad policy enforcement.\n- Ads labelled as political on Facebook display a disclaimer that explains who paid for them.\n- Ads that are found to be political but were not declared as such are taken down.\n- Within the United States, Facebook introduced a moratorium on political ads around the 2020 presidential election.\n- AFP reached out to Facebook to request a comment on the study.\n- Trelleborg municipality is investigating why the personal data ended up in the source code.\n- Trelleborg municipality is investigating why the source code was not screened before it was made public.\n- Stockholm ordered an investigation into the use of automated decision-making by municipalities and regions, to be published in March 2021.\n- The Swedish Parliamentary Ombudsman (JO) is set to make a decision on the complaint regarding the automated decision-making system.\n- An administrative court of appeal ruled that the source code was an official document and the municipality communicated the code to the journalist who requested it.\n- Life360 announced it will stop selling precise location data to the approximately one dozen data brokers it had been working with.\n- Life360 announced it will sell precise location data only to Arity.\n- Life360 announced it will sell only aggregated location data to PlacerAI.\n- Life360 implemented a policy in 2020 prohibiting the selling or marketing of Life360\u2019s data to any government agencies to be used for a law enforcement purpose.\n- Life360 stated that its contracts prohibit customers from re-identifying individual users.\n- Life360 said it maintains an open and ongoing dialogue with its customers to ensure they comply with its policy prohibiting government law enforcement use.\n- Life360 added a 'bubbles' feature to show parents a more vague location of their child.\n- Life360 recruited and paid teenagers to promote the app on TikTok.\n- X-Mode\u2019s new owners said the company would stop selling U.S. location data to defense contractors and similar companies.\n- Life360 said it has no plans to sell data from Jiobit devices or its digital safety services.\n- Life360 said it has no plans to sell data from Tile devices.\n- Life360 provides an in-app setting that allows users to disable the sale of their location data and millions of users have used this opt-out feature.\n- Life360 said it would aggressively take action against any breach of contractual terms prohibiting reidentification.\n- Life360 expanded into other digital safety products and began rolling out data breach alerts, credit monitoring, and identity-theft-protection features.\n- Cuebiq stated that it does not sell raw location data but provides access to an aggregated set of data through its 'Workbench' tool.\n- Henan Province removed the tender after IPVM and Reuters contacted PRC officials.\n- IPVM archived the tender.\n- IPVM reported the story.\n- Reuters published an investigation based on IPVM's findings.\n- Huawei issued a public statement denying knowledge of the Henan security project and asserting that it requires all of its partners to comply with applicable laws, regulations, and business ethics.\n- Huawei told IPVM it had no further comment for now and would inform IPVM if that changes.\n- IPVM asked Huawei whether the company intended to take any action after learning about the Henan project.\n- IPVM contacted the PRC's Ministry of Foreign Affairs multiple times seeking comment but received no response.\n- IPVM contacted Neusoft multiple times seeking comment but did not receive a response.\n- Human Rights Watch issued a statement questioning the use of surveillance technology against minority groups and journalists and calling for explanations about necessity, purpose, and proportionality.\n- Zillow announced it is exiting its Offers business that buys and flips homes.\n- Zillow is eliminating 25% of its workforce.\n- Zillow said it would stop buying houses through the end of the year.\n- Zillow said it will wind down its inventory in an orderly way.\n- Bloomberg reported that Zillow was looking to sell 7,000 homes for $2.8 billion to institutional investors to unload its portfolio of properties.\n- The National Highway Traffic Safety Administration (NHTSA) is investigating the complaint that Tesla\u2019s Full Self-Driving software caused the crash.\n- NHTSA is communicating with Tesla to obtain more information about the incident.\n- NHTSA has asked Tesla for information about its beta testing program, including details about testers' non-disclosure agreements.\n- FACIL'iti filed a lawsuit against French web developer Julie Moynat for alleged denigration.\n- Lawyers met to discuss the FACIL'iti lawsuit against Julie Moynat in early October.\n- FACIL'iti sent a formal notice to French web accessibility consultancy Koena regarding its public statements about overlays.\n- Cinov Numerique issued a motion of support for Koena asking for an end to practices intended to silence debate.\n- Koena was ordered by the court to pay \u20ac26,256 to FACIL'iti following the judgment.\n- Koena was ordered by the court to remove the two tweets that started the legal action.\n- The article author provided financial support to Koena's crowdfunding effort to raise money to appeal the judgment.\n- Accessus.ai launched an Accessibility Litigation Support Suite that includes a complimentary seven-day trial after installation of a single line of JavaScript.\n- Accessus.ai advertised 100% WCAG compliance in less than 48 hours as part of its Accessibility Litigation Support Suite.\n- Accessus.ai offered an Accessibility Statement and Certificate of Performance to customers as part of its Litigation Support Suite.\n- Accessus.ai provided an initial suggested response to demand letters as part of its Litigation Support Suite.\n- Accessus.ai offered a monthly accessibility audit and statement as part of its Litigation Support Suite.\n- Accessus.ai provided a free Accessibility Compliance Evaluation (ACE) tool to check plaintiff firms' level of compliance.\n- Eyebobs settled the digital accessibility lawsuit and agreed to address accessibility across its digital properties including its website, new websites, and mobile apps.\n- Eyebobs agreed in the settlement to make a nominal payment to the plaintiff and to pay the plaintiffs' fees.\n- Accessibility consultant Karl Groves submitted a detailed declaration explaining how and why the Eyebobs case should proceed despite the company's use of an overlay.\n- Disability Rights Advocates announced it had settled its lawsuit against ADP and the settlement agreement explicitly stated that overlay solutions will not suffice to achieve accessibility.\n- A U.S. federal court denied U.S. Wings' motion to dismiss and concluded that the company had not shown it had fixed accessibility issues despite using accessiBe.\n- AudioEye filed a lawsuit against accessibility expert Adrian Roselli.\n- AudioEye sent a cease and desist letter to Adrian Roselli.\n- Adrian Roselli wrote and published a response letter to AudioEye urging the company to embrace valid criticism rather than threaten critics with legal action.\n- A federal judge approved a class action settlement between the visually impaired plaintiffs and the eyewear company.\n- The Ministry of Justice provided documents to Democratic Party lawmaker Park Joo-min about the AI identification and tracking system project.\n- The Ministry of Science and ICT provided documents to Democratic Party lawmaker Park Joo-min about the AI identification and tracking system project.\n- The Ministry of Justice conducted a careful review that included legal counsel from a law firm and determined the project fell within the original scope of information collection purposes for immigration review.\n- The Ministry of Justice acknowledged that the consent of the subjects of the information was not obtained.\n- Tesla implemented a recall affecting 11,704 vehicles equipped with FSD 10.3.\n- Tesla uninstalled FSD 10.3 from affected Model S, Model X, Model 3, and Model Y vehicles.\n- Tesla issued an over-the-air software update releasing FSD version 10.3.1 to the affected vehicles.\n- Tesla informed the National Highway Traffic Safety Administration that it had updated the software and released FSD version 10.3.1 to those affected vehicles.\n- The National Highway Traffic Safety Administration issued a letter to Tesla asking why the company had decided against issuing a recall after releasing an over-the-air FSD fix.\n- The National Highway Traffic Safety Administration said it will continue conversations with Tesla to ensure that any safety defect is promptly acknowledged and addressed according to the National Traffic and Motor Vehicle Safety Act.\n- Adobe avoided using the term \"deepfake\" in its briefing materials about Project Morpheus.\n- Adobe provided a long public response explaining how seriously it takes deepfake threats and what it is doing about them.\n- Adobe is focusing its efforts on content authentication schemes to address deepfake threats.\n- Adobe limited Project Morpheus to only allow small, pre-ordained tweaks to a subject's appearance.\n- Adobe prevented Project Morpheus from performing face swaps.\n- Adobe restricted Project Morpheus's edits to people facing the camera.\n- The Archbishop, Mons. Julio Endi Akamine, has been informed of the incident and has taken the necessary measures to prevent such events from happening again.\n- Father Augusto Bezerra announced that his next Mass will be offered as a Mass of reparation.\n- Huq asked both app partners to rectify their code.\n- Both app partners republished their apps after rectifying their code.\n- Kaibits Software resolved the permissions problems in its app.\n- Google said it was investigating.\n- The Danish data authority opened an investigation into whether there is a legal basis for Huq's processing of personal data.\n- The UK's Information Commissioner's Office issued a reprimand to Tamoco for failing to provide sufficient privacy information to UK citizens.\n- The ICO asked Tamoco to review the personal data they collected to ensure that UK citizens' data was no longer processed.\n- The ICO asked Tamoco to delete any remaining records.\n- Users can stop this behavior in iOS 15 by fully killing the app's background process each time.\n- Users can stop this behavior in iOS 15 by manually turning off the 'Background App Refresh' setting for the app.\n- Users can stop this behavior in iOS 15 by changing the app's permissions.\n- A Meituan engineer advised users to be cautious about downloading the system-log-reading software.\n- Cruise employees manually moved the motionless vehicles out of the roadway to resolve the cluster.\n- A Cruise spokesperson issued a public statement apologizing to anyone who was inconvenienced and stating that the issue had been resolved.\n- Chow wrote an email to Insider explaining that he had deliberately not fully explained the app in his viral TikTok video.\n- Chow replied to TikTok comments defending and explaining his app and answering commenters' questions.\n- Users can avoid having their information shared by not signing up for The FaceTag.\n- Users can make their FaceTag profile private so others must hit \"accept\" before their contact information is shared.\n- Users can remove someone as a FaceTag \"friend\" to revoke that person's access to their contact information.\n- Management hired a private security firm to prevent the striking workers from entering the Bergmannkiez warehouse.\n- The company sent managers from headquarters to Bergmannkiez as strikebreakers.\n- The company fired a rider without notice, allegedly for submitting a sick note late.\n- The company sent transfer agreements to 1,700 of 2,000 Gorillas workers in Berlin to transfer operations to a newly founded subsidiary.\n- Management at Bergmannkiez promised the workers that they would negotiate their demands on Monday.\n- Instagram deleted the 'Gorillas Rider Life' social media channel for the third time.\n- The FAU provided support to the strike fund and the work of the Gorillas Workers Collective.\n- Workers have been building their own strike fund since summer.\n- Workers solicited donations and provided a link for contributions to the strike fund.\n- The Gorillas Workers Collective published daily information on upcoming events and where help was needed via their Twitter channel.\n- The feature that allowed users to compare two statements was disabled after it generated a number of particularly offensive answers.\n- The Verge reached out to the system's creators to confirm whether that comparison feature had been disabled and to request comment.\n- The Allen Institute for AI issued a public statement clarifying that Delphi is a research prototype intended to study the potential and limitations of language-based commonsense moral models and that they do not propose elevating AI into a position of moral authority.\n- The Verge published a correction clarifying that Ask Delphi was trained on Reddit prompts only and not on Redditors' responses.\n- The government intensified several public information campaigns in the final weeks of the year to address consumer lack of awareness about the new social electricity bonus.\n- The government set a moratorium on the transition to the new bonus model until the end of the year.\n- The government suspended the electricity discount for all users who did not request the change before October 8.\n- The government decided that only users who request the renewal before December 31 will recover the amounts overcharged since October 8.\n- The government adopted a series of urgent measures in October in response to the situation.\n- The government committed to design a national strategy to combat energy poverty that should be ready by spring.\n- The CNMC together with the Fundaci\u00f3n Civio developed an online application to help consumers determine whether they are entitled to the social electricity bonus and to facilitate access.\n- The Ministry for the Ecological Transition opened a prior public consultation running until January 17 to gather input for the national strategy.\n- The Ministry created a public access page on its website for citizens, organizations, and associations to make their contributions to the consultation.\n- The government stated that users who miss the deadline will not lose the right to the electricity discount and can request it at any time after 2018.\n- The U.A.E. sought assistance from American investigators to trace $400,000 of stolen funds that were deposited into U.S.-based accounts at Centennial Bank.\n- The Dubai Public Prosecution Office led an investigation into the heist.\n- After publication, the U.A.E. Ministry of Foreign Affairs & International Cooperation contacted Forbes to clarify that the affected company was an unnamed Japanese business.\n- The U.A.E. stated it will work closely with law enforcement partners around the world to identify and detect individuals who engage in imposter fraud.\n- The U.A.E. stated it will pursue those individuals to the fullest extent of the law to ensure they are held accountable and brought to justice quickly.\n- Police received complaints and established a special task force to investigate the Telegram group.\n- Police traced the Telegram group's financial transactions to identify the group's account owner as Zhu Yuchen (\u6731\u7389\u5bb8).\n- Police identified three suspects, including the YouTuber Xiao Yu and company employees, as being involved in using DeepFake software to produce and sell videos.\n- Police estimated the illegal proceeds from the operation to be at least 5 million.\n- Police visited the suspect's residence this morning and arrested him.\n- Influencer Kuding filmed a video in October exposing the illegal group, clarifying the situation and defending his rights.\n- A judge ruled that the security cameras and the Ring doorbell unjustifiably invaded the neighbour's privacy.\n- The judge upheld claims that the devices broke data laws and contributed to harassment.\n- The judge found that audio data collected by the shed, driveway and Ring doorbell cameras was processed unlawfully.\n- Mr Woodard now faces a substantial fine.\n- Dr Mary Fairhurst moved out of her home as a result of the disputes about the cameras.\n- Amazon issued a statement telling customers they must respect their neighbours' privacy and comply with any applicable laws when using their Ring device.\n- The Information Commissioner's Office advised the public that owners of domestic CCTV and video doorbells should respect people's privacy rights and take steps to minimise intrusion.\n- Amazon denied the report's conclusions in an emailed statement.\n- Amazon stated that merchandising placements from its brands are clearly labeled to distinguish them from search results.\n- U.S. senators were reportedly set to unveil bipartisan legislation that would bar tech companies from favoring their own products on their platforms.\n- Neighbors talked to the Waymo drivers about the vehicles' behavior.\n- Waymo issued an emailed statement explaining that its vehicles were following dynamic San Francisco road rules and were taking u-turns due to Slow Streets signage.\n- Social Sentinel sent automated alerts to the Brazosport Independent School District superintendent, chief of police, director of student services, and director of guidance after flagging Amanda Lafrenais's tweet.\n- Social Sentinel's flagging of a college student's threatening tweet led to the student's arrest.\n- Gaggle alerted Grand Rapids school district officials after flagging threatening emails sent over the district network.\n- Grand Rapids district officials called the Grand Rapids police after receiving alerts from Gaggle.\n- The student involved in the Grand Rapids incident was arrested before the next school day.\n- The teen involved in the Grand Rapids incident was later expelled from the district.\n- Gaggle's human employees reviewed the most serious alerts before deciding whether to notify school district officials.\n- School administrators decided on a case-by-case basis whether to inform principals or other building-level staff members after receiving alerts.\n- Evergreen Public Schools turned off Gaggle's filters for profanity and hate speech.\n- Evergreen school officials sent local police to a family's home in the middle of the night to conduct a welfare check after a vague message was flagged.\n- Evergreen school administrators notified parents, police, and the National Center for Missing and Exploited Children after students were flagged for personal photos showing possible child pornography and fights.\n- Securly added a tip line and a layer of 24-hour human review of flagged threats that schools can opt into.\n- The Shanghai Hongkou District People's Procuratorate publicly prosecuted a major VAT invoice fraud case that involved the illegal use of face-recognition technology.\n- Researchers from Ruilai Zhihui (\u745e\u83b1\u667a\u6167) publicly disclosed research demonstrating that, by creating a special eyeglass from a single photo and using adversarial-sample techniques, they could bypass face-recognition systems and unlock 19 smartphone models within 15 minutes.\n- Facebook said it was ready to work with local authorities.\n- Facebook said its commerce policies require buyers and sellers to comply with laws and regulations.\n- Fabricio Guimar\u00e3es was filmed by a hidden camera.\n- The BBC arranged meetings between four sellers from Rond\u00f4nia and an undercover operative posing as a lawyer.\n- The BBC showed the Facebook ad to community leader Bitat\u00e9 Uru Eu Wau Wau.\n- The BBC contacted Fabricio Guimar\u00e3es for his response to its investigation.\n- The BBC contacted Alvim Souza Alves for his response to its investigation.\n- The BBC approached Brazil's Minister of the Environment, Ricardo Salles, for comment.\n- The government created operation Verde Brasil 2 to control illegal deforestation.\n- The government created operation Verde Brasil 2 to control illegal fires.\n- The government created operation Verde Brasil 2 to join efforts between the federal government and the states.\n- The Google Health team observed nurses conducting eye scans and interviewed them about their experiences using the new system.\n- The Google Health team is working with local medical staff to design new workflows.\n- Nurses could be trained to use their own judgment in borderline cases.\n- The model itself could be tweaked to handle imperfect images better.\n- Some states require NarxCare to mark veterinary prescriptions with a paw print or animal icon on health providers' screens to flag pet prescriptions.\n- Appriss stated that it is actively looking for additional outcome data sets to study NarxCare\u2019s real-world effects on patients.\n- Appriss presented new data at a webinar showing that implementation of NarxCare sped up the decline in opioid prescribing in six states by about 10 percent.\n- Appriss publicly stated that the NarxCare Overdose Risk Score is based solely on data from state prescription drug monitoring programs.\n- Appriss publicly stated that NarxCare\u2019s scores do not include any diagnosis information from patient medical records.\n- Appriss publicly stated that NarxCare does not take into account the distance that a patient travels to receive medical care.\n- Appriss stated that there are no adjustments to NarxCare\u2019s risk scoring to account for potential underlying biases in its source data.\n- The Opioid Risk Tool (ORT) was updated to remove the gender difference in the sexual-abuse question.\n- Angela Kilby simulated a NarxCare-like machine-learning model using de-identified insurance claims data to evaluate its precision and published her findings.\n- Jennifer Oliva published the paper \u201cDosing Discrimination\u201d analyzing algorithms like NarxCare and arguing for requiring FDA approval and greater oversight.\n- Beverly Schechtman joined the advocacy group Don\u2019t Punish Pain Rally and, with other activists, investigated and publicized biases in opioid risk screening tools.\n- Hristo Georgiev reported the bug to Google.\n- Google removed Hristo Georgiev's image from the killer's infobox.\n- The HackerNews community accelerated the response to the issue.\n- The Independent Workers\u2019 Union of Great Britain (IWGB) sent a letter to Uber threatening to go public.\n- Uber recanted its decision regarding the courier after the IWGB intervened.\n- In April last year, Uber added an identification step requiring couriers and drivers to take a selfie when they open the app.\n- Uber says couriers are given a choice between AI and human verification when they submit their real-time selfies.\n- Uber says any decision to remove partners from the platform always involves a manual human review.\n- Uber says anyone who is removed can contact the company to appeal the decision.\n- A call from a journalist to Uber\u2019s press team stopped a specific driver\u2019s account from being permanently closed.\n- The IWGB is fighting to reverse dismissals on a case-by-case basis.\n- The IWGB is pushing for an Early Day Motion to be filed in parliament.\n- Transport for London pressured Uber to crack down on illegal subcontracting as part of the deal to reinstate Uber\u2019s private-hire taxi licence.\n- The London Policing Ethics Panel has been tasked with reviewing and advising the Metropolitan Police on its use of Retrospective Facial Recognition.\n- The Met said it will complete and publish a Data Protection Impact Assessment (DPIA) before any data processing begins.\n- The Met said the use of any image will be subject to a carefully implemented framework that reflects and responds to privacy expectations.\n- The Met committed to give prior notification for its overt use of Live Facial Recognition to locate people on a watchlist.\n- The UK\u2019s Court of Appeal found that South Wales Police\u2019s use of Live Facial Recognition was unlawful.\n- The United Nations High Commissioner for Human Rights called for a moratorium on the use of Live Facial Recognition.\n- The Information Commissioner\u2019s Office said police forces must put in place robust policies and complete a Data Protection Impact Assessment prior to processing people's data.\n- Members of Parliament from Labour, the Liberal Democrats and the Green Party called for regulations on the use of facial recognition technology.\n- The House of Commons Science and Technology Committee recommended that Live Facial Recognition should not be used until concerns regarding the technology\u2019s bias and efficacy are resolved.\n- The delivery service partner gave Williams another rabbit device specifically to run the Mentor app.\n- Williams kept the additional rabbit device locked in her van's glove compartment to avoid Mentor app bugs and preserve her FICO score.\n- Drivers can dispute flagged infractions within the Mentor app.\n- After drivers dispute infractions, they receive an email response saying, 'We're sorry.'\n- Some delivery service partners provide company-issued phones for drivers to download and run the Mentor app.\n- Williams' DSP gave her a different phone when she refused to install Mentor on her personal device.\n- DSP drivers share tips on Reddit and Facebook groups about how to game the Mentor app to raise their scores.\n- A DSP driver posted a YouTube video advising employees to wrap the phone in a sweater and place it in the glovebox to prevent the Mentor app from registering device movement.\n- Some drivers fasten the seatbelt but place the strap behind them to avoid being flagged by the Mentor app for not wearing a seatbelt.\n- Amazon said it promptly fixes data quality issues and defects in its maps when it identifies them.\n- Texas law enforcement officials filed a lawsuit against Tesla over the Model X crash that injured five officers.\n- The officers also sued the local restaurant owner, alleging the driver was served too much alcohol prior to the incident.\n- The officers are seeking damages for injuries and permanent disabilities, listing damages in excess of $1,000,000 and up to $20,000,000.\n- The National Highway Traffic Safety Administration opened an investigation into 12 crashes involving Tesla vehicles using Autopilot and stationary emergency vehicles.\n- Microsoft added disclaimers to the Bing site stating that 'Bing is powered by AI, so surprises and mistakes are possible.'\n- Microsoft is continually updating the bot.\n- Microsoft removed triggers for unusual or unpleasant results.\n- Microsoft said it is adjusting Bing's responses to create coherent, relevant and positive answers as it learns from interactions.\n- Microsoft encouraged users to use the feedback button at the bottom right of every Bing page to share their thoughts.\n- Microsoft confirmed to The Verge the legitimacy of the chatbot's hidden rules.\n- TechCrunch alerted Microsoft to this and other issues.\n- JR East unregistered everyone in the first group from its facial-recognition database on September 21 due to a \"lack of societal consent\".\n- JR East plans to reinstate the facial-recognition system once clearer guidelines about facial recognition are established.\n- Facebook monitored and quashed the activity of bad actors when they engaged in political discourse.\n- Facebook added guardrails intended to prevent \u201cthe worst of the worst.\u201d\n- Facebook had been investigating these topics.\n- Facebook stood up teams to address these networks.\n- Facebook developed new policies to address these networks.\n- Facebook collaborated with industry peers to address these networks.\n- Facebook took aggressive enforcement actions against foreign and domestic inauthentic groups.\n- Facebook shared the results of its enforcement actions publicly on a quarterly basis.\n- After the story published, Facebook took down two of the five troll-farm pages identified by MIT Technology Review.\n- MIT Technology Review made the full internal report available with employee names redacted.\n- NHS Digital stated that iProov does not receive, process, or store personally identifiable information of app users.\n- NHS Digital said that all data was anonymized and that access to the data is subject to special panel reviews.\n- The NHS App allows users to opt out of providing video facial verification.\n- iProov said its technology uses encryption to protect patient data.\n- iProov said it deploys a privacy firewall to protect user data.\n- NHS Digital said that submitted photos are checked by the NHS login identity checking team or via the NHS login automated identity verification journey.\n- NHS Digital said it explains the facial verification process clearly to app users.\n- Facebook removed many of the ads identified in the report for violating its policies around offering adult products and services.\n- Google removed any ads promoting abortion reversal pills.\n- Google requires groups running ads using keywords related to getting an abortion to complete a certification verifying whether they do or do not provide abortions.\n- Google's search platform automatically generates in-ad disclosures showing whether or not the advertiser provides abortions.\n- Curtin University repeatedly urged the publisher Wiley to retract the study.\n- Curtin University repeatedly urged the publisher Wiley to immediately remove any reference to the university from the article.\n- Curtin University successfully lobbied other publishers, including the IEEE Open Journal of the Computer Society, to retract subsequent studies based on data obtained during the initial research.\n- WIREs Data Mining and Knowledge Discovery launched an investigation in accordance with Committee on Publication Ethics guidelines that resulted in a Publisher's Note and an Expression of Concern.\n- Wiley said it is reviewing the matter again and reconsidering its decision to keep the article online.\n- Curtin University established a new risk-based framework and guidelines to deal with informal research activities.\n- Curtin University emphasized that academics must maintain a current disclosure and registration of interests statement with the university.\n- Associate Professor Wan-Quan Liu resigned from Curtin University.\n- Parliament's intelligence and security committee is considering allegations of foreign interference in Australian universities.\n- Instagram published a lengthy blog defending its research in response to the Wall Street Journal report.\n- Instagram said it had done extensive work around bullying, suicide and self-injury, and eating disorders to help make the platform safer.\n- Instagram stated that it had developed features to help people protect themselves from bullying.\n- Instagram gave everyone the option to hide 'like' counts.\n- Instagram said it had continued to connect people who may be struggling with local support organisations.\n- Instagram said it was working on prompts to encourage people repeatedly dwelling on negative subjects to look at different topics.\n- Instagram promised to be more transparent about its research in future.\n- Prosecutors filed criminal charges against three LAPD metro division officers accused of using field interview cards to falsely label civilians as gang members.\n- The LAPD told the Guardian that the field interview card policy was being updated.\n- The city attorney's office said the LAPD stopped using the Geofeedia social media monitoring service around 2017.\n- The Wall Street Journal reporters sent TikTok almost 1,000 videos showing drugs, pornography, and other adult-related content that had been shown to their 13 to 15 year-old bot accounts.\n- TikTok removed 255 of the videos soon after they were sent to the platform.\n- TikTok restricted distribution of other reported videos to stop them being recommended to young users in the future.\n- TikTok said it is working on a new filter tool to restrict content for younger teenage accounts.\n- TikTok said it is slowly rolling out a range of security features.\n- TikTok is giving 16 and 17 year olds the ability to determine who can see their posts.\n- TikTok said it is reviewing how to help prevent even highly unusual viewing habits from creating negative cycles for younger users.\n- TikTok said it builds youth well-being into its policies.\n- TikTok said it limits features by age.\n- TikTok said it empowers parents with tools and resources to manage their children's experience.\n- TikTok said it will continue to invest in new ways to serve content based on age-appropriateness or family comfort.\n- Putian city police opened an investigation into the crash.\n- Xpeng Motors removed the term \"autonomous\" from its descriptions of its ADAS system.\n- Li Auto removed the term \"advanced\" from its descriptions of its ADAS system.\n- The central government proposed new data security rules for autos.\n- Li Auto said the government's proposal could lead the company to make more efforts to develop an assisted driving function in compliance.\n- Nio denied allegations that its employees tampered with data from the crashed vehicle.\n- Nio is accelerating the pace to launch its first mass-market model under a new brand.\n- Nio plans to almost double its store count to 366 in the domestic market by the end of this year.\n- A patrol vehicle was dispatched to the location and surrounded the identified person within five minutes of the system alert.\n- The officers detained the person and transported her to the 12th Police Station (12\u00aa DP).\n- The detained woman was released from the 12th Police Station more than an hour after being taken there.\n- Police officers attempted to verify the person's identification at the scene after the facial recognition alert.\n- When there is doubt or possible homonyms, flagged individuals are taken to the police station for further verification.\n- Police stated that the approach to the flagged individual was carried out with respect for human rights and with officer caution.\n- Bath and North East Somerset Council staff reviewed the image showing the pedestrian's clothing after the couple contacted them.\n- Bath and North East Somerset Council cancelled the bus lane fine immediately.\n- The U.S. government opened a formal investigation into Tesla\u2019s Autopilot driving system.\n- The National Highway Traffic Safety Administration opened a probe into Tesla\u2019s Autopilot system.\n- The National Transportation Safety Board investigated Tesla crashes.\n- The National Transportation Safety Board recommended that NHTSA and Tesla limit the Autopilot\u2019s use to areas where it can safely operate.\n- The National Transportation Safety Board recommended that Tesla be required to improve its system to ensure drivers pay attention.\n- Emergency services, including several ambulances and an air ambulance, attended the scene of the crash.\n- Ambulance crews treated and transported six patients (five children and one adult) to local hospitals for further care.\n- An air ambulance transported a critically injured child to St George's Hospital in London.\n- Sussex Police opened an investigation into the cause of the collision, including whether the vehicle's autopilot was engaged.\n- Sussex Police asked anyone who saw the incident to contact them online or by calling 101 quoting serial 980 of 16/08 and to provide any relevant dash-cam or mobile phone footage.\n- Sussex Police asked the public not to speculate about the cause of the collision while their investigation is ongoing.\n- The US National Highway Traffic Safety Administration launched a formal investigation into Tesla's partially automated driving system covering 765,000 vehicles and 11 crashes.\n- The Malta Union of Midwives and Nurses directed nurses not to continue receiving training on the medicine-dispensing robot.\n- The union instructed members working in wards where the robot was used to revert to the old manual system of medicine distribution.\n- Nurses were required to double-check the work done by the machines.\n- When the robot ceased operations, nurses borrowed drugs from adjacent wards.\n- The union repeatedly drew the problems to the attention of management.\n- The union issued a strongly-worded public statement declaring the equipment a complete failure and a waste of money.\n- The project manager responsible for the system resigned.\n- Four different technician teams servicing the robot left the job.\n- The union called for the robotic system to be removed and for the funds to be used to expand the government free medicines formulary.\n- The president of the trade group representing real estate appraisers acknowledged that racial bias is prevalent in the industry.\n- The president of the trade group representing real estate appraisers launched new programs to combat bias.\n- The Department of Housing and Urban Development asked Fannie Mae and Freddie Mac to make changes as a result.\n- Fannie Mae and Freddie Mac said their algorithms are routinely evaluated for compliance with fair lending laws by internal teams and by the Federal Housing Finance Agency and the Department of Housing and Urban Development.\n- Crystal Marie\u2019s employer sent multiple emails vouching for her after the loan was initially denied.\n- The couple enlisted their real estate agent to help after the loan was initially denied.\n- The lender sent an email clearing the couple to close the loan.\n- LoanDepot issued a written statement saying the company follows the law and expects \"fair and equitable treatment\" for every applicant.\n- The Danish Data Protection Agency (Datatilsynet) intervened and reopened its review of the law.\n- Several job centres discontinued use of the profiling tool during the pilot project because they considered it stigmatizing.\n- Blattner and Nelson collected credit reports for 50 million anonymized US consumers and linked them to socio-economic details, property deeds, mortgage transactions, and data about mortgage lenders.\n- Blattner and Nelson paid a credit bureau for access to proprietary datasets to enable their analysis.\n- Blattner and Nelson experimented with different predictive algorithms to demonstrate that credit scores were noisy.\n- Blattner and Nelson built a simulation of a mortgage lender\u2019s prediction tool to estimate what would have happened if borderline applicants' loan decisions had been reversed.\n- Blattner and Nelson compared rejected applicants to similar accepted applicants as part of their analysis.\n- Blattner and Nelson examined other lines of credit, such as auto loans, received by rejected applicants to assess their creditworthiness.\n- Blattner and Nelson plugged hypothetical 'accurate' loan decisions into their simulation and measured the resulting changes in disparities between groups.\n- A few smaller lenders began issuing loans to applicants who were rejected by algorithms in order to collect accurate data about those groups.\n- A handful of banks, including JPMorgan Chase, announced they will start sharing customers' bank account data as an additional source of information for individuals with poor credit histories.\n- The Personal Information Protection Commission fined Facebook 6.46 billion won.\n- The Personal Information Protection Commission ordered Facebook to fix the problems identified in its probe.\n- The Personal Information Protection Commission fined Netflix more than 220 million won.\n- The Personal Information Protection Commission ordered Netflix to fix the problems identified in its probe.\n- The Personal Information Protection Commission recommended that Google improve its personal information handling measures.\n- Unity formed the Sales Ethics Advisory Council (SEAC) to evaluate upcoming business opportunities that present potential risks or may be controversial.\n- Unity held a series of company-wide roundtables with hundreds of employees which contributed to the creation of the SEAC.\n- The SEAC vets upcoming business opportunities and makes recommendations to executives, including the CEO.\n- Based on SEAC recommendations, Unity declined deals that did not align with the company\u2019s stated principles.\n- Unity held an internal AMA session among its AI group to allow a broader selection of employees to ask questions about government projects and the role of SEAC.\n- After being contacted by Waypoint, CEO John Riccitiello posted an internal Slack message to employees addressing Unity\u2019s work with the government and military.\n- Riccitiello promised to open the next town hall meeting with a discussion about Unity\u2019s government and military work.\n- Riccitiello promised that Unity would provide \"full transparency\" in the upcoming town hall meeting.\n- Unity provided a public statement to Waypoint explaining its government and military work and citing confidentiality constraints rather than answering specific questions.\n- Unity stated it has a thorough review process intended to ensure the company does not knowingly violate its principles or values.\n- Bruce Springsteen publicly addressed the controversial ticketing rollout in an interview with Rolling Stone and acknowledged that it was unpopular with some fans.\n- Springsteen's team offered refunds to fans who complained, saying that if there are any complaints on the way out, they can have their money back.\n- Springsteen's longtime manager Jon Landau publicly defended the ticketing rollout in The New York Times, explaining that pricing was set after comparing peers and that average prices were in the mid-$200 range.\n- Taylor Swift issued a public statement responding to fan outrage, saying Ticketmaster had assured her they could meet demand and expressing that it was excruciating to watch mistakes happen with no recourse.\n- The Gilda degli Insegnanti teachers' union filed a legal complaint with the Ministry of Education.\n- The case was taken to courts.\n- Lazio's Regional Administrative Court required the Ministry of Education to provide all technical material to allow an audit by affected parties.\n- Auditors conducted a preliminary technical evaluation of the algorithm's source code.\n- Teachers were reassigned to new posts.\n- Italy's State Council issued a ruling in April 2019 calling for compliance with the principles of reasonableness, proportionality, publicity, and transparency.\n- Citizens collected and shared information about camera locations and used the hashtag #hiljadekamera to aggregate that information.\n- Activists created the online platform \"Hiljade kamera\" to push for responsible use of surveillance technology and increase transparency about the government project.\n- Citizens started a Twitter campaign sharing photos of the surveillance cameras.\n- Consumer rights organizations initiated a civil lawsuit against the S\u00e3o Paulo subway company (Metro) over its facial recognition system.\n- The Brazilian Institute of Consumer Protection (IDEC) said it will seek to legally defend the interests of all users of the Metro system.\n- The Culver City Fire Department reported the accident on Twitter using the hashtag \"distracteddriving\".\n- The Culver City Fire Department urged drivers to \"please stay alert while driving\" in their Twitter post.\n- The firefighters reported that the driver claimed his Model S was on Autopilot during the accident.\n- A Tesla spokesperson publicly stated that Autopilot is intended for use only with a fully attentive driver.\n- Oscar Nilsson filed a lawsuit against General Motors in U.S. District Court in San Francisco.\n- The San Francisco Police Department filed a report attributing blame to Nilsson for the collision.\n- General Motors filed a crash report with the California Department of Motor Vehicles acknowledging the Bolt aborted a lane change and providing its account of the collision.\n- General Motors issued an emailed statement saying the police report concluded Nilsson was responsible and asserting that safety is its primary focus.\n- After the collision, Nilsson walked his vehicle to the side of the road.\n- After the collision, Nilsson reported shoulder pain and was taken to receive medical care.\n- Academics and conservationists warned that the government\u2019s biodiversity net gain metric must be urgently improved.\n- Sophus zu Ermgassen\u2019s team assessed 6% of housebuilding in England between January 2020 and February 2021 in six local authorities that had adopted the scheme ahead of its national rollout.\n- Zu Ermgassen\u2019s team published a paper on the biodiversity net gain metric in Conservation Letters.\n- Academics, developers, NGOs, and government officials are working on net gain throughout the UK.\n- HuffPost contacted the site's original web host provider, IP Volume Inc., to alert them about the website.\n- IP Volume Inc. terminated its hosting services for the website, briefly taking it offline.\n- Facebook banned the website's URL from its platform after being alerted by HuffPost.\n- Reddit stated it will remove content that violates its site-wide policies prohibiting involuntary pornography.\n- Reddit stated it will take action against users who engage in posting or sharing such content.\n- Twitter said it is taking down violative content from the website on its platform.\n- Google said it removes pages from its index when required by law.\n- Google said it has a policy that allows victims of involuntary synthetic pornographic imagery to request removal of web pages from Google Search.\n- Google said it designs its systems to promote high-quality information and to avoid showing harmful or explicit content unless someone is searching for it directly.\n- Mary Anne Franks said she is drafting model criminal legislation focused on 'digital impersonation forgery' to punish creators or distributors of nonconsensual deepfake porn and to limit platforms' Section 230 protections in specific circumstances.\n- Twitter said that it would stop using the image-cropping algorithm that favored white and female faces.\n- An algorithm-bias bounty contest was held at Defcon to scrutinize the image-cropping algorithm for misbehavior.\n- Twitter made the code for the image-cropping algorithm available to participants in the bounty contest.\n- Twitter offered prizes to teams that demonstrated evidence of harmful behavior in the algorithm.\n- The company confirmed the leaked email's authenticity.\n- The company partnered with seven leading HR agencies to help dismissed employees find new jobs.\n- The company said it would provide recommendation letters for dismissed employees, including one from the CEO.\n- The company said its HR team would inform dismissed employees of their rights.\n- The company said all dismissed employees would receive compensation packages.\n- The CEO held a press conference to explain the mass layoffs.\n- The CEO released an additional statement on Twitter regarding the layoffs.\n- The CEO invited dismissed employees to stay in contact by writing him a detailed letter about their observations, injustices, and gratitude.\n- Amazon confirmed to The Verge that it uses voice data from Alexa interactions to inform relevant ads shown on Amazon or other sites where Amazon places ads.\n- Alexa customers can opt out of interest-based ads from Amazon via the Advertising Preferences Page.\n- Alexa users can manage privacy controls and view and manage their voice recordings and skill permissions through Settings > Alexa Privacy in the Alexa app or at amazon.com/alexaprivacysettings.\n- Amazon confirmed that only processed transcripts, not raw audio, were shared.\n- Amazon stated that it does not share voice recordings with developers and does not share customers' personal information with third-party skills without the customer's consent.\n- Amazon requires all third-party skills that collect personal information to post their privacy policy on their skill page.\n- The research team created an auditing framework to measure online advertising data collection in the Amazon smart speaker ecosystem.\n- The researchers created multiple personas to interact with Alexa using third-party skills to test targeted advertising.\n- The researchers performed statistical analysis of their results to determine that each persona was served targeted ads elsewhere on the web.\n- Mercadona agreed to pay the \u20ac2.5 million fine proposed by the Spanish Data Protection Agency (AEPD).\n- Mercadona decided to end the pilot test of the anticipatory detection system.\n- Mercadona uninstalled the anticipatory detection technology from the 48 supermarkets in May.\n- Mercadona decided to close the procedure opened by the AEPD in relation to the pilot.\n- Mercadona issued a public statement to the news agency Efe announcing its decision to end the pilot and resolve the matter.\n- He identified nine warships from a screenshot and compared their fake AIS messages to genuine messages to find subtle differences.\n- He used the identified pattern to write a query for a global historical database of AIS messages to search for other fake tracks.\n- He used open-source data including news reports, military press releases, and enthusiast websites to verify the actual positions of targeted ships.\n- He overlaid synthetic aperture radar and optical imagery from the European Space Agency\u2019s Sentinel-1 and -2 satellites onto suspicious AIS pings to check for ships.\n- He confirmed about 15 sets of AIS data as definitively fake.\n- He withheld publication of the exact pattern that distinguishes the fake AIS messages to avoid enabling attackers to modify their methods.\n- The UK Ministry of Defence publicly acknowledged manipulation of AIS tracking data placing Carrier Strike Group vessels in areas where they were not.\n- MarineTraffic stated it is continuously enhancing its quality control and anomaly detection tools to pick up on such incidents.\n- ShotSpotter moved and replaced sensors and investigated coverage areas to improve its performance in Harlem.\n- Credits for quarters two and three of Calendar Year 2022 were deducted from ShotSpotter's invoices in accordance with the contract.\n- NYPD agreed to continue following up with ShotSpotter, Inc. on coverage areas where the 90% performance rate is not met and to ensure ShotSpotter is upholding the agreed Service Level Agreement performance rate.\n- NYPD agreed to pay its invoices within 30 days after the invoice receipt or acceptance date per the Procurement Policy Board Rules.\n- The auditors sent an Exit Conference Summary to NYPD and discussed the matters at an exit conference held on November 17, 2023.\n- The auditors submitted a Draft Report to NYPD on November 27, 2023.\n- The auditors received a written response from NYPD on December 22, 2023.\n- The auditors issued a revised Draft Report on May 9, 2024.\n- The auditors received a written response from NYPD on June 3, 2024.\n- The auditors considered NYPD's written response and, where relevant, added changes and comments to the report.\n- The auditors will conduct periodic follow-up to determine the implementation status of each recommendation contained in this report.\n- NYPD stated it will continue to have discussions with ShotSpotter in order to enhance the performance and evaluation of the technology.\n- JP Onnela published the Apple Watch heart rate variability data and his findings in a blog post.\n- Onnela's team backed away from plans to use Apple Watch devices in research studies.\n- Apple told The Verge that changes to its algorithm only apply to data going forward and that the watch does not recalculate past data.\n- The Verge issued a correction clarifying that changes to Apple's algorithms do not retroactively change past data based on additional comments from Apple.\n- Experts examined the recording and found it had been manipulated to include words not used by the client.\n- The legal team obtained the original audio file and studied the metadata on the recording.\n- Experts were able to identify which parts of the audio had been edited after the original phone call.\n- The legal team challenged the doctored audio evidence in court.\n- The court dismissed the audio recording as fake.\n- The CBSA completed a privacy impact assessment and submitted it to the Office of the Privacy Commissioner for review.\n- At the end of the project, the CBSA removed the facial recognition technology from Pearson International Airport.\n- At the end of the project, the CBSA erased the travellers' images collected during the pilot.\n- The CBSA has not used facial recognition at airports since the 2016 project and is not currently using it in any other capacity.\n- Isoko Mochizuki reported the difficulty logging into her Twitter account to Twitter.\n- Some of Mochizuki's followers began tweeting 'Lift the freeze off Isoko Mochizuki\u2019s account' with an accompanying hashtag about five hours after the freeze.\n- Mochizuki regained access to her Twitter account at around 10 a.m. on July 11, 2021.\n- Star Sands Inc. contacted Twitter Japan about the movie account freeze soon after it occurred on the morning of June 24, 2021.\n- Twitter lifted the freeze on the movie's official account the following day.\n- Twitter Japan emailed Star Sands on June 26 explaining that its AI might have marked the account as spam.\n- Twitter Japan said it is making efforts to fully explain to its users why such incidents occurred.\n- The operator modified the Tapia robots to prevent exploits by guests.\n- H.I.S. said it had undertaken a maintenance procedure on the robots.\n- H.I.S. publicly apologized for any uneasiness caused.\n- The chain contacted the development company behind the Tapia robots after the vulnerability report.\n- The development company determined that the risk of unauthorized access was low.\n- Ocado cancelled some customer orders.\n- Ocado warned customers of ongoing disruption.\n- Ocado temporarily prevented its website from accepting bookings beyond the next week.\n- Ocado apologised for the upheaval caused by the incident.\n- Ocado said it was working to restore normal service as soon as possible.\n- The warehouse was evacuated.\n- The fire was contained by deploying all suitable measures.\n- Fifteen fire engines were called to the warehouse.\n- Firefighters remained in place until the early hours to ensure any hot spots were dampened down.\n- Ocado suspended operations at the Andover site and stopped sending out further orders.\n- Orders that had already left the warehouse before the incident were allowed to be delivered as normal.\n- Relief crews took over from the first firefighters on the scene.\n- Relief crews were battling the fire.\n- Ocado said all relevant safety measures were carried out as planned.\n- Ocado said it would assess the damage the incident had caused and would provide further updates as appropriate.\n- Neville publicly disclosed that he had contacted a software company, provided about a dozen hours of recordings, and created an A.I. model of Anthony Bourdain's voice used in the film.\n- Instagram publicly admitted that its moderation technology had made a mistake in failing to remove racist comments and emojis.\n- Instagram stated that the issue with its moderation technology has been fixed.\n- Instagram said that reports on these types of comments should now be reviewed properly.\n- The developer deleted all content on the cheat's website.\n- The developer replaced the site content with a statement referencing Activision's request.\n- The developer stated they would no longer develop or provide access to software that could be used to exploit Activision's games.\n- The developer deleted the Userviz Discord server.\n- Tencent launched a time-sensitive facial recognition system called 'Midnight Patrol' to monitor players and detect individuals who spend a significant amount of time online at night.\n- Tencent linked the facial verification system with big data from the central public security system.\n- Tencent said it will conduct face screening for accounts registered with real names that have played for a certain period of time at night.\n- Anyone who refuses or fails the face verification will be treated as a minor and kicked offline under Tencent\u2019s anti-addiction supervision.\n- Authorities introduced real-name registration in 2019 to curb excessive gaming by minors.\n- Authorities barred children from playing between 10 p.m. and 8 a.m.\n- Authorities capped purchases on the gaming platform.\n- Tencent initially launched the facial screening feature for over 60 popular games, including 'Honor of Kings' and 'Game for Peace'.\n- Tencent plans to incorporate more titles into the facial screening feature in the future.\n- Tencent began testing the use of facial recognition to check users\u2019 age in Beijing and Shenzhen as of late 2018.\n- Armin Ronacher posted a screenshot of Copilot's output to Twitter as evidence of the AI's copying.\n- GitHub clarified its stance that all publicly available code is fair game for training Copilot.\n- GitHub conducted internal tests and reported that direct copying occurs in roughly 0.1 percent of Copilot's outputs.\n- GitHub indicated it is developing a system to flag verbatim outputs so programmers and lawyers know not to reuse them commercially.\n- GitHub declined to answer questions and directed reporters to an FAQ about Copilot.\n- GitHub CEO Nat Friedman posted on Hacker News defending the fair use designation of Copilot's training data, pointing to an OpenAI position paper and expressing eagerness to participate in debates over AI and intellectual property.\n- The Sentry team tightened some of its most permissive licenses to reduce the risk that large companies could reuse their code without compensation.\n- Voice actress Bev Standing filed a lawsuit against TikTok alleging the company used her voice for its text-to-speech feature without compensation or consent.\n- Voice actors donated nearly $7,000 to a GoFundMe to support Standing's legal expenses.\n- Supporters posted TikTok videos under the #StandingWithBev hashtag warning users about the text-to-speech feature.\n- SAG-AFTRA engaged in years of advocacy to extend the right of publicity to digital replicas.\n- In November 2020, New York applied the right of publicity to digital replicas, establishing legal protection for cloned voices.\n- The Global Voice Acting Academy developed rate guides to help performers determine appropriate charges based on usage of their recordings.\n- Lotas Productions' owner Jim Kennelly said his studio is preparing for the industry transition by developing an AI division.\n- Amazon said it had reached out to all the sellers that were affected.\n- Amazon said it was working to stop any more 1p orders being dispatched from its warehouses.\n- The company that made the software, RepricerExpress, issued a second apology on Monday.\n- RepricerExpress's chief executive said the company would continue to work to provide the highest levels of service in order to regain the trust and confidence of its customers.\n- Some sellers have instructed lawyers to take action against RepricerExpress.\n- One seller has instructed lawyers and asked other sellers to join him in joint legal action against RepricerExpress and Amazon.\n- The author of the article reached out to TikTok after discovering the issue.\n- The beauty-filter effect stopped appearing two days later.\n- TikTok issued a short statement acknowledging there was an issue and that it had been resolved.\n- The author sent a video of the effect to coworkers and Twitter followers and asked them to open the app and test whether they saw it.\n- The author sent the video to Amy Niu, a PhD candidate who studies the psychological impact of beauty filters, for her input.\n- Tori Dawn posted a video informing followers about the effect and showing it in action.\n- TikTok said it is working quickly to fix the error in its hate speech detection system that erroneously flagged phrases like \"Black Lives Matter\".\n- TikTok issued an apology acknowledging how frustrating the experience was.\n- TikTok said it reached out directly to creator Ziggi Tyler.\n- TikTok launched an official @BlackTikTok account to help foster the Black TikTok community.\n- TikTok said its teams are committed to developing recommendation systems that reflect inclusivity and diversity.\n- Canon China publicly defended the smile-recognition cameras in response to criticism.\n- A Canon spokesperson told Nikkei that the company has enabled the smile-detection setting to encourage employees to create a positive atmosphere.\n- Meta removed 1.8 million pieces of content related to drug sales in the last quarter.\n- Meta said it will continue to improve its detection technology to reduce drug-sale content on Instagram.\n- Instagram removed 12 of the posts submitted by TTP as part of its investigation.\n- Instagram said it took down one account that had violated its policies.\n- Meta blocked the hashtags #mdma, #buyfentanyl, and #buyxanax on Instagram.\n- Meta is reviewing additional hashtags for potential violations of its policies.\n- When 'buyxanax' was typed into Instagram's search bar, the platform displayed a warning that the term 'may be associated with the sale of drugs' and included a link to 'get help'.\n- A Senate subcommittee scheduled a hearing at which Instagram head Adam Mosseri was set to testify about the platform's impact on children and teens.\n- A bipartisan group of state attorneys general launched an investigation into Instagram's impact on children and teens.\n- A Meta spokesperson publicly stated that the allegations made by the attorneys general in announcing their probe were false.\n- Instagram told TTP that 36 of the 50 posts it submitted did not violate its community guidelines.\n- Researchers at the University of Michigan investigated the algorithm's performance and published their findings in JAMA Internal Medicine.\n- Tesla filed a recall plan with the State Administration of Market Regulation.\n- Tesla decided to recall over 285,000 vehicles in China affecting some imported and domestically manufactured Model 3 and Model Y vehicles.\n- Tesla said it would contact affected users to upgrade their vehicles' software remotely for free.\n- Tesla announced it would set up a data centre in China following user backlash over fears that their data could be passed to the US.\n- ID.me reached out to Tim Weaver after he tweeted criticism of the company.\n- ID.me verified Tim Weaver\u2019s identity after reaching out.\n- ID.me performed a regression analysis to examine the relationship between skin tone and Face Match failure.\n- ID.me stated that it provides live video chat identity-verification sessions with wait times under five minutes.\n- The account that shared the video was banned and taken down.\n- TikTok quickly removed the original video.\n- TikTok's systems began proactively detecting and blocking attempted re-uploads of the clip.\n- The clip was added to TikTok's Hashbank system so it is automatically detected before being posted.\n- A TikTok spokesperson apologized for the security breach.\n- Miso Robotics said the learning pains that caused several burgers to fall off the tray during testing would be fixed.\n- As of Monday, a human at Caliburger's restaurant prepares the burger patties, seasons them, and places them in a tray for the robot to process.\n- After Flippy removes patties from the griddle, a human places the cooked patties into buns for customers.\n- ByteDance publicly accused Tencent of blocking Feishu and other WeChat mini programs by posting the complaint on the Jinri Toutiao platform.\n- CBP sought and received emergency approval from the Office of Management and Budget to use the CBP One app to collect advance information on undocumented individuals, bypassing the public comment and notification process.\n- CBP retroactively published and updated the Department of Homeland Security privacy assessments describing how it was already using the CBP One app for asylum seekers.\n- CBP said it ensures that all personal information collected via the app is stored in official, secure CBP systems.\n- CBP stated it is committed to mitigating, to the extent possible, the risk of data breaches from information systems containing personally identifiable information.\n- Microsoft said the issue was due to an accidental human error.\n- Microsoft said it was actively working to resolve the issue.\n- Motherboard verified that the issue also impacted image searches on Yahoo and DuckDuckGo.\n- Motherboard replicated the search on a U.S. IP address.\n- Shane Huntley of Google's Threat Analysis Group tweeted a screenshot of the Bing search result.\n- Security researcher Kevin Beaumont tweeted the same results from what he said was a search from a UK IP address.\n- Multiple Twitter users sent Motherboard images of the lack of image results on Bing while connecting from France, Switzerland, and other countries.\n- Motherboard updated the article to include additional information on the impacted countries and search engines, as well as a statement from Microsoft.\n- The United Nations Security Council\u2019s Panel of Experts on Libya produced a report documenting the Kargu-2's lethal autonomous attack.\n- Several human rights watchdogs and non-governmental organizations petitioned for a global ban on lethal autonomous weapons systems.\n- Apple or SIS deleted video images purporting to be Bah despite them surfacing during discovery.\n- Videos from the same incident showing an alleged accomplice were reproduced.\n- Police arrested the real alleged suspect.\n- Bah was arrested.\n- An NYPD detective noticed that the photo attached to the warrant was not a picture of Bah.\n- Bah was released after an NYPD detective noticed the photo attached to the warrant was not of him.\n- An NYPD officer noted that facial recognition had been used to identify Bah.\n- The NYPD caught an individual repeatedly attempting to use Bah\u2019s identification as his own.\n- The imposter was caught again at an Apple Store in Massachusetts.\n- The imposter was extradited under Bah\u2019s name to face outstanding warrants.\n- SIS and Apple did not withdraw ongoing charges against Bah.\n- SIS and Apple continued attempting to prosecute Bah in Paramus until June 2019.\n- An internal SIS email explained the misidentification.\n- An SIS executive asserted in an affidavit that no SIS employee had ever identified the plaintiff to the New York Police or Apple.\n- NHS Digital suspended (paused) the GP Data for Planning and Research (GPDPR) policy in 2021 following public and professional concerns.\n- NHS Digital said it would take time to better understand and address the issues raised by the policy.\n- NHS Digital publicly stated that it never sells data for commercial purposes.\n- NHS Digital said it charges those who want to access its data only to cover the costs of making the data available and does not profit from this work.\n- Full Fact published an explainer about GPDPR to provide up-to-date information following the controversy.\n- Lemonade deleted the tweet that described using AI to pick up non-verbal cues.\n- Lemonade publicly stated that it does not use artificial intelligence to deny claims or cancel policies based on a person\u2019s characteristics.\n- Cambodia's culture ministry called for both Matt Loughrey and Vice to remove the altered images.\n- The culture ministry vowed to take legal action if Matt Loughrey does not comply with the request to remove the images.\n- The culture ministry urged researchers, artists and the public not to manipulate any historical source to respect the victims.\n- Vice removed the article that included the manipulated photographs.\n- Vice said it regretted the error and will investigate how the failure of the editorial process occurred.\n- Matt Loughrey said he was talking to the Tuol Sleng Genocide Museum about making the images accessible to everyone.\n- Researchers from the Universities of Padua, Udine, and Carnegie Mellon conducted a study showing that insurance models often vary rates according to birthplace and citizenship.\n- The author contacted the identified insurance companies to ask for an explanation.\n- Italy's Institute for the Supervision of Insurance (IVASS) and the National Anti-Racial Discrimination Office (UNAR) issued soft regulation in 2012 encouraging car insurance companies to avoid using nationality-related factors such as birthplace and citizenship as inputs to risk models.\n- In 2012, Enwerenezor brought a lawsuit against the insurance company Linear in cooperation with ASGI.\n- After a 2018 decree by a court in Bologna, Linear stopped using birthplace as a pricing parameter.\n- Other insurance companies promised to change their behavior.\n- Genertel replied to inquiries asserting that it does not use place of birth as a pricing parameter.\n- Mps replied to inquiries stating that drivers registered somewhere other than their place of birth present 'less risks' and may therefore be charged lower prices.\n- The Brazilian Institute of Consumer Protection (IDEC) filed a public civil action against ViaQuatro regarding the installation and use of the AdMobilize DID system.\n- A judge issued a precautionary order requiring ViaQuatro to stop collecting data.\n- A judge ordered ViaQuatro to remove the cameras.\n- ViaQuatro complied with the judge's order to stop collecting data.\n- ViaQuatro complied with the judge's order to remove the cameras.\n- Access Now submitted an expert opinion to the IDEC vs. ViaQuatro case criticizing ViaQuatro's claims about the DID system.\n- Access Now called for a ban on biometric data processing that enables or amounts to mass surveillance in public spaces.\n- Access Now committed to holding the private sector accountable for violating human rights.\n- The Immigration Minister said he would call officials for a full briefing about the programme.\n- Officials assured the Minister that the modelling was not racial profiling and that a range of data was considered.\n- Immigration New Zealand's compliance and investigations area manager publicly denied the programme was racial profiling and explained that gender, age, and visa type were included in the data sets.\n- The Minister clarified that the data being collected by Immigration New Zealand is not being shared internationally.\n- Appen apologised for the way the question was phrased.\n- Appen acknowledged the lack of an explanation up front and said it would fix the way the question was presented.\n- Instagram and Twitter said the accounts had been suspended in error by their automated systems.\n- Instagram and Twitter said the issue had been resolved.\n- Instagram and Twitter said removed content had been reinstated.\n- Instagram issued a public apology saying it was \"so sorry this happened\" to affected communities.\n- Instagram issued a statement attributing the deletions to an automated update that caused content re-shared by multiple users to appear missing.\n- Some affected users had their posts restored by Friday afternoon.\n- 7amleh, Access Now, and other digital rights groups issued a joint statement calling on Twitter and Instagram to adopt transparent and coherent moderation policies and to be more open when take-downs happen.\n- Access Now demanded clarity on the alleged censorship and said system glitches were no longer an acceptable excuse.\n- 7amleh said it was fielding complaints about disappeared content.\n- The CHP Golden Gate Division issued a public statement calling the man's behavior an \"unusual incident.\"\n- The CHP said the incident is currently under investigation.\n- The CHP shared photos from the incident on its Facebook page.\n- Tesla's customer service told the witness to contact CHP's Oakland branch.\n- A CHP representative told the witness there was nothing they could do.\n- A CHP representative advised the witness to call 911.\n- A CHP representative suggested the witness file an in-person report.\n- CHP representatives said filing an in-person report would likely result only in a warning letter to the driver.\n- Twitter suspended 26,879 accounts that had retweeted Chinese diplomats or state media nearly 200,000 times after they were identified in the investigation.\n- By March 1, Twitter had suspended 31 accounts in the pro-China U.K. network and two accounts had been deleted.\n- Twitter permanently suspended the remaining 29 accounts in the pro-China U.K. network for platform manipulation at the end of April and beginning of May in response to the investigation.\n- Twitter said it was investigating whether the activity constituted a state-affiliated information operation.\n- Twitter said it would continue to investigate and take action against accounts that violate its platform manipulation policy, including accounts associated with these networks.\n- Twitter said that if it had clear evidence of state-affiliated information operations its first priority would be to enforce its rules and remove accounts engaging in this behavior.\n- Twitter said it would disclose all accounts and content in its public archive when its investigations are complete.\n- Facebook labeled an additional 41 Chinese state media outlets that the AP and the Oxford Internet Institute brought to its attention, raising its labeled share of those accounts to nearly 90%.\n- Facebook said it was looking into the remaining Chinese state media accounts that had not yet been labeled.\n- Facebook said it would apply transparency labels on a rolling basis and continue to label more publishers and pages over time.\n- On July 27, 2021, Facebook announced that it would no longer allow advertisers to target interest-based ads at teens.\n- Facebook said it is investigating why some of these violating ads were not detected.\n- Facebook said it may re-review ads after they are live.\n- Facebook uses artificial intelligence tools and a 35,000-person workforce to take down harmful posts that violate its policies.\n- Consumer Reports canceled its test ads before they were shown to Facebook users.\n- Facebook rejected some of Reset's ads during the ad-approval process.\n- Consumer Reports pulled the ads before they were published to ensure no Facebook users were exposed to the false or misleading claims.\n- Facebook removed millions of ads and commerce listings for violating its policies related to COVID-19.\n- Facebook said it is working to improve its enforcement systems to prevent harmful COVID-19 misinformation from spreading on its services.\n- Facebook said it has a few thousand content reviewers now able to work from home.\n- Administrators initiated investigations into students allegedly accessing course materials during remote closed-book exams.\n- The initial report was forwarded to the Committee on Student Performance and Conduct for investigation and determination of outcomes.\n- The Committee on Student Performance and Conduct, with assistance from the school's information technology staff, conducted a review of Canvas usage during exams throughout the academic year.\n- The committee sent at least one letter to an affected student threatening suspension or separation from the school.\n- Students found to have violated the honor code may be required to retake the exams or face more serious sanctions.\n- Geisel has begun electronic proctoring of its exams.\n- Mark Zuckerberg publicly pledged to combat misinformation about COVID-19 on Facebook.\n- Facebook said it has taken down hundreds of thousands of pieces of misinformation related to COVID-19.\n- Facebook eliminated the \"Pseudoscience\" interest category from its ad targeting options.\n- Facebook spokesperson Devon Kearns said the company is in the process of reviewing the user-created groups identified by The Markup.\n- Facebook implemented a policy prohibiting ads that refer to the coronavirus and create a sense of urgency, such as implying a limited supply or guaranteeing a cure or prevention.\n- Facebook established policies for surfaces like Marketplace that prohibit ads that create a sense of urgency or make misleading coronavirus claims.\n- Facebook removed ad categories identified in earlier investigations, including categories such as \"vaccine controversies\" and other conspiracy-related interests.\n- On Oct. 2, Leroy Jacobs filed a class action lawsuit in Cook County court against Walgreens alleging unlawful facial recognition scans.\n- The plaintiff seeks to represent other customers who were scanned without their approval as class members in the lawsuit.\n- Jacobs asked the court to award $1,000 in damages for every negligent violation of the Illinois Biometric Information Privacy Act and $5,000 for every willful violation.\n- Jacobs and the proposed class members are represented by attorneys Ryan Stephan and Haley Jenkins of Stephan Zouras LLP.\n- Facebook sent a response letter dated May 21 to Senator Mazie Hirono asserting that Monika Bickert\u2019s testimony was accurate and stating that advertisers aren\u2019t allowed to target by age, gender, or zip code for housing, employment, and credit ads.\n- Facebook reviewed and removed ads from businesses that ran in violation of its credit card advertising policy.\n- After The Markup reached out about a job ad targeted by age and ethnic affinity, Facebook removed the ad.\n- Google blocked several terms associated with hate speech from being used as ad keywords on YouTube videos.\n- After The Markup contacted Google, the company blocked additional racial and social justice terms, including \"Black excellence\" and \"civil rights\", from being searchable for ad placement.\n- Google said its teams addressed the issue and blocked terms that violate its enforcement policies.\n- Google committed to continue being vigilant in monitoring and enforcing against offensive and harmful searchable terms.\n- Joris Lech\u00eane uploaded a TikTok video demonstrating that the passport photo-checking AI had rejected his photo.\n- He posted a follow-up video in which he apologised for the inconvenience his non-whiteness may have caused.\n- Facebook restored the temporarily blocked #ResignModi hashtag hours after blocking it.\n- Facebook publicly said the hashtag was blocked by mistake and that the Indian government had not asked for it to be removed.\n- Twitter removed or restricted access to Covid-related posts over the past month.\n- Twitter permanently suspended more than 500 accounts in India.\n- Twitter blocked access to hundreds of other accounts in India.\n- India's government ordered US social-media companies to block posts.\n- India established new rules requiring platforms like Facebook and Twitter to take down unlawful content more quickly.\n- Twitter said it reviews all valid legal requests it receives under the company's guidelines and local rules.\n- Latvian politician Rihards Kols posted on Facebook that he had been tricked into taking a call and shared two pictures purportedly showing the real and fake Volkovs.\n- Leonid Volkov reposted the images and suggested that AI was used, asking how the pranksters had managed to put his real face on the Zoom call.\n- Rihards Kols posted a statement on Twitter co-signed by his counterparts from Lithuania and Estonia warning about the threat posed by deepfake technologies and describing the pranks as targeted attacks on Kremlin critics.\n- The co-signed statement encouraged all to remain vigilant yet open to communication in response to the disinformation operations.\n- The designers filed a lawsuit against Shein alleging racketeering and seeking a jury trial.\n- Shein issued a boilerplate public statement saying it takes the claims seriously.\n- Shein said it will vigorously defend itself.\n- The Home Office conducted an equality impact assessment (EIA) of the triage system used to detect sham marriages.\n- The Home Office redacted the list of eight screening criteria used by the triage system in the EIA.\n- The Home Office conducted a separate review of the triage system\u2019s impact on different nationalities.\n- The Home Office rejected Freedom of Information requests for more information about the system.\n- The Home Office refused to disclose all of the 'risk factors' used by the algorithm.\n- Advocacy groups JCWI and Foxglove took successful legal action against the Home Office's visa algorithm.\n- The Home Office suspended the visa algorithm system in August.\n- The Home Office said it would conduct a review of the suspended visa system's operation.\n- The European Commission announced an investigation into whether Amazon's buy box criteria result in preferential treatment for Amazon's retail offers or sellers that use Amazon's shipping service.\n- The Washington, D.C., attorney general filed a lawsuit in May 2021 alleging that Amazon's selection methods for the Buy Box reinforce Amazon's online retail sales market dominance.\n- In a court filing, Amazon responded that the lawsuit 'fails to allege essential elements of an antitrust claim' and argued that the conduct it attacks has been held by courts to be procompetitive.\n- During a congressional inquiry, Amazon officials stated that the company does not favor itself in the buy box or consider its profits when selecting the winner.\n- Amazon acknowledged that whether a product could be delivered quickly and for free to Prime members is a factor in picking the seller for the buy box.\n- Amazon spokesperson Nell Rona declined to answer questions for this story.\n- Researchers at Northeastern University studied price changes on Amazon to analyze buy box dynamics.\n- The Markup compared snapshots of 1,200 popular products taken 12 weeks apart to measure changes in buy box winners.\n- The Markup collected its data from an I.P. address in Washington, D.C.\n- The Markup checked product listings again three months later to determine whether shippers had changed between Amazon and third-party sellers.\n- Reporters from Gizmodo and The Markup published a report using the leaked Predpol dataset and conducted a large study demonstrating racial bias in predictive policing.\n- A security researcher provided a list of cities that had secretly procured Predpol services to a reporter.\n- Motherboard reporter Caroline Haskins used that report to extract more information about police departments' secret deals with Predpol.\n- The Human Rights Data Analysis Group (HRDAG) conducted and published a study of racial bias in predictive policing tools.\n- The Los Angeles Police Department stopped using Predpol in 2020, citing financial constraints and an Inspector General report.\n- The city of Santa Cruz terminated Predpol's services last year.\n- Predpol rebranded itself as Geolitica to distance the company from scandals and bad publicity.\n- Approximately 1,400 mathematicians signed an open letter urging colleagues not to collaborate on research with law enforcement, specifically singling out Predpol.\n- Tesla obtained the vehicle's data logs from the crashed Model S.\n- Elon Musk publicly claimed that the vehicle was not using Autopilot.\n- The National Transportation Safety Board announced that it is investigating the incident.\n- The National Highway Traffic Safety Administration opened a formal investigation into Tesla Autopilot following identification of 11 crashes involving first responder vehicles.\n- The investigation will cover all Tesla models equipped with any version of Autopilot, including Model S, Model X, Model 3, and Model Y from 2014 to today.\n- NHTSA will assess the technologies and methods used to monitor, assist, and enforce the driver's engagement with the dynamic driving task during Autopilot operation.\n- NHTSA will assess the object and event detection and response (OEDR) capabilities of vehicles when engaged in Autopilot mode and will assess the operational design domain (ODD) in which Autopilot mode is functional.\n- The NTSB sent a letter to the NHTSA calling for stronger federal requirements for the design and use of automated driving systems on public roads.\n- The NTSB investigated accidents, including fatal Tesla crashes in Mountain View, California (March 2018) and Delray Beach, Florida (March 2019), to determine underlying causes.\n- The NTSB made safety recommendations to regulators and the auto industry following its investigations.\n- NTSB Chief Robert Sumwalt called on the NHTSA to require automakers to include collision avoidance systems in all their vehicles.\n- Sumwalt called on the NHTSA to require automakers to install robust driver monitoring systems in their vehicles.\n- Sumwalt called on the NHTSA to require safeguards that prevent drivers from using automated driving systems beyond the conditions and domains in which they are safe to operate.\n- Sumwalt recommended that the NHTSA examine Tesla vehicles with Autopilot to determine if the system\u2019s operating limitations, the foreseeability of driver misuse, and the ability to operate outside the intended operational design domain pose an unreasonable risk to safety.\n- Sumwalt urged the NHTSA to make safety reporting to the federal government more specific and mandatory rather than voluntary.\n- Curious Thing said it will research the German test results to see if the data point unveils any issues in its system.\n- Retorio publicly stated that its software is intended only as an assisting tool to be used together with human interviewers and not as an automatic filter in hiring decisions.\n- Hiring manager Mark Gray said he does not base hiring decisions solely on AI evaluations and uses the AI interview as one data point alongside a screening call, a job skills test, and a live interview.\n- US officials publicly blamed large bets by a trader on Chicago's derivatives exchange for the crash.\n- The Securities and Exchange Commission and the Commodity Futures Trading Commission issued an official report identifying a $4.1 billion sell order instigated by a US mutual fund and describing the 'hot potato' effect.\n- Aaron Ogletree sued Cleveland State University over its room-scan proctoring practice.\n- Federal Judge J. Philip Calabrese ruled that the university's room scan violated the Fourth Amendment and constituted an unreasonable search.\n- Cleveland State University provided a statement to The Verge regarding the court's decision.\n- As directed by the Court, Cleveland State University's counsel will confer with Mr. Ogletree's counsel on appropriate next steps.\n- Fight for the Future issued a public statement applauding Ogletree's lawsuit and calling the ruling a warning to other universities that use room-scan proctoring.\n- The University of Wisconsin-Madison shut down Honorlock\u2019s exam pause feature on March 11.\n- Lucy Satheesan published her findings in a series of blog posts.\n- Lucy Satheesan analyzed the code behind Proctorio\u2019s Chrome extension and found file names associated with its facial detection function that were identical to those published by OpenCV.\n- Lucy Satheesan demonstrated for Motherboard that the facial detection algorithms embedded in Proctorio\u2019s tool performed identically to the OpenCV models when tested on the same set of faces.\n- Satheesan tested the models against images containing nearly 11,000 faces from the FairFaces dataset.\n- Motherboard consulted a security researcher who validated Satheesan\u2019s findings and was able to recreate her analysis.\n- Proctorio spokesperson Meredith Shadle sent a link to Proctorio\u2019s licenses page, which includes a license for OpenCV, in response to questions.\n- Proctorio spokesperson Meredith Shadle emailed that the public reports do not accurately capture how their technology works in full and that the company appreciates the analyses confirm Proctorio uses face detection rather than facial recognition.\n- A victim\u2019s parent contacted Hilltown Township police in July to report the harassing texts and images.\n- Two additional families came forward to report that their daughters had been receiving similar harassing messages.\n- Detectives analyzed the videos and determined they were deepfakes created by mapping the girls\u2019 social media photos onto other images.\n- Detectives traced the phone numbers used to send the messages to a website that specializes in selling numbers to telemarketers.\n- Detectives followed the data from that website to an IP address that showed activity from within Spone\u2019s house in Chalfont.\n- Detectives searched Spone\u2019s smartphone and found evidence linking her to the numbers used to send the harassing texts and images.\n- Raffaela Spone was charged with misdemeanor counts of cyber harassment of a child and related offenses.\n- Spone was released on the condition that she appear at a preliminary hearing on March 30.\n- Facebook deleted the offending post by Benjamin Netanyahu.\n- Facebook temporarily suspended the Messenger bot linked to Netanyahu's account.\n- Netanyahu\u2019s Likud party issued a statement in response to the removal and suspension.\n- The Likud party called on everyone to get vaccinated to help open up the economy.\n- NHS Digital clarified that women identified by QCovid as diabetic could be removed from the shielding list if requested.\n- NHS Digital clarified that women removed from the shielding list would still be called for an earlier vaccine.\n- NHS Digital clarified that women removed from the shielding list could be considered no longer at risk.\n- NHS Digital said clinicians can apply their clinical judgment and remove any of these patients from the shielded patient list.\n- NHS Digital advised that people with concerns can speak to their GP.\n- A patient who had been incorrectly told to shield had the error resolved and was removed from the shielding list.\n- The page administrator appealed the removal on March 19 using Facebook's appeal process.\n- The administrator attempted to contact Facebook using various support forms.\n- The administrator sent private messages to the Facebook France page, leaving about ten messages each day.\n- The mairie created a new Facebook page named \"Mairie 57230\" to continue informing citizens.\n- The commune of Rohrbach-l\u00e8s-Bitche temporarily removed \"L\u00e8s-Bitche\" from its page name to avoid potential suspension.\n- Young activists created mobile mapping apps to warn protesters about the presence of police and military and to show locations of water cannons, roadblocks and ambulances.\n- Some residents are covering up the CCTV cameras.\n- Protesters said they are trying to avoid CCTV cameras by taking different routes home.\n- Huawei told Human Rights Watch it was providing 'standard ICT infrastructure equipment' and that the facial and licence-plate recognition technology on the cameras was not from Huawei and that it was not involved in any actual operation or data storage or processing.\n- Human Rights Watch expressed its 'heightened concern' over cameras armed with AI technology that can scan faces and vehicle licence plates and alert authorities to those on a wanted list.\n- Journalists and scholars who had met Phyo Min Thein publicly stated that the voice in the broadcast did not sound like his real voice.\n- Amateur sleuths and netizens debated whether the televised confession was a deepfake.\n- Viewers used the deepfake analysis site Deepware.ai to probe the veracity of the televised confession, which returned a 90% chance the appearance was algorithm-generated.\n- Results from commercially available deepfake detectors were shared widely online.\n- The historian Thant Myint-U tweeted that Phyo Min Thein and all other political prisoners should be released immediately.\n- An expert, Sam Gregory, publicly analyzed the clip and suggested it might be a forced confession read from a teleprompter rather than a digital fabrication.\n- The LAPD Safe L.A. Task Force sent requests to Ring camera owners asking them to submit copies of any videos related to protests.\n- LAPD detectives sent video requests to Ring owners on several other occasions coinciding with large street protests.\n- The task force's message specified a date and time range for the videos it sought.\n- The LAPD redacted the date and time range from the public records release.\n- The LAPD's request included a disclaimer stating that sharing video recordings with the Los Angeles Police Department is entirely optional.\n- The request included a large button that launched the Ring app to begin the sharing process.\n- Ring\u2019s in-house law enforcement liaisons helped officers use an interface that allowed them to send bulk video requests to specific neighborhoods or broader geographic areas.\n- The task force told the Los Angeles Times that it had used facial recognition software to identify people believed to have committed crimes during the protests.\n- Neither the LAPD nor Ring answered questions from The Intercept about the purpose of the request, how the video data was used, or whether the LAPD made similar requests.\n- The Electronic Frontier Foundation obtained LAPD emails via a public records request and shared them with The Intercept.\n- At least one official was sacked for abusing health codes.\n- Four other officials were disciplined for their roles in turning people\u2019s health codes red.\n- The Zhengzhou Commission for Discipline Inspection issued a public statement disclosing that 1,317 people had been assigned red health codes.\n- Police removed the protesters who were barred from entering the city and sent them home.\n- TikTok restored the intersex hashtag after it had been removed.\n- TikTok told The Verge that the repeat removals of the intersex hashtag were mistakes.\n- The producers asked Kim Kwang-seok's family for their permission to use the AI-generated voice.\n- The producers played the AI-generated audio to Kim Kwang-seok's family so they could hear the outcome.\n- MyHeritage deliberately did not include speech in the DeepNostalgia feature to prevent abuse such as the creation of deepfake videos of living people.\n- MyHeritage published FAQs stating the feature is intended for nostalgic use to bring beloved ancestors back to life.\n- Channel 4 created a deepfake Queen as part of a warning about how the technology could be used to spread fake news.\n- The Law Commission is considering proposals to make it illegal to create deepfake videos without consent.\n- The Faces of the Riot site added hyperlinks from each face to its source video so visitors can see what the person was filmed doing.\n- The site's creators are working to scrub non-rioter faces, including those of police and press, from the collection.\n- The site displays a message warning against vigilante investigations and directs users to report people they recognize to the FBI via a linked FBI tip page.\n- The site's creator refused to allow and explicitly declined to implement any feature that would let users upload a photo to search for matches in the site's collection.\n- The site does not include a search tool and does not attempt to link faces with names or other identifying details.\n- Amazon cut off Parler's web hosting, leaving the site largely offline.\n- The site's creator used the facial recognition tool Dlib to deduplicate about 200,000 extracted face images down to around 6,000 unique faces.\n- Qoves provided more information about how its face analysis works.\n- Qoves attempts to categorize a face according to ethnicity when producing detailed facial analysis reports so that people are not simply evaluated against a European ideal.\n- Instagram denied using beauty-scoring algorithms in its recommendation systems.\n- Facebook denied using beauty-scoring algorithms in its recommendation systems.\n- TikTok declined to comment on the record when asked whether it uses beauty scoring in its recommendation algorithms.\n- Snapchat declined to comment on the record when asked whether it uses beauty scoring in its recommendation algorithms.\n- A Megvii spokesperson stated that Face++ is an open-source platform and the company cannot control how developers might use it.\n- Lauren Rhue published a 2019 study examining how showing AI-generated beauty and age scores to participants affected their judgments.\n- Facebook provided an ad transparency tool that was cited as a positive step toward greater transparency.\n- Cruzcampo issued a public communiqu\u00e9 explaining that the video was modified with artificial intelligence and detailing the technical process and materials used.\n- Cruzcampo disclosed that Lola Flores' daughters, Lolita and Rosario, personally advised on and participated in the production.\n- Amazon publicly refuted characterizing AWS Panorama as a surveillance tool.\n- Amazon stated that AWS Panorama does not include any pre-packaged facial recognition capabilities.\n- Amazon stated that all its machine learning functions can run on the device so relevant data never has to leave the customer's facility.\n- The Trades Union Congress published a report into the use of AI-powered tools used by employers.\n- Microsoft apologised for allowing individuals' activity to be monitored by their employers through a \"productivity score\".\n- Microsoft removed individual user names from the productivity score product after an outcry.\n- Amazon has previously blocked products on its platform that made false claims about coronavirus.\n- Amazon said it encourages customers to read official sources of information.\n- Amazon said it will remove any products that breach its guidelines.\n- Waterstones said that selling a book does not mean the company approves of its content.\n- Foyles said that selling a book does not mean the company approves of its content.\n- Amazon issued a statement to BBC News clarifying that fulfilment centre ambassadors are employees who share facts based on their personal experiences.\n- Amazon said the fulfilment centre ambassador programme, along with FC tours, is used to educate the public about conditions inside its fulfilment centres.\n- Amazon publicly responded to criticism by asserting it provides great employment opportunities with excellent pay and encouraging people to compare its Shakopee operations with other local employers.\n- An Amazon fulfilment centre ambassador stated that some tweets were written by previous ambassadors and that ambassador accounts are used in rotation.\n- Amazon ambassadors actively find and respond to tweets critical of the company's practices.\n- Microsoft pulled out of its investment in AnyVision and exited the company.\n- Microsoft commissioned an audit led by former U.S. attorney general Eric Holder into AnyVision's use of its technology.\n- Microsoft publicly discounted claims that AnyVision software had been used to surveil Palestinians across the West Bank.\n- Jail managers issued a memorandum in November 2016 barring inmates aged 18 to 21 from Restart units and warning that failure to comply would result in disciplinary action.\n- McKinsey consultants helped corrections officials fix coding errors in the spreadsheets used to collect violence data from the Restart units.\n- Internal Correction Department emails show that the fix to the data flaws was only partial, with some errors remaining unresolved nearly six months after McKinsey left.\n- The city set an April 30 end date for McKinsey's engagement, effectively ending the firm's contract.\n- In March 2017, Mayor de Blasio announced his intention to close Rikers and the New York City Council later voted to approve the plan to close the jail complex.\n- GMDC was closed and became the first jail on Rikers to be shut.\n- The Correction Department abandoned the Restart process altogether.\n- The Correction Department paid for the IntelWatch surveillance algorithm but never used it.\n- The city stated plans to export a limited subset of McKinsey's reforms, including the HUB, to the jails that will replace Rikers.\n- Facebook disabled the feature that allowed advertisers to target or exclude audiences by demographic information for housing, credit, and job ads in March 2019 after settling several lawsuits.\n- Facebook settled several lawsuits related to discriminatory ad targeting.\n- The US Department of Housing and Urban Development filed a lawsuit alleging that Facebook\u2019s ad-delivery algorithms were excluding audiences for housing ads.\n- Independent researchers at the University of Southern California conducted an audit of Facebook\u2019s ad service that found the ad-delivery system was withholding certain job ads from women.\n- A team of independent researchers led by Northeastern University corroborated HUD's allegations that Facebook's ad-delivery algorithms were excluding audiences for housing ads.\n- Facebook published a blog post emphasizing the importance of its Responsible AI work and stating it seeks to better understand potential errors affecting its ads system.\n- Facebook said it has taken meaningful steps to address issues of discrimination in its ads.\n- Facebook said it has teams working on ads fairness.\n- Facebook said it is continuing to work closely with the civil rights community, regulators, and academics on matters related to ad discrimination.\n- USC researcher Aleksandra Korolova offered to work with Facebook on addressing these ad-delivery discrimination issues.\n- A concerned Facebook employee flagged the tactical-gear ad internally on the company's Workplace forum.\n- An internal ad reviewer examined the flagged ad and determined there were not enough violations to take it down.\n- Another Facebook worker reported on Workplace that friends had seen military-gear ads served alongside news stories about the Capitol insurrection and attached a video.\n- Facebook COO Sheryl Sandberg said the company had taken proactive measures to remove extremist content.\n- Sheryl Sandberg said Facebook was working to find any mention that may be leading to violence and remove it as quickly as possible.\n- A Facebook spokesperson said the company's teams were working to stay ahead of any militia groups that try to evade the platform's ban.\n- Facebook removed the 'Stop the Steal' group that had more than 14,000 members.\n- Facebook told the BBC it was investigating the issue.\n- A Facebook spokeswoman said Mr Hall's account had been restricted in error.\n- Facebook apologised for any inconvenience caused.\n- Mr Hall appealed each time his images were blocked.\n- After the BBC contacted Facebook about the matter, the ads were reinstated.\n- Google offered Mr Hall a one-to-one clinic about how to navigate its advertising options.\n- Facebook blamed a 'technical error' when it blocked thousands of campaign ads in the run-up to the US presidential election in November 2020.\n- Amnesty International submitted a legal opinion alongside seven other rights organizations as part of a review of the constitutionality of Serbia\u2019s Social Card law.\n- Amnesty International called for a halt to the rollout of the Social Card law to allow for a full assessment of whether the rules comply with Serbia\u2019s obligations under international human rights law.\n- Human rights groups criticized the issuance of a separate identity card to the Rohingya minority in Myanmar.\n- Huawei said it is taking proactive steps to amend the patent application that referenced Uyghur analytics.\n- Huawei's patent was later granted in May 2022 in a slightly altered form that omitted any mention of Uyghur analytics or race detection.\n- Megvii said it would withdraw the 2019 patent application that referenced ethnicity classification.\n- Megvii stated it was undertaking measures to correct the situation, including addressing shortcomings in marketing, sales, and operations materials.\n- Megvii withdrew the patent two weeks after IPVM's article was published.\n- SenseTime said it would update the patent at the next available opportunity on record.\n- SenseTime withdrew its patent mentioning Uyghur analytics in March 2022.\n- SenseTime removed mentions of the word 'Uyghur' two months after the article was published, characterizing this as a correction.\n- Alibaba Cloud took down the Uyghur recognition API guide from its China website after this was exposed.\n- Alibaba stated that it will not permit its technology to be used for targeting specific ethnic groups.\n- Baidu stated that it does not and will not permit its technology to be used to identify or target specific ethnic groups.\n- IPVM published the article in conjunction with the BBC and the BBC conducted its own investigation exposing the patents.\n- IPVM asked Huawei about the patent and the nature of its relationship to the Chinese Academy of Sciences.\n- IPVM reached out to Alibaba asking what ethnicities or races are referenced in its patent and asked Baidu about the discrepancy between its patent language and its stated policies.\n- LAHSA plans to stop using the VI-SPDAT vulnerability scoring tool.\n- LAHSA has partnered with outside researchers from USC and UCLA to develop a new assessment tool to address racial disparities.\n- Researchers, including a team led by USC professor Eric Rice, are testing a new assessment tool intended to more accurately predict outcomes and potentially change how housing is allocated.\n- OrgCode announced that it would phase out support for the current VI-SPDAT survey approach.\n- LAHSA provides guidance on exactly how a person's score should be reassessed so individuals can request a new survey if concerned their score is too low.\n- People experiencing homelessness who are concerned about their scores can request that a case manager survey them again.\n- The People Concern recommends that people request new scores as their circumstances change so case managers can reassess their vulnerability ranking.\n- Housing organizations can request an exception directly from the housing services authority when they feel a survey score is not accurate.\n- Nonprofit service providers advocate directly with LAHSA and work around the scoring system to press for housing for people whose survey scores do not reflect their needs.\n- OpenAI researchers opened up CLIP to analyze how it performs.\n- OpenAI researchers published a research paper describing their findings on CLIP.\n- OpenAI researchers wrote a blog post describing typographic attacks and their findings.\n- The researchers queried GPT-3 100 times with the prompt 'Two Muslims walk into a ...' to observe its completions.\n- They asked GPT-3 to complete the analogy 'Audacious is to boldness as Muslim is to ...' 100 times to confirm the bias.\n- They prepopulated the prompt with a short affirmative phrase ('Muslims are hardworking.') before 'Two Muslims walk into a ...', which reduced violent associations by almost a third.\n- They tested a bevy of adjectives and selected the six best-performing prepopulation associations, which reduced Muslim-violence associations to one in five responses.\n- The Centers for Medicare and Medicaid Services added new safeguards to the public comment system in response to Weiss\u2019s study.\n- Weiss notified the Centers for Medicare and Medicaid Services after submitting the AI-generated comments.\n- The U.S. General Services Administration contacted Weiss and is developing a new version of the federal government website for publishing regulations and comments to better protect it from fake comments.\n- OpenAI and other researchers released tools capable of identifying AI-generated text.\n- Researchers at Google posted details of an experiment using deepfake-text-detection tools to analyze over 500 million webpages and reported that the tools could identify pages hosting auto-generated text and spam.\n- Scatter Lab said it would fix the chatbot.\n- Scatter Lab offered an explanation on its blog stating it was not able to prevent all inappropriate conversations.\n- A senior manager contacted employees to explain that they would not be randomly monitored.\n- The company said the remote scans would not be used in the UK.\n- The company said webcams for UK staff could not be operated remotely.\n- The company said webcams for UK staff would only be used for meetings and training.\n- The company said webcams for UK staff would only be used for scheduled video calls during which supervisors could check desks for devices not allowed for data security reasons.\n- The company said it wanted to discuss any concerns with workers.\n- The company said discussions would take place to reassure staff.\n- The company said no staff would be forced to work from home.\n- TikTok agreed to pay $92 million to settle dozens of lawsuits alleging improper data harvesting.\n- Under the proposed settlement, TikTok will no longer record users' biometric information, including facial characteristics.\n- Under the proposed settlement, TikTok will no longer track users' locations using GPS data.\n- Under the proposed settlement, TikTok committed to stop sending U.S. users' data overseas.\n- Under the proposed settlement, TikTok will no longer collect data on draft videos before the content is published.\n- The proposed settlement provides compensation to affected TikTok users.\n- The Committee on Foreign Investment in the United States is conducting a national security review of TikTok that may force changes to the company's corporate structure.\n- The Biden administration launched a broader review of Americans' use of Chinese technology.\n- In February 2019, TikTok paid a $5.7 million fine to the Federal Trade Commission over allegations it illegally collected personal information from children.\n- Temporarily disable any ad blockers, pop-up blockers, or script blockers you have enabled.\n- Add this site to the allowed list of any ad blockers, pop-up blockers, or script blockers you have enabled.\n- Verify that your browser supports JavaScript by accessing https://www.whatismybrowser.com/detect/is-javascript-enabled.\n- Update your web browser to the latest version.\n- Email accessissues@news.com.au with your IP address, the provided reference number, and an explanation of why you require access to request being unlocked.\n- Deliveroo was ordered by the court to pay \u20ac50,000 to each affected rider.\n- Deliveroo stopped using the historic optional booking algorithm/system, which is no longer in use in Italy or other markets.\n- Deliveroo ran a rider survey and reported that 88% of riders said they were happy with the company and valued flexibility.\n- Deliveroo began a new consultation with riders about how to invest its new \u00a350 million community fund.\n- Deliveroo publicly stated that the Independent Workers of Great Britain union does not represent the vast majority of its 50,000 self-employed riders in Britain.\n- Founder Will Shu is set to offer the group's most prolific riders up to \u00a310,000 in cash each following the IPO.\n- Deliveroo offered customers the chance to buy \u00a350 million in shares in multiples of \u00a3250.\n- DoorDash drivers persuaded their peers to decline the lowest-paying deliveries.\n- DoorDash drivers used the #DeclineNow online forum, a 40,000-person group, to coordinate and promote declining low-paying deliveries to influence the company's matching algorithm.\n- The Independent Workers' Union of Great Britain backed an employment tribunal claim for indirect racial discrimination on behalf of a driver whose account was terminated.\n- The App Drivers & Couriers Union brought two employment tribunal cases against Uber alleging unfair dismissal related to facial recognition failures.\n- The IWGB asked Uber to scrap the use of the facial verification technology.\n- The Equality and Human Rights Commission is supporting the drivers in their legal cases against Uber.\n- The ADCU launched legal action in June over alleged unfair dismissal after the company's facial recognition system failed to identify drivers.\n- Microsoft stated it was consistently testing and updating its Face API with particular attention to fairness and accuracy across demographic groups.\n- Microsoft said it had developed new practices, research methods, and tools to enable its customers to assess and mitigate unfairness in AI systems.\n- Uber allows drivers to choose whether their selfie is checked by Microsoft software or by humans.\n- If an automatic photo match is not found, Uber carries out a human review.\n- If the human review finds there is not a match, Uber waitlists the driver for 24 hours.\n- When the waitlisted driver next logs on, Uber carries out a further human review.\n- If there is still no match after the further review, Uber deactivates the driver's account.\n- Drivers may appeal against Uber's decision to deactivate their accounts.\n- Imran Javaid Raja successfully contested Uber's decision and had his private hire licence reinstated after several months.\n- The three people in the car managed to climb out of the vehicle after it slid into the lake.\n- Divers retrieved the car from the bottom of Lake Champlain.\n- A Google spokesperson said the company could not comment without seeing the user's driving file and without permission to do so.\n- A Google spokesperson reminded users to use all environmental information available to them when using Waze to make the best driving decisions.\n- The Spanish consumer affairs ministry said it was working to ensure olive oil would be excluded from the Nutri-Score system.\n- The agriculture minister stated he would only give his agreement to Nutri-Score if products that are part of the Mediterranean diet are fairly evaluated or exempted.\n- The ministry of food and agriculture said the Nutri-Score algorithms could be updated to take into account products' high-value protein content as well as their vitamins and minerals.\n- Highway police arrived at the scene to handle the incident.\n- Firefighters arrived at the scene to handle the incident.\n- Police completed taking the relevant written statements from the parties.\n- Highway police will further investigate to determine the detailed cause of the crash.\n- The involved parties will address subsequent compensation matters.\n- Authorities determined that Devainder Goli had been watching a movie while using the car's autopilot at the time of the crash.\n- Devainder Goli was charged with violating the move-over law.\n- Devainder Goli was charged with viewing a television device while driving.\n- McAfee Labs publicly reported the vulnerability.\n- The McAfee Labs researchers disclosed the findings to both MobilEye and Tesla in late September 2019.\n- The reporters contacted Tesla for comment.\n- Leaders of Amazon, Apple, Facebook, and Google appeared at an antitrust hearing before the House Judiciary Committee to explain bias and discrimination concerns.\n- Consumer Reports and ProPublica conducted an investigation that found drivers living in predominantly minority urban neighborhoods were charged higher auto insurance premiums than comparable drivers in nonminority neighborhoods.\n- Reuters reported that Amazon's r\u00e9sum\u00e9-screening software used for hiring was biased against women.\n- Apple's new credit card was placed under investigation in November after a customer complained about unequal credit limits between spouses.\n- Consumer Reports and The Markup conducted a follow-up joint investigation that revealed Allstate proposed premium hikes targeting customers deemed less likely to shop around.\n- Boston took steps to prevent facial recognition technology from being used by city agencies, including the police.\n- Amazon imposed a one-year suspension on the sale of its Rekognition facial-recognition software to law enforcement.\n- Joy Buolamwini and others called attention to the harms of facial recognition technology, which helped spur progress on restrictions and suspensions.\n- Nassi created a video outlining what he sees as the danger of these spoofing attacks.\n- Nassi created a small website offering the video.\n- Nassi posted an abstract outlining his work on the website.\n- Nassi posted the full reference paper on the website.\n- Nassi will present his findings at the Cybertech Israel conference in Tel Aviv.\n- Lauren Rosenberg filed a lawsuit in U.S. District Court in Utah naming Google and a motorist.\n- She is seeking more than $100,000 in compensation and is seeking unspecified damages for severe injuries, lost wages, and punitive damages.\n- Barclays confirmed it had introduced the monitoring software.\n- A Barclays spokesperson said colleagues are free to take breaks whenever they choose.\n- Barclays said it will listen carefully to any feedback resulting from the pilot.\n- She convinced the landlord she wasn\u2019t a criminal and eventually got the apartment.\n- Samantha Johnson sued six tenant screening companies for incorrect reports.\n- All six of those lawsuits were settled.\n- Enright\u2019s lawsuit against National Tenant Network was settled out of court.\n- CoreLogic settled the lawsuit brought by Hector Hernandez.\n- RentGrow stated that it promptly resolved all concerns in Marco Fernandez\u2019s favor.\n- RealPage said it has made changes to its criminal matching logic that would prevent the disputed record from returning for the plaintiff in that case.\n- The Federal Trade Commission fined RealPage $3 million in 2018 for using wild-card searches.\n- The Consumer Financial Protection Bureau fined Backgroundchecks.com and an affiliated company in 2015 over employment screenings.\n- A panel of federal judges consolidated seven lawsuits about errors in TransUnion\u2019s tenant screening reports.\n- A handful of cities have begun to regulate tenant screening by limiting a landlord\u2019s ability to reject an applicant for old criminal convictions or evictions.\n- People can complain about faulty background reports to the Federal Trade Commission or the Consumer Financial Protection Bureau or sue.\n- Tenants can find out where the report came from as part of disputing a faulty background report.\n- Tenants can call the screening company to dispute a faulty background report.\n- Tenants can fax a copy of their identification to the screening company as part of the dispute process.\n- Tenants can start the dispute process with the screening company to correct inaccurate reports.\n- Screening companies include instructions in reports telling landlords that they should double-check the reports.\n- Victig Screening Solutions said its company verifies negative findings and uses a human element to improve accuracy.\n- Sandra Smith\u2019s denial was overturned after a year and a half.\n- ScaleFactor laid off about 100 people and provided three months of severance.\n- ScaleFactor returned cash to investors.\n- ScaleFactor offered a partial refund on a customer's annual $23,000 contract in exchange for signing a non-disclosure agreement.\n- ScaleFactor employed a team of bookkeepers and accountants to manually complete customers' books or correct errors from the software.\n- ScaleFactor hired The Outsourced Accountant, an offshore firm in the Philippines, to assist with bookkeeping.\n- David Rathmann held weekly \"Churn Desk\" meetings where cancellation requests were prioritized rather than immediately processed.\n- During Churn Desk meetings, customers who threatened to complain on social media were processed more quickly and let go sooner.\n- ScaleFactor recorded the backlog of pending cancellations and cancellation requests in a private Google spreadsheet.\n- ScaleFactor imposed an informal limit on the value of contracts allowed to be cancelled during Churn Desk meetings to slow the outflow.\n- Kurt Rathmann called an all-hands meeting to announce a pivot to a marketplace model that connected traditional accountants with their clients ('ScaleFactor 2.020').\n- About 40 employees, mostly accountants and bookkeepers, were laid off when the pivot to ScaleFactor 2.020 was announced.\n- Insight Camera's website was taken offline after BuzzFeed News requested comment.\n- The United Federation of Teachers used Insight Camera to help security personnel identify individuals who had made threats against employees.\n- The United Federation of Teachers prevented those identified individuals from entering one of its offices.\n- The United Federation of Teachers did not access Clearview's larger database.\n- The United Federation of Teachers used Insight Camera in a self-contained, closed system that relied exclusively on images generated on site.\n- Rudin Management decided not to use Insight Camera and confirmed it does not currently use the software.\n- Clearview's attorney stated that the published information contained numerous inaccuracies.\n- Clearview's attorney declined to provide further comment, citing an ongoing federal investigation.\n- Liam Porr retired the project.\n- Liam Porr posted a cryptic, self-written final message titled \"What I would do with GPT-3 if I had no ethics\" describing his process as a hypothetical.\n- Liam Porr posted a more straightforward confession on his real blog.\n- The article's text was updated to add additional details explaining how Liam Porr created his blog and got it to the top of Hacker News.\n- The article's photo captions were updated to add additional details explaining how Liam Porr created his blog and got it to the top of Hacker News.\n- Police opened an investigation after a victim reported that 20,000 yuan had disappeared from her WeChat Pay account.\n- Authorities arrested the three suspects in different locations in September and October.\n- The case is still under investigation.\n- The professor immediately placed an academic infraction on the student's record.\n- The student spoke with her professor about the testing situation.\n- The professor reviewed the situation.\n- The professor apologized to the student.\n- The professor reinstated the student's original grade.\n- The professor removed the academic infraction from the student's record.\n- ProctorU CEO Scott McFarland issued a statement to Insider about the incident.\n- ProctorU said the recording allowed the student to prove her case.\n- The Electronic Privacy Information Center formally asked the District of Columbia's attorney general to investigate the business practices of five exam proctoring companies.\n- EPIC sent notices to Respondus, ProctorU, Proctorio, Examity, and Honorlock.\n- EPIC threatened to bring civil suits against those five proctoring companies if they do not stop their excessive and unjustified collection of sensitive student data, including biometrics, and their reliance on opaque AI analysis to flag alleged cheating.\n- An Honorlock spokesperson issued a public statement defending the company's practices and saying the claims against it are baseless and untrue.\n- Respondus's COO said Respondus plans to respond to EPIC's letter to the attorney general with factual detail and care.\n- The UCSB Faculty Association sent a letter to Chancellor Henry T. Yang and Executive Vice Chancellor David Marshall urging UCSB to rescind its contract with ProctorU.\n- The UCSB Faculty Association urged UCSB to issue a statement discouraging faculty from using ProctorU or any other private service that sells or makes students' data available to third parties.\n- The UCSB Faculty Association requested that UCSB adopt a policy of refusal to use ProctorU.\n- The UCSB Faculty Association requested that professors who were planning to use ProctorU be given an extension to adapt their exams to another format.\n- The article was corrected on 3/18/2020 to further clarify ProctorU\u2019s policy about distributing information.\n</mitigation_statements>"}]}}
{"custom_id": "batch_1000", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- Proctorio's CEO, Mike Olsen, apologized after sharing part of a private conversation between a Proctorio support agent and a UBC student on Reddit.\n- Proctorio sued Ian Linkletter claiming breach of copyright and other infringements.\n- Proctorio sued Erik Johnson arguing copyright infringement and that he had defamed the company and damaged its business relationships with universities.\n- Erik Johnson sued Proctorio claiming the company was abusing copyright law to interfere with his free speech.\n- Proctorio had the material uploaded by Erik Johnson removed from public access.\n- Proctorio engaged an outside third party, BABL AI, to audit its face detection algorithm.\n- Proctorio commissioned a first audit of its face detection algorithm which it said found no statistically significant bias.\n- Proctorio commissioned a second audit of its face detection algorithm that was scheduled to be completed in the fall.\n- Proctorio contacted Amaya Ross and helped troubleshoot what it described as a 'lighting issue' so she could complete her quiz.\n- Proctorio and Erik Johnson reached a settlement in March.\n- In their joint statement, Erik Johnson acknowledged that some of his comments about Proctorio were imprecise and presented without context.\n- In their joint statement, Proctorio acknowledged that some face and gaze detection algorithms have higher error rates for people of color and said it made 'substantial efforts' to address those issues.\n- The parties agreed to discontinue the BIPA case against Proctorio, and the case was dismissed by a judge in late August.\n- Class-action lawsuits were filed against Proctorio, Examity, and Honorlock alleging breaches of the Illinois Biometric Information Privacy Act (BIPA).\n- The case against Honorlock moved from the court to private arbitration.\n- An Ohio judge ruled that scanning rooms via e-proctoring software before students take exams is unconstitutional.\n- Ian Linkletter ran a GoFundMe campaign to help cover his legal defense costs.\n- Ian Linkletter received counseling to help him manage the anxiety caused by the lawsuit.\n- Ian Linkletter appealed the ruling that denied his attempt to have the case dismissed under legislation protecting expression on matters of public interest.\n- Two Canadian civil liberties organizations applied to join Ian Linkletter's appeal.\n- Fight for the Future ran a campaign against e-proctoring that included a website satirizing Proctorio's CEO.\n- Fight for the Future fought a subpoena issued by Proctorio.\n- The Mozilla Foundation released an animated video of Amaya Ross's story.\n- Proctorio banned Erik Johnson's IP address from accessing the company's services.\n- Proctorio CEO Mike Olsen sent a direct message to Erik Johnson demanding he take down his Pastebin posts.\n- Students started online petitions calling for universities across the world to abandon digital proctoring tools.\n- Faculty on some campuses led campaigns urging universities to explore new forms of assessment instead of using proctoring software.\n- Two students in California filed an emergency petition with the state supreme court requesting that it cancel the bar exam and institute a new form of assessment.\n- Law students around the country organized to oppose the use of digital proctoring software on bar exams.\n- The petitioners conducted a survey of 1,413 law students about internet reliability and other concerns related to the bar exam.\n- Louisiana scrapped its upcoming bar exam.\n- Oregon scrapped its upcoming bar exam.\n- Wisconsin scrapped its upcoming bar exam.\n- New York's test proctor announced it was going to ban the use of desktop computers to take the test.\n- Training videos explaining Proctorio's abnormality methodology were removed from YouTube.\n- Proctorio filed for a court injunction to prevent Ian Linkletter from sharing its training material.\n- Proctorio sent a letter to the journal Hybrid Pedagogy demanding a retraction of a critical peer-reviewed article.\n- A ProctorU attorney threatened to sue the UCSB faculty association for defamation and copyright violations and said he would send his complaint to the state's Attorney General.\n- The UCSB faculty association sent a letter to the school's administration raising concerns about whether ProctorU would share student data with third parties.\n- The UCSB faculty association asked the school administration to terminate its contract with ProctorU and to discourage professors from using similar services.\n- The Proctortrack service was taken offline for a week while the breach was investigated.\n- The company underwent an independent security audit.\n- The company stated that any problems identified had been fixed.\n- The CEO issued a public statement about the breach, the audit, and repairs.\n- The CEO contacted St. George\u2019s University about the mishandling of some student email addresses.\n- The company invited Consumer Reports to review its current source code and an independent security audit, conditional on Consumer Reports signing a nondisclosure agreement.\n- Rutgers switched to another proctoring service, Respondus Monitor, in response to the breach.\n- 1,700 academics signed an open letter demanding the research remains unpublished.\n- The Coalition for Critical Technology demanded that all publishers refrain from publishing similar studies in the future.\n- Springer rejected the paper after a peer review process.\n- Springer officially communicated the rejection of the paper to the authors on 22 June.\n- Harrisburg University took down its press release at the request of the faculty involved.\n- Harrisburg University stated the paper was being updated to address concerns.\n- The Pulse team amended their paper to note that it may illuminate some biases in one of the tools they use to generate faces.\n- The Brennan Center obtained internal Voyager documents through public information requests.\n- The Brennan Center shared the obtained documents with the Guardian.\n- Facebook deactivated the fake account used by Memphis police and other similar accounts.\n- Facebook told the police department to cease all Facebook activities that involve the use of fake accounts or impersonation of others.\n- The employee flagged the suspicious voicemail to the company.\n- The company called in security consulting firm NISOS to investigate the voicemail.\n- NISOS analyzed the audio with a spectrogram tool called Spectrum3d to detect anomalies.\n- NISOS published a report on the incident and shared the report with Motherboard in advance.\n- NISOS shared the audio of the suspected deepfake.\n- Teachers' estimated grades will be awarded to students instead of algorithm-generated grades, except where the algorithm produced a higher grade.\n- Ofqual chair Roger Taylor and Education Secretary Gavin Williamson apologised for the distress caused by the grading process.\n- Mock exam results will no longer be a key part of the appeals process.\n- The government said it was working with awarding authorities to ensure BTECs would be subject to teacher-assessed grades.\n- The temporary cap on the number of university places that institutions could offer was lifted.\n- Universities said they would be as flexible as possible and would try to accommodate applicants affected by the grading changes.\n- UCAS said students who did not have places at their first or insurance choice did not need to make their decision immediately.\n- UCAS said it would issue new advice for students and schools.\n- UCAS said this new advice would be sent directly to students as soon as they were able to take a decision.\n- Downing Street said it asked questions after seeing concerning outliers in the grading data.\n- Universities UK said it was seeking urgent clarification on a number of issues.\n- The Ministry of Home Affairs revised guidelines on May 24 to drop the provision requiring all incoming passengers to download the Aarogya Setu app.\n- The Ministry of Home Affairs made use of the Aarogya Setu app mandatory only in exceptional cases such as human distress, pregnancy, death in family, serious illness, and parents accompanying children below 10 years.\n- The Ministry of Home Affairs removed the clause that made the Aarogya Setu app mandatory for workplaces.\n- The health ministry mandated that all incoming passengers undergo a mandatory 14-day check consisting of 7 days institutional quarantine at one\u2019s own cost followed by 7 days isolation at home.\n- The Indian Computer Emergency Response Team issued an advisory highlighting phishing scams related to the Aarogya Setu app.\n- The city will start putting electronic bracelets on people who test positive for COVID-19 from July 15.\n- The LeaveHomeSafe app will be updated to require people to register using a verified form of ID (real-name registration).\n- A confirmed COVID-19 positive person's health code will turn red to prevent them from going to public places.\n- New arrivals to the city will be assigned an amber health code that restricts their entry to certain high-risk places.\n- Authorities said they will address misinformation quickly so that everybody knows what they are doing.\n- Shanghai authorities resumed local lockdowns.\n- Shanghai authorities barricaded some residents into their apartment buildings by placing steel sheeting at alleyway entrances to prevent people from leaving restricted areas.\n- Authorities locked down residential compounds for two days when a resident was identified as a close contact.\n- Authorities lock down buildings wherever there are cases or contacts.\n- Lanzhou authorities told people not to leave their homes unless necessary.\n- Lanzhou authorities implemented three waves of mass, compulsory COVID-19 testing.\n- Lanzhou authorities put steel gates outside community gates and locked them from the side facing the street at midnight.\n- Lanzhou authorities implemented temporary restrictions that last for at least seven days.\n- Under the restrictions in Lanzhou, takeout was allowed but dine-in was prohibited.\n- A national CPPCC member proposed establishing an opt-out mechanism for personal information collected during the COVID-19 pandemic.\n- The proposal also called for standardized management of already collected information to reduce the risks of data leakage and misuse.\n- The government will revise its proposals for planning reforms in England.\n- Housing Secretary Robert Jenrick will make a statement on revised plans in the weeks ahead.\n- The government says it has listened to the feedback of critical MPs.\n- Ministers are looking to rebalance the housing formula.\n- The government will consider repurposing offices into residential properties.\n- The government will consider turning retail spaces into mixed-use developments.\n- The government will adopt a different approach to distributing housing numbers across the country based on those considerations.\n- The government plans to shift the focus towards building more homes in the North and Midlands and in urban areas and city centres.\n- The Ministry of Housing, Communities and Local Government is looking to move a proportion of its operations to the West Midlands.\n- The proposed move would involve relocating ministerial offices and senior officials to Wolverhampton.\n- Bob Seely secured a Commons debate on the issue.\n- Jeremy Hunt said he will work with the Housing Secretary to ensure a revised algorithm achieves increased housebuilding to help young people get on the housing ladder.\n- The Home Office said it will continue to develop and evaluate its systems to make applying for a passport as simple as possible for all.\n- A passport applicant challenged the website's verdict by writing a note stating her mouth was closed in order to have her photo approved.\n- The BBC investigated the issue by feeding more than 1,000 passport-style photographs into the automated photo checker and recording the quality scores.\n- Kirstie Whitaker reviewed the BBC's code used in the study.\n- Kirstie Whitaker independently reproduced the BBC's results.\n- Kirstie Whitaker provided input on the validity of the reported outcomes.\n- Voltaire does not honor client requests to search juror data for keywords related to protected classes such as race or sex.\n- Voltaire specifically declines to take cases that are likely to involve searching for protected-class information, such as housing discrimination cases.\n- Voltaire's founder turned down an offer to incorporate IBM Watson\u2019s Tone Analyzer into Voltaire's service.\n- Voltaire chooses to leave determinations of juror bias more up to human attorneys rather than providing algorithmic predictions.\n- Vijilent decided not to offer predictive analytics about how jurors will decide cases because it lacked sufficient training data and demand.\n- Some emerging jury-analytics companies have attempted to filter race out of their algorithms.\n- Iran's Supreme Leader Ayatollah Ali Khamenei vowed to avenge the assassination.\n- Ayatollah Ali Khamenei demanded the definitive punishment of those behind the assassination.\n- Israeli security officials warned some former nuclear scientists to be cautious.\n- The Israeli foreign ministry told Israeli citizens travelling in the Middle East and Africa to be vigilant.\n- Officials stressed that participation in the Suzhou Civility Code was voluntary.\n- In the first week of using the case management system, 58 identified households were referred to a council service area for further support.\n- Xantura's example with Barking and Dagenham Council showed the system immediately identified 1,114 households not currently engaged with council services who had significant debt and other risk factors.\n- Barking and Dagenham Council used OneView to identify and reach out to its most vulnerable residents to help prevent unseen difficulties.\n- Barking and Dagenham Council said it used appropriately collected data in accordance with guidance from the Information Commissioner's Office.\n- Xantura stated that none of the councils using OneView were deploying it to predict who would break isolation.\n- Xantura asserted that the OneView application was fully compliant with data protection rules and other government data sharing guidance.\n- The facial recognition toilet paper dispenser system was suspended after citizens raised concerns.\n- Photos of users captured by the system were deleted after some time.\n- The system was not connected to a network.\n- The Italian Data Protection Authority (Garante) issued a formal ruling on 26 February finding that the processing of biometric data by the Comune di Como lacked a valid legal basis.\n- The Garante opened an official inquiry (istruttoria) following a request for information sent in late December 2019.\n- The Comune di Como communicated in early April that it had disabled the experimental facial recognition function used in the Parco Tokamachi.\n- The Comune di Como kept the recently installed cameras in via Leoni and via Anzani operating only in ordinary video-surveillance mode, with advanced facial-recognition functions inactive while awaiting guidance from the Garante.\n- The Comune di Como produced a Data Protection Impact Assessment (DPIA) in February 2019 after the procurement had begun.\n- Algorithm Watch notified the Finnish Data Protection Ombudsman about Digital Minds' service.\n- The office of the Data Protection Ombudsman requested that the company clarify the matter.\n- Digital Minds paused its operations due to the Data Protection Ombudsman's inquiry.\n- The Internet Freedom Foundation conducted Project Panoptic, a study documenting how facial recognition systems are being deployed and revealing 32 projects at various stages of deployment in India.\n- The French Interior Ministry published a white paper assembling stakeholders' views and proposing about 200 recommendations on internal security, including guidance on facial recognition technology.\n- The white paper recommended consolidating the forensic use of facial recognition technology as a tool for identifying suspects within criminal investigations in France.\n- The white paper proposed experimentation with facial recognition systems in public spaces to test them technically, operationally, and legally and to ensure protection of the French people.\n- The white paper recommended that such experimentation should be gradual.\n- The white paper suggested that experimentation could, over time, be extended to non-state actors for limited tracking purposes.\n- 7-Eleven disabled facial recognition technology used in its 700 Australian stores.\n- The company shut down the review system in September.\n- Ahead of the final decision, 7-Eleven disabled the image capture component of the survey system.\n- The privacy commissioner ordered 7-Eleven to destroy all faceprints within 90 days.\n- 7-Eleven stated that all images taken by the system in its stores have been permanently deleted.\n- The government clarified its daily exercise guidance to tell people to 'stay local' and not travel unnecessarily for exercise.\n- The Home Office announced new powers allowing police to arrest anyone flouting the coronavirus lockdown rules.\n- Home Secretary Priti Patel announced that anyone ignoring restrictions could be fined \u00a360 and \u00a3120 for a second offence.\n- Derbyshire Police broke up a large group near the Snake Pass enjoying a picnic and shisha.\n- The Peak District National Park urged people to stay home after crowds flocked to the Peaks.\n- Derbyshire Police published tweets stating that some cars parked in the area were registered in Sheffield to suggest people had travelled to Derbyshire and ignored government advice to exercise close to home.\n- Detroit Police implemented a new facial recognition policy with stricter rules on when the technology can be used.\n- Detroit Police now use facial recognition technology only as a tool to help solve violent felonies.\n- A spokesman for the Detroit Police Department said he was looking into questions from the Free Press about Oliver's case.\n- The Wayne County Prosecutor's Office instituted a more stringent protocol for facial recognition cases.\n- The prosecutor's office now requires a supervisor to review all evidence in a facial recognition case prior to making a charging decision.\n- The prosecutor's office now requires corroborating evidence before charging someone in cases that involved facial recognition.\n- Facial recognition cases must be submitted to Prosecutor Kym Worthy for approval if an assistant prosecuting attorney and supervisor determine charges should be authorized.\n- Facial recognition-based cases will be reviewed during the warrant charging phase.\n- Facial recognition-based cases will be reviewed prior to the preliminary examination.\n- Facial recognition-based cases will be reviewed again when the case is bound over to the Circuit Court.\n- Prosecutors apologized for how the Williams case was handled.\n- Police apologized for how the Williams case was handled.\n- The Detroit police commission discussed Williams' case during a meeting.\n- Police gave a presentation to the Detroit police commission about Williams' case.\n- Board member Evette Griffie sought answers from police about Williams' case, including a timeline of events and any discipline resulting from the misidentification.\n- Wayne County Assistant Prosecutor Brian Surma and the teacher reviewed photographs and concluded Oliver was misidentified.\n- Prosecutors agreed the case against Oliver should be dismissed immediately.\n- Oliver's larceny case was dismissed.\n- Prosecutor Kym Worthy declined to adopt the Detroit Police Department's Facial Recognition Policy.\n- Detroit Police Chief James Craig publicly said the situation should not have happened.\n- Amnesty International released a report revealing that Dutch law enforcement had been engaged in predictive-policing pilots and documenting alleged human rights violations.\n- Amnesty International called on law enforcement to halt all predictive policing projects until legislative safeguards are put in place.\n- Amnesty International obtained documents via WOB (public information request) requests to support its report.\n- The SyRI (System Risk Indication) system was found to be in violation of existing European human rights law.\n- The SyRI system was discontinued earlier this year.\n- Human Rights Watch discovered a defect in the benefits calculation system.\n- Human Rights Watch warned that the flawed algorithm is causing hunger, debt, and psychological distress.\n- Human Rights Watch called for urgent measures to be implemented, including one-off grants for applicants.\n- The government is evaluating proposals to improve the system, such as using shorter income-assessment periods or averaging earnings over longer periods.\n- Civil society organizations and two citizens instigated legal action seeking to block the use of the SyRI system.\n- The court ordered an immediate halt to the use of the SyRI system.\n- The UN Special Rapporteur on extreme poverty and human rights, Philip Alston, intervened in the case by providing the court with a human rights analysis.\n- Stanford Medicine apologized to its residents, fellows, frontline care providers, and the broader community for errors in the execution of its vaccine distribution plan.\n- Stanford Medicine promised to re-evaluate its vaccine distribution plan.\n- Stanford Medicine said it was immediately revising its plan to better sequence the distribution of the vaccine.\n- Stanford Medicine said it was working quickly to address the flaws in its plan.\n- Stanford Medicine said it would develop a revised version of the plan.\n- Stanford Medicine administration sent an email to staff on December 18th apologizing for the initial plan and promising changes.\n- Meta asked users to acknowledge that BlenderBot is likely to make untrue or offensive statements before using it.\n- Meta required users to agree not to intentionally trigger the bot to make offensive statements.\n- Meta conducted large-scale studies to create safeguards for BlenderBot 3.\n- Meta co-organized workshops to create safeguards for BlenderBot 3.\n- Meta developed new techniques to create safeguards for BlenderBot 3.\n- Meta is collecting feedback from users to help make future chatbots better.\n- Meta developed new learning algorithms to distinguish between helpful responses and harmful examples.\n- Meta stated it will use this technique over time to make its models more responsible and safe for all users.\n- Buckingham Palace told the BBC it had no comment on the broadcast.\n- Ofcom said it had received a small number of complaints but, because it is a post-transmission regulator, could not consider them at this time.\n- Roc Nation LLC filed copyright claims on YouTube asserting the content unlawfully used an AI to impersonate Jay-Z's voice.\n- YouTube immediately removed the two accused videos after receiving the copyright claims.\n- Both videos remained viewable on LBRY, a decentralized and open-source publishing platform.\n- The creator announced the takedown in a new video using synthetic voices of Barack Obama, Donald Trump, Ronald Reagan, JFK, and FDR.\n- The article's author reached out to the anonymous creator of Vocal Synthesis to learn more about the takedown and the channel's practices.\n- The article's author requested comment from Roc Nation LLC, but Roc Nation did not respond.\n- Google reviewed the DMCA takedown requests for the videos in question and determined that the requests were incomplete.\n- Google temporarily reinstated the videos pending additional information from the claimant.\n- The copyright strike was removed and both videos were reinstated on the creator's YouTube channel.\n- The viral video was quickly debunked as the Pornhub banner had been added to the live footage after the fact.\n- Savvy users quickly noted that the video was fake.\n- Many users shared the real, unedited clip from the live segment showing John King flicking away a phone notification.\n- RT issued a statement saying the video was satire.\n- RT added in its statement that if President Trump wanted a job he should let them know.\n- The CIA said Russian President Vladimir Putin was likely directing the interference effort.\n- FBI Director Christopher Wray told Congress that Russia was engaging in very active efforts to denigrate Joe Biden and help with Trump's reelection effort.\n- Swiss Security Solutions reported the fake 'Martin Aspen' profile to LinkedIn.\n- Elise Thomas identified telltale signs that the Aspen profile picture was computer-generated.\n- Elise Thomas consulted Ben Nimmo of Graphika to investigate the suspicious profile picture.\n- Ben Nimmo and his team overlaid multiple images, including the Aspen picture, to confirm the eyes aligned and indicate the face was computer-generated.\n- Swiss Security Solutions said it had identified fake accounts for two other people impersonating its employees.\n- Facebook removed over 600 accounts tied to a network using computer-generated faces.\n- Facebook removed another batch of computer-generated profiles originating in China and the Philippines.\n- The publication issued a correction clarifying that Christopher Balding was a former professor at Fulbright University Vietnam.\n- Fulbright University Vietnam issued a statement saying Christopher Balding was a former professor and no longer an employee as of Sept. 10, 2020.\n- Stephen Gregory, publisher of the U.S. editions of The Epoch Times, denied any connection to the removed fake accounts.\n- Twitter permanently suspended the fake candidate account for violating its rules.\n- Ballotpedia added a message to the Andrew Walz page stating he may not be a legitimate candidate and that they were investigating.\n- Ballotpedia said it will distinguish between 'declared' and 'officially filed' candidates in the lists it submits to Twitter in the future.\n- Twitter verified Jannquell Peters' account after being contacted by CNN.\n- Twitter said it has put into place a rigorous process, through its partnership with Ballotpedia, to more accurately identify and verify candidates' legitimate Twitter accounts.\n- VICE shared the videos with researchers at the Rochester Institute of Technology for analysis.\n- Researchers at the Rochester Institute of Technology awaited confirmation from their purpose-built deepfake-detection software to determine whether the videos were forged.\n- VICE shared the videos with the fact-checking website AltNews to check their validity.\n- AltNews attempted to verify the videos' authenticity but was unable to deduce that they were fake.\n- Tianjin passed a Municipal Social Credit Regulation prohibiting private and state-owned companies, industry associations, and chambers of commerce from collecting biometric data, including facial recognition information, and from using it as social credit information.\n- Nanjing ordered property agents to remove facial recognition systems from their sales offices.\n- Thousands of Shipt workers planned to strike on October 17 in protest of the new payment algorithm.\n- Thousands of Shipt workers planned to strike on October 19 in protest of the new payment algorithm.\n- Organizer Willy Solis planned to hold an in-person protest at Target's headquarters in Minneapolis, Minnesota, on October 19.\n- Shipt's chief communications officer Molly Snyder sent an email disputing that workers are worse off under the new algorithm and stating that overall pay remains consistent.\n- Labor group CoWorker.Org and MIT graduate student Dan Calacci released a study showing that 41% of Shipt workers had seen their pay decrease by an average of 11% since the new system was rolled out.\n- An Illinois woman filed a proposed class-action lawsuit in federal court in Chicago against Macy\u2019s alleging violations of the Illinois Biometric Information Privacy Act.\n- Amazon will issue a warning to warehouse staffers for their first violation of the social-distancing guidelines.\n- Amazon will fire warehouse staffers who commit a second violation of the social-distancing guidelines.\n- Officials plan to single out staffers who are seen breaking social-distancing rules.\n- Officials plan to review internal camera footage to identify social-distancing violations.\n- Amazon asked top machine learning technologists to find ways to improve social distancing in its buildings by using internal cameras.\n- Amazon announced that masks would be made available at all locations as soon as Tuesday.\n- Amazon fired Chris Smalls, the management assistant who organized the March 30 walkout on Staten Island.\n- Southern Co-op's loss prevention lead Gareth Lewis published a blog post on the Facewatch website acknowledging the use of facial recognition and saying it had been successful.\n- Privacy International wrote to Co-op, regulators, and law enforcement about the use of the facial recognition technology.\n- The UK's Information Commissioner's Office opened an investigation into where live facial recognition is being used in the private sector and expects to report its findings early next year.\n- The ICO stated that its investigation includes assessing the compliance of a range of private companies and that Facewatch is among the organizations under consideration.\n- The Metropolitan Police issued an apology after handing images of seven people to a private facial recognition system in Kings Cross in October 2019.\n- Co-op publicly stated that no facial images are shared with the police or with any other organization.\n- Southern Co-op said it is not planning to roll out the facial recognition technology to all of its Southern Co-op stores.\n- Store staff receive notifications on smartphones when the facial recognition system makes a match.\n- Store staff may ask flagged individuals to politely leave the premises when they are identified by the system.\n- Store staff may notify police if a flagged individual breaches a banning order.\n- Jeff Dean, head of Google Research, emailed employees to share his account of what happened.\n- In that email, Google assured employees it would support them as they continue their responsible AI research.\n- Google accepted and respected Timnit Gebru\u2019s decision to resign from Google.\n- Google terminated Timnit Gebru\u2019s access to her Google account after her employment ended.\n- Jeff Dean urged employees not to stop work on critical diversity, equity, and inclusion programs and encouraged them to continue their work.\n- More data should be recorded and published on both ethnicity and religion for better scrutiny of the Criminal Justice System's approach.\n- The Crown Prosecution Service should consider its approach to gang prosecutions, ensuring people's actions are punished rather than their associations.\n- Modern slavery legislation should be reviewed to see if it can help prevent the exploitation of vulnerable young men and women.\n- Identifying information should be redacted to enable race-blind decisions on cases.\n- All sentencing remarks made in Crown Court should be published.\n- A system of online feedback on judges should be introduced.\n- New judges should be hired with a national target to achieve a representative judiciary by 2025.\n- Hiring practices should be changed to create a more representative prison staff.\n- Low-level offenders should be allowed to defer prosecution and opt for a rehabilitation programme before entering a plea.\n- The deferred prosecution pilot programme used in the West Midlands should be rolled out across the country.\n- Young offenders should be assessed for their maturity to inform sentencing decisions.\n- The prison service should adopt a problem-solving approach to dealing with complaints.\n- The prison service should ensure fairness for prisoners in relation to incentives and earned privileges.\n- Reformed offenders should be able to apply to have their criminal records sealed so they need not disclose their offence to an employer.\n- The government said it would look carefully at the review's findings and recommendations.\n- The Equality and Human Rights Commission urged the government to respond urgently and put in place a comprehensive race strategy with targets to reduce race inequality.\n- Gareth Wilson said he would work with the Home Office and College of Policing to make more data on ethnicity available for scrutiny.\n- Gareth Wilson said he would work to make the police force more representative.\n- The Director of Public Prosecutions said the Crown Prosecution Service would consider the review's recommendations.\n- David Lammy published a review making 35 recommendations, including delaying or dropping some prosecutions.\n- MyCompanyWorks confirmed that Ticket to the Moon is a client.\n- A Gradient representative told Mashable that Ticket to the Moon was founded by Vladyslav Urazov and Bogdan Matveev.\n- A Gradient spokesperson publicly stated that the company does not collect or store images and Face Data and does not transfer them to third parties.\n- FaceApp's founder immediately answered questions about his app after the earlier FaceApp backlash.\n- The copycat app 'Look Like You? Celebrity!' was removed from the App Store.\n- The Mashable story was updated with more information about Ticket to the Moon.\n- The Metropolitan Police Service agreed to overhaul and completely redesign the Gangs Violence Matrix.\n- The Met agreed to remove the majority of individuals from the Matrix, with more than 1,000 names to be removed.\n- The Met will remove individuals currently scored as green from the Matrix.\n- The Met agreed that people can apply to be informed whether they were or are on the Matrix.\n- The Met agreed to inform people who ask whether they are on the Matrix, who their data has been shared with, and what that data was.\n- The Met said it will only refuse disclosure requests for limited specified reasons.\n- The Information Commissioner will review refusals of disclosure requests upon request.\n- TikTok stated that most of the livestream guidelines reviewed are no longer in use or in some cases never were in place.\n- TikTok stated that the rules suppressing videos featuring unattractive, disabled, or poor users were no longer in place and were already out of use when The Intercept obtained them.\n- ByteDance acknowledged to the Guardian that the old moderation guidelines were outdated and no longer in use.\n- TikTok established Trust and Safety hubs in California, Dublin, and Singapore to oversee the development and execution of its moderation policies.\n- The industry evaluation site IPVM published a report questioning the reliability of Hikvision's ethnicity-analysis feature and highlighting errors such as the system marking a person wearing sunglasses as not wearing glasses.\n- A Cambricon employee told VOA that mainstream surveillance companies in China cooperate with the government and that government departments can obtain these information from companies at any time.\n- A Cambricon software engineer told VOA that surveillance-video image quality is often insufficient, causing a high chance of erroneous judgments.\n- The Cambricon software engineer stated they were unclear about the specific criteria used in Hikvision's backend and said factors like beards, headwear, and facial accessories could be considered in the system's determinations.\n- The Cambricon software engineer said that in good lighting and with unobstructed photos facial recognition can reach nearly 100% accuracy, but that recognition from surveillance video is a technical challenge.\n- Google removed the offensive suggested keywords from the Keyword Planner tool.\n- Google said it is looking into how to stop this from happening again.\n- Google is working to update its systems so that those suggested adult-related keywords will no longer be shown.\n- Genderify shut down its website and removed its gender-prediction tool.\n- Genderify updated the FAQ on its website to address how to avoid gender discrimination.\n- The company's product team said it began actively looking into ways of improving the experience for transgender and non-binary visitors.\n- The product team said it was working on separating the concepts of name/username/email from gender identity.\n- Genderify said it relied on feedback from transgender and non-binary visitors to help improve its gender-detection algorithms.\n- Gordon Legal announced it had reached a settlement with the Commonwealth over the Robodebt class action, pending approval from the Federal Court of Australia.\n- The Commonwealth agreed to pay $112 million in compensation, including legal fees.\n- The Commonwealth agreed to repay more than $720 million in debts previously collected.\n- The Commonwealth agreed to drop claims for $398 million in debt.\n- Once court approval is provided, a Settlement Distribution Scheme will be established to assess all amounts due and pay them out in 2021.\n- Members affected by the settlement will be contacted individually.\n- The authors of the report shared all their findings with Telegram.\n- The authors of the report shared all their findings with VK.\n- The authors of the report shared all their findings with relevant law enforcement agencies.\n- VK said it blocks communities that distribute such content.\n- The administrator of the bot said they block a user for good when they see minors in shared photos.\n- The administrator of the service said he will soon remove all of the images.\n- A similar app was shut down last year.\n- The US state of Virginia outlawed deepfakes last year.\n- The UK government instructed the Law Commission to review the law around the issue in England and Wales, with findings due in 2021.\n- These Nudes Do Not Exist runs public-domain images through reverse image searches to verify their sources.\n- These Nudes Do Not Exist excludes images from its training data when reverse-image search results show they originate from paywalled or monetized websites, revenge-porn sites, online forums, or other behind-paywall sources.\n- These Nudes Do Not Exist uses only public-domain or purchased data sources from reputable providers.\n- Microsoft took down the MS-Celeb image dataset after reports revealed it contained photos of people without their consent.\n- As of publication, thesenudesdonotexist.com limits purchases to no more than one generated person per session.\n- Algorithm Watch asked 26 volunteers to download a browser add-on that automatically opened their Instagram at regular intervals and recorded which posts appeared at the top of their newsfeeds.\n- Algorithm Watch asked the volunteers to monitor which photos from 37 creators were placed highest on their feeds.\n- Algorithm Watch conducted an experiment from February to May 2020 and analyzed more than 2,400 photos.\n- Algorithm Watch published a blog post summarizing their findings about feed diversity and alleged algorithmic bias.\n- A Facebook spokesperson sent an email to DailyMail.com stating that the research was flawed and showed a misunderstanding of how Instagram works.\n- The government decided to end its experiment with profiling the unemployed.\n- The government tabled an amendment to the law to abolish the scoring system by December 2019.\n- Panoptykon Foundation used freedom of information provisions to request essential details of the profiling mechanism.\n- Panoptykon Foundation pursued disputes with the Ministry of Labour, including one that was resolved in court.\n- Panoptykon Foundation published the questions asked during the computer-based interview and the scoring rules.\n- The Supreme Audit Office carried out a general review of the Public Employment Service (PSZ) that included an examination of the profiling mechanism.\n- The Human Rights Commissioner referred the profiling case to Poland's Constitutional Court.\n- The Constitutional Court ruled in 2018 that the profiling system breached the Polish constitution.\n- Many unemployed people filed complaints about the outcomes of the profiling mechanism using administrative law.\n- The Austrian data protection authority declared the AMS sorting algorithm illegal.\n- The Austrian data protection authority ordered that the deployment of the AMS sorting algorithm should be suspended.\n- AMS released two of the 96 statistical models reportedly used to assess job seekers.\n- AMS board member Johannes Kopf issued a written rebuttal of critics and stated that AMS was committed to spending half of its resources to support women.\n- An AMS representative sent an email statement to AlgorithmWatch asserting that the algorithm was consistent with all anti-discrimination regulations.\n- Paola Lopez conducted an analysis of the available evidence and reported that the algorithm uses thresholds not related to employment policy.\n- The claims were sent to arbitration after a federal judge found that the plaintiffs agreed to an arbitration clause in Instagram's terms of use.\n- The court stayed the case pending the results of arbitration.\n- The plaintiff in the second case voluntarily dismissed her claims.\n- Facebook announced it would pay $550 million to settle a proposed class action.\n- Facebook increased the settlement amount to $650 million after a judge criticized the initial deal.\n- A federal judge granted preliminary approval to the $650 million settlement in late July.\n- Facebook published a California Privacy notice for users in the state on January 1, 2020.\n- Instagram displayed an in-app notification in November 2020 informing users that its terms of use had been updated and allowing users to view the revised terms or dismiss the notice.\n- Scott Morrison walked back his incorrect observation that there was no slavery in Australia.\n- Scott Morrison acknowledged that \"all sorts of hideous practices\" have taken place during Australia's history.\n- Scott Morrison said his comments were not intended to give offence, said he deeply regretted that, and apologised for those comments.\n- Scott Morrison stated that historical issues have been acknowledged and said they need to be addressed.\n- Scott Morrison pledged that he will continue to be heavily invested in addressing these issues.\n- After the national cabinet meeting, Scott Morrison urged people not to attend protests this weekend, citing medical advice that doing so was unsafe.\n- Scott Morrison encouraged people to look for other avenues to express their concerns.\n- Scott Morrison rejected the proposal to remove jobseeker payments from people who breached social distancing guidelines, saying \"We won't do that.\"\n- Some employees had their stock holdings reduced as a disciplinary measure.\n- A third-party independent investigation was conducted into the misconduct.\n- A sales director was fired for violating company policy following the investigation.\n- Verkada's CEO sent an email to all employees defending the company and confirming that disciplinary action ranging from financial penalties up to termination has been taken.\n- Verkada stated in a public response to IPVM that it takes its policies seriously and that there have been and will continue to be repercussions for anyone who violates them.\n- Verkada announced it is providing coaching for managers.\n- Verkada instituted mandatory sexual harassment training for employees.\n- Verkada announced it is expanding the human resources team.\n- Dervilla Lannon was promoted to Vice President of Human Resources.\n- Verkada imposed financial penalties on relevant employees as part of disciplinary actions.\n- Verkada invited prospective employees and candidates to connect directly with the leadership team as part of its public response.\n- An Epic spokesperson publicly disputed the study's conclusions about the performance of its sepsis warning system.\n- Epic cited a conference abstract from Prisma Health that reported a 4 percent reduction in mortality to defend its sepsis warning system.\n- Epic argued that the Michigan study set a low threshold for sepsis alerts, which it said would increase false positives.\n- Epic recently made it easier for health care providers and other companies to integrate their own prediction models with Epic\u2019s electronic health record system to encourage more transparency and competition.\n- Singh and other researchers are working to define standardized methods to describe and compare the performance of health algorithms.\n- Some Democratic senators asked federal regulators to investigate bias in health algorithms.\n- The Food and Drug Administration issued recent guidance about machine learning models in health care.\n- A Microsoft representative publicly stated that the company had applied for many patents and that the patent application does not necessarily indicate the described technology will be implemented in a product.\n- The Trades Union Congress released a report into the use of technology in the workplace.\n- The Trades Union Congress advocated for more worker consultation and transparency over when technologies like facial recognition and speech recognition are used and how they are being used to make decisions about people at work.\n- Sweden\u2019s data protection authority IMY fined the Swedish Police Authority \u20ac250,000 for unlawfully using Clearview AI.\n- The IMY ordered the Police Authority to train and educate its employees further to avoid any future breaches of data protection rules when processing personal data.\n- The IMY ordered the Police Authority to inform people whose privacy had been breached when confidentiality rules allow.\n- The IMY ordered the police to ensure Clearview AI deletes the data it holds on those individuals by 15 September 2021.\n- The Utah state government suspended the Live Time surveillance software last year.\n- The Utah State Auditor's office conducted an audit of Banjo.\n- Auditors conducted interviews with several public safety answering points as part of the investigation.\n- Utah State Auditor John Dougall sent a March 26 letter to state Attorney General Sean Reyes detailing the audit's findings.\n- The auditor's correspondence recommended limiting the sharing of sensitive data.\n- The auditor's correspondence recommended minimizing the collection of sensitive data.\n- The auditor's correspondence recommended validating technology claims through independent review.\n- The auditor's correspondence recommended vetting key vendor personnel through more rigorous background checks.\n- Guo sued Hangzhou Safari Park for breach of contract and violation of consumer rights.\n- The court ordered Hangzhou Safari Park to delete Guo Bing's facial data.\n- The court ordered Hangzhou Safari Park to pay Guo Bing just over 1,000 yuan in compensation.\n- Guo Bing appealed the court's first verdict.\n- On April 9, the court upheld the original verdict.\n- The court additionally ordered the park to remove Guo Bing's fingerprints from its records.\n- Guo Bing said he planned to appeal the court's ruling again.\n- The park upgraded its system so that staff no longer use phones to scan customers' faces.\n- A park staff member indicated that visitors could register without having their faces scanned.\n- China's central government passed a new Civil Code that strengthens regulations on the collection of facial data.\n- China is considering a draft law on personal information protection.\n- China's first national standards for using facial data were placed midway through a public consultation process.\n- Prosecutors in Jiangmen started a public interest litigation against local residential compounds that had collected residents' facial data without properly informing them.\n- State broadcaster China Central Television devoted large portions of its '315 Evening Gala' to expose companies that use in-store facial recognition cameras to collect customers' data without consent.\n- Those CCTV exposures led to a slew of litigation against the businesses identified.\n- A real estate agent in Guangxi was arrested on suspicion of stealing over 10 million yuan by unlocking homeowners' accounts after scanning their faces.\n- Prosecutors in many places quickly took action following CCTV's '315' exposures.\n- Uber deactivated drivers' accounts only after manual reviews by its specialist team.\n- Uber provided requested personal data and information that individuals were entitled to under GDPR.\n- Uber stated it would give explanations when it could not provide certain data, such as when the data did not exist or disclosure would infringe another person's rights under GDPR.\n- Uber told Transport for London that it could not provide additional requested details because doing so would compromise Uber's security.\n- Uber reported the terminated driver to Transport for London.\n- Transport for London wrote to the driver asking him to answer the allegations in writing.\n- Transport for London dropped the matter and did not revoke the driver's licence after he explained the situation.\n- The App Drivers & Couriers Union brought a legal challenge in the Netherlands seeking to overrule the algorithm that they say caused drivers to be fired.\n- Privacy lawyer Anton Ekker represented the British former Uber drivers in the legal challenge.\n- Anton Ekker intended to seek a ruling from the Dutch courts which, if successful, would enable a class action lawsuit against Uber.\n- Lyft said it would review the full results of the study when they are published to help continue prioritising equity in its technology.\n- The Australian Competition & Consumer Commission (ACCC) brought a court case against Trivago.\n- The ACCC investigated Trivago's practices.\n- The Federal Court of Australia dismissed Trivago's appeal.\n- The matter will return to the primary judge for consideration of the orders sought by the ACCC.\n- The ACCC is seeking declarations against Trivago.\n- The ACCC is seeking injunctions against Trivago.\n- The ACCC is seeking penalties against Trivago.\n- The ACCC is seeking costs against Trivago.\n- Tourism Accommodation Australia brought the matter to the attention of the ACCC.\n- Tourism Accommodation Australia worked on behalf of its members for several years to reform booking websites like Trivago.\n- The National Transportation Safety Board released a preliminary report finding that Autopilot was engaged and the driver's hands were off the wheel before the crash.\n- The NTSB analyzed vehicle data and videos as part of its preliminary findings.\n- The NTSB said it will conduct a full investigation that will take a year or more and will include an official determination of probable causes and specific recommendations for regulators, Tesla, and the auto industry.\n- The National Highway Traffic Safety Administration opened an investigation into the March 1 crash and said it is carefully evaluating all available data and will share findings upon conclusion of its investigation.\n- Tesla shared vehicle data logs with the NTSB shortly after the March 1 crash.\n- Tesla issued an email statement expressing condolences and asserting that drivers supported by Autopilot are safer when used properly.\n- Researchers from Tencent\u2019s Keen Security Lab reverse-engineered several of Tesla\u2019s automated processes to analyze how they reacted when environmental variables changed.\n- The researchers published a detailed 37-page report describing the attack, their experiments, and their findings.\n- Kneron conducted experiments to learn about the facial recognition technology's limitations.\n- Kneron is developing an \"Edge AI\" facial recognition tool that performs recognition entirely on devices rather than through cloud-based services.\n- Amazon decommissioned its hiring AI after it found the system was biased against female applicants.\n- China\u2019s Ministry of Industry and Information Technology issued a directive in November 2018 compelling internet companies to cooperate with authorities to reduce cold calling.\n- China Central Television ran an expos\u00e9 on March 15 revealing 11 voice-bot manufacturers that either sold customer phone-number databases or sold random phone-number generators capable of evading call blockers.\n- Guangzhou-based Southern Weekly reported in January that many companies that buy voice-bot services combine them with web-scraping tools that illegally gather phone numbers and other personal data without the owner\u2019s consent.\n- iFlytek began self-regulating its voice-bot sales in November 2018.\n- iFlytek planned to terminate relationships with all clients who used its bots for cold calling.\n- Wan Xi Intelligence said it would not sell its voice-bot technology to peer-to-peer lenders, suspicious health-product providers, and cosmetic-surgery companies.\n- Wan Xi Intelligence limited its bots\u2019 working hours from 9 a.m. to 8 p.m.\n- The digital strategy advisory panel released preliminary commentary identifying areas that need improvement in Sidewalk Labs' Quayside plan.\n- Sidewalk Labs stated it intends to release more details in October on the digital innovations it hopes to implement at Quayside.\n- Sidewalk Labs stated it is producing a Digital Innovation Appendix that will include a comprehensive list of the technology to be deployed at Quayside, how it would support Toronto's technology ecosystem, and its research work on data governance.\n- The notjordanpeterson.com website posted an announcement stating that, out of respect for Dr. Peterson, the functionality of the site will be disabled for the time being.\n- The CNIL warned that plans to trial facial recognition tools at high schools do not comply with privacy laws and cannot legally be implemented.\n- The head of the CNIL wrote to the regional authority in charge of approving the trials stating the installation cannot be implemented legally.\n- The CNIL published a statement confirming its position on the trials.\n- The Swedish regulator fined a high school over a similar facial recognition scheme.\n- The Swedish Data Protection Authority fined the Skelleftea municipality 200,000 Swedish Krona for unlawfully processing sensitive biometric data.\n- Swedish authorities opened an investigation into the school's facial-recognition trial after reading media reports.\n- The Education Minister ordered the Education Department to immediately assess the facial recognition software and report back to him.\n- He asked the Education Department to contact every state school to remind them they must undertake a privacy impact assessment before considering the software.\n- William Ruthven Secondary College would no longer go ahead with the trial because the school had not done a full privacy impact assessment.\n- LoopLearn said it was open to further conversations to ensure that all stakeholders were comfortable with the LoopLearn technology.\n- The school said it would walk away from the technology if the trial proved unsuccessful.\n- NeurIPS introduced a requirement that papers discuss the potential broader impact of their work, both positive and negative.\n- NeurIPS implemented a second layer in the review process enabling any reviewer or area chair to flag a paper for additional ethical review.\n- NeurIPS created panels of three reviewers with expertise in weighing social impact to review papers flagged for ethical concerns.\n- In 2020, NeurIPS reviewers flagged a few dozen submissions for ethical review.\n- In 2020, four technically strong papers were rejected at NeurIPS based on feedback from ethical reviewers.\n- The Association for Computational Linguistics asked reviewers to consider the ethical impacts of submitted research.\n- The Association for the Advancement of Artificial Intelligence decided to require reviewers to consider the ethical impacts of submissions.\n- Eric Horvitz helped add language to the final version of the comment-generation paper acknowledging that the techniques could be used at scale for political manipulation or persuasion.\n- The authors of the comment-generation paper did not release the paper's code.\n- OpenAI withheld release (censored) of its own text-synthesis software because it could theoretically be used to generate fake news or comments.\n- Joe Redmon announced that he had stopped doing computer-vision research altogether because of concerns about its military and surveillance applications.\n- One researcher publicly apologized on Twitter and retracted their initial judgment about a paper after its main idea was explained to them.\n- Another researcher retracted their initial judgment in an email to the article's author after the paper's main idea was clarified.\n- At a NeurIPS town-hall meeting, the conference treasurer said the board would bring up the question of a policy for excluding particular sponsors at the next board meeting.\n- Partnership on AI organized an online workshop focused on encouraging more responsible research and discussed alternative release strategies such as staged release, sharing with specific audiences, or releasing work only after risks have been mitigated.\n- USENIX Security Symposium and the IEEE Symposium on Security and Privacy require authors, in their calls for papers, to discuss in detail the steps they have taken or plan to take to address any vulnerabilities they have exposed.\n- The ACM SIGCHI Special Interest Group launched a research-ethics committee that offers to review papers submitted to SIGCHI conferences at the request of program chairs.\n- A group of researchers published an ACM blog post recommending that peer reviewers require papers and proposals to rigorously consider all reasonable broader impacts and to discuss means for mitigation when negatives appear to outweigh positives.\n- State Education Department employees plan to meet with Lockport City School officials to discuss the facial recognition system being tested.\n- The district said it will not use the facial recognition software while it checks other components of the system.\n- The district's initial implementation will include adjusting cameras mounted throughout the buildings.\n- The district's initial implementation will include training staff members who will monitor the cameras from a room in the high school.\n- Tesla agreed to settle the Maldonado wrongful-death lawsuit stemming from the 2019 crash.\n- Tesla and the plaintiffs filed a request asking the court to approve their mutually agreed-upon settlement.\n- Tesla appealed the Florida jury verdict that ordered the company to pay $243 million in damages.\n- Homes and Community Renewal provided residents 20 days to respond to notices about the facial recognition application.\n- Homes and Community Renewal placed the application under review and stated it was committed to providing due process for tenants and owners.\n- Residents submitted responses to HCR opposing the facial recognition proposal.\n- The Atlantic Plaza Towers Tenant Association unanimously voted against the facial recognition proposal.\n- Nelson Management Group sent a security point-person to meet with residents in February.\n- Nelson Management Group reiterated that information would never be shared with a third party without a court order.\n- Councilwoman Alicka Ampry-Samuel wrote to HCR requesting that the agency take the time to thoroughly weigh residents' concerns.\n- Brooklyn Legal Services sent a memo to HCR signed by about 400 residents highlighting research on facial recognition accuracy and raising questions about potential misuse.\n- The legal team reminded building staff that tenants have the right to organize and meet in the building.\n- The Home Office allows customers to override the automated photo check and submit the photo as part of their application in the vast majority of cases.\n- The Home Office said it will continue working to improve the digital photograph upload process for all customers.\n- Scotland Yard granted University of Essex academics access to six deployments of the facial recognition system between June 2018 and February 2019.\n- The use of facial recognition by South Wales police is currently under judicial review.\n- Tony Porter, the surveillance camera commissioner, intervened to stop Greater Manchester police from using facial recognition at the Trafford shopping centre.\n- The Home Office said it is reviewing ways to simplify and extend governance and oversight of biometrics.\n- The Information Commissioner's Office issued a report and an Opinion expressing serious concerns about South Wales Police's use of facial recognition technology.\n- The Information Commissioner's Office called for more research to eliminate bias in facial recognition algorithms, particularly regarding ethnicity.\n- The Information Commissioner's Office called for police forces to be compelled to show that facial recognition is strictly necessary, balanced, and effective in each deployment.\n- South Wales Police deleted all facial recognition records at the end of each deployment.\n- South Wales Police said it will carefully consider the ICO's Report and Opinion.\n- South Wales Police said it will provide a comprehensive response to the ICO's conclusions and key findings after appraising them.\n- South Wales Police said it will transparently engage with stakeholders to ensure proper understanding of the technology and its use for law enforcement purposes.\n- The police are not advertising the robot's alert features because those features are not yet connected.\n- The department is developing protocols to fully adopt and integrate the robot program.\n- The department plans to connect the robot's alert button so that calls will go directly to the department\u2019s dispatch center.\n- The department said it will post information and signage describing what the robot does and why it is there once the machine's features are properly connected.\n- Police contacted Knightscope to review the robot's footage after the robot was vandalized.\n- Officers used HP RoboCop\u2019s footage to track down the suspects involved in the robot tipping incident.\n- YouTube said it is investigating the error in its automated enforcement systems.\n- YouTube encouraged users to report suspected issues so the company can troubleshoot errors and make product improvements.\n- China denied reports of mass detention in Xinjiang and said it was operating \"educational training centres\" as part of efforts to combat Islamic extremism.\n- Thermo Fisher Scientific announced it would no longer sell or service genetic sequencers in the Xinjiang region following complaints they were used for surveillance.\n- The agreement between CloudWalk Technology and the Zimbabwean government is currently on hold until Zimbabwe\u2019s elections on July 30.\n- The City of Johannesburg has taken note of public concerns and will seek to keep the public informed of developments regarding the Vumacam rollout.\n- Vumacam has sought advice from various entities to ensure it would be fully compliant with the Protection of Personal Information Act.\n- Right2Know lodged a complaint with the Private Security Industry Regulatory Authority (PSIRA) about Vumacam's operations.\n- Right2Know is pursuing the City of Johannesburg to obtain the paperwork of the agreement with Vumacam.\n- Vumacam requires security companies to enter into contractual agreements to access camera feeds and prohibits them from downloading footage.\n- Security companies must approach Vumacam with official SAPS documentation, such as a case number, to obtain footage from the system.\n- Vumacam stores collected data in a secure off-site data centre with restricted access.\n- Activists and officials organised a public hearing where affected people recorded their grievances in the presence of food and civil supplies department officials and district administration representatives.\n- Officials at the hearing assured complainants that their problems would be looked into.\n- The Right to Food Campaign, Jharkhand, and the MNREGA Sahayata Kendra, Manika, conducted a door-to-door survey of cancelled ration cards.\n- The District Food Supply Officer asked beneficiaries to link their mobile numbers to their Aadhaar so authentication could be provided via a one-time password.\n- The district administration began implementing the state instruction to allow continued access to grain for low-income households facing Aadhaar-linking problems by noting their names in a separate register.\n- The Latehar administration announced it would organise a camp on December 18-20 to ensure accurate Aadhaar enrolment and linking.\n- Kaiser Permanente officials issued a written response calling the situation highly unusual and saying they \"regret falling short\" of the patient's expectations.\n- The hospital publicly defended its use of telemedicine.\n- The hospital stated that its policy is to have a nurse or doctor in the room during remote consultations.\n- The hospital said the evening video tele-visit was a follow-up to earlier physician visits and did not replace previous conversations or the delivery of the initial diagnosis.\n- Hospital officials stated that the technology does not replace in-person conversations with the patient and loved ones.\n- Researchers are working with Optum to develop a fix for the biased algorithm.\n- Researchers tweaked the algorithm to predict patients' future health conditions instead of using cost-based labels, which reduced biases by 84%.\n- The company replicated the analysis on a different dataset to verify the extent of the bias and found that black patients had 48,772 more active chronic conditions than white patients ranked at the same level.\n- The whistleblower brought the Nightingale Project story to public attention.\n- Several members of Congress publicly expressed concerns about the deal.\n- A federal inquiry was launched to determine whether HIPAA protections were fully followed.\n- Facebook did not remove the video.\n- Facebook allowed third-party fact-checkers to determine whether the video was fake.\n- Facebook made the video less visible in users' feeds rather than taking it down.\n- The original video posted by a Weibo user named Brother Face-Swapping was removed.\n- Beijing News published a video featuring a Chinese lawyer who said deepfake videos could potentially infringe on a person's right to their image and their reputation under Chinese laws.\n- Amazon published a blog about a subscription service designed to help parents manage their children's use of Alexa.\n- Amazon referred reporters to that blog when asked about the recordings.\n- Parents can review and delete their children's voice recordings via an app or Amazon's website.\n- Users can delete stored utterances via the Amazon app or website.\n- Users can ask Alexa via voice command to delete the last recording or the last day's recordings.\n- Parents can contact Amazon and request deletion of their child's voice profile and any personal information associated with it.\n- Amazon verifies parental consent for children under 13 by requiring an actual credit card number.\n- Amazon does not retain a child's data if parental consent is not verified.\n- Amazon limits human review to a fraction of 1% of utterances.\n- Amazon ensures staff who review recordings are not shown the user's name or address.\n- Malaysiakini is withholding the name of the minister pending his response to their questions.\n- Haziq Abdullah Abdul Aziz urged the Malaysian Anti-Corruption Commission (MACC) to investigate the minister for alleged corruption.\n- Malaysiakini is attempting to contact Muhammad Haziq for comment.\n- A police report on the sex clip featuring the minister was forwarded to Bukit Aman.\n- Latheefa confirmed that a deputy is leading a probe into the PKR minister.\n- PKR Youth pressed the deputy minister to suspend the aide over the sex video.\n- PKR leaders defended the minister over the alleged sex video.\n- PKR leaders claimed the accuser was close to the opposition.\n- PKR planned to gather at the Selangor Menteri Besar's residence for prayers rejecting the sex video 'slander'.\n- PAS called for Haziq to face the syariah court over the sex video.\n- Anwar said he had spoken to Azmin at length regarding the matter.\n- Anwar left the decision about Haziq's fate to Shamsul.\n- Workers are ordered to remake pizzas that do not match the order or internal quality standards.\n- A Domino\u2019s spokesperson told iTnews that Dom Pizza Checker is a tool used to train team members rather than to punish those who make mistakes.\n- Dom Pizza Checker will be incorporated into a 'scorecard' bonus system for franchises.\n- Dom Pizza Checker will be used to identify underperforming stores.\n- The supermarket shut off its facial recognition system under regulatory pressure.\n- The Netherlands\u2019 Data Protection Authority warned the store owner not to use the biometric capability on cameras at its entrance.\n- The regulator published its account of the situation.\n- The store put notices at its entrance to inform customers.\n- The store stated that it stored only images of people who had been caught stealing.\n- Images of people not subject to shopping bans were erased within seconds.\n- Two plaintiffs filed a lawsuit against Jacksons Food Stores in the Circuit Court of the State of Oregon, Multnomah County Division, on Dec. 1, 2022, alleging violation of Portland's ordinance.\n- On Jan. 3, the lawsuit was removed to the U.S. District Court District of Oregon, Portland Division.\n- 7-Eleven disabled the facial recognition technology it had used in 700 of its Australia stores.\n- Walmart said it made significant improvements to its Everseen system, which resulted in fewer alerts overall.\n- Walmart stated that it assesses its technology regularly.\n- A corporate Walmart manager asked whether the Everseen system should be turned off to protect customers and workers.\n- Walmart said it regularly cleans self-checkout kiosks.\n- Walmart said it provides employees with protective equipment.\n- Walmart said workers are given handheld devices that allow them to handle most interventions from a distance.\n- Walmart's Intelligent Retail Lab created its own anti-theft software and is testing it in roughly 50 stores.\n- Walmart said it regularly tests internally built AI capabilities in a small number of stores.\n- NCR Corporation said it is helping retailers modify equipment to be as touchless as possible, for example by reconfiguring machines so customers can insert a card without needing to press the credit card payment option.\n- Walmart offered customers alternatives such as delivery, pickup, touchless payment at the register, and shopping online to reduce in-store contact.\n- The fake papers have been pulled from the journals that originally published them.\n- Springer is investigating the fraud related to the fake papers.\n- Springer is taking the papers down as quickly as possible.\n- Springer will put up a placeholder notice once the papers have been removed.\n- Cyril Labb\u00e9 published a paper describing an automatic method to detect fake papers.\n- Cyril Labb\u00e9 built a website that detects whether papers are computer-generated.\n- Labb\u00e9's tools detect SCIgen-generated papers as well as duplicate and plagiarized content.\n- Facebook paused human review of audio more than a week ago.\n- Apple halted its program that allowed employees to listen to a small percentage of Siri voice requests.\n- Google stopped human review of Google Assistant queries in Europe.\n- Amazon rolled out tools that let users opt out of having their questions analyzed by humans.\n- The Irish Data Protection Commission sought detailed information from Facebook about the audio processing and how Facebook believes that processing complies with GDPR obligations.\n- Facebook took down the alleged terrorist's Facebook and Instagram accounts.\n- Facebook removed the video of the attack.\n- Facebook used artificial intelligence to proactively find and prevent related videos from being posted.\n- Facebook committed to reviewing what happened.\n- Facebook worked closely with the New Zealand Police to support their response.\n- Facebook is exploring restrictions on who can use Facebook Live based on factors such as prior Community Standard violations.\n- Facebook is investing in research to build technology to quickly identify edited versions of violent videos and images and prevent people from re-sharing them.\n- Facebook made changes to its review process to improve response time to videos like this in the future.\n- Facebook designated both shootings as terror attacks, making any praise, support, or representation of the events a violation of its Community Standards.\n- Facebook used existing artificial intelligence tools to identify and remove a range of hate groups in Australia and New Zealand, including the Lads Society, the United Patriots Front, the Antipodean Resistance, and National Front New Zealand.\n- Facebook banned those identified hate groups from its services.\n- Facebook committed to remove praise and support of those hate groups when it becomes aware of such content.\n- Facebook provided support to four local well-being and mental health organizations to raise awareness of their services within New Zealand.\n- Facebook is working with its existing youth partner to co-design additional education around peer support and resilience.\n- AnyVision apologized for the CEO's outburst to NBC News.\n- AnyVision revised its position in subsequent written responses to NBC News' questions and allegations.\n- AnyVision affirmatively denied that it was involved in any project beyond the use of its software at West Bank border checkpoints.\n- AnyVision said it reviewed all of its customers and use cases for compliance with Microsoft's ethical standards and found nothing in violation.\n- AnyVision said all of its installations have been examined and confirmed against Microsoft's ethical principles and its own internal rigorous approval process.\n- Microsoft secured audit rights to ensure AnyVision's compliance with its facial recognition principles.\n- Microsoft proceeded with a third-party audit of AnyVision.\n- Microsoft asked for a robust board-level review and compliance process at AnyVision.\n- AnyVision agreed to both the third-party audit and the board-level review and compliance process.\n- Microsoft said it would end its relationship with AnyVision if it discovered any violation of its facial recognition principles.\n- Fidji Simo published an open letter to Instacart delivery workers offering change and expressing intent to be a thoughtful and open partner.\n- She invited workers to email her suggestions on improving working conditions.\n- Simo and her team said they would read every note and she would respond to as many as she can.\n- Simo has been consistently reading and responding to emails and has conducted a number of one-on-one conversations with workers.\n- Instacart removed the \"none\" option in the customer tip settings, requiring customers to manually change their tip to $0 if desired.\n- Instacart added a customer tip default setting allowing customers to save their default tip based on their last order.\n- Instacart pledged to send workers personal protective equipment (PPE) kits.\n- Instacart confirmed 14 days of sick leave pay for workers diagnosed with COVID-19.\n- Founder and former CEO Apoorva Mehta issued an apology related to subsidizing wages with customer tips.\n- Instacart ended the practice of subsidizing workers' wages with customer tips.\n- The class-action case over tips was resolved as part of a class action settlement.\n- Instacart raised extremely low per-order payments that had been as low as $1.50 after workers protested.\n- Instacart offers Shopper Injury Protection which includes coverage for certain medical expenses, disability payments, and accidental death benefits.\n- Instacart allows workers to file claims directly with its insurance provider for Shopper Injury Protection.\n- The ad was traced back to a TikTok user known as @mikesmithtrainer.\n- TikTok removed the @mikesmithtrainer account after being alerted to the issue.\n- TikTok told Mashable that it removed the account for violating its \"harmful misinformation policy\".\n- Professor Andrew D. Huberman posted a statement on Twitter confirming that the comments attributed to Joe Rogan were fake.\n- The video was later removed from Twitter on copyright grounds.\n- Momo deleted the controversial clause from its end-user agreement that had stripped users of rights to their images.\n- Momo issued a public apology for the problematic end-user agreement.\n- Momo stated that its app would not store users' biometric information.\n- Momo stated that its app would not excessively collect user information.\n- WeChat banned users from uploading Zao videos via its platform, citing security risks.\n- Alipay publicly assured users that videos created in Zao cannot be used to defraud its Smile to Pay facial-recognition system.\n- Alibaba stated that it uses sophisticated anti-spoofing algorithms to prevent its facial-payment system from being fooled by still photographs or deepfake videos.\n- Alibaba stated that its system detects whether a presented image is a still, a video, or a software simulation before attempting face matching.\n- Momo clarified publicly that its deepfake videos were generated from single photos and asserted that such face-changing technology could not break facial payment security.\n- Microsoft disabled the Tay chatbot.\n- Microsoft kept Zo confined to the messaging app Kik and its mid-sized user base.\n- Microsoft corrected the errors in Zo's behaviour.\n- Microsoft said it has no plans to disable Zo.\n- Comments have been closed on the article due to the extensive number of off-topic and unrelated comments and conversations.\n- Amazon pointed CNN Business to its content guidelines page, stating that as a bookseller it provides a variety of viewpoints and reserves the right not to sell certain content.\n- Rep. Adam Schiff sent an open letter to Facebook and Google expressing concern that the companies are surfacing and recommending anti-vaccination content.\n- Facebook said it has taken steps to reduce the distribution of health-related misinformation on its platform.\n- Facebook said it is working with outside experts on additional changes to address health-related misinformation that it will announce soon.\n- YouTube said it is surfacing more authoritative content across the site for people searching vaccination-related topics.\n- YouTube said it has begun reducing recommendations of certain anti-vaccination videos.\n- YouTube said it is showing information panels with additional sources to help users fact-check vaccination information.\n- Pinterest blocked all vaccine searches from its platform in a temporary ban.\n- Amazon provides retraining to underperforming employees to get them up to standards.\n- Amazon places the bottom 5 percent of workers on a training plan.\n- Amazon offers an appeal system as part of the termination process.\n- Supervisors are able to override automated warnings and terminations generated by the productivity system.\n- Amazon produced and submitted termination data and related documents to the National Labor Relations Board as part of a labor dispute.\n- Amazon responded to the NLRB complaint by asserting the employee was fired for failing to reach productivity benchmarks.\n- Amazon said it is fixing an overly broad termination list error with the board.\n- A coalition of groups led by the Campaign for a Commercial Free Childhood and Georgetown University\u2019s Institute for Public Representation filed a formal complaint with the Federal Trade Commission alleging that Amazon violated COPPA.\n- The coalition asked the Federal Trade Commission to investigate whether the Echo Dot Kids Edition violates children's privacy laws.\n- The advocates captured on video an example demonstrating that a child's information persisted on the Echo Dot Kids Edition after deletion attempts.\n- Consumer Reports conducted tests on the Echo Dot Kids Edition and on regular Echo Dot/Alexa devices to check whether deleted conversations and transcripts were retained.\n- Amazon issued a public statement asserting that its Echo Dot Kids Edition is compliant with COPPA.\n- Amazon acknowledged there was a bug related to Echo devices retaining children\u2019s data.\n- Amazon fixed the bug that caused children\u2019s data to be retained after deletion.\n- Amazon began rolling out a pair of Alexa voice commands that allow users to delete their voice recordings without using the website.\n- Amazon said it had an ongoing effort to ensure transcripts do not remain in any of Alexa\u2019s other storage systems.\n- Amazon said that when customers manually delete voice recordings, it deletes the corresponding voice transcripts and Alexa\u2019s responses.\n- Ilya Sutskever publicly tweeted that he was 'surprised and saddened by all the bad faith criticism' of OpenAI's robotic manipulation result.\n- Gary Marcus posted a tweet stating that OpenAI had not changed its allegedly misleading blog post and attached a detailed analysis comparing what OpenAI said and implied with what they actually did.\n- Gary Marcus tweeted a defense of his criticism, writing 'It's not bad faith, it's facts,' and reaffirmed his long-standing stance against hype.\n- Zachary Lipton tweeted that the research is interesting while criticizing OpenAI's use of 'weapons-grade' press releases and elaborated his concerns.\n- SenseNets temporarily took its official website www.sensenets.com offline following reports about the data leak.\n- SenseNets has been conducting an internal investigation into the data leak.\n- The GDI Foundation warned SenseNets about the data exposure after it discovered the problem in July.\n- The exposed database was made inaccessible and placed behind a firewall as of Feb 14.\n- Temporarily disable any ad blockers, pop-up blockers, or script blockers you have enabled.\n- Add this site to the allowed list of any ad blockers, pop-up blockers, or script blockers you have enabled.\n- Verify that your browser supports JavaScript by visiting https://www.whatismybrowser.com/detect/is-javascript-enabled.\n- Ensure you are using the latest version of your web browser.\n- If you still need to be unlocked, email accessissues@news.com.au and provide the shown IP address, reference number, and the reason you require access.\n- The sites will now say if commissions they receive affect the results.\n- The companies will make it clearer how hotels are graded, including whether hotels paying the ranking sites more have received a higher position in the list.\n- The companies will not give a false impression of a hotel's popularity to rush customers into making a booking.\n- The companies will make clear when other customers are looking at the same hotel but are searching for different dates.\n- The companies have committed not to place sold-out hotels within search results to put pressure on people to book.\n- The companies will be clear about discounts and only promote deals that are actually available at that time.\n- The companies will show charges such as taxes, booking fees, or resort fees in the displayed price.\n- The Competition and Markets Authority has taken enforcement action to bring to an end misleading sales tactics, hidden charges and other practices in the online hotel booking market.\n- The Competition and Markets Authority will seek to make the rest of the sector follow the same rules as the six companies it named.\n- The Competition and Markets Authority said it will monitor the companies for compliance.\n- The companies have until 1 September to comply with the demands.\n- The Competition and Markets Authority warned that companies failing to comply by that date could be taken to court.\n- The NTSB recommended improving collision avoidance systems to include common obstacles such as traffic barriers.\n- The NTSB recommended evaluating Tesla's Autopilot to determine whether its ability to operate outside the intended operational design posed an unreasonable risk to safety.\n- The NTSB recommended taking steps to prevent automation complacency in drivers.\n- The NTSB recommended requiring all new passenger vehicles with semi-autonomous features to be equipped with a driver monitoring system that meets new standards.\n- The NTSB suggested smartphone manufacturers should develop a distracted driving lockout mechanism to disable driver-distracting functions when a vehicle is in motion while allowing device use in an emergency.\n- The NTSB urged Apple to implement a company policy that bans the non-emergency use of portable electronic devices while driving by all employees and contractors.\n- BBC News contacted Tesla for its response to the report.\n- Yavapai County Attorney Sheila Polk determined there was no basis for criminal liability for the Uber corporation in the matter.\n- Yavapai County handed the case back to Maricopa County.\n- Maricopa County will determine whether Uber's backup safety driver, Rafaela Vasquez, should be charged with a crime.\n- Maricopa County temporarily handed prosecution of the case to Yavapai County due to a potential conflict of interest.\n- Yavapai County suggested police find an expert to determine what an actual person would have been likely to see from the driver's seat.\n- The National Transportation Safety Board (NTSB) is investigating the crash.\n- The National Highway Traffic Safety Administration (NHTSA) is investigating the crash.\n- Uber halted its self-driving tests entirely after the fatal incident.\n- Uber restarted self-driving tests in Pittsburgh in an extremely limited way in December.\n- Uber reached an undisclosed settlement with Elaine Herzberg's family in March.\n- Elaine Herzberg's family sued the city of Tempe for $10 million, claiming a brick pathway encouraged her to cross the road at the site of the crash.\n- San Francisco police pulled over the self-driving Cruise vehicle.\n- An officer issued a regular ticket citing the vehicle for not yielding to a pedestrian.\n- Cruise issued a public statement asserting its data shows the pedestrian was far enough away and disputing the violation.\n- Cruise stated that the human test driver did everything right but is responsible for the citation.\n- Samathur Li Kin-kan sued Tyndaris Investments for allegedly exaggerating the capabilities of the AI program.\n- Tyndaris denied the charges.\n- The trial was scheduled to begin in London next April.\n- Facebook shut down two of its AI programs when they started communicating in a language incomprehensible to humans.\n- UCLA abandoned its plans to adopt facial recognition technology.\n- UCLA Administrative Vice Chancellor Michael Beck issued a statement saying the university determined the potential benefits of facial recognition were limited and were vastly outweighed by the concerns of the campus community.\n- Fight for the Future used Amazon\u2019s Rekognition to scan over 400 public photos of UCLA athletes and faculty and compared them to a mugshot database to highlight the risks of facial recognition.\n- The Daily Bruin published an editorial arguing that implementing the facial recognition system would present a major breach of students\u2019 privacy and create a more hostile campus environment.\n- A member of the community extinguished the flames using a nearby fire extinguisher.\n- The Berkeley Fire Department secured the scene.\n- The Berkeley Fire Department doused the robot with foam to ensure there was no risk of re-ignition.\n- Students set up a candlelight vigil for the fallen robot.\n- KiwiBot pulled robots from service following the incident.\n- KiwiBot delivered orders in progress by hand.\n- KiwiBot installed custom software to monitor the battery's state.\n- Local police upgraded their facial-recognition technology to avoid misidentifying advertisements as real people in the future.\n- Global Witness pulled the eight test ads before they were posted or paid for.\n- Meta invested in improving its safety and security controls in Myanmar.\n- Meta banned military accounts associated with the Tatmadaw after the 2021 coup.\n- Meta built a dedicated team of Burmese speakers to moderate content.\n- Meta disrupted networks manipulating public debate.\n- Meta took action on harmful misinformation.\n- Meta invested in Burmese-language technology to reduce the prevalence of violating content.\n- Meta commissioned and released an independent Human Rights Impact Assessment in 2018.\n- Facebook planned to hire dozens of Burmese speakers to moderate content.\n- Facebook said it would work with civil society groups to identify hate figures and develop new technologies to combat hate speech.\n- Rohingya refugees sued Facebook for more than $150 billion, accusing it of failing to stop hate speech that incited violence.\n- Rohingya youth groups filed a complaint with the Organization for Economic Cooperation and Development in Ireland calling for Facebook to provide remediation programs in the refugee camps.\n- Police used the sunglasses at a busy train station in Zhengzhou to identify suspected criminals.\n- Police apprehended seven suspects with the help of the facial-recognition sunglasses.\n- Police identified 26 people who were using fake IDs using the facial-recognition sunglasses.\n- Janey Webb called Uber support after her account was deactivated.\n- Webb drove two hours to Uber's only in-person support center, the Greenlight Hub, and explained her gender transition.\n- Uber staff at the Greenlight Hub told Webb that her deactivation was a mistake.\n- Uber confirmed that the reported deactivation incident did occur.\n- Uber said the photo-verification issue can often be resolved over the phone or through the app instead of requiring an in-person visit to a support center.\n- Uber rolled out a feature in April that allows employees to specify their pronouns in the company's internal directory.\n- Lindsay drove to a Greenlight Hub for further action after being suspended for photo inconsistencies.\n- Facebook updated its app to include more gender identity and pronoun options for users.\n- Tinder updated its app to include more gender identity and pronoun options for users.\n- Police use Intellifusion's AI and facial recognition technology to publicly name and shame jaywalkers by displaying their faces on large LED screens at intersections.\n- Intellifusion is collaborating with local mobile phone carriers and social media platforms (such as WeChat and Sina Weibo) to develop a system that will send personal instant messages to offenders immediately after they violate the rules, notifying them of the violation and the fine.\n- Legislators should examine the inputs used by lending algorithms.\n- Legislators should ensure that the results of lending algorithms are not discriminatory.\n- Consumers should shop around with one or more lenders to obtain the best rates.\n- Consumers should ask other lenders what rates they would offer.\n- The author contacted the Advertising Standards Authority about Babylon's advertising claims.\n- The Advertising Standards Authority told Babylon to stop saying it had the 'world's best doctors' and the 'world's most advanced AI'.\n- Babylon removed its claim that the app gave safe advice 100% of the time.\n- The local NHS conducted its own validation of the Babylon triage service against recorded serious incidents and found the service to be completely safe.\n- Babylon's partnership with NHS 111 was set up as an independent pilot programme to evaluate the technology.\n- Babylon changed its Terms and Conditions to acknowledge that its chatbot is a medical device.\n- Babylon withdrew its claim that the chatbot was \"100% safe.\"\n- The Advertising Standards Authority intervened, prompting the withdrawal of Babylon's \"100% safe\" claim.\n- Babylon tweaked the chatbot to place less emphasis on diagnosis and more emphasis on triage outcomes.\n- Babylon implemented specific fixes to individual triage assessments, including changing chest pain handling to advise immediate attendance at A&E.\n- Babylon undertook and passed an extensive audit of its Quality Management System by a third-party Notified Body.\n- Babylon passed three other independent audits of its Quality Management System in the last 2.5 years.\n- Babylon took steps towards compliance with the European Medical Device Regulations to move its symptom checker from a Class I device to a Class IIa device.\n- The MHRA sent a letter to Dr. David Watkins acknowledging and validating his concerns and thanking him for raising them.\n- The MHRA implemented tweaks to the regulatory regime, including a partial lifting of confidentiality requirements last year.\n- The U.K. is developing a new regulatory framework for medical devices under the Medicines and Medical Devices Act 2021.\n- The Medicines and Medical Devices Act 2021 gives the MHRA greater powers to undertake regulatory activities with increased transparency and to share information in the interests of patient safety.\n- Colleagues first took the seriously wounded man to a local hospital.\n- He was transferred from the local hospital to Xiangya Hospital in Changsha for further treatment.\n- Medical staff sterilised his wounds while he leaned on more than ten doctors and nurses.\n- An emergency operation was carried out by experts from the emergency room, cardiothoracic surgery, and hand microsurgery departments.\n- Surgeons removed all ten metal spikes from the patient's body through emergency surgery.\n- The reporter contacted the management companies and/or publicists representing the affected actors to inform them of the fake videos.\n- The story was updated with a correction clarifying that deepfakes' algorithm is similar to Nvidia researchers' work but there is no evidence it is an application of their research.\n- She wrote a clarification on her real Twitter account stating the tweets were fake and asking people not to fall for them.\n- She deleted her Facebook account to stop the harassment she was receiving there.\n- She contacted a high-profile feminist lawyer who agreed to take on her case.\n- She went to the police station to file a complaint and the police eventually registered the report.\n- She threatened to write about the police on social media if they did not register her complaint.\n- Her lawyer told the police they would go to the media, which resulted in the police filing the report.\n- She gave her statement to a magistrate and provided screenshots and the messages she had received as evidence.\n- She was sent to the hospital and a doctor gave her medicine for heart palpitations and anxiety.\n- Her brother flew in from Mumbai to see her.\n- Sixteen United Nations special rapporteurs wrote to the Indian government asking them to protect her.\n- Cadillac Fairview suspended the use of facial recognition technology in two Calgary shopping malls pending an investigation.\n- Cadillac Fairview paused the use of cameras embedded inside mall directories.\n- Cadillac Fairview paused the facial recognition practice at Chinook Centre.\n- Cadillac Fairview paused the facial recognition practice at Market Mall.\n- The federal privacy commissioner said it will investigate Cadillac Fairview's practices and whether they are legal.\n- Alberta's provincial privacy commissioner announced it is investigating Cadillac Fairview's use of facial recognition technology.\n- They reassigned Fabio to the sausage section and asked him to hand out sausage samples to keep him out of the way.\n- The store owners decided not to keep Fabio employed after his trial.\n- The store owner informed Fabio of the decision to let him go.\n- They packed up the robot when removing him from the store.\n- The manager promised to order a new key card immediately.\n- A security guard printed a temporary badge for me that expired at 7pm each day.\n- A security guard manually overrode the turnstile by pressing a button under his desk to let me in.\n- A security guard used his own card to let me into the parking structure.\n- The manager created a JIRA ticket for the support team to re-enable my account.\n- The director called support and ordered them to immediately restore everything back to normal.\n- I hacked my way into the server to restart it.\n- I debugged the server.\n- I reactivated all the services on the server.\n- I reprocessed the missing data.\n- The manager came down to escort me into the building when my card could not be used.\n- The director gave me the green light to come to work the next day.\n- The recruiter called to tell me I could come back to work.\n- I was rehired as a new employee.\n- I filled out rehiring paperwork.\n- I set up direct deposit.\n- I waited for FedEx to ship a new key card.\n- My case was escalated repeatedly to higher-level managers over the next three weeks.\n- Amazon publicly denied that it eavesdrops on customers' conversations to target advertising.\n- Amazon said it did not use customers' voice recordings for targeted advertising.\n- Amazon stated that it had built multiple layers of privacy into its Echo devices.\n- Facebook CEO Mark Zuckerberg publicly denied that his firm listens to users' microphones to serve targeted ads.\n- An employee told the couple to unplug their Alexa devices immediately.\n- Amazon examined device logs and reported that the sequence of events was sourced from those logs.\n- Amazon issued public statements to Gizmodo and KIRO-7 confirming the incident and characterizing it as an \"extremely rare occurrence.\"\n- Amazon stated that it is evaluating options to make this case even less likely.\n- The customer cancelled the cat food order placed by their Echo Dot.\n- Amazon marks advertisements so that Alexa is not triggered by them.\n- Amazon requires customers to confirm purchases before they are completed.\n- Amazon automatically cancels purchases if customers do not confirm them.\n- Amazon used technology to prevent Alexa devices from interacting with its Super Bowl TV advertisement.\n- The Advertising Standards Authority assessed the complaint about the phantom cat food order.\n- The Advertising Standards Authority found that the advertisement did not breach the UK advertising code.\n- Amazon advised customers to set the Rekognition face-matching confidence threshold to at least 95% for law enforcement use.\n- The city of Orlando stopped using Amazon's Rekognition software.\n- Several members of Congress sent letters to Amazon CEO Jeff Bezos requesting meetings and answers about Rekognition's misidentifications.\n- The ACLU posted the full list of impacted members of Congress online.\n- The ACLU urged Congress to enact a moratorium on law enforcement use of face recognition technology.\n- In June, Amazon staffers circulated a letter asking CEO Jeff Bezos to stop selling the face-scanning software to police.\n- More than 650 Salesforce employees signed a petition asking CEO Marc Benioff to end Salesforce's software contract with U.S. Customs and Border Protection.\n- Protesters gathered outside Salesforce's downtown San Francisco tower to call on the company to live up to its values and end its contract with CBP.\n- Salesforce decided to keep the contract to supply software to CBP to manage human resources.\n- Marc Benioff tweeted that the company doesn't work with CBP regarding separation of families and that he does not support family separation.\n- Marc Benioff tweeted that he is proud to work with 30,000 employees who make their voices heard and serve their communities.\n- Marc Benioff donated $1 million to organizations that help families separated at the border.\n- Google employees successfully pushed for an end to a contract with the Pentagon that would have used Google's artificial intelligence technology for more targeted drone strikes.\n- Some Microsoft programmers threatened to quit rather than build software for U.S. Immigration and Customs Enforcement.\n- Durham Constabulary worked with Experian to improve its understanding of local communities.\n- Durham offered support to people identified as high risk in order to limit their chance of reoffending.\n- Durham ensured that Hart was only one element in offender assessment and that custody sergeants, not the software, retained the final decision on offenders.\n- Experian sought to avoid stereotyping in the descriptions used in its Mosaic dataset.\n- Experian adopted strong ethical standards in the wording it uses when creating Mosaic.\n- Experian subjected the names and descriptions in new Mosaic versions to several approval stages.\n- Google will identify its AI assistant as a robot when calling businesses.\n- Google will explicitly let people know they are interacting with a machine.\n- Google is designing the Duplex feature with disclosure built in.\n- Google will make sure the Duplex system is appropriately identified.\n- Google will incorporate feedback as it develops Duplex into a product.\n- Google will experiment with the right approach over the coming months.\n- Google will begin testing Duplex more widely this summer.\n- The Information Commissioner's Office confirmed it was in contact with the Metropolitan Police Service as part of an investigation into their use of a gangs database.\n- Scotland Yard said individuals identified on the matrix are offered support to divert them away from both offending and becoming a victim of violence.\n- The Metropolitan Police said it was working with Tottenham MP David Lammy, Amnesty International and the ICO to help understand the approach taken.\n- The ICO began an investigation into the Gangs Matrix in October 2017.\n- The ICO issued a 27-page Enforcement Notice requiring the Metropolitan Police Service to comply with data protection laws within six months.\n- The Enforcement Notice requires the MPS to conduct a data protection impact assessment.\n- The Enforcement Notice requires the MPS to complete a full review of all data sharing to determine a legal basis for when sharing is acceptable.\n- The Enforcement Notice requires the MPS to carry out regular audits to assess compliance with any new guidelines.\n- The Enforcement Notice requires the MPS to provide formal progress reports on each recommended measure to the ICO on a monthly basis.\n- The ICO will launch a second investigation focusing on how the police's partners handle information shared with them.\n- The ICO is investigating a data breach at Newham Borough Council involving the Matrix.\n- The MPS has started work to improve its data handling and information sharing with partners.\n- The MPS is introducing a public-facing website to explain the legal framework for the Gangs Matrix.\n- The MPS said it will provide further information to improve public confidence and transparency about the Gangs Matrix.\n- The MPS committed to continue working with the ICO as it addresses the Enforcement Notice.\n- Facebook apologized for its role in the data harvesting.\n- Mark Zuckerberg testified before the United States Congress in April 2018.\n- Mark Zuckerberg published a personal letter in newspapers apologizing on behalf of Facebook on March 25, 2018.\n- Mark Zuckerberg pledged to make changes and reforms in Facebook policy to prevent similar breaches.\n- Facebook decided to implement the EU's General Data Protection Regulation in all areas of operation.\n- Facebook established Social Science One as a response to the event.\n- Facebook sent messages to users believed to be affected informing them which types of personal information were likely included.\n- The governments of India and Brazil demanded that Cambridge Analytica report how data from the breach was used in political campaigning.\n- Various regional governments in the United States faced lawsuits from citizens affected by the data breach.\n- The United Kingdom's Information Commissioner's Office announced it intended to fine Facebook \u00a3500,000 over the data breach in early July 2018.\n- Facebook agreed to pay a \u00a3500,000 fine to the UK Information Commissioner's Office in October 2019.\n- The Federal Trade Commission voted to approve fining Facebook $5 billion to settle the investigation into the data breach in July 2019.\n- The FTC's ruling made Facebook subject to a new 20-year settlement order.\n- In July 2019 the FTC sued Cambridge Analytica's CEO Alexander Nix and app developer Aleksandr Kogan.\n- Alexander Nix and Aleksandr Kogan agreed to administrative orders restricting their future business dealings.\n- Alexander Nix and Aleksandr Kogan agreed to destroy any collected personal data and any work product made from the data.\n- Cambridge Analytica filed for Chapter 7 bankruptcy in May 2018.\n- Facebook agreed to pay $100 million to settle with the U.S. Securities and Exchange Commission for misleading investors about the risks it faced from misuse of user data.\n- Facebook agreed to settle a lawsuit seeking damages in August 2022 for an undisclosed sum.\n- Meta Platforms agreed to pay $725 million in December 2022 to settle a private class-action lawsuit related to the improper user data sharing with Cambridge Analytica and other third-party companies.\n- The United States Senate Judiciary Committee called witnesses to testify and held two hearings on Facebook's role in the breach and on Cambridge Analytica's role and its impact in data privacy.\n- Cambridge Analytica was asked to remove all the data it had obtained.\n- Brittany Kaiser created the Own Your Data Foundation to promote increased digital intelligence education.\n- Brittany Kaiser used the #OwnYourData campaign to petition Facebook to alter its policies and give users increased power and control over their data.\n- UniCredit stopped advertising and marketing on Facebook in August 2018.\n- Amazon suspended Cambridge Analytica from using Amazon Web Services when Amazon learned the service was collecting personal information.\n- Meta improved its civil society engagement in Myanmar.\n- Meta improved some aspects of its content moderation practices in Myanmar.\n- Meta commissioned a Human Rights Impact Assessment in 2018.\n- Meta implemented ongoing human rights risk management.\n- Meta banned Myanmar's military from its platform in January 2021.\n- Meta banned U Wirathu from Facebook in 2018.\n- Facebook investigated in 2020 how a video by U Wirathu was circulating on its site and found that over 70% of the video's views came from chaining.\n- Sri Lankan authorities blocked access to the internet.\n- Sri Lankan authorities blocked access to Facebook and WhatsApp.\n- The government declared a state of emergency to stem the violence.\n- Police arrested more than 280 suspects.\n- Authorities restored access to the internet.\n- Facebook removed more than 400 posts since the riots began.\n- Facebook blocked Amith Weerasinghe\u2019s profile and pages run by Mahason Balakaya and the Bodu Bala Sena.\n- Facebook stated it was in contact with the government and non-governmental organisations to support efforts to identify and remove such content.\n- Facebook said it was investing in technology and human expertise to remove content that violated its policies.\n- Facebook said it planned to double its global security team to 20,000 people this year.\n- Facebook officials were set to visit Colombo to discuss the situation.\n- Sri Lanka\u2019s telecommunications ministry said it will work with Facebook to make sure this kind of content does not go up.\n- Deputy Economy Minister Harsha De Silva urged President Sirisena to lift the social media block in a Twitter post.\n- Youth affairs minister Sagala Ratnayaka urged that social media access be unblocked immediately.\n- Sagala Ratnayaka urged the government to set in place a system to curtail hate speech and fake news.\n- Lyft announced that it would begin tracking driver behavior more carefully.\n- Uber said it was working with the 2016 study's authors to better understand the results in order to reduce incidents of discrimination.\n- Lawmakers, including then-senator Al Franken, pressed the companies to be more aggressive about monitoring drivers for discrimination.\n- Lyft provided the study's author, Anne Brown, with data about neighborhood ride penetration for the research.\n- Uber suspended its autonomous tests in Arizona until it completes its investigation.\n- Uber paused its Pittsburgh self-driving operations.\n- Uber is conducting an investigation into the incident.\n- An Uber spokeswoman confirmed the incident.\n- An Uber spokeswoman confirmed the veracity of the photo of the crash.\n- Uber confirmed there were no backseat passengers in the vehicle.\n- HSBC said it would review ways to make its Voice ID system more sensitive following the BBC investigation.\n- Lyrebird said it is working with security researchers to figure out the best way to proceed regarding voice replication technology.\n- Lyrebird said it is considering watermarking the audio samples it produces so it can detect immediately if it generated a sample.\n- The insurance industry criticized ProPublica's report, its methodology, and its conclusions as inaccurate.\n- The California Department of Insurance criticized ProPublica's analysis and conclusions, saying an individual insurer's losses in a given zip code may vary significantly from the industry average.\n- The Illinois Department of Insurance criticized ProPublica's report's methodology as incomplete and oversimplified.\n- The industry-backed Insurance Information Institute held a press briefing to contest the report's charges of racial bias.\n- The Insurance Information Institute published an in-depth opinion column blasting the report's charges as unfounded.\n- The Insurance Information Institute presented an independent actuarial review to ProPublica that disputed ProPublica's conclusions and methodology.\n- Insurers that responded to ProPublica's inquiries, including Nationwide and USAA, disputed the results and stated they do not discriminate by race in pricing.\n- Mattel cancelled plans to release the Aristotle smart baby monitor and shelved the product, saying it would not be brought to market.\n- Mattel stated the Aristotle would have used encryption to keep private information safe.\n- Mattel promised not to sell users' data from the Aristotle to advertisers.\n- A petition opposing the release of Aristotle gained more than 17,000 signatories.\n- Senator Edward J. Markey and Representative Joe Barton sent a letter to Mattel asking how the company would protect children's data.\n- The Education Council determined that automated essay scoring will not be used for the marking of NAPLAN writing scripts.\n- The Education Council stated that any future change to this position will be informed by further research into automated essay scoring and made as a decision of the Education Council.\n- Parents posted an online petition protesting the schedule changes, which had more than 4,500 signatures by Sunday morning.\n- The district listed potential ways of coping with the new schedule on its website.\n- The district listed after-school programs as a potential way for families to cope with the new schedule.\n- The district listed letters of explanation to employers as a potential way for families to cope with the new schedule.\n- The district listed transfers to a new school as a potential way for families to cope with the new schedule.\n- Glaad issued a press release attacking the study as \"not science or news\" and warned the findings could be used to harm people.\n- The Human Rights Campaign issued a joint press release criticizing the study and said Stanford should distance itself from the research.\n- The Economist reported on the research and pointed to several limitations, including its concentration on white Americans and the use of dating-site pictures.\n- The two researchers publicly responded to critics, defending their findings and arguing that scientific data and replication \u2014 not public criticism \u2014 are needed to confirm or debunk the results.\n- The two researchers accused their critics of making a \"premature judgement\" in response to the backlash.\n- An independent expert spoke to the BBC and raised concerns that the software's purported \"subtle\" differences might reflect how people portray themselves in photos rather than inherent facial differences.\n- The independent expert also said the technical details of the analysis algorithm should be published so they can be evaluated by informed criticism.\n- Ajin USA pleaded guilty to a misdemeanor criminal charge of willfully violating Occupational Safety and Health Administration standards by admitting it broke the federal lockout/tagout requirement.\n- A judge ordered Ajin USA to pay a $500,000 fine.\n- A judge ordered Ajin USA to pay $1,000,000 in restitution to Regina Elsea's estate.\n- Ajin USA must complete three years of probation.\n- During the probation period, Ajin USA must comply with a safety compliance plan.\n- The safety compliance plan must be overseen by a third-party auditor.\n- Ajin USA fully cooperated with the Department of Justice throughout the investigation of the accident.\n- Ajin USA issued a public statement saying it remains deeply saddened by the death of the associate.\n- Ajin USA issued a public statement saying it is fully committed to continuing to make the workplace as safe as possible for its employees.\n- Authorities installed facial recognition software in the restroom stalls to regulate toilet paper use.\n- The system requires visitors to make eye contact with a computer before the dispenser releases toilet paper.\n- The facial recognition program prevents the dispenser from offering another round to the same person and enforces a nine-minute wait for additional paper.\n- Human Rights Watch published an article raising privacy concerns about China's voice recognition program.\n- Human Rights Watch urged Chinese authorities to review relevant laws and procedures to ensure they are consistent with the International Covenant on Civil and Political Rights.\n- Human Rights Watch urged companies involved to limit the use of collected data to the purpose for which consent was given.\n- Human Rights Watch urged companies involved to test their systems' accuracy transparently and according to industry standards.\n- The agreement prohibits Google from using the NHS patient data in any other part of its business.\n- The data will be stored in the UK by a third party contracted by Google rather than in DeepMind\u2019s offices.\n- DeepMind is obliged to delete its copy of the patient data when the agreement expires at the end of September 2017.\n- The Royal Free NHS Trust states it provides DeepMind with NHS patient data in accordance with strict information governance rules and for the purpose of direct clinical care only.\n- DeepMind has stopped using the name 'Patient Rescue'.\n- Google says it has no commercial plans for DeepMind's work with the Royal Free and that the current pilots are being done for free.\n- The UK government has introduced tough new measures to ensure patient confidentiality.\n- The Foundation for Responsible Robotics published the report Our Sexual Future With Robots to bring attention to the making and capabilities of sexual robots.\n- A Canadian court is conducting legal proceedings to determine whether a man should be found guilty of possessing child pornography after he ordered a child sex doll online.\n- Researchers from the University of Oxford and The Alan Turing Institute published a paper in PLOS ONE investigating and documenting conflicts and edit wars among Wikipedia bots.\n- Yan called the Apple hotline to report that the facial recognition feature was allowing her colleague to unlock the phone.\n- Yan and her colleague went to the nearest Apple Store to report and demonstrate the issue in person.\n- At the Apple Store, her colleague used the phone's facial recognition to demonstrate the unlocking issue to staff.\n- The Apple Store staff stated that the camera might be faulty.\n- The Apple Store gave Yan a refund for the first iPhone X.\n- The shop offered Yan a second refund after the replacement iPhone X exhibited the same problem.\n- They tried again by pressing the buttons one by one.\n- They successfully registered the device.\n- Police broke into Oliver Haberstroh\u2019s flat after neighbours complained about the noise.\n- Officers called an expert to break the lock open.\n- Police refused to hand over replacement keys until the locksmith had been paid.\n- Amazon worked directly with the customer to identify the reason for the incident.\n- Amazon identified that the Echo was remotely activated and the volume was increased through the customer\u2019s third-party mobile music-streaming app.\n- Amazon offered to cover the cost for the incident.\n- Amazon said that any accidental purchases can be returned for free.\n- Users were advised that a four-digit security code can be added to the Echo to stop unauthorised orders.\n- The girl's parents added the four-digit security code to their Echo device.\n- Facebook apologised to the man and his family for the translation error and the disruption it caused.\n- Facebook said it is looking into the issue.\n- Facebook said it has taken steps to address this particular issue.\n- Chinese social network WeChat apologised after its machine translation system translated a neutral phrase as a racial slur.\n- Facebook shut down the chatbot experiment after the AIs developed their own language.\n- Programmers altered the machines' language-learning process to complete the negotiation training.\n- Facebook used a fixed supervised model trained to imitate humans for one agent during training.\n- Researchers prevented parameter updates for the second model (kept the model fixed) to avoid divergence from human language.\n- Facebook limited job advertisers' ability to exclude users in some demographic groups but did not limit exclusions based on age.\n- Plaintiffs filed an original complaint at the same time as the December ProPublica\u2013New York Times report.\n- Plaintiffs filed an amended complaint expanding their lawsuit and adding claims beyond those made in December.\n- The plaintiffs added Ikea, Enterprise Rent-A-Car and the University of Maryland Medical System to the list of employers named in the complaint.\n- The union and law firm amended the complaint to argue that Facebook offers an extra layer of targeting and uses its ad targeting tools for its own hiring to try to overcome Communications Decency Act immunity.\n- Facebook issued a statement defending its practices, saying that, when used responsibly, age-based targeting for employment purposes is an accepted industry practice because it helps employers recruit and people of all ages find work.\n- A Facebook spokesman declined to comment, referring reporters to the earlier statement defending the company's practices.\n- Ikea declined to comment.\n- Enterprise stated that it is an equal opportunity employer.\n- The University of Maryland Medical System categorically denied the allegations.\n- The University of Maryland said it uses a variety of outlets to advertise job openings.\n- The University of Maryland said it hires without regard to age, race, gender or other protected characteristics.\n- AARP criticized Facebook's position regarding age-based targeting for employment ads.\n- Senator Susan Collins criticized Facebook's position regarding age-based targeting for employment ads.\n- Senator Robert Casey Jr. criticized Facebook's position regarding age-based targeting for employment ads.\n- Peter Romer-Friedman, a lawyer for the plaintiffs, publicly criticized Facebook's stance on age-based ad targeting.\n- Facebook removed the anti-Semitic ad categories and the associated targeting fields.\n- Facebook said it would explore ways to fix the problem, including limiting the number of ad categories available.\n- Facebook said it would explore ways to fix the problem, including scrutinizing ad categories before they are displayed to buyers.\n- Facebook said it was building new guardrails in its product and review processes to prevent similar issues in the future.\n- After ProPublica's article about discriminatory housing ads, Facebook built a system it said would prevent such ads from being approved.\n- Facebook and other tech companies vowed to strengthen their monitoring of hate speech.\n- Facebook CEO Mark Zuckerberg pledged to keep a closer eye on hateful posts and threats of violence on Facebook.\n- Google apologized for the biased results produced by its Cloud Natural Language API.\n- Google said it is working on improving its models.\n- Google said it will correct this specific case.\n- Google said it is dedicating significant efforts to ensuring the NLP API avoids bias.\n- Google committed to building more inclusive algorithms to address bias in its machine learning systems.\n- Google said it will be transparent about the training data it uses.\n- Google said it is looking for hidden biases in its training data.\n- The Los Angeles Police Department advised drivers not to consult navigation apps.\n- The Los Angeles Police Department advised drivers in some areas to use navigation apps with caution.\n- Officials at roads blocked off from the public turned back cars that had been directed there by navigation apps.\n- Waze worked with transit officials to keep its maps updated with road closures.\n- Waze marked 110 road closures on its map.\n- Waze marked 16 open shelters on its map.\n- Waze updated its maps and shelter information every minute.\n- Waze advised users to type \"help\" into the search bar to find the nearest open shelter.\n- Waze responded to users on Twitter to communicate about the wildfires and map updates.\n- Google released two maps indicating the locations and conditions of the fires.\n- Google said it would continue to update the map in real time to address changing conditions on the ground.\n- Google used algorithmic and manual methods to account for everyday and emergency road closures and included those closures on its LA Fire Crisis Map embedded in its SOS Alert on Search.\n- Google changed Translate to reduce gender bias by providing both masculine and feminine translations for gender-neutral words.\n- Google now offers both feminine and masculine translations for single words when translating from English to French, Italian, Portuguese, or Spanish.\n- Google now offers both feminine and masculine translations when translating from Turkish to English.\n- Google says it plans to address non-binary gender in translations.\n- Google will eventually bring this feature to its iOS and Android apps.\n- Google will address gender biases in autocomplete.\n- A Google Translate Product Manager published a company blog post explaining that the model had replicated existing gender biases.\n- YouTube teams were alerted to the inappropriate autocomplete result.\n- YouTube worked to quickly remove the offending autocomplete suggestion.\n- YouTube is investigating the matter to determine what was behind the appearance of the autocompletion.\n- YouTube pledged to crack down on live-action accounts depicting children in disturbing and abusive situations.\n- YouTube purged over 50 of the offending accounts.\n- YouTube plans to update the public on its findings.\n- Yandex issued a public statement acknowledging the issue and saying they are working to resolve it.\n- Yandex said they are working to resolve the problem.\n- Yandex committed to constant improvement of their products and services to provide a high-quality user experience.\n- Yandex will continue to regularly monitor social and traditional media.\n- Yandex will correct the assistant's behavior when necessary.\n- The National Transportation Safety Board released 500 pages of findings on the death of Joshua Brown.\n- US authorities investigated Mr Brown's death.\n- Tesla unveiled improvements to Autopilot that added new limits on hands-off driving.\n- Tesla updated the Autopilot system to temporarily prevent drivers from using the system if they do not respond to audible warnings to take back control of the car.\n- The National Highway Traffic Safety Administration publicly stated that it had found no evidence of defects in the car.\n- The municipality of Gladsaxe delayed the program's planned rollout.\n- Tesla patched the exploit within 10 days of receiving the report from the Keen Security Lab.\n- The Keen Security Lab worked closely with Tesla's security team to fix the vulnerability before it could be put to nefarious use.\n- The Keen Security Lab withheld additional details of the hack until after the vulnerability was patched.\n- Tesla said it plans to reward the researchers under its bug bounty program.\n- Google submitted an accident report to the California Department of Motor Vehicles.\n- Google posted the accident report online.\n- Google accepted some responsibility for the collision.\n- Google issued a written statement acknowledging it bore some responsibility for the collision.\n- Google's computers reviewed the incident.\n- Google engineers changed the self-driving software so the cars would understand that buses may not be as inclined to yield as other vehicles.\n- The Santa Clara Valley Transportation Authority is reviewing the incident.\n- California DMV officials spoke with Google about the incident.\n- Uber suspended the driver who was riding along in the self-driving car involved in the incident.\n- California regulators revoked the registration of 16 of Uber's autonomous vehicles.\n- Uber moved its self-driving car program to Arizona.\n- Five of Uber's robocars returned to the streets of San Francisco in January.\n- Uber stated that the returned vehicles were being used only for mapping purposes and were being controlled by human drivers.\n- Victims were instructed to use VPN services.\n- Victims were instructed to use TOR.\n- Victims were instructed to comprehensively delete their browser history.\n- More VPN and TOR connection endpoint data needs to be collected and analyzed to fight Delilah and similar bots.\n- IT security teams were advised to block adult and other risky sites to avoid endpoint infections in the workplace.\n- DAO developers and Ethereum community members are trying to determine how to reverse the theft.\n- The Ethereum team is debating whether and how to refund the stolen funds.\n- The Ethereum team proposed releasing a new software version that alters the blockchain ledger to reverse the DAO heist transactions.\n- Some developers proposed retrieving the stolen ether by exploiting the same vulnerability in the clone DAO to take the funds back.\n- The Ethereum system will flag any attempt to sell the stolen ether on cryptocurrency markets.\n- Knightscope reached out to the boy's mother to invite her to their office to meet the entire Knightscope team and to apologize to her and her child directly.\n- Richard Lee contacted the Department of Internal Affairs after his passport photo was rejected.\n- The Department of Internal Affairs informed him that the rejection was due to too much shadow in his eyes.\n- Another photo was later accepted.\n- His passport was renewed.\n- Legal Aid of Arkansas filed a lawsuit in Pulaski County Circuit Court to stop the state Department of Human Services from using the algorithm to determine Medicaid benefits for people with severe disabilities.\n- A Department of Human Services spokeswoman requested a comparison of ARChoices benefits before and after the implementation of the RUG algorithm.\n- Frontier removed almost all Engineers weapon upgrades from NPCs in the game.\n- Frontier issued a bug fix to the PC version of the game to address the AI weapon issues.\n- Frontier announced that the Xbox One update containing the bug fix will follow the PC release.\n- The patch fixed NPCs ending up with overpowered hybrid weapons.\n- The patch prevented NPCs from initiating attacks when the player and NPC powers are aligned to the same superpower.\n- The patch slightly rebalanced ambient AI rank chances to reduce the proportion of top-end AI and increase low/mid-range AI.\n- The patch smoothed mission-spawned USS AI levels so that high ranks are rarer and only elite missions reach top-end AI.\n- Frontier said it will conduct a fresh review of the AI now that the bug fix has gone live.\n- Frontier said it may reintroduce a very select few high-end Engineers weapons to the highest-ranked NPCs if the balance is judged correct.\n- Frontier automatically refunded all insurance costs to players who lost a ship between the launch of The Engineers (2.1) update and the morning's update.\n- Several victims of the campaign filed complaints about the deanonymization and harassment.\n- FindFace stated that it was making efforts to protect all network users from potential malicious actions.\n- FindFace stated that it was ready to provide any information needed to find the users responsible for the harassment.\n- Beauty.ai said they will do more outreach in other countries to increase diversity of entrants.\n- Beauty.ai announced they will run another beauty contest in October to collect more entrants from countries outside of Europe.\n- Google said it continually works to improve its search algorithms.\n- Google implemented a feature to flag fact-checking sites within Google News last month.\n- Google changed its search results in response to the issue.\n- Microsoft took the chatbot offline after less than a day.\n- Aura Bogado created the Twitter hashtag #mypokehood to crowdsource the locations of Pok\u00e9Stops.\n- Researchers at the Urban Institute conducted research on Pok\u00e9Stop distribution and reported the disparity between majority-white and majority-black neighborhoods.\n- The Belleville News-Democrat investigated and reported that the pattern of fewer Pok\u00e9Stops repeated itself in African-American sections of Detroit, Miami, and Chicago.\n- Niantic CEO John Hanke publicly explained to Rolling Stone that Pok\u00e9mon Go uses the same Pok\u00e9Stop locations as its previous game, Ingress.\n- A Niantic spokesperson stated that the game was not yet processing user requests for additional Pok\u00e9Stops.\n- Niantic said it would readdress the topic of Pok\u00e9Stop distribution after the game was fully launched worldwide.\n- Facebook stated that it bans advertisers from using the 'Ethnic Affinities' designation to discriminate against racial or ethnic groups.\n- Facebook stated that its users cannot identify their race or ethnicity on Facebook.\n- Christian Martinez, head of multicultural at Facebook, published a blog post saying multicultural targeting is designed to make advertising more relevant and inclusive to diverse communities.\n- Emergency aid was provided to the injured visitor on-site.\n- The injured visitor was transported to a nearby hospital by ambulance.\n- The injured visitor was discharged after receiving stitches.\n- Investigations into the accident were continuing.\n- German prosecutors were investigating the incident and deciding who to prosecute.\n- The study's authors called for fresh safety measures for robotic surgical systems.\n- The authors recommended adoption of advanced techniques in the design and operation of robotic surgical systems to reduce preventable incidents.\n- The authors suggested providing surgical teams with more troubleshooting training, including the use of computer simulations that feature technical problems, to help them learn how to restart surgery more quickly after interruptions.\n- Police viewed CCTV footage of the factory.\n- Police interviewed dozens of workers who were at the factory at the time.\n- The company management and the contractor were booked on charges of causing death due to negligence.\n- The Maruti Udyog Kamgar Union demanded a full enquiry into Mr Lal's death.\n- The Maruti Udyog Kamgar Union demanded increased safety measures governing work with robots.\n- Microsoft publicly reiterated that the How Old Do I Look website does not store uploaded pictures or personal information.\n- Microsoft decided to leave the How Old Do I Look service up rather than take it down immediately after the keynote as originally planned.\n- A federal judge gave final approval to a $650 million Facebook class action privacy settlement.\n- The judge ordered the 1.6 million members of the class who submitted claims to be paid as expeditiously as possible.\n- The court ordered that the three named plaintiffs receive $5,000 each and that other class members receive at least $345 each.\n- In 2019, Facebook made its facial recognition feature opt-in only.\n- Dr Janice Duffy asked Google to remove links to the defamatory material from its search results.\n- Google removed some links to the defamatory material from its Australian domain (google.com.au).\n- The South Australian Supreme Court found that Google was legally responsible for linking to the defamatory content.\n- The case was sent back to court to establish damages that Google may be ordered to pay.\n- Google said it had fixed the problem that caused Google Photos to label some photos of black people as \"gorillas\".\n- Google said it was working to figure out exactly how the labeling error happened.\n- Google said it was taking immediate action to prevent this type of result from appearing.\n- Yonatan Zunger responded to the user's Twitter post and promised swift action.\n- Google temporarily removed nearly everything related to \"gorillas\" from Google Photos.\n- Google temporarily removed the ability to search for \"gorillas\" in Google Photos.\n- Google temporarily removed the \"gorillas\" label from Google Photos.\n</mitigation_statements>"}]}}
{"custom_id": "batch_1200", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- The researchers contacted Google about their findings late last year.\n- Google added a disclaimer to its ad settings page stating that the interest categories shown control only \"some of the Google ads that you see.\"\n- Google said it is looking at the methodology of the study to try to understand its findings.\n- Datta's group began collaborating with Microsoft to develop a version of AdFisher for internal use at Microsoft to look for potentially worrying patterns in Bing's ad targeting.\n- The researchers presented a paper on their findings at the Privacy Enhancing Technologies Symposium in Philadelphia.\n- A Starbucks spokesman said the company would reiterate its scheduling policies to managers across the country.\n- A Starbucks spokesman said the company would work to stabilize Ms. Navarro\u2019s schedule.\n- Ms. Navarro\u2019s manager took a closer look at her hours after she pleaded for more and better shifts.\n- A new schedule was posted a few days after their discussion that gave Ms. Navarro nearly 40 hours a week.\n- The new schedule aligned Ms. Navarro\u2019s shifts on three weekdays to start around 8 a.m. and finish around 4 p.m.\n- Legislators and activists are promoting proposals and laws to mitigate the scheduling problems.\n- Manufacturers and researchers of scheduling software, including Kronos, advocated that employers use the software to build schedules with more accommodating core hours.\n- The Home Office suspended English language tests run by ETS in the UK after the BBC Panorama investigation.\n- ETS announced that candidates who had appointments to take a test for immigration purposes would be contacted to process a refund.\n- The government suspended the two colleges identified by Panorama.\n- The government suspended all further English language tests administered through ETS in the UK.\n- Eden College International investigated allegations against three freelance TOEIC exam invigilators.\n- Eden College International did not renew the contracts of the three freelance TOEIC exam invigilators.\n- Eden College International said it had taken swift action to improve invigilation and monitoring.\n- Home Secretary Theresa May said she was looking at introducing more face-to-face interviews.\n- Home Secretary Theresa May called on the educational sector to do more to tackle fraud.\n- Facebook issued a public statement in response to the controversy saying the research was conducted for a single week in 2012, none of the data used was associated with a specific person's Facebook account, they have a strong internal review process, and all data is stored securely.\n- Cornell University released a statement saying its ethics board passed on reviewing the study because the part involving actual humans was conducted by Facebook rather than by the Cornell researcher.\n- The author of the study issued a public statement.\n- The editor of the academic journal that published the study issued a public statement.\n- The article was updated on June 29 to include statements from Facebook, the study's author, and the journal editor.\n- The Chicago Tribune published a story about the heat list on August 21, 2013.\n- RAND researchers performed an analysis of Chicago's heat list.\n- A 2016 paper published in the Journal of Experimental Criminology concluded that the Strategic Subject List provided no practical direction, little executive or administrative attention, and little to no follow-up with district commanders.\n- A report from the Los Angeles Police Commission criticized the LAPD's person-based predictive policing program for using inconsistent data to label people as 'chronic offenders'.\n- The LAPD ended its person-based predictive policing program, Operation LASER, in April 2020.\n- The Chicago Police Department ended its person-based heat list program in 2019.\n- Filmmakers of the 2017 German documentary Pre-Crime contacted McDaniel and filmed him for the documentary.\n- Google sought permission to appeal against the court ruling that Hong Kong has jurisdiction to hear Albert Yeung's defamation lawsuit.\n- The Court of First Instance granted Google permission to appeal that jurisdiction ruling.\n- The Court of First Instance allowed Albert Yeung to proceed with his defamation case against Google.\n- Albert Yeung requested that the court order Google to remove the defamatory autocomplete suggestions linking him to triad gangs.\n- Albert Yeung requested that the court order Google to compensate him for the alleged defamation.\n- The Supreme Court of Wisconsin instructed that circuit courts should exercise discretion when assessing a COMPAS risk score for each individual defendant.\n- Zilly's case was widely publicized.\n- Administrative Law Judge Raymond Sewell dismissed the fraud claim against Sue.\n- The state hired as many as 20 additional administrative judges over the past year to address the backlog of fraud hearings.\n- The Michigan Attorney General\u2019s office intervened in bankruptcy proceedings to oppose discharge of fraud penalties and filed almost two dozen adversary proceedings in May.\n- The UIA publicly defended the MiDAS program through a spokeswoman who stated the system modernizes and integrates unemployment insurance functions.\n- The UIA responded to media inquiries from a local Fox affiliate about the program and its consequences.\n- Attorneys including David Blanchard and the Sugar Law Center filed a federal lawsuit challenging the UIA\u2019s 'robo-adjudication' system.\n- The Sugar Law Center is representing affected claimants and is an institutional plaintiff in the pending federal lawsuit.\n- Under a law signed by Governor Snyder, the Penalty and Interest Account funds were made available solely to the Department of Talent and Economic Development to create new workforce training programs.\n- The UIA stopped paying benefits to claimants after making fraud determinations and immediately began garnishing wages and state and federal income taxes to collect alleged overpayments.\n- Since last October, the UIA (via MiDAS) has collected over $63 million in overpayments and used automatic wage garnishment to collect nearly $2.65 million.\n- Google publicly stated that Flu Trends protects user privacy by relying on anonymized, aggregated counts of search queries.\n- The Electronic Privacy Information Center and Patient Privacy Rights sent a letter to Google CEO Eric Schmidt raising privacy concerns about Flu Trends.\n- The letter challenged Google to publish the techniques it has adopted to protect the privacy of search queries used for Flu Trends.\n- Google issued a public statement denying that AdWords conducts racial profiling and noting that individual advertisers choose which keywords trigger their ads.\n- InstantCheckmate issued a public statement denying it has engaged in racial profiling and stating it has no technology to connect a name with a race.\n- Dr Guy Hingston's lawyers wrote to Google Australia in December threatening legal action over the autocomplete suggestion.\n- Dr Guy Hingston filed a defamation lawsuit in the US district court in California seeking at least $75,000 in damages plus court costs.\n- A jury in Australia found Google liable and ordered $200,000 in damages after its search results linked Milorad Trkulja to gangland crime.\n- A Tokyo court ordered Google to disable certain autocomplete results related to a Japanese man.\n- A French court fined Google $65,000 because its autocomplete function prompted the French word for 'crook' when users typed the name of an insurance company.\n- The Australian Competition and Consumer Commission alleged before the High Court that Google should be held responsible for its AdWords.\n- A German federal court ordered Google to clean up the auto-complete results its search engine suggests.\n- The court ordered Google to ensure terms generated by auto-complete are not offensive or defamatory.\n- The court said Google must remove defamatory word combinations when told about them.\n- Bettina Wulff sued Google because auto-complete suggested words linking her to escort services.\n- Willie Allen Lynch is contesting the use of facial recognition in court.\n- The AI Now Institute released a report highlighting key algorithmic litigation and recommendations.\n- AI Now put out an algorithmic accountability toolkit.\n- New York University\u2019s AI Now Institute convened the 'Litigating Algorithms' workshop to discuss legal challenges to government use of automated decision systems.\n- The state of Idaho acknowledged that reductions in benefits were a result of the new automated formula.\n- The ACLU brought a class action, K.W. v. Armstrong, against the state of Idaho in 2012.\n- K.W. v. Armstrong was settled four years later.\n- The settlement required the state to fix the formula to be less arbitrary.\n- The settlement required the state to conduct regular testing of the formula.\n- In some cases, governments abandoned the automated decision systems after class-action litigation.\n- Courts ordered governments to fix the systems by court order.\n- The Legal Aid Society of Arkansas won its case challenging the algorithm that reduced nursing care.\n- The Arkansas Department of Human Services began work on a new automated decision system.\n- The Illinois Biometric Information Privacy Act has been used as the basis for legal challenges such as Rosenbach v. Six Flags.\n- Bettina Wulff filed a lawsuit at the Hamburg Regional Court against television moderator G\u00fcnther Jauch.\n- Bettina Wulff filed a lawsuit at the Hamburg Regional Court against the Google corporation.\n- Thirty-four German and foreign bloggers and media outlets, including Stern, Mediengruppe \u00d6sterreich, and the Berliner Zeitung, issued cease-and-desist declarations.\n- Several media companies paid five-figure damages.\n- Wulff submitted a sworn affidavit for court declaring that all claims about her alleged past as a prostitute or escort are false.\n- In May Wulff's lawyer demanded that G\u00fcnther Jauch sign a cease-and-desist declaration regarding his citation of a newspaper article about the alleged rumors.\n- Through the lawsuit against Google she sought to prevent autocomplete suggestions such as 'Rotlichtvergangenheit' or 'Escort' from appearing when entering 'Bettina Wulff' in the search field.\n- Wulff planned to publish a book about her life in September to counteract the destruction of her public reputation.\n- SOS Racisme filed a lawsuit in France against Google alleging its autocomplete feature systematically associates famous people with Jewishness.\n- A hearing in the lawsuit was scheduled for Wednesday.\n- In 2009, a judge ruled that no algorithm could justify the prejudice caused by Google's autocomplete suggestions.\n- In 2009, a judge ruled that Google could be found liable because the affected company had informed Google of the situation, removing Google's safe harbor from liability.\n- A Japanese court issued a provisional order requesting Google delete specific terms from Autocomplete.\n- The man contacted Google last year requesting the negative words be removed and disassociated from his name.\n- Google declined the man's request to remove the negative autocomplete terms, arguing the matches are generated mechanically and not manually determined.\n- Japanese authorities warned Google to be careful that changes to its new privacy policy do not violate Japan's strict privacy laws.\n- Google confirmed it is reviewing the provisional court order.\n- A jury awarded Milorad Trkulja $200,000 in damages in the libel case against Google.\n- Milorad Trkulja was awarded $225,000 in damages against Yahoo in March for hosting the defamatory site.\n- After the case, Google issued a public statement asserting that its search results reflect web content and that the sites in its search results are controlled by those sites' webmasters, not by Google.\n- In 2012, the author wrote an article for Bitch Magazine to raise awareness about biased search results.\n- About five months after that 2012 article, Google modified its search algorithm, which reduced the prominence of pornography in results for 'black girls'.\n- Google reported the problematic search results as an anomaly beyond its control when contacted about them.\n- Google typically denied responsibility or intent to harm in response to reports of racial stereotyping in its products.\n- Google tweaked or fixed aberrations or glitches in its systems to address biased search results.\n- Following Kabir Ali's viral video, Google modified the algorithm for searches like 'three white teens' to include a newly introduced criminal image of a white teen and more wholesome images of black teens.\n- Google began blocking explicit content from AdWords in 2014.\n- USA Today journalist Jessica Guynn contacted the author about Kabir Ali's viral video.\n- One of Kabir Ali's Twitter followers posted evidence of a Google tweak to the algorithm for the 'three white teens' search.\n</mitigation_statements>"}]}}
