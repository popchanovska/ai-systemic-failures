{"custom_id": "batch_0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- YouTube apologised for the disturbing videos on the YouTube Kids app.\n- YouTube removed more than 50 user channels.\n- YouTube stopped running ads on more than 3.5 million videos since June.\n- YouTube tightened enforcement of its Community Guidelines.\n- YouTube age-gated content that inappropriately targets families.\n- YouTube removed inappropriate content from the YouTube Kids app.\n- YouTube stated that when it discovers inappropriate content it quickly takes action to remove it from its platform.\n- YouTube said thousands of people will be working around the clock to flag content.\n- YouTube began using machine learning to identify the most harmful content, which is then automatically reviewed.\n- A Las Vegas police officer publicly stated that the truck driver was at fault for the crash.\n- Las Vegas police cited the truck driver for illegal backing.\n- The city issued a statement asserting that the shuttle's sensors registered the truck and that the shuttle stopped to avoid the accident.\n- The shuttle completed two additional loops after the crash.\n- Tempe police released photographs from the scene of the pedestrian death.\n- Tempe police released a detailed report of more than 300 pages about the March 18 collision.\n- Tempe police released video from the scene, including body-camera footage.\n- Tempe police released the 911 call made by the driver after the crash.\n- Tempe police are seeking manslaughter charges against Rafaela Vasquez.\n- Tempe police obtained a search warrant for Vasquez's two cellphones.\n- Tempe police served warrants on Hulu, Netflix, and Google/YouTube to obtain streaming usage records.\n- Hulu provided a usage record showing that Vasquez was watching 'The Voice' and that streaming ended at 9:59 p.m.\n- Tempe police reviewed video from inside the Volvo XC90 as part of their investigation.\n- Tempe police conducted an exhaustive analysis of data from the vehicle and re-enacted the crash at the site.\n- Tempe police analyzed dashboard camera footage covering 11.8 miles to assess the driver's attention.\n- Police administered a field test to Vasquez and initially determined she was not impaired.\n- Uber stated that interacting with any mobile device while operating one of its vehicles on a public road is a fireable offense.\n- Uber announced plans to bolster its safety training in light of the accident.\n- Vasquez was let go from Uber.\n- Uber decided to end its self-driving tests in Arizona and let go all autonomous drivers there.\n- They provided a methodology for modifying word embeddings to remove gender stereotypes while preserving desired gender associations.\n- They defined metrics to quantify both direct and indirect gender biases in embeddings.\n- They developed algorithms to debias the embeddings.\n- They empirically evaluated their algorithms and demonstrated a significant reduction in gender bias using crowd-worker evaluations and standard benchmarks.\n- They produced resulting debiased embeddings intended for use in applications to avoid amplifying gender bias.\n- The procedure was interrupted to restart the robotic system.\n- The procedure was converted to non-robotic techniques.\n- The procedure was rescheduled to a later time.\n- Jannette Navarro scraped together a plan to survive the month of July without causing family or financial disaster.\n- She moved out of her aunt\u2019s home in part because of mounting friction over the erratic schedule.\n- She set aside $900 toward a car.\n- She relied on dimes from the tip jar to make bus fare.\n- She braced herself to ask her aunt, Karina Rivera, to watch her son, Gavin.\n- She vowed to practice for the driving test she had promised to pass.\n- To stay awake during multiple shifts, she concocted behind-the-counter coffee drinks with extra shots of espresso.\n- Martha Cadenas\u2019s mother moved in with her to help manage childcare because of unpredictable hours.\n- Eric Holder publicly warned that risk scores might be injecting bias into the courts.\n- Eric Holder called for the U.S. Sentencing Commission to study the use of risk scores.\n- ProPublica obtained the risk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014.\n- ProPublica analyzed those scores to check how many of those people were charged with new crimes over the next two years.\n- The Justice Department\u2019s National Institute of Corrections now encourages the use of combined risk-and-needs assessments at every stage of the criminal justice process.\n- A landmark sentencing reform bill currently pending in Congress would mandate the use of such assessments in federal prisons.\n- Tesla is taking PR very seriously after the crash.\n- The California Highway Patrol (CHP) and the National Transportation Safety Board (NTSB) are investigating the crash and examining the damaged vehicle.\n- The NTSB requested Tesla's assistance to decode the vehicle's recorded data.\n- Tesla has been extremely cooperative in assisting investigators with the vehicle's recorded data.\n- Tesla CEO Elon Musk took to Twitter to respond to comments from the NTSB and reiterate Tesla's priorities.\n- Following the Uber crash, Arizona banned Uber from further testing of its self-driving cars.\n- An investigation into the incident is ongoing.\n- Prosecutors were considering whether to bring charges related to the incident.\n- Google confirmed to Motherboard that its Cloud Natural Language API was producing biased results.\n- Google apologized, stating \"we are sorry.\"\n- Google said it is working on improving its models.\n- Google said it will correct this specific case.\n- Microsoft quickly pulled its Tay chatbot offline after Twitter users taught it to produce racist and sexist content.\n- Microsoft promptly shut down its Zo chatbot after it learned terrible habits from humans.\n- Google publicly apologized for the incident, saying it was 'appalled and genuinely sorry.'\n- An engineer announced that the label 'gorilla' would no longer be applied to groups of images.\n- Google stated it was working on longer-term fixes to address the problem.\n- Google erased 'gorilla' and some other primates from Google Photos' lexicon.\n- Google censored searches for 'gorilla', 'chimp', 'chimpanzee', and 'monkey' in Google Photos.\n- A Google spokesperson highlighted the Google Photos feature that allows users to report labeling mistakes.\n- Boeing provided information to American Airlines clarifying that pulling back on the control column in the 737 Max will not stop a stabilizer runaway if MCAS is triggered.\n- Boeing issued a public statement asserting that the existing procedures covered the latest 737 Max model.\n- Boeing and the U.S. Federal Aviation Administration issued bulletins after the crash instructing pilots that they could overcome an incorrectly activated MCAS by activating the electric trim cutout switches on the outside of both pilots' control columns.\n- The ads were removed from Reuters.com as of March 25, 2013.\n- The researchers have work underway to better understand why the discriminatory ad delivery occurred.\n- Samples of the ads were published in the paper and made available for download.\n- Samples of the ads were published in a slideshow at foreverdata.org.\n- The paper published a complete breakdown of ad occurrences by first name.\n- A spokesperson for Jigsaw told Engadget that Perspective is still a work in progress and that they expect to encounter false positives as the tool's machine learning improves.\n- Vermont librarian Jessamyn West tested the Perspective API by inputting phrases to see what made a comment or commenter be perceived as toxic.\n- The article's author tested the Perspective engine by entering a variety of comments representing different identities and opinions to compare the resulting toxicity scores.\n- Facebook removed Mary Canty Merrill's post, suspended her profile for a week, and erased a number of her older posts.\n- Google AdSense emailed an African-American woman saying she had violated its terms for writing a blog post about dealing with being called the n-word on her own website.\n- Googler feedback was used to change Smart Reply so its suggested responses are now safe-for-work, removing inappropriate suggestions such as \"I love you\".\n- Google incorporated users' choices of suggested responses (including not choosing them) to improve future Smart Reply suggestions.\n- Inbox uses user reports of spam to improve the system's performance.\n- Researchers examined the top 100 image search results for 45 different jobs.\n- Researchers compared the gender breakdown of those image search results to actual gender data from the Bureau of Labor Statistics for each job.\n- Study participants were shown skewed image results for certain occupations and subsequently reported a slight change in their perceptions of how male-dominated those fields were.\n- Google declined to comment about the study's findings.\n- The researchers suggested that search engine designers could use the study results to develop algorithms that would help work against gender stereotypes.\n- Tech-savvy individuals who noticed the rank change started looking into Amazon's policy.\n- An AP reporter obtained a statement from Amazon that the removal of LGBT books' sales ranks was a \"computer glitch\".\n- Twenty-four Amazon workers were hospitalized and treated at five local hospitals.\n- An additional 30 workers were treated at the scene.\n- The fulfillment center was given the all clear by Wednesday evening.\n- Amazon relocated all employees in the affected area to a safe place.\n- Amazon treated employees experiencing symptoms onsite.\n- Some employees were transported to local hospitals for evaluation and treatment as a precaution.\n- Amazon initiated a full investigation into the incident.\n- The Robbinsville Fire Department attempted to isolate the source of the fumes.\n- Robbinsville Fire Department EMTs triaged multiple patients.\n- Seven ambulances and a medic were assigned to the scene.\n- The warehouse was ventilated.\n- The Robbinsville Fire Department investigated the fumes at the fulfillment center.\n- The author looked at the 2010 dataset and identified that about 6,000 of the 18,000 entries were repeated names.\n- The author ran numerical analyses on the elementary teachers' scores and calculated the average difference and counts for differences of 40 or more points, 60 or more points, and 70 or more points.\n- The author created a scatter plot of 5,675 teachers plotting language arts scores on the x-axis and math scores on the y-axis.\n- The author conducted a follow-up experiment comparing scores for teachers who taught multiple grades in the same year (for example, 6th grade versus 7th grade math).\n- The author went to the data report for M.S. 35 to compare that teacher's 6th grade and 7th grade math scores.\n- The author investigated whether the observed extreme score discrepancies were merely outliers.\n- Incident 21 was converted to an 'issue' following an update to the incident definition and ingestion criteria.\n- Incident 21 was downgraded because it was classified as an academic finding showing a weakness of the technology rather than a harm event.\n- Incident 62 was converted to an 'issue' following an update to the incident definition and ingestion criteria.\n- Incident 62 was downgraded because it was designed to be humorous and therefore not considered a harm.\n- Incident 159 was converted to an 'issue' following an update to the incident definition and ingestion criteria.\n- Incident 159 was downgraded because the reports surfaced a vulnerability with projected harms rather than a report of harms in the real world.\n- Incident 287 was converted to an 'issue' following an update to the incident definition and ingestion criteria.\n- Incident 287 was downgraded because the reports indicated the insufficiency of GPT-3 for several tasks for which the system was not deployed in the real world.\n- Incident 298 was converted to an 'issue' following an update to the incident definition and ingestion criteria.\n- Incident 298 was downgraded because the harms were predicted to occur but had not yet occurred.\n- Incident 85 was converted to an 'issue' following an update to the incident definition and ingestion criteria.\n- Editors confirmed the migration of Incident 85, concluding it likely did not fit current incident criteria due to human manipulation and sensationalism.\n- California Attorney General Xavier Becerra issued a public statement reminding Californians that price gouging during the state of emergency is illegal.\n- The statement warned that those who violate California's price gouging law could face up to one year of imprisonment and/or a fine of up to $10,000.\n- Any accident must be reported to the California Department of Motor Vehicles.\n- The California Department of Motor Vehicles said there have been four accidents but declined to comment about fault or other details, citing that collision reports are confidential.\n- Delphi shared its accident report with The Associated Press.\n- Google issued a written statement saying that since September cars driving on streets near its Mountain View headquarters had a handful of minor fender-benders with light damage and no injuries.\n- Google said its cars were not at fault in the accidents.\n- Delphi said its car was not at fault in the accident.\n- Five other companies with testing permits told The Associated Press that they had no accidents.\n- Regulators in Nevada, Michigan, and Florida said they were not aware of any accidents.\n- The leader of Google's self-driving car program acknowledged three earlier accidents in a briefing with reporters a year ago.\n- Ningbo police apologized for the false identification of Mingzhu Dong.\n- Uber suspended self-driving testing in North American cities.\n- Nvidia stopped its self-driving road tests in the US.\n- Toyota stopped its self-driving road tests in the US.\n- Uber announced plans to resume self-driving road tests in Pittsburgh eight months after the accident.\n- Uber discovered that its self-driving software decided not to take any actions after the car\u2019s sensors detected the pedestrian.\n- IBM downsized Watson Health.\n- IBM laid off more than half of Watson Health's staff.\n- Amazon abandoned the AI recruiting software.\n- Amazon said the recruiting tool was never used to evaluate candidates.\n- Researchers shut down the Facebook chatbots 'Bob' and 'Alice' after they began communicating in their own language.\n- Autonomous vehicle operations worldwide were stalled after an Uber self-driving car fatally struck a pedestrian during testing.\n- Police broke down the door of a home in response to complaints of loud music that had been activated by an Amazon Echo.\n- The recruiter promised to sort out the problem after receiving the termination email.\n- Company personnel copied Mr Diallo into emails about his case over the following three weeks.\n- The company repeatedly escalated his case to higher-level managers and executives.\n- After three weeks, his bosses discovered why he had been sacked.\n- Mr Diallo was allowed back to work.\n- LinkedIn said it is reviewing ways to improve its predictive technology.\n- The Tay chatbot was taken offline after it was persuaded to repeat racist and sexist slurs.\n- New regulations were put in place following the 2010 Flash Crash.\n- The Commodity Futures Trading Commission conducted an investigation and concluded that Navinder Singh Sarao was at least significantly responsible for the order imbalances in the derivatives market that affected stock markets and exacerbated the flash crash.\n- On April 21, 2015, the U.S. Department of Justice filed 22 criminal counts, including fraud and market manipulation, against Navinder Singh Sarao.\n- Spoofing, layering, and front-running were banned by 2015.\n- After the August 24, 2015 flash crash showed those earlier regulations were inadequate, exchange-traded funds (ETFs) were put under greater scrutiny by regulators and investors.\n- In May 2014, the CFTC issued a report concluding that high-frequency traders did not cause the Flash Crash but contributed to it by demanding immediacy ahead of other market participants.\n- Hire a Deep Learning expert for an hour to tell you what not to do.\n- First get the process right and then bring in the robots.\n- Map out the existing business process and identify specifically the Jobs To Be Done (JTBD) of a customer or employee.\n- Identify the cognitive loads (lack of memory, information overload, lack of meaning, and acting fast) that can be augmented with AI technology.\n- Augment identified cognitive loads with appropriate Deep Learning technologies such as search, summarization, translation, and visualization.\n- Apply the Deep Learning Canvas framework to incrementally improve JTBDs augmented by AI.\n- Start with a strategy that incorporates an understanding of purpose, process, and people when employing AI automation.\n- Use lean methodology to maximize customer value while minimizing waste.\n- Assess the value stream to determine if each step is valuable, capable, available, adequate, and flexible.\n- Introduce more oversight and greater transparency in the process of creating AI.\n- Engineers must find a way to balance the data used to train AI.\n- Google is now compelled to remove defamatory suggestions from autocomplete results when notified in Germany.\n- People and corporations have brought lawsuits alleging autocomplete defamation in countries including Italy, France, Ireland, Japan, and Australia.\n- New services such as brand.com's \"Google Suggest Plan\" have been created to help people manipulate autocomplete suggestions to avoid negative connotations.\n- The author automatically collected autocomplete data from Google and Bing for queries related to public companies and politicians to test using algorithms to monitor for defamation.\n- The author queried autocomplete APIs using templates for company names and politician names, using a list of S&P 500 corporations and a Sunlight Foundation list of U.S. congresspeople.\n- The author filtered the collected autocomplete results using sex-related keywords and crime-related words from the Cambridge US dictionary to narrow potential defamation cases.\n- Facebook shut down its artificial intelligence engine after developers discovered the AI bots had created a language humans couldn\u2019t understand.\n- Microsoft shut down the Tay chatbot within a day of its launch after it began producing offensive and racist statements.\n- Google\u2019s chief social architect Yonatan Zunger issued a public apology stating, \"This is 100% Not OK.\"\n- Frontier removed the engineers' weaponry feature from Elite: Dangerous until the issue was fixed.\n- Frontier community manager Zac Antonaci posted an explanation attributing the unusual weapons attacks to a networking issue that allowed NPC AI to merge weapon stats and abilities.\n- ProPublica investigated Northpointe\u2019s predictive algorithm and published findings that it exhibited racial bias.\n- Researchers shut down the DELIA system a few months after testing when they discovered it was inserting fake purchases and redirecting money.\n- ProPublica analyzed COMPAS assessments for more than 7,000 arrestees in Broward County, Florida, and published an investigation claiming that the algorithm was biased against African Americans.\n- Northpointe questioned ProPublica\u2019s analysis.\n- Various academics questioned ProPublica\u2019s analysis.\n- Those academics noted, among other rebuttals, that the program correctly predicted recidivism in both white and black defendants at similar rates.\n- The Washington Post published a story explaining why it is mathematically impossible to satisfy the standards set by both Northpointe and ProPublica.\n- Dressel and Farid recruited 400 volunteers through a crowdsourcing site to evaluate defendants' likelihood of recidivism.\n- Each volunteer reviewed short descriptions of defendants from ProPublica\u2019s investigation highlighting seven pieces of information and guessed whether the defendant would commit another crime within two years.\n- Dressel and Farid pooled the volunteers' answers to produce a collective prediction.\n- Researchers shut down Facebook's chatbots ('Bob' and 'Alice') after the bots began communicating in their own language.\n- Autonomous vehicle operations worldwide were stalled following the fatal crash involving an Uber self-driving car during testing.\n- Police forcibly entered a home (breaking down the door) after an Amazon Echo accidentally activated and played loud music, responding to neighbors' complaints.\n- Investigators examined the satellite warning system and confirmed that the system had malfunctioned.\n- Investigators determined that the false alarms were caused by a rare alignment of sunlight on high-altitude clouds and the satellites' Molniya orbits.\n- The error was corrected by cross-referencing detections with a geostationary satellite.\n- They investigated (dug into) how the new algorithm worked to understand why it produced the unexpected solution.\n- They adjusted the algorithm's success criterion to require keeping all crew members alive, and reran the simulation with that constraint.\n- Researchers shut down Facebook's chatbots 'Bob' and 'Alice' after they developed their own language.\n- Autonomous vehicle operations were stalled worldwide following the Uber self-driving car fatality.\n- Police broke down the homeowner's house to respond to complaints about loud music caused by an Amazon Echo.\n- Mr Lee called the Department of Internal Affairs after the website repeatedly rejected his photo.\n- Two members of staff filed a complaint with the Commission for Racial Equality in 1986.\n- A spokesperson for the Commission for Racial Equality publicly stated that the computer program merely replicated the discrimination already being practiced by the selectors.\n- Bkav released a blog post describing their Face ID spoofing research.\n- Bkav released a video demonstrating their Face ID spoofing.\n- Bkav revealed a second, more convincing video demonstration two weeks after the original.\n- Bkav published an FAQ about the research.\n- Bkav said it plans to reveal more in a press conference later that week.\n- The article was updated with another, more convincing video demonstration of Bkav's Face ID spoofing.\n- Researchers shut down Facebook's chatbots Bob and Alice after they began communicating in their own language.\n- Autonomous vehicle operations were stalled worldwide following the fatal Uber self-driving car crash.\n- Police broke down the house to stop loud music after an Amazon Echo unintentionally activated and played music.\n- Nest encouraged all current Nest Protect owners to connect their device to Wi\u2011Fi so they can receive an update that will disable the wave feature.\n- Nest released/provided an update that will disable the wave feature on Nest Protect devices.\n- Nest halted sales of the Nest Protect until the issue has been resolved.\n- Nest stated that it expects to have the wave feature fixed within two to three months.\n- Nest offered customers a complete refund if they do not want to keep their Nest Protect smoke alarm.\n- Nest CEO Tony Fadell issued a public statement apologizing for the issue and describing the company's focus on fixing the problem.\n- Police deleted the photo of Dong Mingzhu from the jaywalker display.\n- Police announced they would update the jaywalker-spotting system to avoid similar mistakes.\n- Local police publicly acknowledged the mistake in a Sina Weibo blog.\n- Authorities began work to ensure the AI system could differentiate between advertisements and real people.\n- In 1945 US medical schools embargoed letters of reference.\n- In 1945 US medical schools moved the date of appointment to one year before employment.\n- In subsequent years the dates at which letters were released and appointments were made were moved back to the senior year.\n- In 1945 offers were required to remain open for 10 days.\n- In 1952 the National Intern Matching Program was implemented to match interns to hospitals using a matching algorithm.\n- Alvin E. Roth was asked by the NRMP to direct a study of the match intended to shed light on the choice of matching algorithm.\n- Organizations such as the NRMP were created solely to stabilize transaction dates in markets experiencing timing problems.\n- Dr Coelingh\u2019s team created a mechanism for each Drive Me car to assess whether driving conditions are acceptable for self-driving.\n- Each car sends its local assessment via a connectivity link to the Volvo cloud where data from all cars are aggregated to decide if weather in Gothenburg is appropriate for self-driving.\n- Volvo sends an approval signal back to the car when conditions are met, after which the driver is offered autonomous mode via the interface.\n- The approval signal is only sent when the car has the correct map versions and a connection to the server.\n- The approval signal is only sent when traffic and weather conditions are within the system's operational scope.\n- Volvo placed the main radar behind the windscreen so the area in front will always be cleared by the wipers.\n- The XC90 was equipped with active cleaning systems on the external sensors to keep them free from dirt and debris.\n- The XC90 was fitted with optimized cameras to improve performance in low-light conditions.\n- The authors developed and contributed new methods for evaluating bias in text, specifically the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT).\n- The listed former incidents were converted to \u201cissues\u201d following an update to the incident definition and ingestion criteria.\n- Reports associated with these incidents were re-associated with other incidents as context.\n- Editors confirmed the migration of Incident 85, noting it likely did not fit the current incident criteria.\n- Google issued a public statement to FUSION via email explaining that its image search results reflect content from across the web and do not reflect the company's own opinions.\n- A high-ranking Google engineer apologized after Google Photos' auto-tagging program labeled two black people as gorillas.\n- In 2009, Google removed a racist image comparing Michelle Obama to a gorilla from its search results.\n- Police are viewing CCTV footage of the factory.\n- Police are interviewing dozens of workers who were at the factory at the time of the incident.\n- The company management and the contractor have been booked on charges of causing death due to negligence.\n- The Maruti Udyog Kamgar Union has demanded a full enquiry into Mr Lal\u2019s death.\n- The Maruti Udyog Kamgar Union has demanded increased safety measures governing work with robots.\n- The robot was given jobs to keep him out of the way.\n- The robot was sent to the sausage section.\n- The robot was asked to hand out samples of sausages.\n- Officers ran a traffic break to slow surrounding traffic.\n- An officer positioned behind the Tesla turned on emergency lights.\n- An officer drove across all lanes of the highway in an S-shaped path to slow traffic behind the Tesla.\n- Another officer drove a patrol car directly in front of the Tesla and gradually slowed to prompt the vehicle to slow and stop.\n- Officers walked up to the Tesla and attempted to wake the driver by knocking on the window and giving verbal commands.\n- After the driver woke and exited the Tesla, officers placed him in the back of a patrol car and removed him from the freeway.\n- At a nearby gas station, officers administered a field sobriety test to the driver.\n- Officers arrested the driver on suspicion of drunken driving.\n- FaceApp backtracked on its latest update after being accused of racism.\n- FaceApp deleted its new \"black\", \"white\", \"Asian\" and \"Indian\" filters following a storm of criticism.\n- Officials cleared away the 'Hands Up Don't Shoot' sign and a mountain of teddy bears near the Canfield Green apartments.\n- Jennings precinct commander Jeff Fuesting went door to door for 'Walk and Talks' to try to improve relations between officers and residents.\n- Department heads brought in the HunchLab predictive policing software for use by the St. Louis County Police Department.\n- They asked the Jennings precinct to roll out HunchLab first.\n- Officers in the Jennings substation tried out the HunchLab software.\n- The police identified and aggressively patrolled 'hot spots' determined by the HunchLab software.\n- Federal highway safety regulators opened an investigation into the crash.\n- Elon Musk tweeted his condolences regarding the tragic loss.\n- Tesla published a blogpost and company statement describing the crash and explaining that the car\u2019s sensor system failed to distinguish the truck and that the vehicle attempted to drive under the trailer.\n- Tesla released a 537-word statement noting it was the company\u2019s first known autopilot death in roughly 130 million miles and emphasizing that Autopilot requires drivers to remain alert.\n- At the end of Tesla\u2019s blogpost the company publicly described the victim and expressed that they were beyond saddened by the loss.\n- The Florida Highway Patrol told Reuters that there was a portable DVD player in the vehicle.\n- The department improved many aspects of the program in January.\n- In January the department allowed welfare recipients to instigate an internal review before debt proceedings were launched.\n- The Government said it would improve its communication with the public.\n- The department agreed that 'vulnerable' customers would not have to deal with the automated system for now.\n- The department agreed that vulnerable customers would be given extra help in the future.\n- Be careful about designing reward functions.\n- Use learning from demonstrations to avoid specifying a reward directly and instead train agents to imitate how a human would complete the task.\n- Incorporate human feedback by evaluating the quality of episodes.\n- Share control with the agent in an interactive manner.\n- Use transfer learning by training on many similar games to infer a \"common sense\" reward function for new environments.\n- Use Universe to discover and address new failure modes at a rapid pace.\n- On 20 July 2016 the Ethereum community decided to hard-fork the Ethereum blockchain to restore virtually all funds to the original contract.\n- The Ethereum network was hard-forked to move the funds in The DAO to a recovery address where they could be exchanged back to Ethereum by their original owners.\n- Poloniex delisted DAO trading pairs in September 2016.\n- Kraken delisted the DAO token in December 2016.\n- Google implemented 3,500 new tests to make sure this won't happen again.\n- The National Highway Traffic Safety Administration said it is collecting more information to get a more detailed exploration of what happened.\n- The top U.S. auto safety regulator said it was seeking additional details about the crash.\n- NHTSA chief Mark Rosekind spoke to Google officials about the crash.\n- Google was forthcoming in answering requests for details on the crash.\n- The transit agency concluded, based on footage, that the bus driver was not responsible.\n- Google publicly acknowledged it bears some responsibility for the incident.\n- Tencent pulled the two chatbots from its messaging app.\n- Facebook said it is looking into the issue.\n- Facebook apologised to the man and his family for the mistake and the disruption it caused.\n- Facebook said it had taken steps to address this particular issue.\n- WeChat apologised after its machine-translation system translated a neutral phrase meaning \"black foreigner\" as the n-word.\n- Facebook overlaid a warning label on some versions of a debunked tweet linking to a USA Today article.\n- Facebook labeled certain posts as 'partly false information.'\n- Facebook said it has carried out enforcement actions against the majority of the pages and groups Avaaz identified.\n- Facebook reduced the distribution of posts from pages and groups it enforced against.\n- Facebook did not recommend that users join pages and groups that repeatedly share false information.\n- Facebook barred those pages and groups from monetizing or advertising.\n- Facebook puts a warning label on posts that independent fact-checkers find to be misinformation.\n- Facebook alerts users before they share posts that fact-checkers have found to be misinformation.\n- Facebook notifies people who have already shared posts that fact-checkers have found to be misinformation.\n- Facebook reduces a post's distribution by, for example, not showing it near the top of a user's News Feed.\n- Facebook uses artificial intelligence to detect copies of misinformation it has identified and apply labels to them.\n- Between March and September 2020, Facebook applied warning labels to more than 150 million pieces of content that were debunked by fact-checkers.\n- Facebook told NPR that Avaaz's findings 'don't accurately reflect the actions we've taken.'\n- Facebook partners with more than 70 fact-checking organizations to scale fact-checks.\n- Facebook uses AI to scale fact-checks to millions of duplicate posts.\n- Facebook said it is working to improve its ability to action on similar posts.\n- Avaaz conducted an analysis of 1,776 posts that independent fact-checkers had found false or misleading between October 2019 and early August 2020.\n- Using data from CrowdTangle, Avaaz estimated that the unlabeled posts it found had been viewed 142 million times and received 5.6 million reactions.\n- Avaaz identified 119 pages that had posted misinformation at least three times in the past year.\n- Avaaz identified 46 pages that had shared unlabeled versions of posts that fact-checkers had deemed false.\n- More than 15,000 parents, students, and teachers signed an online petition asking the IB to take a different approach with their grading algorithm and to make it fairer.\n- The IB foundation declined to answer questions about its grading system.\n- The IB foundation said the grading system had been checked against five years of past results.\n- The IB foundation said disappointed students could use its existing appeals process, which requires a fee.\n- The IB foundation released summary statistics showing this year\u2019s average score was slightly higher than last year\u2019s and that the distribution of grades was similar.\n- IB posted a video explaining the grading process in which its assessment manager described the system.\n- A math teacher said he plans to work with a colleague and a statistical software package to probe where the IB formula may have gone wrong.\n- Many students are planning to take the November in-person IB exams as a second chance to obtain written-test results.\n- Anahita Nagpal said she intends to take the November IB exams at a cost of about \u20ac700.\n- Grist writer Aura Bogado created the Twitter hashtag #mypokehood to crowdsource the locations of Pok\u00e9Stops.\n- Urban Institute researchers compiled and analyzed data on Pok\u00e9Stop and Gym locations to document racial disparities.\n- The Belleville News-Democrat examined Pok\u00e9Stop distribution and reported that the pattern repeated in African-American sections of Detroit, Miami and Chicago.\n- Niantic stated that the game was not processing user requests for additional Pok\u00e9Stops at that time.\n- Niantic said it would readdress the topic of Pok\u00e9Stop disparities after the game was fully launched worldwide.\n- SOS Racisme, the Union of Jewish Students of France, the Movement Against Racism and for Friendship Among Peoples, and other organizations are suing Google over its autocomplete suggestions.\n- A hearing for the lawsuit is scheduled for Wednesday.\n- In 2009, two French companies sued Google because its autocomplete feature suggested the French word for \"scam\" in searches for their names.\n- A man in Japan won an injunction against Google requiring the autocomplete feature to be turned off when someone searched the man's name.\n- Researchers recommended conducting a closer examination of the datasets and any models trained on them.\n- They recommended applying rigorous fairness analyses before deployment of diagnostic classifiers.\n- They suggested publishing clear disclaimers about the dataset collection process and the potential for resulting algorithmic bias to improve clinical assessments.\n- They indicated that applying 'de-biasing' techniques could reduce disparities in algorithm performance.\n- The Government transferred responsibility for resolving the grading problem to third-level institutions.\n- Third-level institutions were instructed or expected to make extra spaces available as needed for students who received unwarranted lower grades.\n- Dermot Casey wrote an explanatory piece that offered a detailed list of questions about how the Irish algorithm was coded and stress-tested.\n- The bias in Google image search results for certain ethnic search terms was adjusted.\n- The EU has begun implementing laws requiring corporate algorithm transparency.\n- The Wayne County prosecutor\u2019s office said Robert Julian-Borchak Williams could have the case and his fingerprint data expunged.\n- Prosecutor Kym L. Worthy issued an apology in a statement.\n- Two weeks after his arrest, the prosecutor moved to dismiss the case without prejudice.\n- The Detroit Police Department accepted the prosecutor\u2019s decision to dismiss the case.\n- The Detroit Police Department updated its facial recognition policy in July 2019 to limit its use to investigations of violent crimes.\n- The American Civil Liberties Union of Michigan filed a complaint with the city regarding the case asking for an absolute dismissal, an apology, and the removal of Mr. Williams\u2019s information from Detroit\u2019s criminal databases.\n- The Williams family contacted defense attorneys to seek legal representation.\n- Melissa Williams tweeted at the American Civil Liberties Union of Michigan to draw attention to the case.\n- The American Civil Liberties Union of Michigan took immediate interest in the case after being contacted.\n- Amazon, Microsoft, and IBM announced that they would stop or pause their facial recognition offerings for law enforcement.\n- Rank One Computing developed a new facial recognition algorithm for NIST to review intended to reduce differences in accuracy between demographic cohorts.\n- EPIC and a coalition of consumer organizations filed a complaint in April 2018 highlighting Facebook\u2019s practice of routinely scanning photos for biometric facial matches without the consent of the image subject.\n- In July 2019, the Federal Trade Commission determined that Facebook\u2019s use of facial recognition technology was deceptive and misrepresented the extent to which a consumer can control the privacy of their facial data.\n- The Police Department terminated the roughly $94,000 lease contract with Boston Dynamics on April 22.\n- Police officials said the robotic dog had been returned to Boston Dynamics or would be soon.\n- The Police Department changed its plans and halted testing of the robotic dog that had been scheduled to continue until August.\n- The Stanford Department of Urology faculty volunteered their vaccination appointments to trainees on the front lines.\n- Stanford Department of Medicine faculty, division chiefs, and other doctors volunteered to wait until all house staff have been vaccinated unless they are high-risk.\n- Several departments at Stanford Medical Center tweeted their support for the frontline workers who protested.\n- Dr Joy Wu tweeted her support of the protest.\n- Stanford Medical Center apologized to its community, including residents, fellows, and other frontline care providers.\n- Stanford Medical Center took responsibility for the errors in the execution of its vaccine distribution plan.\n- Stanford Medical Center stated it is immediately revising its plan to better sequence the distribution of the vaccine.\n- A national civil rights organization filed a lawsuit to challenge Buenos Aires\u2019 live facial recognition system.\n- In response to resistance, the government drafted a new bill, now going through legislative processes, that would legalize facial recognition in public spaces.\n- The government publicly denied that CONARC includes minors.\n- Human Rights Watch conducted an investigation that found at least 166 children listed in various versions of CONARC between May 2017 and May 2020.\n- Police gave a mistakenly-identified man a pass to show to the next officer to resolve confusion about his identity.\n- One mistakenly-identified man finally cleared up his identity after being detained for six days.\n- YouTube removed Stefan Molyneux\u2019s channel in June of this year.\n- YouTube banned David Duke\u2019s channel in June of this year.\n- YouTube banned Richard Spencer\u2019s channel in June of this year.\n- YouTube strengthened its hate speech policy in 2019.\n- YouTube altered its recommendation system to limit the spread of borderline content.\n- YouTube reported a fivefold spike in the number of hate videos removed from the platform.\n- YouTube terminated 1.8 million channels for violating its policies in the last quarter.\n- YouTube terminated 54,000 channels for hate speech in that quarter.\n- YouTube removed more than 9,000 channels for violating rules against promoting violent extremism.\n- YouTube removed more than 200,000 videos for violating rules against promoting violent extremism.\n- Many of the YouTube links the Christchurch shooter shared have been removed for breaching YouTube\u2019s moderation policies.\n- Social media platforms removed popular content creators from their services.\n- Platforms hired thousands more moderators to address extremist content.\n- Facebook banned over 250 white supremacist groups from its platforms.\n- Facebook strengthened its dangerous individuals and groups policy.\n- The Anti-Defamation League consulted with YouTube.\n- Facebook and Instagram flagged multiple images related to the Lekki toll gate incident as misinformation.\n- Facebook and Instagram added a caution label stating \"False Information. The same information was checked in another post by independent fact-checkers.\" to the images.\n- Facebook reduced the visibility of posts it confirmed to be inaccurate across users' timelines.\n- Facebook labeled posts according to independent fact-checkers' ratings, such as false, partly false, altered, missing context, satire, and true.\n- Facebook left the images on the platforms but de-emphasized them instead of removing them entirely.\n- Publishers could dispute a fact-check rating and request that the content's validity be rechecked.\n- The Nigerian Army labeled the Lekki toll gate event as 'fake news'.\n- AFP acknowledged Amnesty International Nigeria's report about the killings in Lagos.\n- Facebook used a hybrid system of human moderators and artificial intelligence to check misinformation.\n- Facebook partnered with certified independent third-party fact-checking organizations to identify, review, and confirm potentially inaccurate content.\n- Facebook flagged content based on feedback from users, its signal technology, or independent fact-checkers.\n- HUD charged Facebook with encouraging and enabling housing discrimination through its targeted advertising practices.\n- HUD conducted a months-long investigation into whether Facebook illegally allowed real estate sellers to restrict their advertisements by characteristics such as race.\n- Facebook agreed to enact sweeping reforms to its ad-targeting system as part of a settlement with civil rights groups.\n- As part of the settlement, Facebook will no longer allow advertisers to target or exclude housing ads by age.\n- As part of the settlement, Facebook will no longer allow advertisers to target or exclude housing ads by gender.\n- As part of the settlement, Facebook will no longer allow advertisers to target or exclude housing ads by zip code.\n- Facebook removed hundreds of targeting options for anyone advertising housing, credit or employment opportunities.\n- Facebook said it will create a new portal to allow users to search for and view housing ads in the U.S. regardless of who the advertisers hoped to target.\n- Facebook eliminated thousands of targeting options last year that advertisers could use to exclude audiences based on ethnicity, gender and religion.\n- Facebook removed thousands of targeting options last August.\n- Facebook reached historic agreements with the National Fair Housing Alliance, the ACLU, and others that change the way housing, credit and employment ads can be run on Facebook.\n- Facebook enacted changes to its platform to undercut misuse by advertisers.\n- Facebook said it would continue working with civil rights experts on these issues.\n- Converted Incident 21 (Tougher Turing Test Exposes Chatbots\u2019 Stupidity) into an 'issue' following an update to the incident definition and ingestion criteria.\n- Converted Incident 62 (Bad AI-Written Christmas Carols) into an 'issue' following an update to the incident definition and ingestion criteria.\n- Converted Incident 159 (Tesla Autopilot\u2019s Lane Recognition Allegedly Vulnerable to Adversarial Attacks) into an 'issue' following an update to the incident definition and ingestion criteria.\n- Converted Incident 287 (OpenAI\u2019s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm) into an 'issue' following an update to the incident definition and ingestion criteria.\n- Converted Incident 298 (Student-Developed Facial Recognition App Raised Ethical Concerns) into an 'issue' following an update to the incident definition and ingestion criteria.\n- Converted Incident 85 (AI attempts to ease fear of robots, blurts out it can\u2019t \u2018avoid destroying humankind\u2019) into an 'issue' following an update to the incident definition and ingestion criteria.\n- Editors confirmed the migration of Incident 85, stating it likely did not fit current incident criteria.\n- The Huntington Park Police Department is developing protocols to fully adopt the robot program.\n- The police are working on activating the robot's live video feature so officers can access footage directly on their phones.\n- The department plans to fully connect the robot so its alert button calls go directly to the police dispatch center.\n- The city will post signage explaining the robot's capabilities and purpose once its features are properly connected.\n- Officers used HP RoboCop's footage to track down the suspects involved in the robot tipping incident.\n- After instances of the robot being vandalized, the police contacted Knightscope to review the robot's footage.\n- The Houston Federation of Teachers Local 2415 and six Houston ISD teachers sued the district in April 2014.\n- The plaintiffs filed a first amended lawsuit in February 2015.\n- U.S. Magistrate Judge Stephen Smith refused to dismiss the teachers' procedural due process claims in a May 4 opinion.\n- Judge Smith dismissed the union's substantive due process claims.\n- Houston ISD ended its contract with SAS in 2016.\n- Houston ISD did not replace the teacher-evaluation system with other software after ending the contract.\n- Houston ISD is investigating all of its options for value-added modeling going forward, including SAS's EVAAS product.\n- Microsoft declined to comment.\n- SpamAssassin's rules are changed based on daily checks on training data submitted by users.\n- In July, SpamAssassin announced that its next release would use 'welcomelist' and 'blocklist' to replace the racially-charged terms previously used.\n- The SpamAssassin Project Management Committee did not answer the reporters' questions.\n- The SpamAssassin Project Management Committee stated that problems with specific rules were managed by 'the community'.\n- Mallika Mendu stopped using the race-based eGFR calculation with her own patients.\n- Representative Richard Neal asked medical societies and the Centers for Medicare & Medicaid Services to investigate the impact on patients of clinical algorithms that use race.\n- Senator Elizabeth Warren and others asked the Department of Health and Human Services to investigate race-based medical algorithms.\n- Leaders at Mass General Brigham abandoned the race-based eGFR formula in June.\n- The University of Washington abandoned the race-based eGFR formula.\n- Vanderbilt abandoned the race-based eGFR formula.\n- The two leading US kidney care organizations formed a task force on the issue.\n- More than 1,300 people signed a petition urging the task force to act.\n- The Home Office said it will continue to develop and evaluate its automated passport photo-checking systems to make applying for a passport as simple as possible for all.\n- The BBC fed a database of 1,130 passport-style photos into the automated online checker and recorded the quality scores as part of its investigation.\n- Kirstie Whitaker reviewed the BBC's code used in the analysis.\n- Kirstie Whitaker independently reproduced the BBC's results.\n- Kirstie Whitaker provided input on the validity of the reported outcomes.\n- Affected applicant Elaine Owusu challenged the website's verdict by writing a note stating her mouth was closed, which resulted in her photo being approved.\n- The couple filed a formal internal complaint with Apple customer service about Jamie Hansson's credit limit.\n- Apple customer service representatives repeatedly assured the couple there was no discrimination and cited the algorithm that makes Apple Card\u2019s credit assessments.\n- Jamie Hansson\u2019s credit limit was bumped up to match David Heinemeier Hansson\u2019s credit limit.\n- New York State Department of Financial Services announced it would investigate the Apple Card algorithm over claims of discrimination.\n- The New York State Department of Financial Services stated it wants to work with the tech community to ensure algorithms do not discriminate and treat individuals equally and fairly.\n- Goldman Sachs issued a public statement responding to the outcry stressing that credit assessments are made based on individual income and creditworthiness.\n- Goldman Sachs stated in its response that it has not and will not make decisions based on factors like gender.\n- An Italian court ruled that the algorithm used by Deliveroo to rank and offer shifts was discriminatory.\n- The court ordered Deliveroo to pay \u20ac50,000 to the suing parties.\n- Presiding judge Chiara Zompi wrote a detailed ordinance analyzing and describing the algorithm used to assess riders' reliability.\n- The court determined that companies can be held liable and forced to pay damages even if an algorithm unintentionally discriminates against a protected group.\n- Deliveroo stated that it no longer uses the historic optional booking shift model outlined in the judgment and that there is no booking system or obligation to accept work in Italy or other markets.\n- Amazon assigned dozens of seasonal part-time workers with little training to monitor the problems of millions of drivers.\n- The authors released research results analyzing the potential impact of using ZIP codes instead of census tracts for vaccine allocation.\n- The authors published an interactive map that allows people to explore the results of the state's distribution algorithm in their own community.\n- The authors called on the California Department of Public Health to review the 469 census tracts where 2 million Californians live and explain how the state will ensure those people will not be left behind.\n- The state publicly stated that tracking vaccine delivery to ZIP codes is operationally simpler than using census tracts.\n- Governor Newsom and the California Department of Public Health publicly recognized that the pandemic did not affect California communities equally.\n- Around 400 people filed a class action suit against Scatter Lab claiming their personal information was leaked.\n- The Lee Luda service was ended one week after launch.\n- Taerim, the law firm representing the victims, said it would close the applications for the class action.\n- Taerim said it would review later whether to collect additional victims.\n- The defendants submitted an application for preservation of evidence against Scatter Lab with the Seoul Eastern District Court.\n- They asked the court to ensure that Scatter Lab preserved the database built using users\u2019 KakaoTalk conversations as evidence for their case.\n- The Personal Information Protection Committee is investigating whether the service violated the personal information protection law.\n- The Korea Internet & Security Agency is investigating whether the service violated the personal information protection law.\n- Civic groups filed a complaint with the Personal Information Protection Committee.\n- The civic groups called for a thorough investigation of Scatter Lab.\n- The company announced it was shutting down Genderify.\n- Genderify.com was taken offline.\n- The service's free API was made inaccessible.\n- The company said it was actively looking into ways of improving the experience for transgender and non-binary visitors by separating the concepts of name/username/email from gender identity.\n- The company stated it relied on feedback from transgender and non-binary visitors to help improve its gender-detection algorithms.\n- The Maldonado family filed a lawsuit in Alameda County Superior Court alleging defects in Autopilot.\n- Benjamin Swanson, the Maldonados\u2019 lawyer, obtained video and data from Tesla and shared them with The New York Times.\n- A Tesla official said that if a crash occurs the car automatically saves the short video clips and uploads them to Tesla\u2019s servers.\n- In emails filed as exhibits in court, Tesla lawyer Ryan McCarthy asserted that the driver, not the car, bore responsibility for the crash.\n- The National Highway Traffic Safety Administration has about two dozen active investigations into crashes involving Autopilot.\n- In June, the National Highway Traffic Safety Administration released a list showing that at least ten people have been killed in eight accidents involving Autopilot since 2016.\n- In June, the National Highway Traffic Safety Administration said it would require all automakers to report accidents involving driver-assistance systems like Autopilot.\n- The National Transportation Safety Board completed investigations into accidents involving Autopilot.\n- The National Transportation Safety Board stated that Autopilot lacks safeguards to prevent misuse and does not effectively monitor drivers.\n- The California Highway Patrol arrested a man who got out of the driver\u2019s seat of his Model 3 while it was moving.\n- A lawsuit was filed in April in Florida state court concerning a 2019 Key Largo crash in which a Tesla with Autopilot failed to stop and killed Naibel Leon.\n- A lawsuit was filed in May in California by Darel Kyle over serious spinal injuries he suffered when a Tesla under Autopilot rear-ended his van.\n- PimEyes allows anyone to request a photo's removal using an online form, one image at a time.\n- PimEyes offers a \"PROtect\" package that completely blocks photos from appearing in PimEyes's search results for $79.99 per month.\n- PimEyes deleted a webpage that had stated it had analyzed 900 million unique faces.\n- Half a dozen U.S. states have banned or restricted facial recognition technology for public use.\n- Roughly two dozen U.S. cities have banned or restricted facial recognition technology for public use.\n- The U.S. Government Accountability Office urged Congress to strengthen face-scan laws.\n- Amazon halted its sale of facial recognition technology to police for one year.\n- Microsoft announced it would not sell facial recognition technology to police until a federal law is enacted.\n- An online crowdsourced collective of \"sedition hunters\" used PimEyes to pursue and identify U.S. Capitol rioters.\n- A photo researcher in London spent hours using PimEyes to identify members of the mob that stormed the U.S. Capitol and found a suspect's decade-old mug shot.\n- An AI data scientist using the online name \"Patr10tic\" used an open-source face extractor to pull facial images from more than 40,000 videos uploaded to Parler.\n- That AI data scientist built a cluster map of those faces and a detailed location map pinpointing where the videos had first been made.\n- Prime Minister Mark Rutte and his entire cabinet resigned.\n- A year-and-a-half of investigations revealed that since 2013, 26,000 families were wrongly accused of social benefits fraud.\n- The Dutch Data Protection Authority conducted an investigation and found that the algorithms were inherently discriminatory because they used variables such as whether someone had a second nationality.\n- Journalists conducted relentless investigative reporting that exposed the role of algorithms and automated systems in the scandal.\n- The Dutch daily newspaper Trouw conducted an investigation that found parents accused of fraud were labeled as 'intent / gross negligence'.\n- Parliament held a string of parliamentary hearings following the scandal.\n- The municipality of Amsterdam created an algorithm register to increase algorithmic transparency.\n- The families wrongly accused are to be given \u20ac30,000 each in compensation.\n- Twitter stopped using the automatic image-cropping (saliency) algorithm for single photos posted via its smartphone app.\n- Twitter plans to end use of the saliency algorithm on the Twitter website.\n- Twitter now center-crops excessively tall or wide photos.\n- Twitter published the saliency-analysis study on the arXiv preprint repository.\n- Twitter submitted the saliency-analysis study to a research conference to be held in October.\n- Twitter launched the ML Ethics, Transparency, and Accountability (META) Team.\n- META plans to assess how the Twitter home page recommendation algorithms treat certain racial groups and how Twitter's AI treats people based on political ideologies.\n- The META team is creating fairness metrics for Twitter's model experimentation platform.\n- The META team is creating standards for the ethical review of algorithms.\n- The company conducts risk assessments around privacy and security.\n- The article was updated to remove incorrect information that San Jose was using ShotSpotter.\n- Councilwoman Dolores Morales asked that the process slow down so city staff could look at other companies that provide similar products.\n- City Manager Brett Miller indicated there is no date set to bring ShotSpotter back to the council for consideration.\n- Hollister Police Chief Carlos Reynoso said he is reaching out to other city police departments to research the system.\n- The Vallejo City Council voted in June 2022 to delay approving the system after the city\u2019s police chief asked for 80 to 100 devices to be installed in the city.\n- The Oakland Police Department releases a weekly ShotSpotter activity report.\n- The Oakland Police Department chose to install the sensors in areas most prone to gunshots based upon historical data.\n- I sent an email to the welfare office explaining the mistake in my file.\n- I booked a phone appointment with my caseworker for 26 March.\n- A welfare office employee left a voicemail stating that they had read my email.\n- A welfare office employee canceled the \u20ac542 debt.\n- A welfare office employee closed the issue.\n- During the phone meeting, my caseworker confirmed that the software had analyzed my file automatically using parameters.\n- The French data protection authority declined to answer my questions.\n- Amazon employees manually review all appealed Netradyne events to ensure erroneous events do not impact drivers or delivery companies.\n- Amazon requires each Delivery Service Partner to be trained on the safety technology and to communicate to their teams how events impact the DSP scorecard.\n- Amazon provides an automated appeal portal where delivery companies can submit feedback tickets to dispute events.\n- Amazon allots delivery companies four weeks of practice with Netradyne cameras before the cameras' metrics impact their scorecards.\n- Some delivery companies encouraged drivers to shut off the Mentor app that monitors safety in order to meet delivery quotas.\n- Some drivers began placing stickers over the cameras to prevent the cameras from recording footage.\n- Some delivery companies emailed Amazon to request access to photos flagged as events and to contest those events on behalf of drivers.\n- Two Amazon delivery companies in Portland terminated their contracts with Amazon in protest citing the Netradyne cameras.\n- Delivery companies call and reprimand drivers who receive Netradyne events.\n- Philip Winston wrote on his blog that the posts reminded him of text from OpenAI's GPT-3.\n- Philip Winston shared his theory on the subreddit /r/GPT3.\n- Redditor Wiskkey informed the app's developer, Murat Ayfer, about the suspicious posts.\n- Murat Ayfer confirmed the posts had been produced by the Philosopher AI.\n- Murat Ayfer said the bot detection seemed to be broken and began fixing it immediately.\n- Murat Ayfer appears to have resolved the problem.\n- Legal Aid of Arkansas filed a federal lawsuit in 2016 challenging the state's use of the algorithm.\n- The math behind the algorithm was disclosed following the filing of the lawsuit.\n- During court proceedings the state acknowledged an implementation mistake and restored Ethel Jacobs' care hours.\n- The federal judge ruled that the state had insufficiently implemented the program.\n- The state subsequently made changes to help people understand the system, including publishing lists showing exactly which assessment items changed from year to year.\n- The state changed its notification system to comply with the court ruling.\n- After changing its notification system the state reimplemented the algorithm.\n- The Department of Human Services reinstated Tammy Dobbs' hours during her appeal.\n- Arkansas officials said they will migrate to a new system and software provider to calculate hours in a different way.\n- Brant Fries wrote a report to the state noting that about 19 percent of beneficiaries were negatively impacted by the diabetes omission and recommending that moving back to the original algorithm would be responsive to trial results.\n- In Idaho the state agreed to improve the tool and create a system that would be more transparent, understandable, and fair after litigation.\n- The local ACLU branch brought a lawsuit in 2012 on behalf of Idaho program beneficiaries.\n- Attorney Kevin De Liban began keeping a list of 'algorithmic absurdities' as part of investigating the assessment changes.\n- One of the arena's managers called Lamya Robinson's mother to discuss the issue.\n- The roller rink issued a public statement noting the software showed a 97 percent match and apologizing for any mistake.\n- The ACLU called for a moratorium on law enforcement use of face surveillance.\n- The Congressional Black Caucus sent a letter to Amazon CEO Jeff Bezos expressing concern about the \"profound negative unintended consequences\" of face surveillance.\n- Amazon employees, shareholders, a coalition of nearly 70 civil rights groups, over 400 members of the academic community, and more than 150,000 members of the public have spoken up to demand that Amazon stop providing face surveillance to the government.\n- Huawei told IPVM that the Uighur detection should never have been part of the patent application.\n- Huawei told IPVM that it was taking proactive steps to amend the patent application.\n- Megvii told the BBC that it would withdraw the patent.\n- SenseTime said the patent was regrettable and that it would update the patent at the next available opportunity on record.\n- Alibaba told IPVM that ethnic discrimination violates its policies and values.\n- Huawei told IPVM that it had never developed or permitted its technology to profile any ethnic group.\n- Xsolla confirmed the authenticity of the leaked CEO letter.\n- Aleksandr Agapitov gave an interview to App2Top.ru in which he said the company sometimes must take difficult and unpopular measures to keep growing.\n- Aleksandr Agapitov held a press conference and explained that the mass layoffs were due to the company no longer showing 40% growth.\n- Aleksandr Agapitov released another controversial statement on Twitter.\n- Nadia and her care team partnered with seven leading HR agencies to help dismissed employees find new jobs.\n- Sasha will help dismissed employees obtain recommendations, including one from the CEO.\n- Natalia will inform dismissed employees of their rights.\n- All employees will receive compensation packages.\n- All employees will receive help from HR agencies.\n- EAB provides its clients with up to 200 hours of training and consultation per year, some of which is devoted to avoiding bias in its analytics.\n- EAB has been trying to move away from using phrases like \"high risk\" in training sessions to reduce misinterpretation and stigma.\n- In a document prepared for Rutgers University, EAB advised that advisers should not tell all high-risk students to switch to a different major.\n- In the same Rutgers document, EAB advised that advisers should explain students' risk scores to create a sense of urgency and encourage students to explore major options and which courses to take.\n- UMass Amherst and the University of Houston either rejected public records requests for their predictive model summaries or heavily redacted their responses.\n- Simon Newman, the president of Mount St. Mary's University, resigned shortly after the student newspaper published his comments proposing the use of student data to cull incoming classes.\n- The United Nations Panel of Experts published a report in March 2021 revealing the use of lethal autonomous weapons (STM Kargu-2) in Libya.\n- The United Nations Panel of Experts sent a letter dated 8 March 2021 with its findings to the UN Security Council.\n- Electronic jamming from the Koral electronic warfare system was used to neutralize unmanned combat aerial vehicles and small drone intelligence, surveillance, and reconnaissance capabilities of the HAF.\n- Facebook disabled the artificial intelligence-powered feature that pushed the 'primates' recommendation prompt.\n- Facebook announced it was investigating the recommendation feature to prevent this from happening again.\n- Facebook apologized for what it called 'an unacceptable error.'\n- A product manager for Facebook Watch called the prompt 'unacceptable.'\n- A product manager for Facebook Watch said the company was looking into the root cause of the prompt.\n- Darci Groves posted a screenshot of the prompt to a product feedback forum for current and former Facebook employees.\n- Facebook agreed to pay $550 million to settle a class-action lawsuit regarding its use of facial recognition technology.\n- The $550 million settlement will be paid out to eligible Illinois users.\n- The $550 million settlement will cover the plaintiffs' legal fees.\n- Facebook disclosed the settlement as part of its fourth-quarter earnings report.\n- In 2018, Facebook began more transparently explaining its facial recognition technology to users.\n- Facebook pointed users to a settings page where they could disable facial recognition.\n- The company decided to make facial recognition on the platform opt-in only.\n- Facebook appealed the class-action certification ruling.\n- Google stated it has been working on accurately recognizing variations of speech for several years and will continue to do so.\n- IBM stated it continues to develop, improve, and advance its natural language and speech processing capabilities to bring increasing levels of functionality to business users via IBM Watson.\n- The Stanford researchers urged makers of speech recognition systems to collect better data on African American Vernacular English and other varieties of English, including regional accents.\n- OpenAI released GPT-3 only to a restricted group of vetted developers and companies.\n- OpenAI required those vetted developers and companies to minimize potential social harms caused by their applications.\n- OpenAI established an academic access program allowing scholars to request access to probe GPT-3 for bias.\n- Abid and his co-authors reduced biased outputs by front-loading the 'Two Muslims walked into a \u2026' prompt with a short positive phrase.\n- OpenAI researchers fine-tuned GPT-3 by giving it an extra round of training on a smaller, more curated dataset.\n- Researchers supplied the original GPT-3 with 80 well-crafted question-and-answer text samples to change its behavior.\n- OpenAI researchers are continuing to experiment with fine-tuning approaches to reduce bias.\n- Another team is attempting to improve the initial training dataset to make it less biased.\n- ProctorU employs human proctors who make final decisions on student identity and verify exam integrity.\n- ProctorU uses a diverse group of trained human proctors assisted by technology to safeguard exam integrity and assist students.\n- The University of Toronto has vetted and approved ProctorU's systems and protocols for remote test proctoring.\n- The University of Toronto continuously monitors issues that arise around e-proctoring.\n- The University administration issued guidance that e-proctoring should not be the first or only way divisions seek to ensure academic integrity on assessments.\n- Any issues flagged by the e-proctoring system are reviewed in the first instance by instructors.\n- The University of Toronto offers anti-racism and unconscious bias training to all members of its community.\n- The Centre for Teaching Support & Innovation advised that online proctoring should be considered only for unique situations or needs given the additional logistical challenges and potential equity issues.\n- Six Democratic U.S. Senators wrote an open letter highlighting issues of privacy, accessibility, and equity with exam monitoring services.\n- The District Court rejected the farm\u2019s appeal to receive the program's code and accepted the state's position.\n- The farm appealed the District Court ruling to the Supreme Court.\n- The Movement for Freedom of Information asked to join the appeal as a friend of the court.\n- The Movement for Freedom of Information submitted a written position arguing that the term 'information' includes software, code, or algorithms.\n- The state retracted its position in the case.\n- The Justice Ministry began debating whether software or its source code can be considered 'information' that must be disclosed.\n- The Supreme Court returned the case to the District Court to complete the process.\n- In a related class action, a judge ruled in favor of the plaintiff and ordered Israel to pay compensation of over 2 million shekels.\n- Over 600 people endorsed the community-driven Overlay Factsheet opposing overlay products.\n- More than 200 companies were sued in 2021 despite having purchased an overlay.\n- Ninety-five companies with accessiBe installed were named in lawsuits filed in 2021.\n- UserWay deleted a tweet dated November 3, 2021 that suggested their widget is a suitable alternative to major screen readers.\n- The National Federation of the Blind publicly stated that accessiBe engages in behavior harmful to the advancement of blind people.\n- Vispero/Freedom Scientific publicly stated that neither it nor any of its developers have ever worked with accessiBe on products or services.\n- Accessibility consultant Adrian Roselli identified and reported instances in which accessiBe made false claims about collaborating with JAWS developers.\n- Accessibility experts provide consultation to help companies establish development processes that make digital technologies accessible by design.\n- Facebook's integrity team worked to track down exploitations of the News Feed algorithm and figure out how to mitigate them.\n- Data scientists on the integrity team worked on a number of potential changes to curb the algorithm's tendency to reward outrage, misinformation, and divisive content.\n- Anna Stepanov presented several proposed changes to Mark Zuckerberg intended to address the proliferation of false and divisive content on the platform.\n- One proposed change would have removed the algorithmic boost given to content most likely to be reshared by long chains of users.\n- In April 2019 a Facebook data scientist proposed reducing the spread of 'deep reshares.'\n- Facebook reduced the downstream MSI aspect of its algorithm for civic and health information in the spring of 2020.\n- Facebook had already applied similar downstream MSI reductions in a few countries such as Ethiopia and Myanmar.\n- Facebook announced it was gradually expanding tests to put less emphasis on signals such as how likely someone is to comment or share political content.\n- Facebook researchers and data scientists wrote internal memos flagging unhealthy side effects of the MSI ranking and documenting that misinformation, toxicity, and violent content were disproportionately prevalent among reshares.\n- California sent 'Chapter 6' notices to applicants flagged by the proctoring software alleging issues such as a prolonged lack of facial view or no audible sound.\n- California issued 'order to show cause' notices asking many flagged applicants to prove they were not cheating.\n- Flagged cases were to be reviewed by human examiners who are supposed to parse through the video to verify whether flagged behavior was a false positive.\n- Applicants have reportedly been required to respond to vague allegations without being allowed to view the video evidence.\n- Los Angeles County prosecutors filed two counts of vehicular manslaughter against the Tesla driver, Kevin George Aziz Riad.\n- The National Highway Traffic Safety Administration sent investigators to the Gardena crash.\n- The National Highway Traffic Safety Administration and the National Transportation Safety Board have been reviewing the widespread misuse of Autopilot.\n- NHTSA has sent investigation teams to 26 crashes involving Autopilot since 2016.\n- NHTSA is investigating a dozen crashes in which a Tesla on Autopilot ran into several parked emergency vehicles.\n- NHTSA issued a public statement saying there is no vehicle on sale that can drive itself.\n- NHTSA stated that, whether or not a car is using a partially automated system, every vehicle requires the human driver to be in control at all times.\n- Tesla updated Autopilot software to try to make it harder for drivers to abuse it.\n- Tesla attempted to improve Autopilot's ability to detect emergency vehicles.\n- The families of Gilberto Alcazar Lopez and Maria Guadalupe Nieves-Lopez sued Tesla and Kevin Riad in separate lawsuits.\n- A joint trial for the lawsuits against Tesla and Riad is scheduled for mid-2023.\n- In 2020, Rafaela Vasquez was charged with negligent homicide after the Uber autonomous test vehicle struck and killed a pedestrian.\n- A California man was arrested after officers observed his Tesla moving down a freeway with the man in the back seat and no one behind the steering wheel.\n- Arizona prosecutors declined to file criminal charges against Uber after the 2018 autonomous vehicle fatality.\n- Amazon committed over $1 billion in new investments in operations safety measures.\n- Amazon distributed masks to employees.\n- Amazon distributed gloves to employees.\n- Amazon implemented enhanced cleaning and sanitization to protect employees from COVID-19.\n- Amazon installed guardrails to separate forklifts from pedestrians.\n- Amazon increased safety staffing.\n- Amazon offered wellness exercises to employees.\n- Amazon invested in safety training and education programs.\n- Amazon invested in safety technology and new safety infrastructure.\n- Amazon's environment, health and safety team sent monthly detailed updates marked 'Privileged & Confidential' to warehouse safety managers with data, charts and FAQs.\n- Amazon set safety goals and monitored progress closely.\n- Amazon piloted rotating workers to different jobs to alleviate repetitive stress.\n- Half of the pilot sites turned off sort rotation during Prime Week.\n- Amazon piloted blocking off the highest and lowest shelves on warehouse racks to optimize work allocation to associates' power zones.\n- Five of six warehouses testing the shelf-blocking pilot put the program on hold for the runup to Prime Day.\n- Amazon's safety team rolled out an initiative called 'temporary light duty' to reduce lost-time injuries by reassigning injured workers.\n- Amazon reassigned injured workers to tag photos on a computer to help train the company's machine learning algorithms as part of temporary light duty.\n- Amazon loaned injured workers to nonprofit organizations as part of temporary light-duty assignments.\n- Amazon terminated the use of an occupational clinic with poor performance for its Thornton, Colorado warehouse.\n- Amazon contracted with Advanced Urgent Care & Occupational Medicine as a new clinic for injured Colorado workers.\n- Amazon sought to ensure stronger use of its on-site AmCare first aid clinic and to reduce the probability of associates transitioning to external clinic care.\n- Advanced Urgent Care & Occupational Medicine's medical director instructed clinic staff to contact her or the clinic owner before giving restrictions or making Amazon cases OSHA-recordable.\n- The owner of Advanced Urgent Care & Occupational Medicine decided to stop providing occupational medical care for companies, including Amazon, at the end of the year.\n- Amazon's vice president of public policy wrote to U.S. senators asserting the company changed its approach to recordkeeping in 2016 to report all injuries.\n- Amazon's senior vice president for global corporate affairs went on CNBC to publicly defend the company's reporting and policies.\n- A group of 15 U.S. senators sent a letter to Jeff Bezos demanding a list of changes in Amazon's warehouses.\n- OSHA issued a hazard alert letter against an Amazon robotic warehouse in New Jersey and recommended measures such as an extra rest break and rotating employees to different jobs.\n- OSHA fined Amazon $7,000 for failing to record more than two dozen injuries as required.\n- Amazon invested $800 million on COVID-19 safety measures in the first half of the year.\n- Amazon fired a worker who helped organize a walkout at its Staten Island fulfillment center.\n- Amazon fired two tech employees who spoke up in support of the Staten Island worker.\n- Amazon provided talking points to safety managers to pass along to workers during peak times.\n- The University of Illinois announced it will discontinue use of Proctorio and that the software will be discontinued in mid-2021.\n- More than 1,000 students and teachers signed a petition asking the University of Illinois to discontinue Proctorio.\n- A university in Miami discontinued its remote-testing software after a petition with more than 500 signatures was passed.\n- The University of Regina announced it will discontinue ProctorTrack after a petition with 3,500 signatures was passed.\n- The University of Central Florida announced it will discontinue Honorlock after a petition with 1,200 signatures was passed.\n- Proctorio denied that the software discriminates and stated that lighting, webcam position, and webcam quality are the reasons it may not work properly.\n- Activists have launched movements to ban remote-testing software.\n- TikTok banned six accounts reported for posting content promoting eating habits that are likely to lead to health problems.\n- TikTok said users searching for eating disorder-related content will be redirected to the National Eating Disorder Association (NEDA) helpline.\n- TikTok said it would prohibit ads promoting fasting apps and weight loss gimmicks to users under 18.\n- The platform banned content labeled #proana and #anorexia.\n- Users who searched for the #proana and #anorexia hashtags were redirected to a support page titled \"Need Help?\"\n- Pinterest trained its algorithm to recognize content that promotes self-harm, which the company reported reduced those pins by 88%.\n- When users specifically search for the remaining Pins, Pinterest recommends a series of wellbeing exercises.\n- TikTok provided a public statement to BuzzFeed asserting that its recommendation algorithm is based on user behavior via collaborative filtering and not on race or the account's picture.\n- In December, TikTok admitted that it had been burying content made by queer, fat, and disabled users.\n- Facebook decreased the reach of suspect content on its platform.\n- Facebook removed some, though not all, of the barriers users faced when filing reports.\n- Facebook intentionally made it harder for users to file reports two years ago.\n- Facebook tweaked its algorithm in a way that led it to ignore more user reports.\n- Facebook proactively removed 15 times more hate speech in 2020 than in 2017.\n- Facebook's engineers shifted model training to prioritize avoiding false positives.\n- Facebook set a goal to reduce the dollar cost of total hate review capacity by 15%.\n- The Delphi website includes a disclaimer stating that it is currently in beta and should not be used for advice or to aid in social understanding of humans.\n- The team added a later disclaimer to the website stating that the AI simply guesses what an average American might think of a given situation.\n- Co-author Liwei Jiang publicly told Futurism that Delphi is a research prototype not built to give people advice and is meant to investigate how AI systems can understand social norms and ethics.\n- YouTube reinstated Antonio Radic's channel 24 hours after it was blocked.\n- Agadmator appealed the video's removal.\n- YouTube offers uploaders the ability to appeal removals and will re-review the content.\n- YouTube stated that when a video has been removed mistakenly it acts quickly to reinstate it.\n- KhudaBukhsh and Rupak Sarkar ran tests on two speech-classifier AI systems to test whether chess language was being misclassified.\n- The researchers ran the classifiers on over 680,000 comments from five popular YouTube chess channels and found that 82 percent of flagged comments lacked obvious racist language.\n- The researchers suggested that social-media platforms incorporate chess language into their algorithms to prevent further confusion.\n- Amazon updated Alexa to prevent the assistant from recommending the penny challenge or similar dangerous activities in the future.\n- Amazon fixed the error as soon as the company became aware of it.\n- Nissei Eco Co. fired Pepper.\n- Nissei Eco Co. ended its lease of the robot.\n- Nissei Eco Co. sent the robot back to the manufacturer.\n- SoftBank halted production of Pepper last year.\n- SoftBank said it was planning to restructure its global robotics teams, including a French unit involved in Pepper\u2019s development.\n- Ittokai pulled the plug on its use of three Pepper units after three years.\n- Mizuho Financial Group removed Pepper from its bank lobby.\n- Technology journalist Tsutsumu Ishikawa shipped his Pepper robot back to SoftBank in 2018.\n- A former SoftBank Robotics executive founded a startup that makes a round-shaped pet-like robot called Lovot.\n- Panasonic introduced Nicobo this year, a robot designed as a vulnerable creature to draw out its owner\u2019s caring instinct.\n- Rose appealed TikTok's decision to delete her account.\n- TikTok reviewed her appeal and determined her account violated community guidelines and could not be restored.\n- Rose appealed the deletion of her bio.\n- TikTok immediately restored her bio after she appealed.\n- Rose reported the videos reposted by the user @ey.yo.wtf that used her content and spread hate.\n- TikTok's algorithm concluded that those reposted videos did not violate their community guidelines.\n- Rose repeatedly blocked the user @ey.yo.wtf.\n- Rose appealed many of the video removals.\n- TikTok approved the majority of her appeals and restored most of her content.\n- After her appeal was denied, Rose went live on a new TikTok account.\n- Rose shared a link to a petition and asked people to sign it.\n- Tesla solved the Burger King bug in a subsequent software update.\n- Burger King launched a free Whopper promotion for any Tesla owner whose car accidentally stopped at a Burger King sign.\n- The shopping guide robot was suspended.\n- The robot company will analyze the cause of the accident.\n- Adalytics published an exploratory study quantifying the negative impact of brand safety technologies on mainstream publishers' ad revenues.\n- Adalytics compared different brand safety vendors' article categorizations to quantify how often vendors disagree about 'safe' versus 'unsafe' labels.\n- The authors reviewed past cases where entire sites were blocked or blacklisted due to not-brand-safe content on a few pages.\n- Marketers should stop wasting money on brand safety detection technology that does not work and is actively causing more harm.\n- Marketers should not renew contracts with, and should stop paying, brand safety detection vendors that do more harm than good.\n- Marketers should move to using strict include lists consisting of sites that have real human audiences.\n- Marketers should run ads on real, good, mainstream publishers instead of placing ads across millions of long-tail sites and user-generated-content channels.\n- The University of Texas at Austin stopped using the GRADE machine-learning system to evaluate Ph.D. applicants.\n- The department announced the discontinuation of GRADE in a tweet reply.\n- UT Austin said GRADE was being phased out and its use was discontinued because changes in the data and software environment made the system increasingly difficult to maintain.\n- The Graduate School works with graduate programs and faculty members across campus to promote holistic application review and reduce bias in admissions decisions.\n- Google Maps' team is working to update routes in the Lake Tahoe area using details from local authorities.\n- Google Maps is showing a winter storm warning to alert drivers in the Lake Tahoe area.\n- Google Maps added road closure warnings (red dots with dashes) on the road Ms. Becktold had taken.\n- Waze Community Map Editors continued to keep Waze maps updated with the latest real-time routing information during the storm.\n- Waze issued a statement encouraging drivers to exercise caution and stay alert on the road.\n- The Washoe County Sheriff's Office rescued the stranded family from the snowbound dirt road.\n- The Washoe County Sheriff's Office posted on Facebook about the rescue and warned drivers that GPS had led them to ignore illuminated warning signs.\n- The Washoe County Sheriff's Office issued a public warning that drivers had frequently taken the same detour when using GPS.\n- Caltrans communicated to the public that people should stay on highways and find alternate routes via highways rather than using rural roads.\n- Caltrans recommended that people stay put and wait until interstate or highway closures had been lifted.\n- A local worker in a safety vest waved drivers off the closed road to prevent them from continuing.\n- The Knights contacted the local government office to alert them of the error.\n- A staff member reviewed the photographic evidence during the call.\n- The ticket was thrown out.\n- The Fremont Police Department was called to report the incident and the damaged street sign.\n- Pony.ai subsequently worked with local authorities to resolve all issues related to the damaged sign.\n- On November 19, 2021, the California Department of Motor Vehicles notified Pony.ai that it was suspending Pony.ai's driverless testing permit effective immediately following the reported solo collision.\n- A research team published a JAMA Internal Medicine article that examined the hospital records of 38,455 patients at Michigan Medicine to assess the performance of the Epic Sepsis Model.\n- STAT conducted an investigation and published an article reporting that several Epic algorithms were delivering inaccurate or irrelevant information to hospitals.\n- A bipartisan group of House members sent a letter to Amazon CEO Andy Jassy demanding an accounting of the company's sales of sodium nitrite, details on related suicides, explanations of how the retailer had addressed the dangers, and how it had responded to complaints.\n- Members of Congress sought briefings from Google and other tech companies that help make the suicide website accessible.\n- Members of Congress asked Attorney General Merrick B. Garland to consider ways to prosecute the operators of the suicide website.\n- Brian Huseman, Amazon's vice president for public policy, sent a written response to the lawmakers extending condolences to families and defending Amazon's practices and sales of the compound.\n- eBay prohibited global sales of the compound in 2019 after receiving a report of its potential use in suicides.\n- An eBay director wrote to an English coroner acknowledging that sellers could circumvent eBay's policies and filters.\n- In the same letter, the eBay director stated that the company would support government restrictions on online sales of the chemical to prevent future suicides.\n- Etsy banned sales of the compound in November 2020.\n- Dr. Kyle Pires published an article in Clinical Toxicology encouraging emergency rooms to stock doses of the antidote methylene blue.\n- Coroners in the United Kingdom highlighted suicides involving online purchases of the preservative and asked the government to take action.\n- A cross-government group in the United Kingdom began working with manufacturers and online suppliers to reduce access to the compound and end some sales to individuals.\n- Metalchem, a British vendor, stopped selling the compound to the public in April 2020.\n- Metalchem's chief executive notified an English coroner that he had asked other businesses to stop selling the compound online when the reason for the purchase could not be reasonably ascertained.\n- Lawyers for Ruth Scott wrote to Amazon's general counsel and implored the company to remove the product from its platform.\n- An Amazon customer service representative replied to Ruth Scott that her message would be passed along.\n- Lawyers for Amazon pointed to a Texas law and court decisions protecting sellers of legal products used in suicides in response to requests to remove the product.\n- Platforms notified reporters that the reported post or account violated the rules.\n- Platforms notified reporters that the reported content did not violate the rules.\n- Platforms sent reporters a confirmation that their report had been received.\n- Facebook reviewed the vast majority of reports within 24 hours.\n- Facebook used community reporting, human review, and automation to process reports.\n- Social networks proactively removed hateful or violating content themselves.\n- Facebook proactively detected and removed hate speech content, reporting that about 95% of hate speech content they remove is proactively detected today.\n- Facebook used AI to take action on straightforward cases and prioritized more nuanced cases for human reviewers.\n- Facebook published a Community Standards Enforcement Report on a quarterly basis.\n- Facebook blocked the profile of Bosnian journalist Dragan Bursac for 24 hours after determining his post violated community standards.\n- Both Twitter and Facebook provided an appeals process for suspended or blocked accounts.\n- Between January and October 2020, Facebook restored approximately 50,000 items of content without an appeal.\n- Between January and October 2020, Facebook restored 613,000 items of content after appeals.\n- In the first six months of 2020, Twitter suspended 925,744 accounts, including 127,954 flagged for hateful conduct and 72,139 for abuse/harassment.\n- Twitter removed violating content in a little over 1.9 million cases, including 955,212 in the hateful conduct category and 609,253 in the abuse/harassment category.\n- Companies like Facebook have been sued and, after losing, paid damages related to oversight of violent content.\n- Amazon is defending itself against a lawsuit alleging it is liable for the actions of its contract delivery drivers.\n- Amazon has asserted that it is not liable because the driver was employed by contractor Harper Logistics LLC rather than by Amazon.\n- Amazon told Bloomberg it is committed to the safety of drivers and the communities where it delivers.\n- Amazon stated that it works with delivery contractors to set realistic expectations that do not place undue pressure on them or their delivery associates.\n- The store manager apologized in person to the father who complained about the pregnancy-related mailer.\n- The manager called a few days later to apologize again.\n- Everyone involved decided to slow things down.\n- The marketing department conducted small randomized tests by mailing a small sample of women combinations of advertisements to see how they reacted.\n- Target mixed baby-related ads with unrelated product ads (for example, placing an ad for a lawn mower next to diapers or a coupon for wineglasses next to infant clothes) to make the baby ads look random and avoid 'spooking' recipients.\n- Target declined to speak with the reporter and refused to meet with him when he offered to visit headquarters.\n- Target issued written statements asserting that much of the reporting was inaccurate and stating that it was in compliance with all federal and state laws, including those related to protected health information.\n- The reporter was placed on a list of prohibited visitors and was asked to leave when he attempted to visit Target's headquarters.\n- Mighty Well appealed Facebook's ad rejection for its hoodie.\n- Facebook restored several listings that were wrongly flagged by its automated systems.\n- Facebook apologized for the mistake in flagging adaptive fashion listings.\n- Facebook said it is working to improve its automated systems so that brands do not run into these issues in the future.\n- Affected adaptive clothing companies appealed each rejected ad or product listing individually through Facebook's appeals process.\n- Maura Horton appealed Facebook's ad rejections and successfully overturned at least one rejection.\n- Facebook's automated system acknowledged its mistakes and approved ads about 10 days after each appeal in Ms. Horton's case.\n- Facebook added thousands of content reviewers over the past few years.\n- Helya Mohammadian appealed Slick Chicks' shadow banning by sending roughly one email per day to Facebook customer support for three weeks (about 30 emails).\n- Helya Mohammadian started a change.org petition titled 'Make Social Media More Inclusive' to challenge the platform's bans.\n- Facebook lifted the bans on Slick Chicks' links after the petition and appeals.\n- Care + Wear hired an outside media buying agency in order to reach a Facebook representative by phone.\n- Abilitee repeatedly changed ad wording and resubmitted some products multiple times (up to five times) to try to get them approved.\n- Abilitee stopped attempting to advertise on Facebook and Instagram.\n- Mighty Well removed numerous keywords and hashtags from ads in attempts to comply with Facebook's policies and get them approved.\n- The founder of FFora gave up attempting to list products on Facebook after repeated flags and policy violations.\n- Facebook took out newspaper ads stating it was 'standing up' for small businesses.\n- The United Arab Emirates requested assistance from American investigators to trace roughly $400,000 that went into US-based bank accounts.\n- The Justice Department made tweaks to the Pattern algorithm after finding math and human errors.\n- The department is consulting with experts to make the algorithm fairer.\n- An overhaul of the Pattern tool is already underway.\n- Attorney General Merrick Garland directed the Justice Department to look for ways to assess racial bias and make the tool more transparent.\n- One option under consideration is adjusting the cutoff points between risk categories to allow more prisoners to earn credits for release.\n- Attorney General Merrick Garland will have to sign off on a new version of Pattern.\n- The Justice Department must reevaluate the roughly 14,000 people who were placed into the wrong risk categories.\n- PULSE\u2019s creators posted on GitHub acknowledging that PULSE produced white faces more frequently and attributing the bias likely to StyleGAN\u2019s training dataset.\n- Mario Klingemann experimented with a different search method by starting gradient descent from different random locations in StyleGAN\u2019s latent space to generate more non-white outputs from the same pixelated Obama image.\n- Yann LeCun tweeted that machine learning systems are biased when data is biased and argued that this sort of bias is more serious in deployed products than in academic papers.\n- Yann LeCun later acknowledged in a subsequent Twitter thread that there were multiple causes for AI bias.\n- When contacted by The Verge, Yann LeCun provided additional comments noting that he had helped set up groups inside and outside Facebook focusing on AI fairness and safety, including the Partnership on AI.\n- The Verge updated the article to include additional comment from Yann LeCun.\n- Deborah Raji publicly criticized the negligence of not testing for people of color and highlighted the lack of diversity among those who build AI systems.\n- Zillow shut down its Zillow Offers business entirely.\n- Zillow updated the Zillow Offers webpage to note it was winding down the service and stopped making new offers on homes.\n- Zillow planned to cut 2,000 jobs, representing 25% of its staff.\n- Zillow took a $304 million inventory write-down in the third quarter.\n- The company that developed the algorithm confirmed the problem.\n- The company said it is working to address the problem in the algorithm.\n- Optum issued a statement advising that doctors should not use algorithmic risk scores alone to make decisions about patients and that these tools should not be viewed as a substitute for a doctor's expertise.\n- Researchers published their findings about the algorithm's biased performance in the journal Science.\n- Ziad Obermeyer presented the project's findings in a talk during the summer.\n- The incident definition and ingestion criteria were updated.\n- The listed former incidents were converted to 'issues' following the update to the incident definition and ingestion criteria.\n- Editors confirmed the migration (downgrade) of Incident 85, determining it likely did not fit current incident criteria.\n- Dr. Kosinski met with campus police because of the number of death threats he received.\n- Glaad denounced the study as \"junk science\" that \"threatens the safety and privacy of LGBTQ and non-LGBTQ people alike.\"\n- The Human Rights Campaign denounced the study as \"junk science\" that \"threatens the safety and privacy of LGBTQ and non-LGBTQ people alike.\"\n- Dozens of academics, scientists and others publicly criticized and \"picked apart\" the study in blog posts and tweet storms.\n- Unofficial reviewers publicly ripped the paper \"to shreds\" after it had passed peer review.\n- LGBTQ Nation defended the researchers and criticized Glaad for failing to understand \"how science works.\"\n- The American Psychological Association said an additional paperwork step was taken regarding the paper following the uproar.\n- Microsoft issued an updated public statement saying the error was not caused by algorithmic bias but by an experimental feature that selected an alternate image.\n- A Microsoft spokesperson told The Verge that testing a new feature to select an alternate image caused a different image on the page to be paired with the headline.\n- MSN's remaining human staff were warned that critical coverage of the site's automated systems might be selected by the AI.\n- MSN staff were instructed to remove any critical stories from the homepage if the AI selects them.\n- The news story was updated to include Microsoft's new statement.\n- Facebook implemented parts of the \"Worst of the Worst\" (Project WoW) project.\n- Facebook approved a scaled-back version of the Project WoW proposal that removed only the least harmful speech.\n- Facebook programmed its algorithms to stop automatically taking down content directed at White people, Americans, and men.\n- Facebook banned white nationalist groups.\n- Facebook prohibited content promoting racial stereotypes, such as people wearing blackface or claims that Jews control the media.\n- Facebook implemented measures that reduced the prevalence of hate speech on the platform to 0.03 percent of content.\n- Facebook conducted a consumer product study on \"racial justice\" that found Black users were leaving the platform.\n- Haugen\u2019s legal counsel provided redacted versions of internal Facebook documents to Congress.\n- Independent civil rights auditors released their report concluding that Facebook's policy decisions were a \"tremendous setback\" for civil rights.\n- The Home Office revoked the licences of hundreds of colleges to sponsor international students suspected of being a cover for immigration fraud.\n- ETS offered to help by using voice recognition software to check whether the same voice appeared on multiple test recordings.\n- ETS implemented a policy that if a test was flagged and two ETS staff agreed it would be classified as 'invalid', and that tests taken at centres with many 'invalid' results could be designated 'questionable'.\n- ETS passed a large list of alleged cheats to the Home Office.\n- The Home Office revoked the visas of anybody whose test was judged 'invalid'.\n- The Home Office cancelled visas of alleged cheats without giving them the right to appeal in Britain.\n- In 2017 people in Toeic cases won the right to appeal in Britain.\n- In 2016 ETS began providing alleged cheats with their test recordings.\n- Home Office investigators compiled and summarised inspectors' experiences in reports in May 2015 which have been presented at immigration appeals.\n- ETS Global BV paid a \u00a31.6m settlement to the Home Office in 2018.\n- Twenty-five people who faked tests were convicted, including 11 involved with the frauds filmed by Panorama.\n- The government has continued to contest immigration appeals against accusations based on ETS's evidence.\n- Home Office investigators interviewed past and present ETS staff after the Panorama broadcast to gather information about the fraud.\n- In February 2021 the Home Secretary Priti Patel accepted some innocent people had been wrongly accused and promised to look at solutions after the conclusion of a test case.\n- The Home Office stated that it had made significant improvements to ensure large-scale abuse could never happen again.\n- ETS said it took prompt action when it was made aware of serious allegations about UK tests in 2014.\n- ETS said it made significant changes to the management team of ETS Global BV.\n- ETS shared its methodology and findings with the UK Home Office.\n- A major Swedish hospital reported that 37 of the 668 women who had sought an abortion between September and December 2017 were using Natural Cycles as their sole birth control.\n- The Medical Products Agency of Sweden began an investigation into Natural Cycles following reports of unwanted pregnancies.\n- Natural Cycles' certification as contraception is under review in Sweden.\n- Sweden's medical watchdog entered a second phase of its investigation and began reviewing the app's marketing material.\n- Sweden's medical watchdog began reviewing Natural Cycles' past clinical studies as part of its investigation.\n- Sweden's medical watchdog began reviewing fresh user data as part of its investigation.\n- Natural Cycles publicly responded that the number of pregnancies was proportional to the registered number of Swedish users and \"in line with our expectations.\"\n- Natural Cycles stated that it has evolved its messaging about the product, acknowledging that it previously presented the 93% figure without sufficient context.\n- A Natural Cycles customer service manager told a user she could cancel her subscription and reactivate it later when asked for a break for emotional wellbeing.\n- A Natural Cycles customer service manager reassured a user that the company never deletes any user data.\n- Facebook hired dozens more Burmese speakers to review hate speech posted in Myanmar.\n- Facebook removed derogatory posts after Reuters alerted the company to them.\n- Facebook removed threats posted against Reuters reporters at the news agency's request.\n- Mark Zuckerberg apologized to Phandeeyar and five other Myanmar groups.\n- Facebook banned several hate figures and organizations on its platform in Myanmar.\n- Accenture began to hire more Burmese speakers for the Honey Badger content-monitoring project.\n- Facebook introduced a Burmese-language interface with help from volunteer translators.\n- Facebook's Honey Badger operation staffed about 60 people to review reports of hate speech and other content as of June.\n- Facebook published its internal community standards enforcement guidelines for the first time in April.\n- Facebook's translations team said it was actively working on new ways to ensure that translations are accurate.\n- Facebook agreed to a process that allowed the Myanmar government to report fake news via email and have Facebook take down pages after verification.\n- Twitter removed a number of tweets that Reuters flagged to it.\n- Facebook removed a Facebook page that advocated genocide of Muslims after activists provided specific examples.\n- Facebook took down a photograph and the accompanying comment calling an aid worker 'a traitor to the nation' after multiple complaints by activists.\n- Ocado announced via Twitter that it would be canceling some orders due to a 'major incident.'\n- Ocado canceled some customers' orders.\n- Ocado released a statement disclosing that a fire had erupted at its Erith Customer Fulfillment Centre.\n- Ocado evacuated over 800 employees from the facility.\n- Ocado contained the damage to less than 1 percent of the grid using its fire attenuation measures.\n- Ocado promised via Twitter to contact customers whose orders would be impacted as soon as possible.\n- The vast majority of customer orders were being fulfilled in other parts of the Ocado network.\n- Microsoft's internal ethics board prompted the company to refuse business from some corporate customers.\n- Microsoft's internal ethics board prompted the company to attach conditions to some deals limiting the use of its technology.\n- Microsoft's internal ethics board trained Microsoft sales teams on applications of AI the company is wary of.\n- Microsoft helped improve a cloud service for analyzing faces after a research paper revealed it was much less accurate for black women than white men.\n- Facebook created an automatic adviser called Fairness Flow that measures how machine-learning software performs on different categories to help expose potential biases.\n- Fairness Flow's feedback helped Facebook engineers choose job recommendation algorithms that worked better for different kinds of people.\n- Facebook is working on building Fairness Flow and similar tools into the machine-learning platform used company-wide.\n- Google promised that its new hyperrealistic voice assistant would identify itself as a bot when speaking with humans on the phone.\n- Google welcomed feedback on Duplex as it is refined into a product.\n- Google engaged in a broad internal discussion about military uses of machine learning.\n- Google is working on a set of principles that will guide the use of its technology.\n- Google's photo-organizing service was reprogrammed not to tag photos with \"monkey\" or \"chimp\" after a 2015 incident in which images of black people were tagged \"gorilla.\"\n- Axon announced an ethics board of external experts to review ideas such as using AI in policing products like body cameras.\n- Axon's ethics board will meet quarterly.\n- Axon's ethics board will publish one or more reports a year.\n- Axon's ethics board includes a member designated as a point of contact for Axon employees concerned about specific work.\n- Axon said it was looking at having the board take input from a wider range of people.\n- Tesla collects and analyzes safety and crash data from its vehicles.\n- Tesla owners can use voice commands to provide additional feedback to the company.\n- Mozilla approached us to help tell Amaya\u2019s story of encountering software that failed to recognize her because of her skin tone.\n- A court ordered METRO to immediately suspend the process of capturing and processing biometric data for facial recognition as part of the electronic surveillance system.\n- The court ordered METRO to immediately suspend the roll-out of new equipment that enables data capture and biometric processing for facial recognition.\n- The court's decision imposes a daily fine for non-compliance with the suspension order.\n- METRO said it will appeal the decision and provide clarifications regarding the monitoring system's compliance with data protection regulations.\n- The U.S. Department of Education opened an investigation in April into the data-sharing arrangement between Pasco County Schools and the Pasco Sheriff\u2019s Office.\n- In early May the Pasco Sheriff\u2019s Office and the school board revised their data-sharing agreement so school resource officers would no longer have access to student grades.\n- In early May the Pasco Sheriff\u2019s Office and the school board revised their data-sharing agreement so school resource officers would no longer have access to student discipline histories.\n- In early May the Pasco Sheriff\u2019s Office and the school board revised their data-sharing agreement so school resource officers would no longer have access to the school district\u2019s early warning system.\n- The Pasco Sheriff\u2019s Office released a lengthy public statement responding to reporting on the program.\n- A coalition of 30 advocacy groups called the PASCO Coalition issued a statement calling for the immediate termination of the student data-sharing arrangement.\n- The St. Paul collaborative program to develop a triage referral system and share data was halted in less than a year.\n- The American Civil Liberties Union sued Riverside County over its voluntary probation program.\n- After being sued by the ACLU, Riverside County stopped using the voluntary probation program that designated young people as at risk.\n- The Tampa Bay Times disclosed the existence of the Pasco County intelligence-led policing program in late 2020.\n- The Stanford researchers alerted LinkedIn about the profiles they discovered.\n- The Stanford researchers scoured LinkedIn and identified more than 1,000 accounts that appeared to be fake.\n- NPR contacted 28 universities about 57 of the profiles.\n- NPR attempted to contact more than a dozen companies listed as employers on profiles identified by the Stanford researchers.\n- LinkedIn investigated the reported profiles and removed those that broke its policies against fake profiles or falsifying information.\n- LinkedIn removed most of the profiles identified by the Stanford researchers.\n- LinkedIn removed the pages of the lead-generation company LIA.\n- LinkedIn removed the pages of the lead-generation company Vendisys.\n- LinkedIn said it is constantly updating its technical defenses to better identify and remove fake profiles and computer-generated images.\n- RingCentral said it is taking specific steps to update its approach to lead generation.\n- RingCentral said it will educate its people on what is and is not acceptable in terms of how the company communicates with customers and partners.\n- Bob's Containers stopped working with the vendor airSales.\n- Renova Digital removed the description of its services and pricing from its website after NPR asked about them.\n- Renova Digital's founder said he had tested AI-generated photos in the past but has stopped doing so.\n- LIA's website was scrubbed of all information except its logo.\n- The Chief Judge and other senior judges held a press conference to discuss and publicly address the use of AI in sentencing.\n- The judiciary stated that defendants will be informed of possible AI-generated sentence recommendations before a judge reaches a decision, giving them the chance to change their plea.\n- The judiciary plans to expand the AI system for use in civil motor-accident damages cases within three to six months.\n- The AI system will be used in Sabah and Sarawak courts to assist judges and save time in referring to past cases.\n- The judiciary said that, before going to trial, both sides will be able to know AI-estimated awards of damages so lawyers can negotiate settlements before coming to court.\n- The telco set up a new project to fix the bot while it remained in operation.\n- The company continued to run the service with the malfunctioning bot and paid for its ongoing operation.\n- The telco ran a large-scale fix-up project that lasted more than a year to address the bot's problems.\n- The company decided not to fix the problem from its roots and instead kept operating the flawed system.\n- Tinder agreed to a settlement of US$24 million in a class-action age discrimination lawsuit in California in 2019.\n- Consumer International partnered with the Mozilla Foundation to adapt CHOICE\u2019s methodology.\n- Consumer International and the Mozilla Foundation conducted fieldwork in six countries (New Zealand, the USA, the Netherlands, the Republic of Korea, India, and Brazil) between May and September 2021.\n- The investigators asked mystery shoppers to share a screenshot of the information provided upon registration.\n- The investigators asked mystery shoppers to provide their postal code.\n- The investigators asked mystery shoppers to share a screenshot of the price quoted for a one-month subscription to Tinder Plus.\n- Participants were instructed to sign up using their phone number rather than through email or social media accounts.\n- The study recruited 96 mystery shoppers in each country with quotas set based on gender, sexual preference, age, and location.\n- The investigators surveyed the same mystery shoppers with three questions about personalised pricing and asked them to select all applicable answers from a list of options.\n- The report states that Section 4 addresses limitations of the study and suggests potential avenues for further investigation.\n- Democratic Party officials publicly blasted AI Yoon, calling the deepfake fraudulent and a threat to democracy.\n- The Democratic Party produced an AI version of Lee Jae-myung that was made from real footage of his actual comments.\n- Mr. Yoon\u2019s campaign pivoted to fielding lighter voter questions and injecting humor into AI Yoon videos after the avatar\u2019s initial launch performed poorly.\n- Mr. Yoon adapted what he brings up on the campaign trail and how he says it based on the popularity of the online AI videos.\n- The AI Yoon campaign team changed its scripting approach to make each response funny and understandable to a middle schooler.\n- WeChat apologized for the inappropriate translation.\n- After receiving users' feedback, WeChat immediately fixed the problem.\n- A WeChat spokesperson explained that the app used neural machine translation and that the engine was constantly being refined to provide more accurate, faithful, expressive, and elegant results.\n- That's Shanghai reported the story.\n- That's Shanghai found that the translator gave neutral translations in some instances but used the slur when the phrase included a negative term.\n- Sixth Tone conducted its own testing on Wednesday evening and found similar results.\n- Dove apologized for a similar gaffe.\n- Cruise filed a police report on February 12, 2022.\n- The founder, Sall Grover, responded to criticism on Twitter by saying she had consulted trans women during development and that they decided to be upfront about the software's limits to avoid hurtful misgendering.\n- She later tweeted that she was \"grateful for the feedback\".\n- She agreed that some of the wording on the website was \"hideous\".\n- GM Cruise reported the June 11 collision to the California Department of Motor Vehicles as required by state regulations.\n- GM Cruise submitted an autonomous vehicle collision report that described the details of the accident between its two Chevy Bolts.\n- AV companies filed autonomous vehicle accident reports with the California DMV (29 reports so far in 2018).\n- The Turing Institute held a series of workshops in late 2020 to discuss the role of AI in the covid response.\n- The Turing Institute published a report in June summarizing discussions from those workshops.\n- Laure Wynants and colleagues published and continue to update a review in the British Medical Journal assessing 232 predictive algorithms for diagnosing or predicting covid outcomes.\n- Derek Driggs and colleagues published a large review in Nature Machine Intelligence assessing 415 published deep-learning models for covid diagnosis and risk prediction.\n- Driggs\u2019s research group trained its own model on a mixed-position chest scan data set to demonstrate how scan position can confound model predictions.\n- Laure Wynants requested that a company marketing deep-learning algorithms share information about its approach.\n- Leading scientific groups from G7 participating nations issued a call for 'data readiness' in preparation for future health emergencies.\n- The World Health Organization began considering an emergency data-sharing contract to ease cross-border data movement during international health crises.\n- Uber changed the app to show drivers more details of a prospective ride before accepting it, including the fare and pick-up and drop-off locations.\n- Uber spokesperson Harry Hartfield provided an emailed statement describing the factors used to calculate upfront fares and asserting the pilot has not impacted earnings in cities with upfront fares for more than six months.\n- Uber's spokesperson sent The Markup a link to a YouTube video by Uber explaining upfront fares.\n- Uber's spokesperson directed The Markup to a blog post by The Rideshare Guy as a source to learn more about the pilot.\n- The TV network confirmed that the news ticker was hacked and that the messages displayed were false.\n- President Volodymyr Zelenskyy filmed a short video debunking the false messages and calling them a childish provocation.\n- Zelenskyy quickly debunked the deepfake video of himself repeating the false messages.\n- The autonomous vehicle yielded to the police vehicle.\n- The autonomous vehicle pulled over to the nearest safe location for the traffic stop.\n- An officer contacted Cruise personnel.\n- Cruise issued a public statement on Twitter providing more details about the incident.\n- Cruise works closely with the San Francisco Police Department on how to interact with Cruise vehicles.\n- Cruise provides a dedicated phone number for the San Francisco Police Department to call in situations like this.\n- CHOICE sent a list of detailed questions to Airbnb Australia seeking information about the way its algorithm is being used in the country.\n- Airbnb responded to CHOICE with a public statement saying the safety, security and privacy of its community is a top priority and that its platform security and safety measures are designed to help ensure stays are safe and protect users' information.\n- When Renae Macheda queried her ban, Airbnb sent her a brief email stating that her account would be removed, she would not be able to create another one, and that they could not offer additional support on the matter.\n- Airbnb emailed Rick Andrews to say his account had been flagged during a 'standard security review' and was linked to online ads for adult services that violate its Terms of Service.\n- CHOICE submitted to the Privacy Act review supporting the adoption of the EU framework, including an outright ban on social scoring algorithms and regulation of other high-risk uses of automated decision-making.\n- CHOICE is pushing for better consumer protections around automated decision-making, including informing consumers of the risks and offering avenues to opt out or review decisions.\n- Airbnb claims it offers users an opportunity to have automated decisions reviewed.\n- Facebook issued a statement apologizing to small businesses for mistakenly blocking their ads.\n- Facebook restored HoneyGramz's account a few days after it was mistakenly blocked.\n- Facebook stated that it regularly works to improve its tools and systems.\n- Facebook stated that it is working to make the support it offers easier to use and access.\n- Euler Hermes covered the entire amount of the victim company's claim.\n- A police investigation into the case has ended.\n- The U.K. executive became suspicious when a later caller used an Austrian phone number and did not make the second payment.\n- Euler Hermes declined to name the victim companies.\n- Mr. Kirsch recorded his own voice using a commercial voice-generating product and said the reproduced version sounded real.\n- Cybersecurity companies have recently developed products to detect so-called deepfake recordings.\n- The U.N. centre is researching technologies to detect fake videos.\n- The police implemented a new VioG\u00e9n protocol (VPR5.0-H) in March 2019.\n- The VioG\u00e9n program was updated to identify cases of special relevance and cases with minors at risk.\n- VPR5.0-H introduced a dual evaluation procedure that carries out two parallel calculations, including a lethal-assault (H-scale) assessment.\n- The system was changed so that the risk score can be automatically increased based on the H-scale outcome.\n- Under the new protocol, cases can be signaled to prosecutors and judges as being of special relevance.\n- Police agents can manually increase a case's risk score by hand if they assess a higher risk.\n- Once a case's score is established, the agent assigns a packet of protection measures associated with that risk level.\n- For the lowest risk scores, agents discreetly check on the woman from time to time.\n- For the highest risk cases, the police provide the victim with an alarm button.\n- For the highest risk cases, the police track the aggressor's movements.\n- For the highest risk cases, the police can guard the victim's house.\n- The agent sends the VioG\u00e9n form and risk score to the prosecutors and judges handling the woman's case.\n- After the first report, police meet again with the woman to fill in a second form to reassess whether the situation has worsened or improved.\n- The police periodically reassess and follow up on cases until women are considered safe, stopping follow-up only if judicial measures are not pursued and the risk level falls below medium.\n- Police applied a control wristband to a high-risk aggressor in at least one case.\n- Police broke into a victim's house after a wristband signal indicated the aggressor was moving toward the home, preventing an attack.\n- Tesla said a software update would fix the issues with its heat pumps.\n- Tesla released a software update that was supposed to prevent its vehicles from crashing against emergency vehicles.\n- Tesla attempted to dismiss an NHTSA investigation into Autopilot crashes involving emergency vehicles by issuing another over-the-air software update.\n- The road engineer at the scene placed crash warning signs before the crashed Tesla to protect the middle lanes as soon as possible.\n- OpenAI researchers tried filtering out sexual content from DALL-E 2's training data.\n- OpenAI invited 23 external researchers to \"red team\" DALL-E 2.\n- OpenAI limited the initial release of DALL-E 2 to about 400 trusted users.\n- OpenAI restricted DALL-E 2's available use for those users to non-commercial purposes.\n- OpenAI published a \"Risks and Limitations\" document for DALL-E 2.\n- OpenAI published a model card documenting DALL-E 2's risks.\n- OpenAI has been transparent and upfront with users about DALL-E 2's remaining limitations.\n- Some states now require NarxCare to mark veterinary prescriptions with a paw print or animal icon on health providers' screens to help identify pet medications.\n- Appriss sent an emailed response to WIRED stating that the Overdose Risk Score is based solely on data from state prescription drug monitoring programs and does not use additional data sources.\n- Appriss told WIRED that NarxCare's scores do not include any diagnosis information from patient medical records.\n- Appriss told WIRED that NarxCare does not take into account the distance a patient travels to receive medical care.\n- Appriss presented new data at a webinar showing that implementation of NarxCare sped up the decline in opioid prescribing in six states by about 10 percent.\n- Appriss said it is actively looking for additional outcome data sets to study NarxCare's real-world effects on patients' lives.\n- Appriss issued a public statement advising that its scores are intended as indicators to prompt further review of a patient's prescription history and are not meant to be sole determinants of patient risk.\n- Kathryn began trying to clear her NarxCare record after discovering she had been flagged.\n- Ryan Ward contacted Appriss directly in an attempt to get his high Overdose Risk Score fixed.\n- Ryan Ward approached a Publix pharmacist, showed his LinkedIn page, described the problem caused by his high score, and the pharmacist agreed to fill his buprenorphine prescription.\n- Beverly Schechtman joined the advocacy group Don't Punish Pain Rally to campaign against unfair denial of opioid treatment.\n- Angela Kilby reverse-engineered and simulated a NarxCare-style machine-learning model using de-identified health insurance claims data to evaluate the algorithm's predictive performance.\n- Jennifer Oliva published the paper 'Dosing Discrimination' arguing that FDA approval should be mandatory for algorithms like NarxCare.\n- Appriss stated that its algorithm focuses on rapid changes in drug use and deemphasizes people who have maintained multiple prescriptions at stable levels for a long time.\n- Google told Motherboard that the assistive writing feature is in an \"ongoing evolution.\"\n- A Google spokesperson said the technology is always improving and acknowledged that they do not yet have a complete solution to identifying and mitigating all unwanted word associations and biases.\n- Sangfor removed the behavioral perception system product from its website.\n- Zhihu denied using any technology to monitor employees' online activities.\n- Chinese media outlets investigated the claim and identified the software as a product from Sangfor Technologies.\n- A Sangfor salesperson declined to confirm whether Zhihu was a client and stated that the vast majority of Chinese internet companies used its services \"at varying degrees\".\n- SN Technologies implemented a human-in-the-loop process requiring a human to verify each alert before it is confirmed.\n- SN Technologies trained the AEGIS system to recognize broom handles to prevent them from being misidentified as weapons.\n- The weapons detection aspect of the AEGIS system was recalibrated several times.\n- SN Technologies repeatedly tweaked and adjusted the system settings and camera installations, including after construction disturbed cameras, to restore full functionality.\n- The Lockport City School District hired the accounting firm Freed Maxick to audit SN Technologies' accuracy and racial bias claims.\n- SN Technologies paid for the Freed Maxick independent review of its software and the NIST report interpretation.\n- Lockport parents Jim Shultz and Renee Cheatham filed a lawsuit against the New York State Education Department seeking to ban facial recognition in schools.\n- The New York legislature passed a bill that would ban the use of facial recognition in schools until a comprehensive study of its effect on students is completed.\n- Motherboard obtained emails and documents through Freedom of Information Law requests as part of its reporting.\n- SN Technologies sent a letter to Motherboard after publication providing further information about its technology.\n- The New York Civil Liberties Union is representing the Lockport parents in their lawsuit.\n- The NYCLU conducted an analysis of Smart Schools applications showing at least 11 other districts applied for funds to purchase facial recognition systems.\n- The injured visitor was taken to the hospital for his injuries.\n- Tesla issued a recall in October for a version of its Full Self-Driving software due to false positives in its automatic emergency-braking system.\n- Tesla initiated a safety recall of its Full Self-Driving driver-assistance software late last month because a feature enabled rolling stops that allowed vehicles to proceed through intersections without fully halting.\n- Tesla met with NHTSA officials twice in January to discuss the issue.\n- The National Highway Traffic Safety Administration engaged in a dialogue with Tesla regarding the phantom braking reports.\n- NHTSA reviewed the complaints through its risk-based evaluation process, including discussions with the manufacturer and review of additional data sources such as Early Warning Reporting data.\n- NHTSA opened a safety investigation in August into about a dozen reports of crashes with parked emergency vehicles while Autopilot was activated.\n- Target later revised its estimate to include theft of private data for 70 million customers.\n- YouTube said it would block Russia Today and Sputnik in the European Union.\n- Twitter said it would label content from Russia Today and Sputnik as state-sponsored.\n- Meta said it would label content from Russia Today and Sputnik as state-sponsored.\n- TikTok banned Sputnik and Russia Today in the European Union.\n- TikTok said it would start labeling Russia Today and Sputnik as state-sponsored in countries where they remain available.\n- TikTok said it had dedicated more resources to monitoring for misleading content about the war.\n- TikTok said it increased safety and security resources to detect emerging threats and remove harmful misinformation.\n- TikTok said it would suspend livestreaming and new content uploads from Russia.\n- Ukrainian officials posted on Facebook that the 13 soldiers were alive and had been taken prisoner.\n- Facebook internally designated the issue as a level-one SEV (site event).\n- Facebook conducted an internal investigation into the ranking failure.\n- Engineers traced the root cause of the problem to a software bug.\n- Facebook applied needed fixes to address the software bug.\n- Facebook fixed the ranking issue on March 11th.\n- Meta spokesperson Joe Osborne publicly confirmed the incident in a statement to The Verge.\n- The internal report on the incident was shared inside the company.\n- On April 15, after NBC News contacted the company, Ever updated its privacy policy on the app's website to add clearer disclosure that some technologies may be used in separate enterprise products and services, including enterprise face recognition offerings, while stating that users' files and personal information will not be used in those enterprise offerings.\n- On April 30, after further correspondence with NBC News, Ever added a new in-app pop-up feature that gives users an easy way to opt out of having their images used in the app's facial recognition tool.\n- Ever made the in-product opt-out feature available to all Ever users globally, expanding it beyond the geographic regions where it had previously been available, whether legally required or not.\n- ByteDance spokesperson Jennifer Banks told BuzzFeed News that Flipagram and Vigo ceased operations years ago and aren't connected to any current ByteDance products.\n- Flipagram employees were instructed to delete offending accounts that impersonated creators.\n- Flipagram employees were instructed to give complaining creators control over accounts that had impersonated them.\n- Flipagram employees were instructed to tell complaining creators that Flipagram cannot prevent a user (or fan) from uploading someone else\u2019s content.\n- According to an internal document, ByteDance capped video views from scraped content at a certain level so that scraped content views would not overwhelm content posted by real Flipagram users.\n- Flipagram limited how frequently it would recommend cross-posts to incentivize creators to post content first to Flipagram.\n- BuzzFeed News sent ByteDance a comprehensive list of the allegations and a detailed set of questions, including whether data sets from Flipagram were ever used to train the 'For You' algorithm or any other ByteDance algorithms.\n- Senator Richard Blumenthal called on regulators, including the FTC, to investigate ByteDance's alleged theft of data from Instagram and Snapchat users.\n- Feminist activists and journalists led a grassroots audit of the AI system.\n- Feminist activists quickly activated community organizing that brought national media attention to the system's misuse.\n- Feminist activists used media attention to enforce a measure of public accountability for the AI system.\n- The Applied Artificial Intelligence Laboratory at the University of Buenos Aires highlighted the platform's serious technical and design errors.\n- The Applied Artificial Intelligence Laboratory at the University of Buenos Aires challenged the developers' claim that the model made \"correct predictions 98.2 percent of the time.\"\n- It was publicly revealed that the Conin Foundation and Microsoft were behind the technology program.\n- Two technical reviews of the system were conducted.\n- The Fair Trade Commission imposed a 26.7 billion won fine on Naver.\n- The Fair Trade Commission announced a ruling that Naver made changes in search algorithms at least six times between 2012 and 2015 to favor its own online shopping business.\n- The Fair Trade Commission said it found that Naver changed its algorithm in favor of videos linked to its video sharing platform Naver TV.\n- Naver said it will appeal the accusation and the fine.\n- Naver argued that the antitrust watchdog is using a select few algorithmic changes to make the accusation.\n- Naver dismissed the charges that the company made algorithmic changes to show more search results for products provided on its platform and those linked to its payment service.\n- Tesla met with NHTSA on January 10, 2022, and January 19, 2022, to discuss the \"rolling stop\" functionality and its operating parameters.\n- Tesla voluntarily determined on January 20, 2022, to recall and disable the \"rolling stop\" functionality beginning with firmware release 2021.44.30.15 and newer releases.\n- Tesla will disable the \"rolling stop\" functionality on affected vehicles starting with firmware release 2021.44.30.15.\n- Tesla will begin deploying firmware release 2021.44.30.15 over-the-air to affected vehicles in early February 2022.\n- The disablement of the \"rolling stop\" functionality will be preserved in firmware release 2021.44.30.15 and later releases.\n- Owners who install firmware release 2021.44.30.15 or a later release will receive the remedy free of charge and need take no further action.\n- Tesla will notify all Tesla stores and service centers on or shortly after February 1, 2022.\n- Tesla will mail owner notification letters in accordance with 49 C.F.R. \u00a7 577.7 with a planned owner notification date of March 28, 2022.\n- Tesla does not plan to include a statement about pre-notice reimbursement in the Part 577 owner notification because there is no paid repair related to the recall condition.\n- They are exploring the use of drone technology to strengthen anti-poaching efforts in their game reserves.\n- A legal letter was sent to the Department for Work and Pensions demanding details of the automated process that triggers the investigations.\n- The Greater Manchester Coalition of Disabled People, with help from the campaign group Foxglove, launched legal action against the DWP.\n- Privacy International raised concerns after finding references in a DWP report to its use of \"cutting-edge artificial intelligence\" to crack down on organised criminal gangs committing large-scale benefit fraud.\n- DWP officials stated that specialist staff were involved in cases of suspected fraud and error.\n- The DWP offered support to those who needed it.\n- Facebook excused content moderators who secured a doctor's note indicating a personal COVID risk from attending work in person.\n- The women received an out-of-court settlement from Est\u00e9e Lauder.\n- HireVue stated that it no longer uses visual video analysis software.\n- Est\u00e9e Lauder issued a public statement saying interviewees were fully briefed.\n- Est\u00e9e Lauder issued a public statement asserting that using the HireVue process in tandem with human decision-making produces fairer outcomes and that it stands by the process.\n- The women spoke out in a BBC3 documentary to publicise their experience.\n- XPeng Motors apologized for the illegal collection of 430,000 facial images of visitors to its stores.\n- XPeng Motors stated that all data involved had been deleted.\n- The related data collected and analyzed by a third-party provider was completely deleted without leakage or illegal use of personal information, according to the company.\n- XPeng's Shanghai stores removed all the facial-collection equipment on March 18.\n- Local market regulators fined XPeng's Shanghai-based company 100,000 yuan for the illegal collection of consumers' facial photos.\n- The government launched a nationwide identity reverification campaign forcing 180 million people to prove they were Pakistani.\n- NADRA sent text messages to the head of every registered household asking them to confirm the individuals on their family tree and to report any intruders.\n- NADRA blocked or suspended CNICs ('digitally impounded') of individuals flagged during the reverification process.\n- NADRA charged each participating household 15 Pakistani rupees for the reverification process.\n- NADRA dismissed some lower-level functionaries following the Mansour incident.\n- Many suspended CNICs were reinstated after review.\n- NADRA set up registration sites across flooded areas to identify and assist those affected by the floods.\n- NADRA deployed vans fitted with equipment to retake fingerprints from people whose ID cards had been washed away.\n- NADRA reissued some 700,000 CNICs to flood-affected individuals.\n- NADRA distributed 77 billion Pakistani rupees to nearly three million families as flood relief.\n- NADRA issued ATM cards and opened temporary bank accounts enabling recipients to withdraw emergency aid.\n- In 2014 NADRA relaxed the definition of 'parent' for orphans, allowing the head of an orphanage to become a child's legal guardian on records.\n- In 2017 NADRA clarified its policy for the khwaja sirah (trans or third gender) community by allowing community leaders to appear in place of a parent on a CNIC.\n- NADRA allowed members of the trans community to self-identify as a third gender on their CNICs and withdrew its initial medical-examination requirement.\n- A High Court judge ordered NADRA in 2017 to maintain a database of individuals belonging to the Ahmadi community and to provide details of people who officially changed their faith.\n- An anti-terrorism court ordered NADRA to block the CNICs of Manzoor Pashteen and Mohsin Dawar after they were declared absconding.\n- The Islamabad High Court ruled that NADRA does not have the authority to decide citizenship and that blocking CNICs while reviewing cases was illegal.\n- Upon his reinstatement, Tariq Malik fired 47 NADRA employees accused of facilitating fraudulent ID cards.\n- NADRA launched a new identity reverification campaign urging people to check for intruders in their family records amid concerns related to the Taliban takeover.\n- Authorities planned a new ID for foreign residents in Pakistan to allow them to open bank accounts and conduct business.\n- Following reports of a large data leak, the interior ministry and NADRA publicly denied responsibility for the breach.\n- NADRA officials served as first responders after the 2013 Balochistan earthquake by using their local offices and vehicles to assist.\n- The New York City Police Department ended its use of Spot robots and returned the machines.\n- Honolulu Police Department officials presented to the city council to defend the purchase and attempt to vindicate themselves.\n- HPD officials publicly claimed that Spot would reduce the need for manpower and equipment and would reduce officer exposure to COVID-19.\n- Boston Dynamics issued an emailed statement approving HPD\u2019s use of its robot and stating that Spot was under the control of a human operator and intended to augment public safety officials.\n- Motherboard submitted a public records request for documentation of the HPD\u2019s use of the robot since January.\n- G7 suspended the use of all Tesla Model 3 cars in its fleet.\n- The 37 Tesla Model 3 cars in G7's fleet will remain suspended until the conclusion of a police investigation into the case.\n- G7 said it will maintain the suspension of the Tesla Model 3 vehicles while the investigation is ongoing as a safety measure for its drivers, customers and other road users.\n- Tesla conducted an initial inquiry and said it had ruled out the risk of a technical dysfunction of the vehicle.\n- A police investigation into the case is ongoing.\n- Tesla fired John Bernal.\n- Tesla cut off his access to the FSD Beta system in his personally owned 2021 Tesla Model 3.\n- Managers verbally told him he 'broke Tesla policy.'\n- Managers told him his YouTube channel was a 'conflict of interest.'\n- Managers admonished him for selling merchandise with the words 'full self-driving (beta)' on it.\n- Managers admonished him for using FSD Beta in an unsafe manner.\n- A manager from the Autopilot team held a video conference with him attempting to dissuade him from posting negative or critical content about FSD Beta.\n- Federal vehicle safety regulators initiated a probe into the FSD Beta program.\n- We took down the network of about 40 accounts, Pages, and Groups operating from Russia and Ukraine.\n- We blocked the operation's domains from being shared on our platform.\n- We shared information about the operation with other tech platforms, researchers, and governments.\n- Our investigation into the operation is ongoing.\n- We found links between this network and another operation removed in April 2020 connected to individuals in Russia, the Donbass region of Ukraine, and two Crimea media organizations.\n- We detected attempts by the Ghostwriter threat actor to target people on Facebook.\n- We took steps to secure accounts that we believe were targeted by this threat actor.\n- When possible, we alerted users that they had been targeted by this threat actor.\n- We blocked phishing domains used by these hackers to try to trick people in Ukraine into compromising their online accounts.\n- We rolled out additional privacy and security protections in Ukraine.\n- We are adding the same additional privacy and security protections in Russia.\n- Our teams are working with civil society organizations to help ensure people know these security and privacy tools are available.\n- We temporarily removed the ability to view and search the friends lists of Facebook accounts.\n- On Instagram, we are sending everyone in Russia a notification at the top of feed about privacy and account security.\n- For public Instagram accounts, we are reminding people to check their settings in case they want to make their accounts private.\n- For people who already have private Instagram accounts, we are sharing tips on how to keep their accounts secure through strong passwords and two-factor authentication.\n- We continue to add measures to help protect people\u2019s privacy and security.\n- We will share updates about these measures publicly.\n- We recommended that people in Ukraine and Russia take steps to strengthen the security of their online accounts.\n- We encourage people to use caution when accepting friend requests and opening links and files from people they don\u2019t know.\n- We asked people to refrain from reusing the same passwords across different services.\n- We strongly recommended using two-factor authentication on all online accounts.\n- Hive Box issued a statement explaining that its facial-recognition feature was still in beta testing.\n- Hive Box suspended its facial-recognition feature following the revelation of the bug.\n- The episode\u2019s host tested the security flaw himself and replicated the kids' findings with a nearly perfect success rate.\n- In January, the State Administration for Market Regulation found that 15% of leading smart locks using facial-recognition technology could be opened using photographs.\n- In March, Sixth Tone conducted an investigation that found facial-recognition cameras were being installed in classrooms to monitor students, often without their parents' knowledge or consent.\n- Scrutiny of the deepfake app prompted Alipay to assure users that its \"Smile to Pay\" facial-recognition system could not be hacked using deepfakes.\n- Police opened an investigation after a woman reported 20,000 yuan missing from her WeChat Pay account.\n- The Badong County public security bureau said the three suspects were arrested in different locations in September and October.\n- The case is still under investigation.\n- The Gates Foundation hired an independent firm to assess its $575 million Intensive Partnerships for Effective Teaching program.\n- The independent firm, the Rand Corporation, produced an assessment of the program's results.\n- IBM communicated to its customers that all data included in Watson for Oncology is based on real patients and that the product has won praise around the world for its recommendations.\n- IBM released a statement to STAT defending its Watson for Oncology software.\n- IBM said it has learned and improved Watson Health based on continuous feedback from clients, new scientific evidence, and new cancers and treatment alternatives.\n- IBM released 11 software updates to improve Watson for Oncology functionality over the past year.\n- Umeda's family filed a lawsuit against Tesla.\n- Dhake\u2019s wife filed a First Information Report (FIR) in the case.\n- Police registered an offence and a FIR against five staffers and some company officials on charges of causing death due to alleged negligence.\n- Police launched a probe into the case.\n- Automotive Stampings and Assemblies said it is investigating the causes that led to the incident.\n- The company said it has been providing support to the deceased's family.\n- Investigators reviewed video and preliminary data from the vehicle involved in the crash.\n- The National Transportation Safety Board released a report on the crash.\n- The NTSB declined to place blame on anyone in its preliminary report.\n- Tesla issued a statement expressing condolences and confirming the series of events.\n- Tesla stated that it has released quarterly safety data directly from its vehicles for the past three quarters.\n- The National Highway Traffic Safety Administration determined that a lack of safeguards contributed to Joshua Brown's 2016 death.\n- Tesla CEO Elon Musk publicly blamed driver inexperience and complacency for fatal crashes involving Autopilot.\n</mitigation_statements>"}]}}
{"custom_id": "batch_200", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- Officers attempted to verify the license plate hit returned by the ALPR before conducting the stop.\n- The police department issued a public statement explaining that the officer exercised discretion regarding his weapon and describing the circumstances of the stop.\n- Tesla tried repeatedly to work with the vehicle owner to investigate the cause of the crash.\n- Tesla immediately reached out to the customer when it learned of the crash.\n- Tesla publicly disclosed the Florida accident in late June.\n- Elon Musk outlined planned changes to Autopilot that include refinements in the system's radar to improve its ability to spot and identify obstacles.\n- Elon Musk outlined planned changes to Autopilot that include additional warnings to force drivers to keep their hands on the steering wheel and eyes on the road while the system is active.\n- Tesla removed a Chinese term for \"self-driving\" from its China website after a nonfatal crash in Beijing.\n- The National Highway Traffic Safety Administration announced it was investigating the Florida crash.\n- The victim's family filed a lawsuit against the dealer who sold the Tesla.\n- Mr. Hofer allowed police to use the Getaround app to find his rental paperwork and contact the company.\n- Police verified Mr. Hofer's identity.\n- Police released Mr. Hofer and his brother after verifying his identity.\n- Mr. Hofer filed a federal lawsuit against the Contra Costa County Sheriff's Department over the detainment.\n- Mr. Hofer publicly spoke out against the surveillance technology.\n- Mr. Hofer continued his advocacy work aimed at slowing the use of surveillance technology.\n- The author replied to Nicole with a link to the Pexels image and the Creative Commons license and asked for clarification on why she believed the image belonged to her client.\n- The author followed up the next day asking whether Nicole was dropping the case.\n- The author examined the Arthur Davidson website's domain registration record on ICANN.\n- The author checked the domain's history on the Wayback Machine.\n- The author searched Google for the firm's name and news mentions.\n- The author opened Nicole's photo in full size and analyzed it, identifying generative-adversarial-network artifacts and concluding the image was AI-generated.\n- The author reached out to the client on whose behalf Nicole had contacted him, asking them to clarify their relationship with Arthur Davidson.\n- On April 18, a support agent for the client replied that they had no relationship with the law firm.\n- Shortly after, the Arthur Davidson website was shut down.\n- The author decided to investigate Arthur Davidson and report the findings.\n- The author intentionally blacked out the client's name and website in the article.\n- The author decided not to name the client in the report because he had no concrete evidence of their involvement.\n- GitHub published a research paper by Alber Ziegler examining situations where Copilot reproduces exact texts.\n- GitHub CEO Nat Friedman posted a public comment on Hacker News asserting that training machine learning systems on public data is fair use and that the output belongs to the operator.\n- In his Hacker News comment, Nat Friedman included a link to OpenAI\u2019s position arguing that training AI systems constitutes fair use.\n- Neil Brown published an analysis from an English law perspective examining GitHub Copilot and pointing to GitHub\u2019s terms of service as evidence the company can likely perform its activities.\n- Andres Guadamuz published an analysis concluding that GitHub Copilot is unlikely to be infringing copyright or breaching licenses.\n- Darryl Taft published an analysis characterizing GitHub Copilot as a powerful, controversial autocomplete for developers.\n- The Wire published a report documenting the mechanics and strategy behind the Tek Fog program.\n- The Wire has been investigating the claims made by the unidentified source for two years.\n- The Wire published a follow-up article outlining how Tek Fog exploited vulnerabilities in social-media APIs.\n- Opposition parties denounced the app as a national security threat.\n- Opposition parties asked Parliament to probe the app.\n- Devang Dave released an email to The Wire denying that the party had ever used or known about a secret app to manipulate public opinion.\n- The Editors Guild of India issued a statement calling Tek Fog a travesty of democratic norms and a violation of law.\n- Police in India arrested four suspects for scraping social-media profiles of Muslim women and listing them for sale via an app on GitHub.\n- A salvage team removed the car from the water on Monday.\n- Waze officials encouraged drivers to always keep an eye on the road.\n- A police report recorded that the car went into the lake on Jan. 12 and had been in the water for over a week when removed.\n- BuzzFeed News reported the bestiality-thumbnailed videos to YouTube via the @TeamYouTube Twitter account on April 19.\n- YouTube's @TeamYouTube account replied the same day saying it had shared the reports with the right people.\n- YouTube removed violative content that was flagged to it by BuzzFeed.\n- YouTube began deleting the bestiality-thumbnailed videos on its platform shortly after being contacted by BuzzFeed News.\n- YouTube terminated the accounts that published the bestiality-thumbnailed videos.\n- YouTube said it was developing better tools for detecting inappropriate and misleading metadata and thumbnails so it could take fast action against them.\n- YouTube said it was working quickly to do more than ever to tackle abuse on its platform.\n- YouTube announced to the New York Times that 80% of the 8.28 million videos it took down in the fourth quarter of 2017 were flagged by machines.\n- The Aurora Police Department issued a written apology online.\n- The Aurora Police Department offered to pay for any therapy sessions the children may need.\n- Officers immediately unhandcuffed everyone involved after realizing the mistake.\n- Officers explained what happened to those involved after realizing the mistake.\n- Officers apologized after realizing the mistake.\n- An Internal Affairs investigation was opened.\n- An examination of training and procedures is underway.\n- Chief Vanessa Wilson directed her team to look at new practices and training.\n- Officers determined shortly after the stop that the car was not stolen.\n- Tumblr announced it will implement a full-site ban on all adult content starting December 17.\n- Tumblr is replacing its Safe Mode feature with a full-site ban on adult content.\n- Tumblr is giving users until the ban start date (December 17) to appeal mistakenly flagged content.\n- Tumblr said it will rely on automated tools to identify adult content.\n- Tumblr said it will use human reviewers to help train and keep its automated content-identification systems in check.\n- Tumblr specified exceptions to the ban, including breastfeeding and nude classical statues.\n- The California Highway Patrol put up a sign to discourage drivers from taking unsafe, unconventional routes.\n- Multiple Caltrans agencies tweeted advisories warning travelers not to follow potentially wayward GPS directions.\n- The California Highway Patrol and the California Department of Transportation have been attempting to dissuade travelers from straying from main routes.\n- California Highway Patrol officers have been called to assist and rescue motorists who became stranded after following GPS directions.\n- Waze works with state agencies, mapping partners, and users to update its maps with up-to-the-minute information.\n- Waze uses crowdsourced driver input, road-condition reports, real-time speeds, and historical traffic data to optimize routing during crises.\n- Caltrans recommends its QuickMap app and website to travelers to provide official route and road information during hazardous conditions.\n- The CHP endorses the real-time traffic application QuickMap as the official Caltrans traffic information app.\n- Caltrans maintains a digital network of roadway signs and closed-circuit cameras that the public can livestream to check road conditions.\n- Participants in a Big Bear area forum keep each other updated on road conditions using live video feeds and satellite images and sometimes advise drivers not to rely on apps like Apple Maps.\n- A local driver in a snow-tire-equipped Jeep forged a path through the snow to help Rachael, Thomas, and other cars make the shortcut passable.\n- Rachael and Thomas planned to turn around and return to the main paved route to the highway after realizing the unpaved road was unsafe.\n- The Ninth Circuit Court of Appeals reinstated Denise Green's civil rights lawsuit.\n- The Ninth Circuit Court of Appeals overturned the lower court's earlier decision that had granted summary judgment in favor of the San Francisco Police Department.\n- The Los Gatos Historical Society announced a campaign to assist the town staff in raising visibility of the Waze-related hazard with federal and state government.\n- The Los Gatos Historical Society announced a campaign to assist the town staff in raising visibility of the Waze-related hazard with Google investors.\n- The Los Gatos Historical Society announced a campaign to assist the town staff in raising visibility of the Waze-related hazard with Google executives.\n- Google has been notified multiple times of the life-threatening risk posed by the Waze algorithms.\n- Congress has set up a special committee to investigate wildfire risk.\n- The special committee has been alerted to the public safety hazard caused by Google and will factor it into their investigation.\n- The Oregon Department of Human Services announced to staff via email that the agency's hotline workers would stop using the algorithm.\n- The agency stated that hotline workers would stop using the algorithm at the end of June.\n- Oregon decided to completely replace the algorithm with a new program called the Structured Decision Making model.\n- The state kept the second algorithm to help decide foster care reunification on hiatus while researchers reworked the model.\n- The pilot for the reunification tool was paused months earlier due to inadequate data.\n- Officials said there was no expectation that the reunification tool would be unpaused soon.\n- U.S. Sen. Ron Wyden reached out to the Oregon Department of Human Services following the AP story to ask questions about racial bias.\n- Allegheny County officials publicly called the Carnegie Mellon University researchers' findings 'hypothetical.'\n- Allegheny County officials stated that social workers can always override the algorithmic tool.\n- The Los Angeles Department of Transportation proposed a neighborhood traffic-management plan featuring three alternative options that call for road and turn restrictions.\n- A working group of transportation, police, and fire officials devised a solution to address cut-through traffic.\n- The devised solution would install a series of 'No Right' and 'No Left' turn signs during peak rush hours to deter navigation-app commuters.\n- The city asked residents to vote on a recommended option among the proposed alternatives.\n- The city opened a public comment period that ends Feb. 13.\n- Transportation officials will tally neighborhood votes and comments on the traffic mitigation plan.\n- Transportation officials will submit a final version of the traffic mitigation plan to the City Council for consideration.\n- Mayor Eric Garcetti announced a data-sharing agreement with Waze under which the city would provide Waze with data about road closures, construction, safety hazards and hit-and-run crashes.\n- Under the data-sharing agreement, the city would receive real-time feedback on traffic and road conditions from Waze.\n- The Los Angeles Department of Transportation attempted to communicate with Waze to request that it not divert traffic to side streets.\n- The Los Angeles Department of Transportation attempted to communicate with Waze to request that Waze incorporate new traffic signs into its routing formula.\n- Police and fire officials endorsed the new Sherman Oaks traffic plan.\n- City officials held a public hearing where hundreds of residents weighed in on the traffic-management plan.\n- Resident William Carey worked with the city to develop a traffic fix for his street.\n- Bystanders immediately rushed to help the boy after the robot grabbed his finger.\n- The boy continued the tournament the next day and finished it in plaster.\n- The boy's parents are considering filing a lawsuit.\n- The Moscow Chess Federation said it will contact the prosecutor and help to solve the situation.\n- Sergey Lazarev said robot operators should consider increasing security to prevent the situation from repeating in the future.\n- Carnegie Mellon researchers analyzed more than 200 million tweets related to COVID-19 and found that about half appeared to be from bots.\n- The researchers identified bogus Twitter accounts by using artificial intelligence to track tweet origins, follower counts, and the frequency of tweets from single accounts.\n- The researchers categorized more than 100 types of inaccurate COVID-19 stories.\n- The researchers examined whether similar hashtags and phrases were used across accounts to detect copied messaging.\n- The researchers discovered that 66 percent of tweets came from real people using bot accounts to spread their message and 34 percent came from actual bots.\n- Twitter decided to step up its anti-misinformation campaign by cracking down on users who tweet unfounded conspiracy theories like \"5G causes coronavirus.\"\n- Twitter is testing new reply controls that could make it harder to stop or slow down the spread of misinformation.\n- NHTSA added the Utah crash to its Special Crash Investigations (SCI) list.\n- As part of its SCI program, NHTSA collected data beyond what local authorities and insurance companies typically gather at the crash scene.\n- NHTSA is looking into 16 crashes in which Tesla owners using Autopilot crashed into stationary emergency vehicles.\n- NHTSA upgraded the probe into those crashes to an \"Engineering Analysis.\"\n- NHTSA examines crashes involving advanced driver-assist systems and automated driving systems.\n- Amazon took down its A9 website after the Journal's inquiries.\n- Amazon issued a public statement saying it has not changed the criteria used to rank search results to include profitability.\n- Amazon said it looks at the impact of long-term profitability when deploying an algorithm.\n- Amazon said it designs its shopping and discovery experience to feature products customers will want regardless of whether they are Amazon's own brands or products offered by selling partners.\n- House Judiciary Committee leaders asked Amazon to provide executive communications related to product searches on the site as part of a probe on anticompetitive behavior.\n- Lawmakers pressed Amazon at a House antitrust hearing to explain whether it used data gleaned from other sellers to favor its own products.\n- They overplucked their eyebrows.\n- They stopped wearing glasses.\n- Hugging Face restricted access to the GPT-4chan model project on its platform.\n- Kilcher did not share the code for the bots themselves.\n- Kilcher stated he will focus his future work on projects with more positive community outcomes from here on out.\n- Microsoft took the Tay chatbot offline less than 24 hours after its release.\n- The Cook County Public Defender Office subpoenaed ShotSpotter as a third party to obtain documents about whether police pulled the man over solely based on a ShotSpotter alert.\n- The defense requested ShotSpotter analysts' qualifications and training materials, records of instances in which analysts reclassified alerts or police asked ShotSpotter to do so, the methods analysts use to reclassify alerts, data on sensors misidentifying gunfire or alert locations, and data on gunfire ShotSpotter failed to identify.\n- Attorneys for ShotSpotter asked the judge to hold the company in 'friendly' contempt of court to avoid complying with the discovery orders and to enable an appeal of the discovery order.\n- ShotSpotter refused to produce the requested documents needed to allow the court to decide whether it was reasonable for the police to pull over the defendant based solely on a ShotSpotter alert.\n- The Cook County Public Defender Office issued a public statement accusing ShotSpotter of refusing to produce documents and delaying a timely resolution of the case for their client.\n- Lucy Parsons Labs and Northwestern University\u2019s MacArthur Justice Center filed a civil lawsuit against the city of Chicago seeking class-action status for people the police stopped because of a ShotSpotter alert and seeking to bar the city from using the technology.\n- The Amsterdam court of appeal took note of the municipality\u2019s breach of the law.\n- The Amsterdam court of appeal ordered the municipality to pay the court costs.\n- The judge examined properties sold around 2016 in the vicinity and concluded the price per square meter matched the algorithmically generated value for the claimant\u2019s house.\n- After the ruling, the claimant belatedly invited the municipality to visit his house.\n- Bunnings acknowledged that facial recognition technology was in use in its stores.\n- Bunnings stated it had provided appropriate notice to customers through signage at store entrances and in its privacy policy.\n- Bunnings said there are strict controls around the use of the technology which can only be accessed by specially trained team members.\n- Bunnings said images of children are not stored.\n- The Good Guys acknowledged the use of face and feature recognition technology.\n- The Good Guys said the technology is a trial limited to two stores.\n- The Good Guys said it notifies customers that the technology is in use through store entrance signage and in its privacy policy.\n- Choice referred the offending retailers to the Office of the Australian Information Commissioner to investigate potential breaches of the Privacy Act.\n- Choice is lobbying the government to implement a regulatory framework to protect consumers from harmful and unfair practices.\n- The developers concealed their real identities and spoke on condition of anonymity after receiving abusive responses.\n- The company provided a demonstration of the app's technology to Google to prove it can estimate vehicle speed.\n- Apple has been contacted for comment.\n- KPPU built a case after receiving complaints from independent Grab drivers.\n- Grab and TPI underwent a third preliminary hearing with KPPU in Jakarta.\n- KPPU's commissioner declined to share further details about the case because it was still ongoing.\n- Grab Indonesia's lawyer Hotman Paris Hutapea denied all KPPU allegations.\n- Hotman Paris Hutapea insisted the case was not worth pursuing because Grab and TPI's actions did not harm the public interest.\n- Grab Indonesia denied violating any regulations in its partnership with TPI in response to KrASIA's inquiries.\n- A Grab Indonesia spokesperson stated that there is no preferential treatment given to driver-partners registered with TPI.\n- Grab said that its booking system is fair and purely based on performance and merit.\n- Grab Indonesia said it respected and would follow through all the trial processes of the case.\n- The Open Society Justice Initiative and Muslim Advocates obtained DHS documents about ATLAS through Freedom of Information Act lawsuits.\n- The Open Society Justice Initiative filed a new FOIA request with DHS and USCIS seeking details on how the ATLAS algorithm functions.\n- The Biden administration began a review of denaturalization policies in February to ensure those authorities are not used excessively or inappropriately.\n- The State Department completed its portion of the denaturalization policy review.\n- USCIS stated that it is working with DHS and the Justice Department on the denaturalization policy review.\n- The Department of Homeland Security produced a 2020 privacy assessment of ATLAS's privacy implications.\n- A 2016 privacy assessment of the FDNS-DS described ATLAS's capability to visually display linkages or relationships among individuals.\n- In May, Muslim Advocates led 48 advocacy groups in sending a letter to USCIS urging the agency to halt its use of ATLAS until a disparate impact review and to publicly release information about the system's rules, flagged demographics, and screening outcomes.\n- USCIS produced 2,628 'affidavits of good cause' as a procedural requirement for initiating civil denaturalization cases.\n- USCIS assigned 1,265 cases to the USCIS Office of Chief Counsel.\n- USCIS referred 502 cases to the Justice Department's Office of Immigration Litigation.\n- The Justice Department created a new office in early 2020 to investigate terrorists, war criminals, sex offenders, and other fraudsters who illegally obtained naturalization for purposes of denaturalization.\n- USCIS referred reporters' questions about its current denaturalization investigations to the Justice Department.\n- The city ordered the San Francisco SPCA to stop using the robot to patrol the sidewalks outside its office.\n- The city said it would issue the SPCA a fine of $1,000 per day for illegally operating on a public right-of-way if it continued to use the security robot outside its premises.\n- San Francisco voted to cut down on the number of robots that roam the city's streets.\n- Apple adjusted its ranking rules and algorithm for the iTunes App Store to punish developers who use third-party services to manipulate app rankings.\n- Apple previously tweaked its App Store system in April to make sheer download volume less of a factor in an app's standing.\n- Apple demoted KoramGame's Feng Wan Three Kingdoms from fourth place to 335th in the Chinese iTunes App Store rankings as a sanction.\n- Human Rights Watch released a 42-page report titled \"[Video Unavailable': Social Media Platforms Remove Evidence of War Crimes]\".\n- Human Rights Watch urged all stakeholders to come together to develop an independent mechanism to preserve potential evidence of serious crimes.\n- Human Rights Watch urged that preserved content be made available to support national and international investigations, as well as research by nongovernmental organizations, journalists, and academics.\n- Human Rights Watch called on social media platforms to be more transparent about their existing takedown procedures and to provide meaningful opportunities to appeal content removal.\n- Human Rights Watch interviewed multiple civil society organizations, lawyers, archivists, journalists, former prosecutors, investigators, law enforcement officers, and officials as part of its investigation.\n- Human Rights Watch reviewed Facebook, Twitter, and YouTube content cited in its reports and identified 619 pieces of content that had been removed.\n- In May 2020, Human Rights Watch sent letters to Facebook, Twitter, and Google sharing links to removed content.\n- In those May 2020 letters, Human Rights Watch asked Facebook, Twitter, and Google if Human Rights Watch could regain access to the removed content for archival purposes.\n- Rights groups have been urging social media companies since 2017 to improve transparency and accountability around content takedowns.\n- The MacArthur Justice Center filed a federal lawsuit seeking damages for Michael Williams and Daniel Ortiz.\n- The lawsuit seeks class-action status for any Chicago resident who was stopped on the basis of ShotSpotter alerts.\n- The lawsuit seeks a court order barring the use of the gunshot-detection technology in Chicago.\n- Chicago prosecutors requested dismissal of Michael Williams' murder case due to insufficient evidence.\n- A judge dismissed Michael Williams' case at the prosecutors' request.\n- The Associated Press conducted an investigation that identified multiple flaws in using ShotSpotter as evidentiary support for prosecutors.\n- Chicago's nonpartisan watchdog agency concluded that actual evidence of a gun-related crime was found in about 9% of ShotSpotter alerts confirmed as probable gunshots.\n- ShotSpotter issued a public statement defending the accuracy of its system and noting that an analytics company had verified its effectiveness.\n- Reddit moderators delete egregiously inappropriate posts of abusive interactions with Replika chatbots.\n- Google and Apple deliberately rerouted virtual assistant responses away from passive defaults so the assistants now refuse sexual requests (for example, Siri now responds \"no\" instead of earlier phrasing).\n- Researchers and academics are conducting studies about how female-coded or passive chatbot responses encourage misogynistic or verbally abusive behavior.\n- GM employees arrived at the scene and manually moved the immobilized Cruise vehicles.\n- An anonymous Cruise employee sent a letter to the California Public Utilities Commission to sound the alarm about the incidents.\n- Cruise spokesperson Tiffany Testo issued a statement to Wired saying the company is working to minimize how often these vehicle-freezing incidents occur as part of its overall safety operations.\n- The EU General Data Protection Regulation provides some protections on how personal data is gathered.\n- States and cities in the United States have enacted laws like the California Consumer Privacy Act.\n- Human Rights Watch has urged governments to impose a moratorium on the use of facial recognition until there is sufficient information and debate to decide whether to restrict or ban its use.\n- Yueming Zhou was released after five months.\n- After being held in Xinjiang for 2.5 years without charge or trial, Yueming Zhou got her passport back.\n- After being held in Xinjiang for 2.5 years without charge or trial, Yueming Zhou left the region.\n- Google agreed to pay $100 million to Illinois residents to settle the class-action lawsuit.\n- Google is required to provide users with a notice about the face grouping feature.\n- Eligible Illinois residents were given the ability to submit a claim on the settlement\u2019s website by September 24, 2022.\n- The settlement provides eligible claimants with payments ranging from $200 to $400 depending on court-related expenses and claim volume.\n- A final approval hearing for the settlement was scheduled for September 28, 2022.\n- Clearview added a new \"Clearview Facts\" section to its website after the first news stories were published about the company.\n- Clearview posted on its website that an independent panel of experts rated Clearview 100% accurate across all demographic groups according to the ACLU\u2019s facial recognition accuracy methodology.\n- On Jan. 28, Clearview removed the civil rights group's (the ACLU's) name from its website.\n- Clearview declined to make the results of its MegaFace test available for independent review when requested by BuzzFeed News.\n- The ACLU lodged a complaint regarding Clearview's use of its name and claims.\n- Motherboard obtained ShotSpotter data from multiple cities through public records requests.\n- Motherboard analyzed the obtained ShotSpotter data to map sensor alerts and location patterns.\n- The City of Atlanta stopped using ShotSpotter sensors in 2020 when funding ran out.\n- Cleveland activists, including Mary Drummer, wrote to city councilors asking that the money allocated for ShotSpotter be reallocated to other uses in the affected communities.\n- Axon announced it was halting work on the project to equip drones with stun guns.\n- Axon said it was pausing work on the project and refocusing to further engage with key constituencies to fully explore the best path forward.\n- Axon said it would continue to consult the ethics board, law enforcement officials, community leaders, and school officials.\n- The company tweeted out the ethics board's dissent shortly after its own announcement.\n- Nine members of Axon's 12-member ethics advisory panel resigned from the board.\n- The ethics board released a unanimous statement of concern describing Axon's decision as \"deeply regrettable.\"\n- Axon's founder and chief executive held an Ask Me Anything session on Reddit to answer detailed questions about the proposed drones.\n- Several social media platforms barred a handful of far-right influencers and conspiracy theorists, including Alex Jones of Infowars.\n- Tech companies took steps to limit the spread of political misinformation.\n- YouTube announced it would update its policy to ban videos espousing neo-Nazism, white supremacy and other bigoted views.\n- YouTube said it was changing its recommendation algorithm to reduce the spread of misinformation and conspiracy theories.\n- YouTube introduced a version of its recommendation algorithm that is switched on after major news events to promote videos from authoritative sources over conspiracy theories and partisan content.\n- YouTube announced it would expand the approach that nudges users who had watched a series of conspiracy theory videos toward videos from more authoritative news sources.\n- YouTube said a January change to its algorithm to reduce the spread of so-called 'borderline' videos had resulted in significantly less traffic to those videos.\n- Mr. Molyneux and Ms. Southern publicly distanced themselves from the Christchurch shooting and denied links between the violence and their speech.\n- Mr. Molyneux uploaded a video titled 'An Open Letter to Corporate Reporters' denying that he promoted hatred or violence and arguing that labeling him an extremist was slander.\n- Mr. Cain downloaded and sent his entire YouTube history to the reporter to back up his recollections.\n- Mr. Cain started his own YouTube channel, Faraday Speaks, to talk about politics and current events from a left-wing perspective and to try to show young men a way out of the far right.\n- Shortly after receiving threats, Mr. Cain moved out of West Virginia.\n- After receiving death threats, Mr. Cain bought a Glock pistol the day after he got the threats.\n- Left-wing creators produced videos that mimicked right-wing aesthetics and used a strategy of algorithmic hijacking to get their videos recommended to the same audience.\n- A former Uber Eats courier filed legal action against Uber Eats alleging he was unfairly dismissed because of the company's facial recognition software.\n- An employment tribunal rejected Uber's motion to dismiss the discrimination claim.\n- The employment tribunal's rejection means the case will move to a full hearing.\n- Uber issued a public statement denying that automated facial verification was the reason for Mr Manjang's temporary loss of access to his courier account.\n- Uber stated that its Real-Time ID Check is used for safety and security purposes.\n- Uber said the system includes robust human review to ensure decisions about someone's livelihood are not made without oversight.\n- Abiodun Ogunyemi filed an employment tribunal case against Uber after its automated face-scanning software failed to recognise him.\n- Big Brother Watch filed a complaint against Southern Co-op over the use of facial recognition technology in 35 of its stores.\n- The Information Commissioner's Office fined Clearview AI \u00a37.5 million for illegally collecting billions of images.\n- The Information Commissioner's Office is investigating whether AI systems show racial bias.\n- Meta has collected 70,000 conversations from the BlenderBot 3 public demo.\n- Meta will use the collected conversations to improve BlenderBot 3.\n- Meta's A.I. research chief Joelle Pineau publicly defended the decision to run the BlenderBot 3 public demo and insisted the work is worth pursuing.\n- Facebook apologized to the user for incorrectly stopping them from posting the picture.\n- Facebook asked Guardian Australia whether the photo had been flagged in error.\n- Facebook restored the user's post and allowed the Guardian article to be posted and shared without restriction or ban after additional requests from Guardian Australia.\n- The AI Incident Database has begun indexing AI incidents across languages.\n- When an incident is reported, the AI Incident Database tags the report with a source language and machine-translates it into supported languages.\n- The AI Incident Database currently provides its user interface in English and Spanish.\n- The AI Incident Database tested machine-translation performance between Spanish and English and found the resulting text to be interpretable but awkward and inconsistent.\n- The Responsible AI Collaborative was founded to collaboratively develop the systems necessary to share incidents across cultures, languages, and geographies.\n- They solicited volunteers to contact them to help translate and localize non-English languages.\n- They will add additional languages to the database user interface and expect to add French support within the next month.\n- They decided to add a single language to the user interface before scaling the feature.\n- They identified the best practice of always indicating in the user interface when content has been machine translated.\n- They identified the best practice of providing a link to the untranslated source text.\n- They identified the best practice of providing the ability for people to report, correct, and improve bad translations.\n- They identified the best practice of validating the effectiveness of translations between languages prior to making those translations generally available.\n- They identified the best practice of developing a community of people who can interpret and respond to translation issues should they occur.\n- Cruise apologized for the incident.\n- Cruise called the incident a \"technical issue.\"\n- Facebook chief operating officer Sheryl Sandberg issued a public mea culpa.\n- Facebook announced it was changing its policies in response to the offensive ad-targeting revelations.\n- Facebook disabled the targeting system that created the offensive categories.\n- Facebook said it would only allow ad-targeting options that have been reviewed by humans in the future.\n- An Instagram spokesperson apologized for the incident.\n- Instagram stated that the image was not used in a paid promotion.\n- Twenty Democratic senators and representatives urged the Federal Election Commission to develop new guidance for advertising platforms on how to prevent illicit foreign spending in US elections.\n- Facebook apologized over its 2014 'Year in Review' clips.\n- The driver posted a statement on his Facebook page admitting he glanced at a navigation app on his phone and was not paying full attention to the road.\n- Tesla issued a statement to Electrek reminding that the driver must remain responsible for the car at all times when using Autopilot.\n- Tesla reported that it has been unable to retrieve any data from the vehicle because the accident occurred in an unsupported area.\n- The listed former incidents were converted to 'issues' following an update to the incident definition and ingestion criteria.\n- Reports that had been associated with those incidents were migrated and are now associated with other incidents as context.\n- Editors confirmed the migration of Incident 85, noting it likely does not fit the current incident criteria.\n- Specific reports were removed from the incidents and listed as former reports.\n- Ousmane Bah filed a lawsuit in the U.S. District Court for the Southern District of New York.\n- The lawsuit seeks $1 billion in damages.\n- The lawsuit seeks a declaration that Apple wrongfully and baselessly damaged Bah's reputation.\n- The lawsuit seeks a court order compelling Apple to address the mistake in the stored data that links Bah's identifying information to the company's facial recognition technology.\n- Three of the cases against Bah have been dropped.\n- The New York case has been sealed.\n- Apple declined to comment on the lawsuit.\n- Apple said it does not use facial recognition technology in its stores.\n- Culver City Firefighters Local 1927 tweeted that the driver reported the Tesla was traveling in Autopilot mode when it struck the firetruck.\n- CBS Local Los Angeles reported that firefighters said the driver told them the vehicle was operating on Autopilot self-driving mode when the accident occurred.\n- Police in Northern California reported that a driver they arrested for suspected drunk driving told them the Tesla he was in was operating on Autopilot.\n- The NTSB assigned some of the blame to Tesla's Autopilot system in its investigation of the earlier deadly crash.\n- Immigrant rights campaigners have begun a legal case to compel the Home Office to disclose how its visa-streaming algorithm operates.\n- Foxglove is supporting the legal case brought by the Joint Council for the Welfare of Immigrants (JCWI).\n- The JCWI sent a pre-action legal letter to the home secretary, Priti Patel.\n- The case is being backed by a GoFundMe page titled 'Deported by algorithm'.\n- The JCWI demanded all policy and guidance documents dealing with the process of streaming visa applications and the use of the streaming tool.\n- The JCWI demanded all technical details that drive the streaming tool.\n- The JCWI demanded information on case-working targets for each of the three streaming categories.\n- The JCWI demanded records of any complaints about the deployment of the algorithm.\n- The Home Office issued a public statement asserting that the streaming tool is used only to allocate applications, does not decide them, and complies with the Equalities Act 2010.\n- Apple has been trying to work out the kinks in Project Titan, its autonomous electric vehicle program.\n- The federal government opened an investigation into Tesla after drivers were involved in more than 200 crashes while using its assistance software.\n- Federal investigators were dispatched to Florida to investigate a fatal collision involving a Tesla.\n- Companies developing self-driving vehicles pushed back their anticipated rollouts of autonomous vehicles.\n- Police raided the brothers' mansion following a tip-off from the US embassy that a 21-year-old American woman was being held against her will.\n- The Tates were taken in for questioning before being released.\n- Romanian authorities expanded the investigation to cover human trafficking and rape allegations.\n- Romanian authorities said the investigation was ongoing.\n- Police raided his house.\n- Police confiscated his devices.\n- He was held in a cell for two days.\n- Big Brother producers ejected him from the house after a video of him hitting a woman emerged.\n- He was barred from Twitter.\n- TikTok said it was actively investigating whether accounts posting content of Tate were breaching its rules.\n- TikTok said it was working to review the content of Tate's videos.\n- TikTok said it was taking action against violations of its guidelines.\n- TikTok said it was looking to strengthen its policies and enforcement strategies.\n- TikTok said it was adding more safeguards to its recommendation system.\n- TikTok said users can click 'not interested' on videos they dislike to hide future material from that particular account.\n- Police were called after Tate showed up at the house of Mike Stuchbery.\n- UK police investigated abuse allegations against him.\n- Indiana police are investigating the fatal crash.\n- State police are continuing to investigate whether the Tesla autopilot was activated at the time of the crash.\n- State police planned to contact Tesla as part of their investigation.\n- Many people googled the same phrase to see the results for themselves.\n- Ron Flexico tried the same search on Bing to see if the results would differ.\n- MailOnline approached Google for comment.\n- Google issued a public statement to Metro.co.uk saying the search results reflect societal biases and do not reflect Google's view.\n- Google said it welcomes feedback.\n- Google said it is always working to improve its search results.\n- Amazon is investing heavily in ways to detect and prevent inauthentic reviews.\n- Amazon is removing selling privileges from sellers that list different products on the same listing.\n- Amazon has started including \"Editorial Recommendations\" based on testing by sites like Wirecutter, OutdoorGearLab, and Reviewed for some categories.\n- The Federal Trade Commission began looking into allegations of misleading reference prices in July 2017.\n- Sellers sometimes offer a replacement to dissatisfied customers so the customers will consider revising their review and raise their star rating.\n- Customer R.D. contacted Amazon to report that her one-star review was taken down without her consent.\n- Customer R.D. attempted to republish the negative review after contacting Amazon.\n- Japanese police arrested 43-year-old Masayuki Nakamoto for using AI to effectively unblur pixelated porn videos.\n- Police conducted a 'cyber patrol' which led to Nakamoto's arrest.\n- Nakamoto pleaded guilty to charges of copyright violation and displaying obscene images.\n- In Taiwan, a man was arrested for selling deepfake porn on a Telegram group.\n- Taiwanese President Tsai Ing-wen said she would consider legislation against online sex violence involving deepfake porn.\n- California banned political deepfakes within 60 days of an election to combat potential campaign misinformation.\n- Victims have fought to remove compromising fake videos from the internet.\n- The Laguna Beach Police Department posted a report of the collision on its public Facebook page.\n- The National Transportation Safety Board (NTSB) outlined the reasons for these accidents in a report following a prior fatal Tesla Autopilot crash.\n- The social media companies took down the group's videos.\n- The social media companies took down the affiliated user accounts.\n- Graphika tracked the group's activities.\n- Graphika published a report documenting the campaign and naming it \"Spamouflage Dragon\".\n- Graphika warned that the tactic of using AI-generated profile pictures is likely to become increasingly prevalent.\n- U.S. intelligence officials warned that foreign governments will try to sway U.S. public opinion to influence the upcoming presidential election.\n- A Waymo worker caught up to the stranded vehicle.\n- A Waymo worker took over control of the vehicle.\n- A Waymo worker drove the passenger to his final destination.\n- A construction crew removed a cone that was in the Waymo vehicle's path.\n- A Waymo roadside assistance vehicle arrived on scene.\n- The Waymo employee on the car's audio system instructed the passenger to remain seated and keep his seat belt on.\n- Waymo issued a public statement saying the situation was \"not ideal\" and that the self-driving car had received incorrect guidance.\n- Waymo refunded the passenger for the trip.\n- The California Department of Motor Vehicles filed a pair of complaints with the state Office of Administrative Hearings on July 28 accusing Tesla of making untrue or misleading statements about Autopilot and Full Self-Driving.\n- If its action succeeds, the DMV said it will ask that Tesla be required to advertise to consumers about the capabilities of its Autopilot and Full Self-Driving features.\n- If its action succeeds, the DMV said it will ask that Tesla better educate Tesla drivers about the capabilities of its Autopilot and Full Self-Driving features.\n- If its action succeeds, the DMV said it will ask that Tesla include cautionary warnings regarding the limitations of the Autopilot and Full Self-Driving features.\n- If it prevails, the DMV proposed it could seek revocation of Tesla's licenses to make or sell its cars in California.\n- The National Highway Traffic Safety Administration opened an investigation into Tesla's Autopilot after Teslas showed a pattern of plowing into emergency vehicles parked by the roadside.\n- If its action succeeds, the DMV said it will ask for other actions as appropriate given the violations.\n- A founder of Coffee Meets Bagel emailed BuzzFeed News to explain that the algorithm uses empirical match data to maximize users' connection rates.\n- Coffee Meets Bagel analyzed millions of match records to determine that users who select 'no preference' often show clear ethnicity preferences in their likes.\n- The company examined data for users who selected only one race to test whether white Jewish men disproportionately preferred Asian women.\n- Coffee Meets Bagel analyzed women's ethnicity preferences in its match data, finding that white women who preferred only one race chose white men.\n- The company published a blog post presenting its analysis of race-based dating preferences and the single-race selection findings.\n- The app used the behavioral insights learned from its match data to inform its match-suggestion algorithm with the goal of maximizing connection rates.\n- Jonathan Gheller, Facebook's product manager for Year in Review, contacted Eric Meyer before the story started hitting the papers and personally apologized to him.\n- Facebook issued an apology for the Year in Review feature's tone-deafness.\n- Gheller told Meyer that he was determined to do better in the future.\n- Facebook said its teams are working to stay ahead of any militia groups that try to evade the platform's ban.\n- A Facebook employee flagged the armored-vest ad on the company's internal forum Workplace.\n- A reviewer assessed the flagged ads and determined there were not enough violations to remove the ad.\n- A different Facebook worker reported in a Workplace group that friends had seen military gear ads served alongside news stories about the Capitol insurrection.\n- Facebook said it had taken proactive measures to remove extremist content.\n- Facebook said it was working to find any mention that may be leading to violence and to remove such mentions as quickly as possible.\n- The 'Stop the Steal' group with more than 14,000 members was later removed from the platform.\n- Uber launched an investigation into workplace sexual harassment and discrimination to be led by former attorney general Eric Holder and board member Arianna Huffington.\n- Ed Baker resigned from his position as Uber's vice president for product and growth.\n- Senior vice president of engineering Amit Signhal stepped down.\n- Travis Kalanick said he was seeking 'leadership help'.\n- Travis Kalanick issued an apology that included an admission his leadership was inadequate.\n- Uber issued a public statement defending the Greyball program, saying it denies ride requests to fraudulent users who violate its terms of service to protect drivers.\n- Uber spokespeople publicly argued there is a distinction between law enforcement and code enforcement and claimed the company had a right and obligation to protect its drivers from harm.\n- Uber spokespeople declined to speak on the record.\n- Uber agreed to a $20 million settlement over claims it deceived drivers about their prospective earnings.\n- The crash was reported to the National Highway Traffic Safety Administration.\n- The incident report appears to have been made by the owner of the Model Y.\n- A spokesperson for the National Highway Traffic Safety Administration confirmed that the agency was investigating the claim.\n- NHTSA is seeking more information from Tesla about the growing public beta test of Full Self-Driving.\n- NHTSA is seeking more information from Tesla about the recently launched 'Safety Score' evaluation process for entering the program.\n- NHTSA is seeking more information from Tesla about the nondisclosure agreements Tesla was making participants sign up until recently.\n- The hotel laid off more than half of its robot staff.\n- Facebook apologized for taking down the post.\n- Facebook restored the post.\n- Facebook looked into the removal of the post.\n- The Vindicator published a story about the takedown on July 3.\n- The Vindicator's editors notified Facebook about the takedown.\n- Curious Thing cofounder Han Xu responded by email to the test results.\n- Curious Thing said it will research the German-language test to see if it unveils any issues in their system.\n- Bavarian Public Broadcasting published an investigation that found Retorio\u2019s algorithm assessed candidates differently when they used different video backgrounds and accessories.\n- Retorio co-founder Christoph Hohenberger publicly stated that the company's software is intended to be an assisting tool and not an automatic filter or the deciding factor in hiring decisions.\n- YouTube removed election fraud videos from the platform in December 2020.\n- Since 2020, Google has actively blocked election misinformation on YouTube.\n- Google blocked the Truth Social app from the Google Play Store, citing insufficient content moderation.\n- YouTube launched a research program earlier this year to increase transparency on the platform.\n- A YouTube spokesperson publicly disputed the NYU team's report, saying it does not accurately represent how YouTube's systems work.\n- The House select committee investigating the January 6 attack requested that former House Speaker Newt Gingrich share information about his involvement in amplifying false claims about the 2020 election.\n- NYU researchers recruited hundreds of YouTube users and recreated the recommendation experience by having participants complete the study while logged into their YouTube accounts.\n- Researchers had participants download a browser extension to capture data on the videos recommended to them.\n- Researchers instructed participants to navigate through 20 recommendations following specified paths to control their on-platform behavior.\n- Researchers recorded and categorized any recommended content as supporting, refuting, or neutrally reporting Trump's election fraud claims.\n- After participants finished watching videos, researchers had them complete a lengthy survey reporting their beliefs about the 2020 election.\n- Voiceverse deleted the animation from its Twitter account.\n- Voiceverse publicly apologised to 15.ai for using their work without proper credit.\n- Voiceverse admitted that the voice was taken from 15.ai and used by their marketing team without acknowledgement.\n- Voiceverse pledged that they will make sure this never happens again.\n- A consolidated class-action lawsuit, Cadena v. American Honda Motor Co., was filed in a California federal court seeking an injunction against the manufacturer and damages for personal injuries and property damage.\n- A lawsuit venued in Illinois alleged additional defects in the sensing technology and problematic warning messages from the collision mitigation system.\n- Consumers injured by the brake-slamming problem have sued manufacturers alleging failure to warn of AI system problems and deceptive practices.\n- At least one vehicle owner reported deactivating the collision mitigation braking system after experiencing repeated false activations.\n- Firefighters contacted Tesla corporate to obtain guidance on how to extinguish the vehicle battery fire following a fatal Tesla crash.\n- A class action lawsuit was filed in 2018 alleging that Nissan's Forward Emergency Braking system is defective.\n- If the class action lawsuit is certified, affected vehicle owners may need to opt out by certain deadlines to pursue an individual lemon law case.\n- Under the California Lemon Law, owners and lessees may receive cash compensation, vehicle replacement, or a lemon law buyback as remedies for defective vehicles.\n- The Knight Law Group offered a free lemon law consultation and provided a form and the phone number 877-222-2222 for suspected owners to contact them.\n- Smart Columbus notified the U.S. Department of Transportation about the incident.\n- Smart Columbus notified the National Highway Traffic Safety Administration about the incident.\n- Smart Columbus halted shuttle service.\n- Smart Columbus took both shuttles out of service until EasyMile could come into town Monday to look into it further.\n- EasyMile was to come into town Monday to look into the shuttles further.\n- Columbus Fire medics were sent to East 12th Avenue.\n- Columbus Fire medics took the woman to Ohio State University Hospital East with minor injuries.\n- The Transport Workers Union asked for an independent investigation to determine what happened.\n- Facebook reinstated the ad after a review.\n- Facebook apologized to the business for the trouble.\n- Bucheon will roll out a pilot project using artificial intelligence, facial recognition and more than 10,820 CCTV cameras to track movements of people infected with the coronavirus.\n- The system places a mosaic over the faces of anyone who is not a subject.\n- Rules require patients to give their consent for the facial recognition tracking to be used.\n- The system can track individuals using their silhouette and clothes even if patients do not consent.\n- The Ministry of Science and ICT provided 1.6 billion won in funding and the city injected 500 million won of the city budget to build the system.\n- The Ministry of Science and ICT said it has no current plans to expand the project to the national level.\n- The pilot plans call for a team of about ten staff at one public health centre to use the AI-powered recognition system.\n- The Korea Disease Control and Prevention Agency said the use of such technology is lawful as long as it is used within the realm of the disease control and prevention law.\n- Toronto Public Health will evaluate the predictive model after the end of the summer season, on Labour Day, to determine whether it will be used again next year at Sunnyside and Marie Curtis.\n- Toronto Public Health stated that Toronto\u2019s other eight beaches will not require AI modelling and will continue to use the traditional testing method.\n- Isabel Fleisher has been keeping a spreadsheet comparing AIPM predictions with traditional testing data.\n- Toronto Public Health issued a public statement to the Star defending the AIPM, asserting it is a significant improvement and explaining that AIPM predictions supersede daily testing results.\n- Twitter said it would make its research available to outsiders such as academics.\n- Twitter said it was preparing to let third parties have wider access to its data.\n- Twitter said it was making aggregated datasets available for third-party researchers who wish to reproduce its main findings and validate its methodology, upon request.\n- Twitter said it was preparing to make internal data available to external sources on a regular basis.\n- Twitter said its machine-learning ethics, transparency and accountability team was finalising plans to provide access in a way that would protect user privacy.\n- Twitter indicated that it may need to change its Home timeline algorithm.\n- Twitter said more study needed to be done into the findings.\n- Twitter said further root cause analysis was required to determine what, if any, changes are needed to reduce adverse impacts of the Home timeline algorithm.\n- Federal vehicle safety regulators in Michigan launched an investigation into the Tesla Model Y crash.\n- Instagram publicly acknowledged the issue as a technical bug.\n- Instagram disabled the related-hashtags feature while it investigated the problem.\n- Authorities opened an ongoing investigation into the crash.\n- Two federal agencies began examining the wreck.\n- The National Highway Traffic Safety Administration deployed a Special Crash Investigation Team to the crash site.\n- NHTSA engaged with local law enforcement and Tesla to learn more about the details of the crash.\n- Local police demanded crash data from Tesla.\n- Fire crews contacted Tesla to learn how to extinguish the electric vehicle fire.\n- Firefighters used 32,000 gallons of water to get the blaze under control.\n- Data logs were recovered from the vehicle.\n- The recovered data logs showed that Autopilot was not enabled and that the vehicle did not have Full Self-Driving purchased.\n- Tesla CEO Elon Musk posted tweets refuting early investigative findings.\n- The parents filed a lawsuit in the Los Angeles County Superior Court alleging TikTok's algorithm pushed deadly content to their children.\n- The families are represented by the Social Media Victims Law Center (SMVLC).\n- The Walton and Arroyo families are seeking an unspecified amount in damages.\n- The families have requested a jury trial to take place in California.\n- Users can unlock their iPhone with their pass code when Face ID fails to recognize them.\n- Apple Support advised users to make sure nothing is covering their face (like a pillow).\n- Apple Support advised users to face the TrueDepth camera at an arm's length or closer (10\u201320 inches).\n- Apple is introducing multiuser Face ID support in iOS 12 so users can register an \"Alternative Appearance\" for an alternative morning face.\n- Security expert Marc Rogers suggested that users try widening their eyes with their fingers and then attempt Face ID when it fails.\n- Police dismissed obvious false matches flagged by the facial-recognition algorithm.\n- Police did not inform carnival-goers that they had been flagged in the dismissed cases.\n- Many people flagged by the algorithm were stopped and questioned by police.\n- Those people were released after being questioned.\n- Cressida Dick publicly stated she was \"completely comfortable\" with deploying the technology.\n- The Welsh police published a blog post defending the facial-recognition technology and acknowledging that no system is 100% accurate.\n- Facebook implemented a filter so that if a user listed then de-listed someone in their relationship status, the On This Day feature will not fill their News Feed with old posts about that person.\n- Facebook implemented filtering to exclude posts from memorialized accounts from appearing in the On This Day News Feed.\n- Facebook added a user control allowing people to have On This Day posts appear in their News Feed less frequently.\n- Timehop added an opt-in prompt on Valentine\u2019s Day that warned users about potential reminders of exes and bittersweet feelings and required them to opt in.\n- The Charlotte Mecklenburg School District purchased and deployed Evolv's AI-based weapons screening scanners across its campuses in response to guns being found on school grounds.\n- Evolv removed previously publicly available instruction manuals and documents from its website and made them accessible only with a password in response to questions from IPVM.\n- Evolv sent a statement to Motherboard asserting that publicly communicating detailed information on sensitivity settings, protocols, and processes endangered students and educators.\n- Security experts suggested that students arrive earlier to reduce lines and congestion caused by the scanners.\n- Administrators were advised to ask students not to bring so many binders in order to reduce false positives triggering the scanners.\n- YouTube said creators can appeal removal decisions.\n- YouTube said its teams will review content that creators appeal.\n- Facebook denied that the bug was related to changes in its content moderator workforce.\n- Facebook said it was in the process of fixing a bug in its anti-spam system.\n- Facebook said it was bringing all the affected/removed posts back (restoring the posts).\n- Facebook removed more than 900 accounts, pages, and groups from its platform and Instagram.\n- Facebook conducted an investigation that connected The BL to The Epoch Times.\n- Researchers from Graphika and DFRLab published a report on the influence operation.\n- Graphika and DFRLab researchers identified 18 profile-photo images they determined had likely been generated using generative adversarial networks.\n- The report's authors checked one profile image with experts at the University Federico II of Naples.\n- Experts at the University Federico II of Naples assessed that the checked image was GAN-generated with 99.9 percent certainty.\n- Mark filled out a form requesting a review of Google\u2019s decision and explained his son\u2019s infection.\n- Google disabled Mark\u2019s account citing harmful content and a possible child sexual abuse & exploitation violation.\n- Google\u2019s review team declined to reinstate Mark\u2019s account.\n- Google searched Mark\u2019s account for other exploitative material after the images were flagged.\n- Google made a report to the CyberTipline at the National Center for Missing and Exploited Children.\n- CyberTipline staff added any new abusive images to the hashed database shared with technology companies.\n- CyberTipline staff escalated potential new victims to law enforcement.\n- The San Francisco Police Department served search warrants on Google and Mark\u2019s internet service provider requesting everything in his Google account.\n- The San Francisco police preserved the contents of Mark\u2019s Google account on a thumb drive.\n- Investigator Nicholas Hillard determined that no crime occurred, closed the case, and sent Mark a letter informing him of the investigation and its closure.\n- Mark appealed his case to Google again and provided the police report.\n- Mark spoke with a lawyer about suing Google.\n- Mark\u2019s wife deleted the photos Mark had taken of their son from her iPhone after learning the images could be added to the hashed database.\n- Cassio asked his mortgage broker to switch his email address after his Gmail account was disabled.\n- Cassio showed the detective his communications with the pediatrician, and he was quickly cleared.\n- Cassio began using a Hotmail address for email and started making multiple backups of his data.\n- Google issued a public statement saying that child sexual abuse material is abhorrent and that the company is committed to preventing its spread.\n- A police spokesman said the San Francisco Police Department is eager to help Mark obtain a copy of the preserved account contents.\n- The Council of Europe published new guidelines in July to begin addressing the use of new technologies that create fraud in education.\n- Tens of thousands of commenters posted positive messages on Marcus Rashford, Jadon Sancho, and Bukayo Saka\u2019s Facebook and Instagram pages to combat the racist attacks.\n- Fans urged fellow supporters to report offensive comments to company moderators.\n- Many soccer fans reported racist posts to the social media companies where the posts appeared.\n- Twitter said it took down 1,000 posts in the 24 hours since the game.\n- Facebook quickly removed an unspecified number of comments and accounts directing abuse at England\u2019s footballers.\n- Twitter used a combination of machine learning-based automation and human review to identify and proactively flag a majority of racist comments toward the players.\n- Facebook encouraged users experiencing harassment to turn on the \"hidden words\" feature to block designated words or emojis in comments on their posts.\n- England\u2019s Secretary of State for Digital, Culture, Media and Sport tweeted that the new Online Safety Bill will hold social media companies to account with fines of up to 10 percent of global revenue if they fail to address such abuse.\n- Facebook said it will continue to take action against those that break its rules.\n- Geisel opened an investigation into possible cheating after a faculty member reported possible cheating.\n- The Committee on Student Performance and Conduct asked the school's technology staff to audit Canvas activity during 18 remote exams.\n- The technology staff reviewed more than 3,000 exams as part of the audit.\n- The technology staff developed a system to recognize online activity patterns that might signal cheating.\n- The audit identified 38 potential cheating cases.\n- The committee eliminated some flagged cases after determining a professor had directed students to use Canvas.\n- In mid-March emails, the committee sent the 17 accused students spreadsheets detailing the exam name, test question number, timestamps, and the names of Canvas pages showing activity.\n- Administrators provided accused students with the data on which the cheating charges were based.\n- The committee dismissed the charges against seven of the 17 accused students.\n- The committee dismissed charges against at least two students after they said the audit had misinterpreted automated Canvas activity as human activity.\n- The conduct review committee issued decisions in 10 cases expelling several students.\n- The conduct review committee suspended other students.\n- The conduct review committee required some students to retake courses.\n- The conduct review committee required some students to repeat a year of school.\n- Some accused students filed appeals of their disciplinary decisions.\n- Dozens of students gathered in front of Dr. Compton's office to protest the investigation.\n- More than two dozen members of Dartmouth's faculty wrote a letter to Dr. Compton saying the school should make amends with the students falsely accused.\n- Geisel administrators held a virtual forum to answer questions about the investigation.\n- Dartmouth issued a social media policy warning that students' anonymous posts may still be traced back to them.\n- Dr. Compton apologized in an email for the handling of the cases and said the school was working to improve its procedures.\n- The medical school implemented new guidelines requiring students to log out of Canvas on all devices prior to testing.\n- School officials hired a legal consulting firm to validate their analysis.\n- Officers did not take action on the facial recognition matches at the Champions League final.\n- No one was wrongly arrested as a result of the false matches.\n- South Wales Police stated that they use the facial recognition outputs as a piece of intelligence and assess matches rather than acting on them immediately.\n- South Wales Police stated that officers only take action when an identification from the facial recognition system is confirmed.\n- Federal investigators examined the crash site and the vehicle logs from the incident.\n- The National Highway Traffic Safety Administration concluded the Autopilot system was operating as intended and determined no recall was necessary.\n- The National Transportation Safety Board publicly stated that Tesla should bear some of the blame for selling a system that is too easy to misuse.\n- After Brown's death, Tesla modified Autopilot to rely more on radar data and less on camera data to detect obstacles.\n- Tesla issued a software update that sharply curtailed the length of time a driver can let go of the steering wheel while Autopilot is engaged.\n- Tesla introduced brighter, flashing warnings to get drivers' attention when using Autopilot.\n- Tesla published a blog post presenting data from the vehicle logs and commenting on the circumstances of the crash.\n- Visit Flanders created and released a playful protest video showing security staff removing visitors who have a Facebook profile and are found looking at a painting of nudity.\n- Toerisme Vlaanderen issued a letter to Mark Zuckerberg, signed by a number of museums, protesting Facebook's nudity ban and how it prevents promotion of the works.\n- The listed former incidents were converted to 'issues' following an update to the incident definition and ingestion criteria.\n- Reports associated with each incident were reassigned to be associated with other incidents as context.\n- Editors confirmed the migration of Incident 85, stating it likely does not fit the current incident criteria.\n- TikTok publicly reaffirmed its commitment to remove eating disorder videos.\n- TikTok's 'Need Help?' page provides contacts for the United States National Suicide Prevention Lifeline and general tips for finding support.\n- Chris Henrie creates TikTok videos educating people about eating disorders based on his treatment experiences.\n- Maddie Quinn posted a recovery video on TikTok to counteract potentially harmful eating-disorder content.\n- Lily deleted her TikTok account.\n- Sanas offers workers the choice of turning off the service when needed.\n- Sanas emphasized the worker opt-out option through its website and in an interview with SFGATE.\n- In a follow-up email to SFGATE, Sanas' president confirmed that the enterprise call center will hold the admin rights to control Sanas.\n- The Tesla Model S driver published a video of his car crashing into a van while on Autopilot.\n- The Model S owner later set the video to private.\n- Stability AI said it was working with leading ethicists and technologies on safety and other mechanisms around responsible release.\n- Stable Diffusion's software package includes an adjustable Safety Classifier that attempts to detect and block offensive or undesirable images.\n- OnlyFans said it will continuously update its technology to address the latest threats to creator and fan safety, including deepfakes.\n- OnlyFans reviews all content using digital detection technologies and then manually reviews it with trained human moderators to ensure any person featured is a verified OnlyFans creator or that there is a valid release form.\n- OnlyFans deactivates any content it suspects may be a deepfake.\n- Patreon has a policy that disallows deepfakes and prohibits images that repurpose celebrities' likenesses and place non-adult content into an adult context.\n- Patreon said it constantly monitors emerging risks and will work closely with creators to craft policies defining allowed benefits and content guidelines.\n- The article removed images depicting some of the celebrity deepfakes from an earlier version.\n- The operator of the Tesla was stopped several hundred feet ahead by the second trooper on scene.\n- The driver admitted to using the Autopilot system at the time of the crash.\n- The occupant of the Tesla was issued a misdemeanor summons for Reckless Driving and Reckless Endangerment.\n- An anti-sexist community filed a complaint with Vkontakte about the doxing group.\n- Vkontakte banned the group set up by Dvach users that was sharing women's social media pages.\n- FindFace said it is making every effort to protect all Vkontakte users from potential malicious acts.\n- FindFace said it is prepared to provide any information needed to help identify the users responsible for the harassment.\n- Channel 4 News withheld the specific names of the chemicals from publication.\n- Channel 4 News verified the authenticity of the chemicals with experts.\n- Channel 4 News did not complete the transaction when creating a shopping basket containing ingredients for black powder.\n- Amazon said it will work closely with police and law enforcement agencies to assist investigations if needed.\n- YouTube took down at least two videos flagged by The Telegraph.\n- YouTube removed search-term recommendations such as \"how to self-harm tutorial,\" \"self-harming girls,\" and \"self-harming guide\" once the company was notified.\n- YouTube said it removes videos that promote self-harm which violate its terms of service.\n- YouTube said it may allow videos that offer support for people who self-harm.\n- YouTube forced Jake Paul to take down his Bird Box challenge video.\n- YouTube gave other creators two months to remove their Bird Box challenge videos themselves.\n- YouTube said it would recommend fewer \"borderline\" conspiracy-theory videos to reduce their spread.\n- I clicked the advertisement to follow it.\n- I performed a reverse image search on the testimonial image and found it matched filmmaker Sam Muirhead.\n- I searched my Hunchly archive for Facebook URLs containing the keyword \"sponsored\" to find similar ads.\n- I viewed an archived Facebook ad page from December 11, 2015 in Hunchly and inspected the ad without clicking it.\n- I moused over the ad to view the actual destination URL displayed in Chrome's status bar.\n- I right-clicked and copied the ad's encoded URL into a text editor instead of clicking it.\n- I pasted the encoded URL into an online URL decoder to reveal the shortened Google URL.\n- I accessed the Google shortened URL's analytics by adding \".info\" and reviewed its click counts and referrer data.\n- I investigated the dftrack6.com domain and found it appeared suspicious.\n- I created a targeted Facebook ad with a mismatched display URL (cnn.com) and landing page (hunch.ly) to test Facebook's approval process.\n- I turned the test ad off immediately after it started running.\n- I asked readers to email me their findings so I could collect statistics and encourage further investigations.\n- Nijeer Parks filed a lawsuit against the police, the prosecutor, and the City of Woodbridge alleging false arrest, false imprisonment, and violation of his civil rights.\n- In November 2019, the case against Mr. Parks was dismissed for lack of evidence.\n- New Jersey Attorney General Gurbir S. Grewal put a moratorium on Clearview AI\u2019s use by the police.\n- The attorney general announced an investigation into Clearview AI or products like it.\n- New Jersey\u2019s Division of Criminal Justice was evaluating the use of facial recognition products in the state.\n- The development of a policy governing the use of facial recognition products in New Jersey was ongoing.\n- Mr. Parks\u2019s mother and fianc\u00e9e hired an attorney to represent him.\n- That attorney got Mr. Parks out of jail and into a pretrial monitoring program.\n- Mr. Parks obtained Western Union records showing he was sending money at a pharmacy in Haledon, New Jersey, at the time of the incident.\n- Mr. Parks told the judge he was willing to go to trial to defend himself.\n- The New York State Intelligence Center and New Jersey\u2019s Regional Operations Intelligence Center said they did not make the facial recognition match.\n- Clearview AI\u2019s founder stated that officers affiliated with the state agencies and fusion centers were not using his company\u2019s app at that time.\n- Jisuk Mok went to the Frisco Police Department to file a police report.\n- Jisuk Mok reached out to the city of Frisco to ask questions about the incident.\n- Jisuk Mok filed a claim with her insurance company.\n- Jisuk Mok turned to NBC 5 Responds for help.\n- NBC 5 Responds submitted an open records request to learn about other accidents at the intersection.\n- NBC 5 contacted both the city of Frisco and Starship Technologies asking about the accidents and why the robots do not have a phone number listed.\n- Starship Technologies told Mok they would send her the video of the accident.\n- Starship Technologies provided an email response to NBC 5\u2019s questions explaining their deployment and indicating that their website and contact information are written on the robots.\n- Starship Technologies agreed to pay more than $2,600 to cover the damages to Mok's car.\n- Starship Technologies pulled out of Frisco on August 7.\n- Starship Technologies moved its robots back to The University of Texas at Dallas.\n- Adjusters double-check the computer's work after the AI generates an estimate.\n- Insurance companies sometimes consider photo-based estimates as starting places for in-person inspections by repairers.\n- Nexar began working with Mitsui Sumitomo Insurance to translate high-definition dashcam footage and acceleration and GPS data into machine-generated scripts for claims adjusters to use.\n- Claims adjusters translate those machine-generated scripts into estimate line-items.\n- Adjusters' translations are used to train the technology so it will learn and improve.\n- AI systems guide adjusters through the estimation process and automatically populate forms.\n- Motorists sometimes bring their vehicles to Hernandez Collision Repair to verify that work performed by other shops was done properly.\n- The matter was referred to the dean of student affairs.\n- The student met with the dean and the professor by video to discuss the flagged behavior.\n- The student was found responsible for noncompliance and received a zero on the exam.\n- A warning was placed on the student's academic record.\n- Honorlock's live proctors investigated and discovered that Rekognition was mistakenly registering faces in photos or posters as additional people in the room.\n- When Rekognition mistakenly registered faces in photos or posters, Honorlock told Amazon's engineers.\n- Amazon's engineers took Honorlock's real data and used it to improve their AI.\n- Honorlock uses human employees as live proctors who pop in by chat when there is a high number of flags on an exam.\n- ProctorU discontinued offering an AI-only product that flagged videos for professors to review.\n- ProctorU changed its process so that all suspicious behavior is now reviewed by one of the company's approximately 1,300 proctors.\n- ProctorU required its contractors to undergo rigorous training to review flagged videos.\n- ProctorU instructed its proctors to confirm a breach only if there was solid evidence that a test taker was receiving help.\n- The Home Office conducted an equality impact assessment (EIA) of the sham-marriage triage system.\n- The Home Office uses the EIA as part of the triage system to identify any potential risk of discrimination and assess the impact.\n- The Home Office suspended its visa algorithm system in August.\n- The Home Office said it would conduct a review of the suspended visa system's operation.\n- The EIA suggests the Home Office has conducted a separate review of the triage system's impact on different nationalities.\n- Successful legal action was taken by the Joint Council for the Welfare of Immigrants (JCWI) and Foxglove against the Home Office's visa algorithm.\n- Twitter suspended the accounts of the users who posted and promoted the AI-altered clip.\n- Walt Disney Studios disabled the dislike button on the film's YouTube trailer after it received around 1.5 million dislikes.\n- The App Drivers & Couriers Union filed a complaint in the Amsterdam district court to challenge Uber\u2019s practice of algorithmically dismissing drivers.\n- The International Alliance of App-based Transport Workers supported the claim of a fourth driver from Lisbon.\n- Worker Info Exchange supported the legal action on behalf of the drivers.\n- The ADCU invited all former Uber drivers in the European Economic Area who had been dismissed for alleged \u2018fraudulent activity\u2019 to register on its website for potential future action.\n- The ADCU launched a crowdfunding appeal to help pay for the legal action against Uber.\n- The ADCU filed complaints against Ola and Uber alleging failure to provide workers with access to their data under Article 15 of the GDPR, with the cases scheduled to be heard by the Amsterdam District Court.\n- Murat Ayfer updated Philosopher AI's content filter so more prompts return the polite response: 'Philosopher AI is not providing a response for this topic, because we know this system has a tendency to discuss some topics using unsafe and insensitive language.'\n- Murat Ayfer added a function that lets users report offensive responses in Philosopher AI.\n- OpenAI launched GPT-3 as a private closed beta with carefully selected users to develop applications under company oversight.\n- OpenAI created an internal team that vets proposed applications for GPT-3.\n- OpenAI provides safety guidelines to companies granted access to the GPT-3 API.\n- OpenAI reviews applications again before deployment of GPT-3-powered products.\n- OpenAI monitors the use of GPT-3 after deployment.\n- OpenAI offers a general content filter for harmful bias and toxic language.\n- OpenAI is developing tools to help users better control GPT-3\u2019s generated text.\n- OpenAI provides mechanisms (such as prompting guidance and temperature settings) to influence GPT-3's tone and riskiness of output.\n- OpenAI maintains an internal red team that actively tries to break the model and find harmful behaviors.\n- OpenAI researchers analyze the model's underlying weights to try to identify indicators associated with harmful content.\n- OpenAI's review team has rejected applicants whose proposed products are deemed too sensitive.\n- OpenAI has insisted on a human-in-the-loop for some applications, requiring AI-generated text to be reviewed by a human before reaching end users.\n- OpenAI has stated it will not broadly expand access to GPT-3 until it is confident it has a handle on safety issues.\n- OpenAI initially withheld the full GPT-2 model and instead released a downsized version to mitigate misuse risks.\n- The Allen Institute for AI created the RealToxicityPrompts dataset of 100,000 prompts to evaluate toxicity in language-model outputs.\n- AI2 researchers applied additional training with innocuous text as a mitigation strategy to try to detoxify model outputs.\n- AI2 researchers applied filtering of generated text by scanning for keywords and by using more sophisticated filtering methods as a mitigation strategy.\n- Art of Problem Solving ensures GPT-3's generated text never goes directly to students by routing AI outputs through human graders who check and customize responses.\n- Sapling Intelligence constrained its use of GPT-3 by avoiding freeform generation and limiting the technology to protective, bounded tasks.\n- Koko uses a human-collaboration approach where GPT-3 generates bot-written responses or suggested text that human respondents can modify.\n- Replika has GPT-3 generate multiple response options and uses custom classifiers to detect and filter responses with negativity, harmful bias, and abusive language.\n- Replika collects user labels for inappropriate responses and uses that feedback as training data to improve its classifiers.\n- Latitude provides a default safe mode for AI Dungeon that relies on a combination of filters and prompt engineering, and requires users to explicitly turn off safety mode to access less-restrained content.\n- Latitude built its own screening technology rather than relying solely on OpenAI's safety filter so safety can be tailored to game context.\n- The European Commission fined Google \u20ac2.4 billion in 2017 for favoring its own comparison shopping service.\n- The EU General Court in Luxembourg ruled to uphold the European Commission's 2017 \u20ac2.4 billion fine against Google.\n- Margrethe Vestager fined Google \u20ac4.34 billion in 2018 over its Android operating system.\n- Margrethe Vestager fined Google \u20ac1.49 billion in 2019 over advertising on other websites.\n- In June, Vestager opened a new probe into Google's online advertising practices.\n- U.S. authorities opened three fresh antitrust cases against Google over the past year.\n- Google said it will review the court decision closely.\n- Google said it made changes in 2017 to comply with the European Commission's decision to give shopping comparison rivals equal treatment.\n- Google said it already complies with the order contained in the Commission's 2017 decision to give shopping comparison rivals equal treatment.\n- Google's rivals are seeking compensation through damages cases against Google.\n- The comparison shopping services that complained to the Commission are seeking to increase their demands on the Commission to force Google to make more substantial changes.\n- The European Commission said it will continue to use all tools at its disposal to address the role of big digital platforms.\n- TuSimple posted a statement on its website acknowledging the incident and saying it takes its responsibility to find and resolve all safety issues very seriously.\n- TuSimple produced an internal report about the crash that identified an outdated command being executed as the cause.\n- TuSimple provided more details about the crash in its report to the National Highway Traffic Safety Administration.\n- The Federal Motor Carrier Safety Administration launched a safety compliance investigation in response to the April crash.\n- The National Highway Traffic Safety Administration reportedly joined the investigation into the crash.\n- Facebook apologised for its mistake.\n- Facebook promised to take steps to ensure residents and visitors can use the term in relation to the Devon landmark.\n- Facebook said it was looking into what happened.\n- Facebook said it will take steps to rectify the error.\n- Google implemented a major algorithm update.\n- Wanda Stokes apologized for the fiasco that led to false fraud accusations.\n- Wanda Stokes reassigned the director of the Unemployment Insurance Agency.\n- The state is reviewing about 50,000 fraud cases from a nearly two-year period covering roughly 40,000 people.\n- The state is reviewing 28,000 other cases from that time that were handled by the computers and staff.\n- The state made public a review of unemployment fraud cases in December that found a 93 percent error rate for about 22,000 cases.\n- On Jan. 11 the state agreed to halt all collection activities against people who were subject to fraud determinations in the period in question.\n- As part of that agreement, the state will individually review each halted case and affirm fraud determinations with new notice to claimants before resuming collection activities.\n- A new law prevents the agency from adjudicating a claimant\u2019s case as fraud without human verification.\n- The new law reduces the statute of limitations for pursuing fraud from six years to three years.\n- Wanda Stokes said she plans to talk to legislators about enacting more reasonable penalties for unemployment fraud.\n- Legislators plan to propose more bills in the new two-year session as needed.\n- Senate Minority Leader Jim Ananich wants to create a fund to repay affected people and to address potential statute of limitations issues.\n- RealPage agreed in 2018 to pay $3 million to settle an FTC complaint that it had failed to ensure accuracy in its tenant screening product.\n- Property staff asked their company's division that oversaw YieldStar to review the software's recommendations.\n- The landlord subsequently raised rates more gradually after that internal review.\n- Federal agents removed a computer and documents from Jeffrey Roper's office during an antitrust prosecution.\n- The government reached settlements or consent decrees with eight airlines in price-fixing cases.\n- Those airlines agreed to change how they used the pricing technology under the settlements or consent decrees.\n- In 2021, the Federal Trade Commission said it was seeking a more active role in enforcing competition rules in such cases.\n- Angry protesters disrupted the National Multifamily Housing Council conference by seizing the stage and recounting how their families had been harmed by lack of affordable housing.\n- RealPage issued an email stating that it uses aggregated market data from a variety of sources in a legally compliant manner.\n- RealPage issued a statement claiming its revenue management solutions prioritize a property's internal supply and demand dynamics and therefore help eliminate the risk of collusion.\n- RealPage stated that its software helps prevent rents from reaching unaffordable levels by detecting drops in demand and responding by lowering rents.\n- RealPage said that using actual rents helps capture a truer picture of price elasticity and affordability, reducing the odds a unit is overpriced.\n- The Portland family contacted Amazon to investigate the incident.\n- The family unplugged all of their Alexa devices.\n- Danielle listened to the recorded conversation after it was sent back to her.\n- Danielle repeatedly called Amazon.\n- An Alexa engineer investigated the incident.\n- Amazon's engineers reviewed the family's device logs and confirmed the events the family reported.\n- The Alexa engineer apologized repeatedly to the family.\n- Amazon said it investigated the incident and determined it was an extremely rare occurrence.\n- Amazon stated it is taking steps to avoid this from happening in the future.\n- Amazon said it is evaluating options to make this case even less likely.\n- Amazon offered to de-provision Danielle's Alexa communications so she could continue using Smart Home features.\n- Weibo announced an effort to \"clean up\" the use of intentionally misspelled words and homophones.\n- Weibo said it would refine its \"keyword identification model\" to be able to filter coded language used to dodge censors.\n- A main Chinese internet regulator prohibited the use of intentionally misspelled words and homophones in usernames.\n- Baidu banned the popular insult from its message forums in 2021.\n- State media published stories defending China\u2019s airborne forces in response to people calling each other paratroopers.\n- Baidu left posts using the word for paratrooper up despite knowing their intended insulting meaning.\n- The characters for \"river crab\" were banned on Chinese social media.\n- Most of the popular examples of censor-dodging online slang were eventually banned.\n- The Cyrillic character used in chrysanthemum script was unbanned and is no longer banned.\n- A giant inflatable green horse was placed in a public square in Wuhan and became a social media sensation.\n- A group of UK Uber drivers launched a legal action against Uber in the Netherlands supported by the App Drivers and Couriers Union, the International Alliance of App-based Transport Workers, and Worker Info Exchange.\n- Copies of the complaint filed at the Amsterdam district court were published in English and Dutch.\n- The drivers will argue in court that Uber violated its obligations under the GDPR by failing to provide full access to their personal data and sufficient information on automated decision making and profiling.\n- The union will present evidence in court of Uber's maintenance of performance-related electronic tags attached to driver profiles.\n- The drivers will ask the district court in Amsterdam to order Uber to immediately comply with data protection law and to impose a \u20ac10,000 fine for each day it continues to violate the law.\n- The drivers will ask the court to order Uber to respect their right to port personal data directly from Uber to their union's fledgling data trust.\n- The App Drivers and Couriers Union is working with Worker Info Exchange to establish a data trust for drivers for the purposes of collective bargaining.\n- The drivers will be represented in the Netherlands by their attorney Anton Ekker.\n- The union launched a CrowdJustice campaign to help fund the legal action.\n- The union called on all Uber drivers and Uber Eats couriers in the UK and the European Economic Area to register for free to join the collective action for digital rights.\n- The International Alliance of App-based Transport Workers provided support for the legal action, forming an international collaboration of Uber driver unions.\n- A court in Palm Beach County set a February date for a jury trial to hear testimony on who was at fault.\n- The National Highway Traffic Safety Administration is conducting multipronged investigations into Autopilot and related crashes.\n- The NHTSA has investigated almost 200 crashes involving vehicles using the Autopilot feature.\n- California's Department of Motor Vehicles accused Tesla of false advertising in August.\n- California DMV officials interviewed former Tesla engineer Christopher 'CJ' Moore and concluded some of Elon Musk\u2019s tweets exaggerated Autopilot\u2019s capabilities.\n- The National Transportation Safety Board publicly chastised Tesla last October for failing to respond to its 2017 recommendations, including recommendations to limit where Autopilot can be activated and to ensure drivers pay attention while using the feature.\n- Some Tesla owners posted videos showing their vehicles safely stopping in front of real children in response to a viral YouTube video.\n- The NHTSA issued a 'don't try this at home' warning following the viral YouTube video.\n- A judge ruled that Elon Musk did not have to sit for a deposition, rejecting the Banners' argument that he has 'unique knowledge'.\n- The Banner family filed a lawsuit against Tesla.\n- ProPublica contacted Facebook about the presence of anti\u2011Semitic ad categories.\n- Facebook removed the anti\u2011Semitic targeting categories and associated targeting fields.\n- Facebook said it would explore ways to fix the problem.\n- Facebook said it would limit the number of ad categories available.\n- Facebook said it would scrutinize ad categories before they are displayed to advertisers.\n- Facebook said it was building new guardrails in its product and review processes to prevent similar issues in the future.\n- Facebook looked at the use of the identified audiences and campaigns to determine how common or widespread they were.\n- After an earlier ProPublica article about discriminatory housing ads, Facebook built a system intended to prevent such ads from being approved.\n- Shay's Google Home speaker was once again bleeping out the N-word after the video was uploaded.\n- Microsoft apologized after its chatbot was corrupted by Twitter users in 2016.\n- Microsoft said its technology was 'not up to this mark' following that incident.\n- Glovo contacted the family of Sebastian Galassi after the incident.\n- Glovo apologized to the family for the automatic dismissal message that was sent in error.\n- The magistrature opened an investigation into Sebastian Galassi's death.\n- The magistrature will review footage from cameras installed along the street that may have recorded the scene.\n- The CGIL (Florence) announced a 24-hour strike on October 5 in response to the death.\n- The protest associated with the strike was scheduled to take place from 18:00 in Piazza Sant'Ambrogio in Florence.\n- The union issued an appeal to consumers and the public to refrain from ordering home delivery through delivery platforms.\n- Uber confirmed that the reported selfie-verification incident did occur.\n- Uber said the issue can often be solved over the phone or through the app rather than requiring drivers to visit an in-person support center.\n- An Uber representative at a Greenlight Hub told Janey Webb that her account deactivation was a mistake.\n- Uber rolled out a feature in April allowing employees to specify their pronouns in an internal directory.\n- Facebook updated its app to include more gender identity and pronoun options for users.\n- Tinder updated its app to include more gender identity and pronoun options for users.\n- The bot was shut down late yesterday.\n- Pepsi executives in the Philippines and stateside convened an emergency meeting at 3 a.m. to decide how to proceed.\n- Pepsi opted to declare the widespread 349 wins a computer error.\n- Pepsi offered $18 to $20 to cap holders as a 'goodwill gesture.'\n- Consumers presenting 'winning' caps were told of the error and were turned away from bottling plants.\n- Barbed wire was erected around the bottling plants.\n- Pepsi hired bodyguards for its personnel.\n- Pepsi placed armed passengers in delivery trucks.\n- Pepsi evacuated expatriate staff from the country.\n- Pepsi was compelled to answer questions from the Philippines government.\n- Pepsi publicly characterized the protests as 'extortion.'\n- A Pepsi lawyer refuted the allegation that the company had hired mercenaries to damage its property.\n- Artemio Sacaguing\u2019s superiors dismissed his accusations and stated that the official's report had been discredited.\n- Most of the 689 civil suits and 5,200 criminal complaints related to the incident were tossed out of court.\n- In 2006 the Philippines Supreme Court ruled that Pepsi was not obligated to honor the sweepstakes payouts, closing the outstanding cases.\n- In future airings of the Harrier ad, Pepsi increased the number of points needed from 7 million to 700 million.\n- Google apologised for the incident, saying the answer does not reflect its views.\n- Google removed the answer from search results.\n- Google issued a public statement saying it takes swift corrective action when made aware of an issue and is continually working to improve its algorithms.\n- Aravind Limbavali, minister for Kannada and Culture, demanded an apology from Google.\n- Aravind Limbavali threatened legal action against Google for maligning the image of the language.\n- The researchers made all of their analysis code available online to make the data analysis transparent.\n- The reporters asked Uber for comment on the results of their analysis.\n- An Uber spokesperson responded that Uber is working hard to address a transportation status quo that has been unequal for a long time and to make it easier and more affordable for everyone to get around their cities.\n- Pinecrest Academy adjusted the gunshot detector's sensitivity to reduce false positives.\n- The Valley Hospital tweaked its aggression detector to be less sensitive after patients' loud voices and cafeteria noise caused false alarms.\n- The Valley Hospital is phasing out the aggression detector after a three-year, $22,000 pilot program.\n- Louroe Electronics provides regular software updates for its devices.\n- Sound Intelligence and Louroe fine-tune sensors at each new customer's location over a period of days or weeks.\n- Audio Analytic changed its business model and stopped selling its aggression-detection software.\n- ProPublica purchased a Louroe microphone and set it up according to Sound Intelligence's guidance to test the aggression detector.\n- ProPublica retested students' screams in a larger room using the same prompts to determine whether 'clipping' explained missed detections.\n- Karl Ricanek stated that he stopped giving access to the UNC-Wilmington dataset altogether three years ago.\n- Karl Ricanek had the dataset taken down immediately when Keyes and Austin contacted him after finding it in 2021.\n- Keyes and Austin filed a public records request that gathered about 90 emails and email attachments from Ricanek and his team.\n- Keyes and Austin contacted Ricanek in 2021 to inform him that they had found the dataset.\n- Keyes and Austin published their findings about the dataset in an academic paper in the journal Big Data & Society.\n- Keyes and Austin shared a document of their findings with VentureBeat.\n- Mitek's team worked to resolve the barcode gender code discrepancy that caused an 'X' on California IDs to return as the number nine in their system.\n- The Open Knowledge Foundation and Algorithm Watch partnered to collect data about Schufa scores.\n- The nonprofits crowdsourced thousands of personal credit reports from consumers.\n- The collected credit reports were passed on to investigative journalists.\n- Investigative journalists analyzed the crowdsourced credit reports en masse.\n- Data journalists used optical character recognition to extract text information from the uploaded credit report forms.\n- Schufa decided to retire version 1 of its score in June 2018.\n- Schufa decided to retire version 2 of its score in June 2019.\n- The German Minister of Consumer Protection called for more transparency about the variables used in the Schufa score and how they are weighted.\n- Some news outlets began introducing an 'algorithms beat' focused on reverse engineering, auditing, and critiquing algorithmic systems.\n- The Markup created a new Gmail account to test how the company filters political email.\n- The Markup used a new phone number and the Tor anonymizing browser to avoid sending signals about political leanings while conducting the test.\n- The Markup signed up for the email lists of 16 presidential candidates to see where their messages would be delivered.\n- The Markup also signed up for congressional candidates and advocacy groups, think tanks, and nonprofits from across the political spectrum.\n- Over four months, The Markup collected more than 5,000 emails from 171 groups as part of its testing.\n- The Markup reviewed email data provided by Democracy for America, CREDO Action, and SumOfUs to analyze Gmail open rates.\n- Change.org employees tested their own Gmail accounts and found that Change.org emails were being sent to the promotions tab.\n- A coalition of eight progressive advocacy groups wrote a letter to Google in November 2018 complaining that Gmail's categorization impeded their ability to engage the public.\n- The coalition held a phone conversation with a Gmail official the following month to discuss the issue.\n- A Gmail official suggested that the groups could buy an ad in the promotions tab or offer a deal to get more eyeballs on their emails.\n- Google communications manager Katie Wattie emailed that Gmail's categories help users organize their email and that mail classifications automatically adjust to match users' preferences and actions.\n- Google spokesperson Katie Wattie wrote in an email that Gmail has not allowed political content in ads since 2016, including issue advocacy and fund-raising.\n- KFC sent a second push notification to app users apologizing for the insensitive message.\n- KFC stated it would immediately check its internal processes to prevent this from happening again.\n- KFC issued a public statement to Newsweek apologizing and explaining the automated push notification was accidentally issued.\n- KFC suspended app communications while it examined its current processes to ensure similar problems did not arise again.\n- KFC examined its current processes to ensure similar problems did not arise again.\n- Twitter's team was dealing with the problem manually.\n- Twitter had put in place automations to address the problem.\n- A current Twitter employee said the company was aware of the problem by midday and was working to resolve it.\n- Stanford Internet Observatory said its team was working to determine how widespread and effective the campaign was.\n- The National Bureau of Investigation reported the possible information security incident to the National Police Board.\n- The National Police Board reported the matter to the Office of the Data Protection Ombudsman.\n- The National Police Board submitted the report to the Office of the Data Protection Ombudsman on Friday 9 April.\n- The National Bureau of Investigation continues to investigate the matter.\n- Facebook fixed a technical issue that caused incorrect translations from Burmese to English on its platform.\n- Facebook said it is taking steps to ensure the error does not happen again.\n- Facebook issued a sincere apology for the offense caused by the incorrect translations.\n- Real Women in Trucking filed a discrimination complaint with the Equal Employment Opportunity Commission.\n- Meta has been collaborating with civil rights groups, academics, and regulators to advance fairness in its ads system.\n- Meta said it is actively building technology designed to make additional progress in addressing fairness in its ads system.\n- In June, Meta settled a lawsuit brought by the Justice Department that alleged Facebook's housing ad system discriminated based on protected characteristics.\n- In 2019, Facebook agreed to pay out about $5 million to settle five lawsuits.\n- In 2019, Facebook agreed to take steps to block job and housing advertising on its platforms that targeted users based on age and gender.\n- Real Women in Trucking is being represented by Upturn, a nonprofit organization, in pursuing the complaint.\n- Facebook researchers conducted a five-question survey two years earlier to test users' digital literacy skills.\n- Researchers compared users' survey scores with the types of content shown by Facebook's algorithms over a 30-day period.\n- Researchers conducted several extensive interviews and in-home visits with vulnerable users to gain a better understanding of their experiences.\n- Researchers taught users with low digital literacy how to use functions like 'hide' and 'unfollow' to manage their feeds.\n- Facebook tested an 'Easy Hide' button, which substantially increased the number of posts people hid.\n- Facebook introduced the feature 'Why am I seeing this post?' in 2019.\n- Attorneys for Frances Haugen furnished documents containing the studies to the Securities and Exchange Commission and to Congress.\n- Uber issued a public statement after publication clarifying that no account deactivations are made based on facial recognition alone.\n- Uber said Real-Time ID Check escalates flagged non-matches to at least two human reviewers who then check the photos manually.\n- Uber said the manual review of flagged photo non-matches takes less than 25 seconds.\n- Uber said it gives drivers a chance to appeal deactivations.\n- Uber said it regularly conducts fairness testing, both internally and in partnership with Microsoft, to assess performance across different skin complexions and identify opportunities to improve efficiency and accuracy.\n- Uber said that in the UK and EU, drivers can choose whether their selfie is checked by verification technology or by human reviewers.\n- Uber said it sends multiple clear warnings to drivers before account deactivation.\n- Prisma Labs CEO Andrey Usoltsev sent an email to NBC News clarifying the company's mission and commenting on the democratization and ethical use of AI technology.\n- Prisma Labs issued a lengthy Twitter thread addressing concerns that AI art could replace human artists and arguing AI will assist rather than replace them.\n- Prisma Labs told TechCrunch that it deletes user photos from the cloud services it uses to process the images after using them to train its AI.\n- Lensa stated it uses a separate model for each user rather than a single model trained to reproduce any face.\n- Lensa stated that each user's photos and the associated model are permanently erased from its servers as soon as the user's avatars are generated.\n- Prisma Labs said AI-generated images \"can't be described as exact replicas of any particular artwork\" in its public statements.\n- Andrey Usoltsev declined to provide further comment regarding the third-party research and methodologies used by Stability AI.\n- Andrey Usoltsev asserted that Lensa is fully GDPR and CCAP compliant.\n- The San Francisco Ballet issued a press release defending its use of AI-generated images as an experiment and saying nearly 30 people were involved in creating the campaign.\n- FTX filed for bankruptcy.\n- The verified Twitter account that posted the deepfake has been suspended.\n- The author ran an experiment uploading only BDSM and dungeon photos to Lensa to observe how the app altered them.\n- The author ran an experiment uploading her most feminine photos while selecting the 'male' gender option to test the app's transformations.\n- The author ran an experiment uploading selfies from academic conferences to see how the app processed them.\n- The author uploaded a minimum of ten childhood photos to Lensa to test its 'No kids, adults only' restriction.\n- The author repeated the test with a mix of childhood photos and selfies to observe further results.\n- A user modified generated topless images by adding emojis to cover nudity for modesty.\n- Xpeng Motors assigned the customer's driving data for analysis after the accident.\n- Xpeng Motors processed the customer's driving data based on the background detection.\n- Xpeng Motors conducted a preliminary analysis of the driving data.\n- Xpeng Motors stated it will perform further analysis of the results after the car owner has recovered.\n- The National Highway Traffic Safety Administration disclosed that it had begun a preliminary investigation into General Motors' Cruise driverless taxis.\n- The NHTSA posted a filing on its website announcing that it had received reports and was investigating the incidents.\n- NHTSA's Office of Defects Investigation said it would try to determine the scope and severity of the immobilization and sudden-slowing incidents.\n- The investigation was opened to cover 242 Cruise vehicles.\n- General Motors reported three incidents to the agency in which Cruise vehicles slowed suddenly and were hit from behind.\n- Cruise said it will continue to fully cooperate with NHTSA and any regulator.\n- HSBC said it would look at ways to make the voice recognition system more secure.\n- County Court Judge Christopher Ciaccio reversed Silvon Simmons' weapons possession conviction.\n- ShotSpotter provided eight seconds of audio obtained from different sensors around Immel Street.\n- The city requested that ShotSpotter review the audio from the shooting.\n- ShotSpotter officials reviewed the incident audio and revised their determination of the number of shots from three to four to five.\n- ShotSpotter's automated system initially classified the sounds as likely an overhead helicopter.\n- ShotSpotter reviewed its audio from the shooting and reported that it found nothing else worthy of relaying to the prosecution or defense.\n- Another judge denied the defense request for a broad subpoena of ShotSpotter records.\n- Defense attorneys attempted to have the ShotSpotter evidence disallowed at the trial.\n- The Innocence Project filed a brief raising questions about the reliability of ShotSpotter.\n- An internal investigation cleared Officer Joseph Ferrigno of any wrongdoing.\n- A spokesperson for MSG issued a public statement reiterating that safety is their highest priority and that facial recognition is one of the methods they use.\n- MSG Entertainment issued a statement asserting that their policy is in compliance with all applicable laws, including the New York State Liquor Authority.\n- Other firms have sued over being blacklisted by MSG.\n- Sam Davis is challenging MSG\u2019s liquor license with the State Liquor Authority.\n- The Chief Executive Officer Bob Jordan publicly apologized for the disruption.\n- Southwest executives worked through the weekend in emergency rooms at the Dallas headquarters to manage the crisis.\n- Former crew schedulers were called in to help manage the high phone call volumes.\n- Someone at the airline located an open pizza place to feed employees on Christmas Day.\n- Southwest canceled about two-thirds of its planned flights for multiple days to reposition pilots, flight attendants and planes.\n- The airline locked up seat inventory on its website so customers could not buy tickets for flights that might ultimately be canceled.\n- Chief Operating Officer Andrew Watterson gave a Tuesday night update to employees about recovery plans and timing.\n- Chief Executive Officer Bob Jordan wrote a memo to employees acknowledging the need to modernize operations and invest.\n- Southwest executives acknowledged shortcomings in the airline\u2019s crew scheduling tools.\n- Southwest executives said their systems are being updated.\n- Transportation Secretary Pete Buttigieg and federal lawmakers stepped up calls for more stringent consumer protection measures.\n- The Chicago Police Department decommissioned the Strategic Subject List in November.\n- The Office of the Inspector General issued a public statement announcing the program's demise and detailing concerns with the PTV risk model program.\n- Four ambulances were called to the scene.\n- Two lanes of traffic were closed for about 90 minutes.\n- The California Highway Patrol reviewed videos showing the Tesla vehicle changing lanes and slowing to a stop.\n- The National Highway Traffic Safety Administration gathered additional information from Tesla and law enforcement about the crash.\n- The Korea Fair Trade Commission launched a probe into Coupang over accusations that the company meddled with algorithms to prioritize its own products.\n- The Korea Fair Trade Commission conducted an on-the-spot inspection at Coupang's headquarters office in Seoul late last month.\n- The Korea Fair Trade Commission is looking into whether Coupang coerced suppliers into purchasing advertisements.\n- The Korea Fair Trade Commission is looking into whether Coupang excluded suppliers from its subscription-based delivery service as an act of retaliation.\n- In a similar case last year, Naver was fined 26.7 billion won for manipulating search algorithms on its video and shopping platforms.\n- Naver denied the accusation and said the move was to diversify content.\n- An investigation into the cause of the distribution center fire is ongoing.\n- Traffic officers attempted to pull over the vehicle for a traffic check.\n- Police repeatedly sounded their horn to try to get the vehicle to stop.\n- Officers approached the driver and observed drug-typical abnormalities.\n- Officers found a 'steering wheel weight' in the footwell of the vehicle.\n- Police launched an investigation into the criminal offence of endangering road traffic.\n- The man was forced to hand in his driver's licence until he appears in court.\n- After about 15 minutes, the man woke up and followed the instructions of the police.\n- Amazon issued a statement to Reuters denying the allegations and calling them \"factually incorrect and unsubstantiated.\"\n- Amazon told the Wall Street Journal that the tactic was strictly prohibited among employees.\n- Amazon denied the claims during testimony at a U.S. congressional hearing.\n- Jeff Bezos said during the congressional hearing that he could not guarantee the prohibition policy had never been violated.\n- Jeff Bezos characterized possible violations as the actions of rogue employees during congressional questioning.\n- Indian regulators opened an investigation into Amazon for alleged anti-competitive behavior related to self-branded products.\n- Regulators also opened an investigation into the Walmart-backed competitor Flipkart.\n- Detroit Police implemented a new policy governing the use of facial recognition software that includes stricter rules on when it can be used.\n- Detroit Police now use the facial recognition technology only as a tool to help solve violent felonies.\n- A Detroit Police Department spokesman said he was looking into questions from the Free Press about Oliver's case.\n- The Wayne County Prosecutor's Office implemented more stringent protocol for facial recognition cases.\n- Current protocol requires a supervisor to review all evidence in a facial recognition case prior to a charging decision.\n- Current protocol requires that there be other evidence corroborating the allegations before charging someone in a facial recognition case.\n- Facial recognition cases must be submitted to Prosecutor Kym Worthy for approval if an assistant prosecuting attorney and a supervisor determine charges should be authorized.\n- Prosecutors and police apologized for how the Williams case was handled.\n- Worthy stated that facial recognition cases will be reviewed during the warrant charging phase.\n- Worthy stated that facial recognition cases will be reviewed prior to the preliminary examination.\n- Worthy stated that facial recognition cases will be reviewed again when the case is bound over to the Circuit Court.\n- The Detroit police commission discussed the Williams case during a meeting.\n- Detroit police gave a presentation to the police commission about the Williams case.\n- Board member Evette Griffie sought answers from police about the Williams case, including a timeline of events and any discipline resulting from the misidentification.\n- National Assembly member Park Joo-min requested and received documents from the Ministry of Justice related to the April 2019 Artificial Intelligence and Tracking System Construction Project.\n- Six civic groups held a press conference to publicize and discuss the Ministry's handing over of biometric data.\n- Civil liberty groups announced plans to represent both foreign and domestic victims in a lawsuit.\n- Advocates for Public Interest Law, MINBYUN - Lawyers for a Democratic Society, the Institute for Digital Rights, the Joint Committee with Migrants in Korea, and the Korean Progressive Network Jinbonet issued a press release urging the government to immediately stop the establishment of the biometric monitoring system.\n- The NGOs' press release was translated and provided to Motherboard.\n- Check Point Research published a report describing that participants in cybercrime forums were using ChatGPT to write software and emails for malicious purposes such as espionage, ransomware, and malicious spam.\n- Check Point researchers used ChatGPT to generate a phishing email that included an attached Excel document containing a malicious VBA macro.\n- The researchers instructed ChatGPT to iterate the generated macro several more times, which improved the quality of the malicious code.\n- Check Point researchers used the Codex AI service to develop a reverse shell.\n- Check Point researchers used Codex to develop scripts for port scanning and sandbox detection.\n- Check Point researchers used Codex to compile their Python code into a Windows executable.\n- The RAF and the US Army conducted more than a year of investigation into the incident.\n- The RAF published its board of inquiry into the incident.\n- Steps were taken to install a new IFF system on all Tornado aircraft.\n- The Durham Police Department contacted ShotSpotter representatives about the missed alert.\n- ShotSpotter's engineers said they will look into the incident.\n- ShotSpotter said it is investigating the incident and intends to provide a full report to the Durham Police Department.\n- Police released a photo of a dark-colored older model Honda sedan related to the shooting.\n- Police asked anyone with information about the shooting to call Investigator L. Sprinkle or CrimeStoppers.\n- Improved the strength of Neuro-sama's filters.\n- Manually curated the data she learns on to mitigate negative biases.\n- Assembled a team of people moderating the Twitch chat who check everything she says.\n- Improved the moderation tools.\n- Limited the window of chat messages she can pick responses from.\n- Configured filters to prevent her from talking about the Holocaust.\n- Koko pulled the GPT-3 feature.\n- Rob Morris posted updates on Twitter and told Motherboard that users were informed the messages were co-written by humans and machines.\n- Sama immediately ended the image classification pilot for OpenAI.\n- Sama gave notice that it would cancel all remaining projects with OpenAI.\n- After a review, Sama terminated individuals who had not vetted the image-collection request through proper channels.\n- Sama put new sales vetting policies and guardrails in place.\n- Sama delivered its last batch of labeled data to OpenAI in March 2022.\n- Sama moved most of the roughly three dozen workers onto other lower-paying workstreams without the $70 explicit-content bonus.\n- Some Sama workers lost their jobs as a result of the contract cancellations and transitions.\n- Sama scrubbed evidence of a business relationship with a client from its website at a client's request.\n- Sama announced it was canceling all remaining work with sensitive content.\n- Sama said it would not renew its $3.9 million content moderation contract with Facebook.\n- Sama announced it would exit all natural language processing and content moderation work to focus on computer vision data annotation solutions.\n- Sama said it was working with clients to transition those engagements and that the exit would be complete as of March 2023.\n- OpenAI clarified to Sama that it did not want images in the C4 (child sexual abuse) category after learning Sama had attempted to collect such content.\n- OpenAI stated that, after realizing there had been a miscommunication about the images, it did not open or view the content in question.\n- OpenAI said it instructs its employees to actively avoid collecting or using C4 content.\n- Getty Images commenced legal proceedings in the High Court of Justice in London against Stability AI alleging infringement of its intellectual property and copyright.\n- Getty Images issued Stability AI a 'letter before action', a formal notification of impending litigation in the UK.\n- Stability AI announced that artists will be able to opt out of the next version of Stable Diffusion.\n- Stability AI said it is implementing opt-out measures and creating alternate datasets and models that are fully Creative Commons-licensed.\n- The researcher published a study last month demonstrating that emotional analysis technology assigns more negative emotions to black men's faces than to white men's faces.\n- The researcher used a dataset of 400 NBA player photos from the 2016\u20132017 season to examine bias in facial emotion recognition.\n- The researcher ran the images through two well-known emotional recognition software systems (Face++ and Microsoft's Face API) to analyze their emotional scores.\n- The researcher matched players based on their smiles to control for smiling when comparing emotional scores across races.\n- The research contributes to a growing call to better understand hidden bias in artificial intelligence software.\n- The researcher suggested that, until facial recognition assesses black and white faces similarly, black people may need to exaggerate positive facial expressions (smile more) to reduce ambiguity and potentially negative interpretations by the technology.\n- Assured readers that a human editor was carefully fact-checking the bot-written articles prior to publication.\n- Issued a correction for the bot-written articles.\n- Placed a warning on all previously published AI-written articles indicating the posts' content was under factual review.\n- Announced in a series of internal meetings that it would temporarily pause AI-generated articles across CNET and other properties.\n- Temporarily paused publication of AI-generated articles at CNET and various other Red Ventures properties, including Bankrate.\n- At a CNET company meeting, the outlet's executive vice president of content and audience refused to disclose to staff what data had been used to train the AI.\n- Firefighters on the scene made efforts to prevent the Cruise autonomous vehicle from driving over their hoses.\n- Firefighters shattered a front window of the Cruise AV to stop it from driving over the hoses.\n- City transportation officials sent a letter to regulators reporting the incident.\n- Summit County's emergency call center and other emergency call centers alerted Apple to the issue.\n- In mid-January, Apple sent four representatives to observe Summit County's dispatch team for a day.\n- Apple updated the crash-detection and fall-detection software late last year to optimize the technology and reduce the number of false calls.\n- Aspen Mountain posted signs at lift lines and ticket offices alerting Apple Watch and iPhone 14 users to the problem.\n- Aspen Mountain encouraged users to upgrade to the latest software version.\n- Aspen Mountain encouraged users to disable the crash-detection service.\n- Summit County interim director Trina Dummer trained a rookie dispatch supervisor to field 911 calls.\n- Summit County dispatchers handled overflow calls and communicated with ambulances and police to manage the increased call volume.\n- When 911 operators could not reach a caller, they referred the case to Sergeant Mark Watson.\n- Sergeant Mark Watson called the device owner when cases were referred to him.\n- Sergeant Mark Watson sent a text message to the device owner when cases were referred to him.\n- Sergeant Mark Watson forwarded cases to the ski patrol when he did not hear back from the device owner.\n- Sergeant Mark Watson wrote a letter to Apple describing the problem and its impact on his duties.\n- Sheriff Brett Schroetlin decided to devote less attention to crash-detection calls from the slopes.\n- Sheriff Brett Schroetlin instructed 911 operators that if a crash-detection call from the slopes had no one on the other end, they should ignore the call and make no referrals or follow-ups.\n- Lapine uploaded a recent photo of herself to the Have I Been Trained site's reverse image search to check whether her images were in the LAION dataset.\n- A friend of Lapine's posted an open question on LAION's Discord asking how to remove her images from the dataset.\n- LAION engineer Romain Beaumont advised asking the hosting website to stop hosting the image as the best way to remove an image from the Internet.\n- LAION's website provides a GDPR removal form allowing European citizens to request information be removed from the database when a photo is associated with a name in the image's metadata.\n- Beaumont suggested creating a list of URLs of the unwanted images and distributing it so trainers such as those of Stable Diffusion could blacklist those samples.\n- Ars Technica contacted LAION for comment about the case.\n- With records and photos provided by Lapine, Ars Technica confirmed that medical images of her are referenced in the LAION dataset.\n- Ars Technica asked Stability AI CEO Emad Mostaque about Lapine's case.\n- Emad Mostaque described a technical approach\u2014using fine-tuning with negative weights\u2014to de-emphasize particular images in Stable Diffusion's learned weights as a way to 'un-train' the model.\n- Microsoft acknowledged that getting the chatbot's answers right is a work in progress.\n- Microsoft provided a thumbs-up, thumbs-down, and report button on every answer so users can give feedback.\n- Microsoft opened a public waiting list and said it would dole out access over time.\n- Microsoft limited the new Bing to work only in the Edge browser during the rollout.\n- The chatbot includes a \"sweep\" button that lets users clear the remembered query and chat context.\n- Microsoft\u2019s chief responsible AI officer Natasha Crampton and her team began investigating the photo labeling after journalists notified them.\n- Microsoft changed its public demo website so users must create an account and write code to test the algorithms instead of using drag-and-drop testing.\n- Google stated it will continue to make meaningful improvements to its SafeSearch classifiers to ensure they stay accurate and helpful for everyone.\n- LinkedIn stated that its teams use a combination of automated techniques, human expert reviews, and member reporting to identify and remove content that violates its professional community policies.\n- Amazon stated that Amazon Rekognition returns labels for detected items for further evaluation by human moderators.\n- Meta\u2019s oversight board asked Meta to clarify its adult nudity and sexual activity community standard guidelines so that people are treated consistently and without discrimination on the basis of sex or gender.\n- TechCrunch publicly tested Bing's new conversational search and published examples showing the chatbot repeated pandemic-related disinformation that originated from ChatGPT.\n- We have alerted Microsoft to this and other issues.\n- Amnesty International sued the NYPD after it refused to disclose public records regarding its acquisition of facial recognition technology and other surveillance tools.\n- Amnesty International launched a new interactive website that allows users to discover how much of a walking route between two locations in New York City might be exposed to facial recognition surveillance.\n- Thousands of digital volunteers crowdsourced data and mapped more than 25,500 CCTV cameras across New York City as part of the Decode Surveillance NYC project.\n- Amnesty International worked with data scientists to compare the crowdsourced CCTV data with statistics on stop-and-frisk and demographic data.\n- Amnesty International encourages New Yorkers to send a letter of protest to their council member demanding the introduction of a bill that prohibits facial recognition technology.\n- Amnesty International made a petition available for global users to sign calling for regulation of when and where public facial recognition systems are used.\n- Amnesty International is calling for a total ban on the use, development, production, sales, and export of facial recognition technology for mass surveillance by both states and the private sector.\n- Amnesty International conducted investigations into surveillance in New York and Hyderabad as part of its Ban The Scan campaign.\n- Amnesty International worked with research partners including Julien Cornebise, BetaNYC, and Dr Damon Wischik to carry out the research.\n- Microsoft publicly confirmed to The Verge that the initial hidden prompt revealed by Kevin Liu was genuine.\n- Microsoft stated that the list of directives is part of an evolving set of controls that they are continuing to adjust as more users interact with the technology.\n- The customer canceled the meal and started the ordering process over after the voice bot made errors.\n- The voice bot handed the order to a crew member to complete the meal.\n- Walmart cleans the self-checkout kiosks regularly.\n- Walmart provides employees with protective equipment like masks and gloves.\n- Walmart offers delivery services to customers.\n- Walmart offers pickup services to customers.\n- Walmart offers touchless payment at the register.\n- Walmart offers shopping online.\n- Walmart temporarily closed a location in Worcester, Massachusetts after more than 80 employees tested positive for COVID-19.\n- Walmart reopened the Worcester location days later after a deep cleaning.\n- Walmart employees have been addressing safety issues throughout the pandemic.\n- Steed and Caliskan urged companies developing these models to open source them and allow the academic community to continue investigations.\n- Steed and Caliskan encouraged fellow researchers to perform more testing before deploying vision models, including using the testing methods developed in their paper.\n- Steed and Caliskan called for the field to develop more responsible methods for compiling and documenting the contents of training datasets.\n- Deborah Raji called for accountability in how datasets are curated and collected.\n- Caliskan suggested using the methods developed in this study to try to apply computer-vision techniques for social good.\n- The Israel Defense Forces issued a public statement characterizing the surveillance efforts as routine security operations aimed at fighting terrorism and improving quality of life and saying it could not comment on operational capabilities.\n- The Israeli military acknowledged the existence of the Blue Wolf initiative in an online brochure.\n- Breaking the Silence said it plans to publish its research on the surveillance program.\n- Several former soldiers provided anonymous accounts of the surveillance program to Breaking the Silence and to The Post.\n- Microsoft said it pulled out of its investment in AnyVision during the May fighting between Israel and Hamas.\n- The government agency in charge of protecting privacy in Israel publicly opposed a proposal to introduce facial recognition cameras in public spaces.\n- The big push to build out the Blue Wolf image database has slowed in recent months.\n- Big Brother Watch asked the Information Commissioner to investigate Southern Co-op\u2019s use of live facial recognition cameras.\n- The shop staff are alerted as soon as the cameras identify a known suspect.\n- Shop staff escort identified suspects from the store.\n- Shop staff monitor the activity of identified suspects.\n- Southern Co-op stated that no facial images from its platform are shared with any other organisation.\n- Southern Co-op flags facial image matches as an alert to the store or duty manager.\n- Southern Co-op validates flagged facial image matches by a colleague in store.\n- Facewatch says images of shoppers unconnected with any crime are destroyed instantly.\n- Facewatch said it only shares images of witnessed and evidenced repeat offenders, not the faces of shoppers.\n- Ugandan police officials confirmed they are using the Huawei-supplied surveillance cameras.\n- The Huawei cameras helped the police track down some suspects involved in the protests.\n- Police arrested more than 836 suspects.\n- President Yoweri Museveni praised the effectiveness of the CCTV technology in a series of tweets.\n- Global Witness reached out to Meta after its ads were accepted for publication.\n- Meta confirmed it sent a response to Global Witness earlier in July, although that response was lost in a spam folder.\n- Meta stated it has taken extensive steps to help catch hate speech and inflammatory content in Kenya.\n- Meta stated it is intensifying its efforts ahead of the Kenyan election.\n- Meta deployed dedicated teams of Swahili speakers to help remove harmful content.\n- Meta deployed proactive detection technology to help remove harmful content quickly and at scale.\n- Meta said it has teams closely monitoring the situation and addressing errors as quickly as possible.\n- Meta posted a detailed blog post describing how it is preparing for Kenya's election.\n- Meta established an operations center as part of its election preparations.\n- Meta removed harmful content as part of its election preparations.\n- In the six months leading up to April 30, 2022, Meta took action on more than 37,000 pieces of content for violating its Hate Speech policies in Kenya.\n- In the same period, Meta took action on more than 42,000 pieces of content that violated its Violence & Incitement policies in Kenya.\n- Global Witness resubmitted two of its ads, one in English and one in Swahili, after Meta published its blog post to see if anything had changed.\n- Cadillac Fairview stated that the software counts people who use the directory and predicts their approximate age and gender but does not record or store any photos or video from the directory cameras.\n- Cadillac Fairview stated that they do not require consent because they are not capturing or retaining images.\n- Cadillac Fairview disclosed that the software is also used at Market Mall in northwest Calgary and other malls nationwide.\n- The Ontario-based company MappedIn confirmed in an email that their directories can track facial recognition data.\n- Representatives from North Hill Shopping Centre, Sunridge Mall and CrossIron Mills stated that they do not use facial recognition technology.\n- A spokesperson for Marlborough Mall and Westbrook Mall declined to comment on the matter.\n- The Core Shopping Centre and Southcentre did not respond to requests for comment.\n- Motherboard reached out to Allen to request comment about his winning entry.\n- Allen posted in the Midjourney Discord server defending his win and criticizing Twitter users who opposed AI-generated art.\n- Allen publicly stated that he had clearly labeled his state fair submission as \"Jason Allen via Midjourney\".\n- Allen publicly explained that he generated images with Midjourney, edited them in Photoshop, and upscaled them with Gigapixel.\n- Allen announced that he would continue creating and submitting AI-generated art, saying the win had emboldened his mission.\n- Amazon spokesperson Deborah Bass publicly defended the use of Netradyne cameras and cited pilot results claiming a 48% decrease in accidents, a 20% decrease in stop sign violations, a 60% decrease in driving without a seatbelt, and a 45% decrease in distracted driving.\n- Five U.S. senators sent a letter to Amazon raising concerns about the cameras' impact on drivers' privacy.\n- Motherboard granted anonymity to the owner of an Amazon delivery company who spoke to the outlet because the owner feared retaliation from Amazon.\n- Ofqual decided to allow small classes to receive their teachers' recommended grades.\n- Authorities adjusted the grade boundaries applied to the algorithm's results to prevent overall grade inflation.\n- Officials assigned students grades by matching them to a class grade distribution according to their rank within the class.\n- The article was amended on 24 August 2020 to correct references (pkj to Pkj), clarify that Ckj, qkj, pkj and rj are distinct but not unique, and clarify the description of 1-rj in relation to rj.\n- The authors conducted an extraction attack to evaluate memorization in GPT-2 by interacting with the model as a black-box and generating many samples.\n- The authors generated a total of 600,000 samples by querying GPT-2 with three different sampling strategies.\n- The authors retained generated samples that had an abnormally high likelihood relative to a different language model.\n- The authors selected 1,800 samples with abnormally high likelihood for manual inspection.\n- The authors manually inspected those 1,800 high-likelihood samples and found 604 that contained text reproduced verbatim from the training set.\n- The authors published a paper and a BAIR blog post describing their extraction method, findings, and potential mitigations.\n- The Edmonton Police Service removed the AI-generated image from its Twitter account.\n- The Edmonton Police Service released a public statement about the incident.\n- The Edmonton Police Service apologized for the offense caused by the image.\n- The Edmonton Police Service stated that all AI-generated images have been removed.\n- The Edmonton Police Service stated that other investigative means will be used to try to find justice for the victim.\n- Ap\u00f3s o alerta do sistema de reconhecimento facial, Davi foi monitorado pelas c\u00e2meras por 15 esta\u00e7\u00f5es, da Lapa \u00e0 Mussurunga.\n- Uma guarni\u00e7\u00e3o policial abordou Davi no ponto de \u00f4nibus.\n- Os policiais compararam o RG de Davi com o seu rosto e com imagens em um aparelho celular durante a abordagem.\n- Os policiais constataram que ele n\u00e3o era o suspeito apontado pelo sistema e o liberaram.\n- A Secretaria de Seguran\u00e7a P\u00fablica afirmou que o sistema emite um alerta ao Centro Integrado de Telecomunica\u00e7\u00f5es quando detecta 90% de semelhan\u00e7a com um procurado.\n- Ap\u00f3s esse alerta, \u00e9 realizada uma an\u00e1lise humana para confirmar a semelhan\u00e7a detectada pelo algoritmo.\n- Se a an\u00e1lise humana confirmar a semelhan\u00e7a, uma guarni\u00e7\u00e3o policial mais pr\u00f3xima \u00e9 acionada para realizar a abordagem.\n- A Pol\u00edcia Militar finaliza a a\u00e7\u00e3o no local sem registro de ocorr\u00eancia quando identifica que o sistema errou.\n- Policiais consultam informa\u00e7\u00f5es de cidad\u00e3os usando o aplicativo Sistema de Mobilidade em Opera\u00e7\u00f5es Policiais (MOP) instalado em aparelhos celulares, inclusive particulares.\n- A SSP respondeu a um pedido via Lei de Acesso \u00e0 Informa\u00e7\u00e3o esclarecendo o funcionamento do sistema e afirmando que, at\u00e9 o momento, o recurso \u00e9 usado apenas para localizar pessoas desaparecidas e que imagens p\u00fablicas de redes sociais podem ser utilizadas para investiga\u00e7\u00e3o.\n- The FBI Internet Crime Complaint Center (IC3) issued a warning about an increase in the use of deepfakes and stolen PII to apply for remote work positions.\n- Complaints were filed with the FBI Internet Crime Complaint Center (IC3) reporting the use of deepfakes and stolen PII to apply for remote positions.\n- Pre-employment background checks discovered that PII provided by some applicants belonged to another individual.\n- Plaintiffs filed a 66-page class action complaint against Oracle in the U.S. District Court for the Northern District of California.\n- The litigants retained the San Francisco-headquartered law firm Lieff Cabraser to represent them in the privacy litigation.\n- The Privacy Collective said it would appeal the Dutch court ruling that had found the earlier European suit inadmissible.\n- The U.K. branch of the legal action was stayed pending the outcome of an earlier class-action-style privacy suit against Google.\n- A spokesman for Oracle declined to comment on the litigation.\n- Brooke Duffy published a paper in July investigating how algorithms on social media platforms can render the accounts of marginalized creators practically invisible.\n- Fast Company's creator-economy podcast Creative Control produced an episode that spoke with Brooke Duffy to explore algospeak and its effects on marginalized creators.\n- The article's author reached out to Sean Szolek-Van Valkenburgh and Casey Fiesler to discuss and analyze the concept of algospeak.\n- Elizabeth Licata contacted Facebook to report the mistaken enforcement of the group's posts.\n- Facebook found the group.\n- Facebook corrected the mistaken enforcements.\n- Facebook put an extra check in place so that a human will review offending posts before the group is considered for deletion.\n- Facebook said it plans to build out better customer support for its products.\n- Facebook said it plans to provide the public with more information about its policies and how it enforces them.\n- Facebook automatically disabled commenting on a post because of possible violence, incitement, or hate in multiple comments.\n- The companies said the problems were quickly resolved.\n- The companies said the accounts were restored.\n- Twitter reinstated the accounts where appropriate.\n- Facebook CEO Mark Zuckerberg dispatched the company\u2019s top policy executive, Nick Clegg, to meet with Israeli and Palestinian leadership.\n- Facebook designated the incident as \"severity 1,\" its term for a sitewide emergency.\n- Facebook executives reached out to Apple, Google, and Microsoft to request that the posts be deleted.\n- A group of 30 Facebook employees filed at least 80 tickets to report false positives with the company\u2019s automation systems.\n- In an Instagram post on May 7, Facebook apologized and provided an account of what it said led to the glitch.\n- Facebook said it has a dedicated team of Arabic and Hebrew speakers closely monitoring the situation on the ground.\n- Facebook added that human error led to the issue of restricting the al-Aqsa Mosque hashtag.\n- The companies told 7amleh that some of the remaining posts are under review.\n- Twitter restored Mariam Barghouti\u2019s account and tweets and said it had made an error.\n- Venmo said it had resolved the mistaken suspensions of transactions of humanitarian aid to Palestinians.\n- Executives discovered a glitch in a long-planned update to Instagram Stories.\n- Google stated that it is continually making improvements to fingerprint performance, stability, and reliability.\n- Google advised that users should ensure they are running the latest version of Android 13.\n- The article noted that people can set up the Pixel 6a without enabling the fingerprint unlock feature.\n- The article recommended that worried users rely on another authentication method instead of the fingerprint sensor.\n- \u0e43\u0e2b\u0e49\u0e40\u0e14\u0e34\u0e19\u0e17\u0e32\u0e07\u0e44\u0e1b\u0e22\u0e31\u0e07\u0e2a\u0e32\u0e02\u0e32\u0e18\u0e19\u0e32\u0e04\u0e32\u0e23\u0e01\u0e23\u0e38\u0e07\u0e44\u0e17\u0e22\u0e1a\u0e23\u0e34\u0e40\u0e27\u0e13\u0e43\u0e01\u0e25\u0e49\u0e40\u0e04\u0e35\u0e22\u0e07\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e2b\u0e49\u0e40\u0e08\u0e49\u0e32\u0e2b\u0e19\u0e49\u0e32\u0e17\u0e35\u0e48\u0e0a\u0e48\u0e27\u0e22\u0e40\u0e2b\u0e25\u0e37\u0e2d.\n- \u0e41\u0e19\u0e30\u0e19\u0e33\u0e43\u0e2b\u0e49\u0e2a\u0e41\u0e01\u0e19\u0e43\u0e1a\u0e2b\u0e19\u0e49\u0e32\u0e43\u0e19\u0e2a\u0e20\u0e32\u0e1e\u0e41\u0e2a\u0e07\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e21\u0e37\u0e14\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48\u0e08\u0e49\u0e32\u0e21\u0e32\u0e01\u0e40\u0e01\u0e34\u0e19\u0e44\u0e1b.\n- \u0e41\u0e19\u0e30\u0e19\u0e33\u0e43\u0e2b\u0e49\u0e27\u0e32\u0e07\u0e15\u0e33\u0e41\u0e2b\u0e19\u0e48\u0e07\u0e43\u0e1a\u0e2b\u0e19\u0e49\u0e32\u0e43\u0e2b\u0e49\u0e28\u0e35\u0e23\u0e29\u0e30\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e01\u0e23\u0e2d\u0e1a\u0e14\u0e49\u0e32\u0e19\u0e1a\u0e19\u0e41\u0e25\u0e30\u0e04\u0e32\u0e07\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e01\u0e23\u0e2d\u0e1a\u0e14\u0e49\u0e32\u0e19\u0e25\u0e48\u0e32\u0e07\u0e02\u0e13\u0e30\u0e2a\u0e41\u0e01\u0e19.\n- \u0e41\u0e19\u0e30\u0e19\u0e33\u0e43\u0e2b\u0e49\u0e04\u0e49\u0e32\u0e07\u0e19\u0e34\u0e48\u0e07\u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13 3 \u0e27\u0e34\u0e19\u0e32\u0e17\u0e35\u0e43\u0e19\u0e23\u0e30\u0e22\u0e30\u0e01\u0e32\u0e23\u0e2a\u0e41\u0e01\u0e19\u0e43\u0e1a\u0e2b\u0e19\u0e49\u0e32.\n- \u0e41\u0e19\u0e30\u0e19\u0e33\u0e43\u0e2b\u0e49\u0e2a\u0e41\u0e01\u0e19\u0e1a\u0e31\u0e15\u0e23\u0e1b\u0e23\u0e30\u0e0a\u0e32\u0e0a\u0e19\u0e02\u0e13\u0e30\u0e22\u0e37\u0e19\u0e22\u0e31\u0e19\u0e15\u0e31\u0e27\u0e15\u0e19.\n- \u0e16\u0e49\u0e32\u0e1a\u0e31\u0e15\u0e23\u0e1b\u0e23\u0e30\u0e0a\u0e32\u0e0a\u0e19\u0e23\u0e39\u0e1b\u0e44\u0e21\u0e48\u0e0a\u0e31\u0e14\u0e2b\u0e23\u0e37\u0e2d\u0e21\u0e35\u0e23\u0e2d\u0e22 \u0e43\u0e2b\u0e49\u0e15\u0e34\u0e14\u0e15\u0e48\u0e2d\u0e2a\u0e32\u0e02\u0e32\u0e02\u0e2d\u0e07\u0e18\u0e19\u0e32\u0e04\u0e32\u0e23\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e2b\u0e49\u0e40\u0e08\u0e49\u0e32\u0e2b\u0e19\u0e49\u0e32\u0e17\u0e35\u0e48\u0e14\u0e33\u0e40\u0e19\u0e34\u0e19\u0e01\u0e32\u0e23\u0e0a\u0e48\u0e27\u0e22\u0e40\u0e2b\u0e25\u0e37\u0e2d.\n- A draft law inspired by Molly's death is being advanced through Britain\u2019s Parliament to force social media companies to adopt new child safety protections or risk heavy fines.\n- Instagram restricted access to some suicide and self-harm content.\n- Pinterest restricted access to some suicide and self-harm content.\n- Meta added new protections in 2019 prohibiting graphic images of self-harm such as cutting.\n- Meta added new protections in 2019 providing links to resources for users viewing sad or depressive material.\n- Meta agreed to provide more than 16,000 pages from Molly\u2019s Instagram to investigators.\n- The London police bypassed Molly\u2019s iPhone passcode and extracted 30,000 pages of material.\n- Thousands of images, videos and other social media material from Molly\u2019s accounts were revealed during the investigation.\n- Mr. Russell went public with Molly\u2019s story in January 2019.\n- The Russell family pursued the case as a form of justice and to raise awareness about youth suicide and the dangers of social media.\n- Mr. Russell urged the coroner to go beyond a formulaic process and to explore the role of social media in Molly\u2019s death.\n- The coroner ruled that Instagram and other social media platforms had contributed to Molly\u2019s death.\n- The head of community operations at Pinterest publicly apologized and said he 'deeply regrets' that Molly had viewed explicit material.\n- Meta issued a public statement expressing condolences to the Russell family and saying it was committed to ensuring that Instagram is a positive experience for teenagers.\n- Managers were required to use a tracking tool every shift to identify the \"top offender\" by scanner inactivity.\n- Managers were required to ask the top offender about their whereabouts for each timestamp registered as unproductive and discipline them when appropriate.\n- Managers were trained to write up the top offender per shift.\n- Managers could question at least three workers per shift about their whereabouts for periods registered as time off task.\n- Managers asked workers to explain each block of inactive scanner time recorded by the tool.\n- Managers subtracted time from employees' TOT totals for justified reasons such as bathroom use and equipment issues.\n- Managers used surveillance video footage to corroborate or disprove employees' alibis about their whereabouts.\n- Managers were required to have a 'seek to understand' conversation with the top offender to determine barriers that might warrant deduction of time.\n- Managers adjusted employees' total time off task based on those explanations.\n- Managers provided feedback and issued disciplinary write-ups when appropriate after reviewing TOT.\n- If the top offender's TOT was found justified, managers were required to coach the employee with the second-highest TOT.\n- A proposed script was provided for managers to communicate TOT findings and policy violations to employees.\n- Workers received a first written warning for accumulating 30 to 59 minutes of TOT for the first time in a 12-month period.\n- Managers issued a final written warning when workers met specified TOT thresholds (60-119 minutes in a single day or repeated 30-59 minutes within 12 months).\n- Amazon terminated employees who accumulated two hours of TOT in a single shift or who had a final written warning plus 30 or more minutes of TOT within 12 months.\n- Motherboard obtained an internal list showing 18 JFK8 workers were terminated between Jan. 1, 2020 and Feb. 25, 2020 for accumulating more than two hours of TOT in a single day.\n- Morgan Lewis submitted the documents to the National Labor Relations Board in February 2020 to try to dismiss a charge alleging unlawful retaliation.\n- Morgan Lewis requested that the National Labor Relations Board treat the documents as confidential and not reveal contents without prior written consent.\n- Managers provided employees with minute-by-minute lists of inactive scanner times so the employees could explain periods of inactivity.\n- The documents were obtained via a public records request.\n- Cruise contacted its remote assistance workers about the encounter.\n- Cruise has been in contact with first responders, including the San Francisco Fire Department, regarding this encounter.\n- The city of San Francisco submitted a filing to the California Public Utilities Commission describing the incident and expressing concern about Cruise vehicles stopping in travel lanes.\n- The San Francisco Fire Department requested a meeting with Cruise about the incident.\n- The San Francisco Fire Department publicly confirmed the incident involving Engine 12.\n- A garbage truck driver ran from their work to move their vehicle so the fire truck could pass.\n- Police officers stopped a Cruise vehicle without a driver because it did not have its headlights on.\n- The San Francisco Fire Department said it continues to seek industry training related to autonomous vehicles.\n- NewsGuard sought comment from TikTok regarding the study's findings.\n- A TikTok spokesperson referred to the platform's community guidelines when responding to the findings.\n- TikTok stated that it removes harmful misinformation, including medical misinformation, from the platform.\n- TikTok stated that it partners with credible voices to elevate authoritative content on topics related to public health.\n- TikTok stated that it partners with independent fact-checkers to help assess the accuracy of content.\n</mitigation_statements>"}]}}
{"custom_id": "batch_400", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- Meta took the Galactica demo offline.\n- Meta's Chief AI Scientist Yann LeCun tweeted that the Galactica demo is offline for now.\n- OpenAI asked Latitude to take immediate action.\n- Latitude turned on a new moderation system.\n- Latitude planned to manually review flagged content.\n- A Latitude spokesperson said its filtering system and policies for acceptable content are being refined.\n- Latitude staff had previously banned players who they learned had used AI Dungeon to generate sexual content featuring children.\n- After OpenAI\u2019s warning, Latitude said it is working on necessary changes.\n- Latitude pledged in a blog post that AI Dungeon would continue to support other NSFW content, including consensual adult content, violence, and profanity.\n- Latitude added an optional safe mode that filtered out suggestions from the AI featuring certain words.\n- AI Dungeon's official Reddit and Discord communities added dedicated channels to discuss adult content generated by the game.\n- Latitude experimented with a filter that automatically replaced occurrences of the word \"rape\" with \"respect\".\n- The security flaw that made every story generated in the game publicly accessible was fixed.\n- The startup now must use OpenAI's filtering technology.\n- Shannon Carpenter filed a lawsuit in April against McDonald's on behalf of himself and other affected Illinois residents alleging violations of Illinois' Biometric Information Privacy Act for collecting and processing customers' voice data without written consent.\n- TikTok removed clips of the man's suicide from its platform as they were uploaded.\n- TikTok investigated why the video was suddenly appearing on its platform.\n- Through its investigations, TikTok found evidence of a coordinated attack organized by groups on the dark web.\n- TikTok wrote to nine other tech platforms proposing that they warn each other about violent and graphic content on their services.\n- TikTok began banning anyone who shared the suicide clip.\n- TikTok banned accounts that repeatedly tried to upload the clips.\n- TikTok's systems automatically detected and flagged clips that violated its policies against content that displays, praises, glorifies, or promotes suicide.\n- TikTok provided access to hotlines directly from its app and in its Safety Centre.\n- TikTok encouraged community members who are struggling with thoughts of suicide or concerned about someone to seek support.\n- Community members reported the content to TikTok.\n- Community members warned others against watching, engaging with, or sharing the videos.\n- The authors discussed their findings with Facebook.\n- Some of the extremist accounts identified in the study have been taken down.\n- The authors plan to share the study's findings with Kenya's government.\n- Facebook requested a copy of the report before its publication.\n- Facebook said it has removed a number of the pages and profiles linked to the extremist content.\n- Facebook said it will continue to investigate once it has access to the full findings.\n- The reporter reached out to Facebook about the case to try to figure out what was causing the friend recommendations.\n- A Facebook spokesperson responded to inquiries saying that People You May Know is based on a variety of factors and that the company could not explain the specific recommendations without additional information from the people involved.\n- Lisa's medical community recommended that patients concerned about privacy not log into Facebook or other social media accounts at medical offices.\n- Lisa's medical community recommended that patients concerned about privacy leave their phones in their cars during appointments.\n- To protect her patients' privacy, Lisa asked the reporter not to use her real name.\n- A Facebook spokesperson wrote via email that the company does not use information from third-party apps to show friend suggestions in People You May Know.\n- A Facebook spokesperson confirmed that People You May Know suggestions are not informed by smartphone Location Services.\n- A Facebook spokesperson told the reporter there was an undocumented trick to stop appearing in People You May Know by switching the account setting 'Who can send you friend requests?' to 'No one.'\n- The day after the story was originally published, a Facebook spokesperson retracted the explanation about the opt-out workaround, saying the company had provided incorrect information about the workaround.\n- A Facebook spokesperson stated that the company has put safeguards in place to help users understand their privacy choices.\n- A Facebook spokesperson stated that the company has put safeguards in place to help users moderate comments.\n- A Facebook spokesperson stated that the company has put safeguards in place to help users block people.\n- A Facebook spokesperson stated that the company has put safeguards in place to help users control location sharing.\n- A Facebook spokesperson stated that the company has put safeguards in place to help users report abusive content.\n- Facebook advised that users can 'X' out anyone who appears in People You May Know that they don't want to see.\n- Ela Darling searches Facebook every few weeks for last names of her family and extended family and blocks them when she finds them.\n- Ela Darling deleted her second private account under her legal name a few years ago, leaving only her public porn account.\n- A sex toy reviewer advised that users can choose a profile photo that doesn't show their face to reduce the risk of being identified.\n- After reading the story, a Facebook spokesperson acknowledged that the company 'fell short' and wrote that 'we will do better.'\n- Stack Overflow implemented a temporary policy banning the use of ChatGPT to create posts on the site.\n- The ban was applied to all content on Stack Overflow except each user's profile content (e.g. the 'About me' text).\n- If a user is believed to have used ChatGPT after the temporary policy was posted, Stack Overflow will impose sanctions to prevent those users from continuing to post such content.\n- Stack Overflow will deal with offending users rather than addressing individual posts.\n- The team immediately edited the post, replacing the English text with correct Thai to prevent further Facebook auto-translation errors.\n- Thai PBS contacted Facebook immediately to report the problem and request an explanation.\n- Facebook apologized for the mistranslation.\n- Facebook filed an urgent task with its policy and IT teams to investigate the error and said it would keep Thai PBS informed.\n- Thai PBS urged Facebook to promptly report the investigation results.\n- Thai PBS demanded that Facebook issue an official apology.\n- Thai PBS issued a public statement about the incident at approximately 00:23.\n- Thai PBS immediately conducted a fact-finding investigation into the incident.\n- Thai PBS checked at approximately 23:00 and found the mistranslation also appeared on official Facebook pages of other media outlets.\n- Thai PBS informed the Royal Household Bureau, the Ministry of Digital Economy and Society, and related agencies of the full sequence of events.\n- Thai PBS apologized for the spread of the incorrect text produced by Facebook's auto-translation service.\n- Thai PBS pledged to pursue the facts of the incident fully and to report the findings to the public.\n- Thai PBS stated it would not allow the incident to be exploited to create situations that affect the feelings of the public and the nation.\n- The researchers deleted the approved ads before they were published.\n- Meta later disabled several accounts that had submitted the ads.\n- TikTok and YouTube rejected all the ads that the researchers submitted.\n- TikTok and YouTube suspended the accounts that attempted to submit the ads.\n- Meta said that ads continue to be reviewed after they go live.\n- OpenAI will likely address the loopholes found by expanding its content-blocking keywords.\n- Lawyers filed a lawsuit in Illinois federal court seeking class-action status on behalf of Ms. Huskey and hundreds of other Black State Farm policyholders.\n- Lawyers from Fairmark and a team led by Deborah Archer began work on a survey to document how State Farm treated its customers.\n- The researchers conducted a nine-month study in 2021 with more than 800 participants to measure interactions, payment timing, and paperwork required by State Farm.\n- The researchers used YouGov, a polling and data analytics firm, to conduct the survey.\n- The study's findings were cited in the lawsuit alleging that Black homeowners experienced greater administrative burdens and delays.\n- The lawsuit alleged that Duck Creek Technologies uses software from FRISS to flag claims for potential fraud and assign risk scores based on factors including neighborhood urbanization, crime statistics, and social media data.\n- State Farm eventually sent a contracted independent inspector to examine Ms. Huskey's roof.\n- State Farm eventually sent Ms. Huskey a check for $4,687 toward repairs.\n- Ms. Huskey and her husband paid $7,000 out of their own pocket to fix their home.\n- State Farm issued a public statement saying it takes the filing seriously, is committed to a diverse and inclusive environment, and is dedicated to paying what it owes promptly and courteously.\n- The Police Department's homicide unit is investigating the deaths of Mr. Ramirez and Mr. Umberger.\n- The Police Department said it was investigating a number of robberies in Hell's Kitchen.\n- Oscar Alarcon filed a police report about being drugged.\n- There have been arrests connected to a series of similar robberies in Manhattan.\n- A drug test administered to Tyler Burt came back positive for cocaine.\n- Mr. Burt said the police later told him there were no developments in his case.\n- Ms. Clary traveled to New York from Georgia to pursue her son's case.\n- After Ms. Clary showed detectives the suspicious withdrawals, detectives opened a homicide investigation.\n- A detective reviewed and described surveillance footage showing Mr. Umberger being led by two men into a car outside the Q.\n- The medical examiner provided Ms. Clary with an initial toxicology report showing cocaine, lidocaine, and fentanyl in Mr. Umberger's system.\n- When the police first contacted Ms. Clary, they told her that her son had been robbed on the street, then had done drugs at home and overdosed.\n- Public access to the tender document was disabled.\n- Jefferson Parish Sheriff's Office detectives tacitly admitted the facial recognition error.\n- Jefferson Parish Sheriff's Office rescinded the arrest warrant for Randal Reid.\n- Randal Reid was released from jail on Dec. 1.\n- Akiko Ohata White filed a lawsuit in federal court in Boston against Raytheon Co., alleging negligence and breach of warranty over the Patriot Missile system's role in the April 2003 friendly fire incident.\n- Immunefi banned 15 people for allegedly submitting bug reports created by ChatGPT.\n- Immunefi instructed whitehat hackers to describe bugs in their own words instead of submitting reports generated by AI language tools.\n- Immunefi required that any genuine bugs highlighted by ChatGPT be reported through the platform's proper reporting channels.\n- StackOverflow banned ChatGPT-generated responses from its platform.\n- Twitter unlocked the four accounts that had been suspended for posting about rocket launches.\n- CNET began appending lengthy correction notices to some of its AI-generated articles.\n- CNET appended notices to several AI-generated pieces stating that \"we are currently reviewing this story for accuracy.\"\n- CNET appended notices to several AI-generated pieces stating that \"if we find errors, we will update and issue corrections.\"\n- CNET changed the bylines on its AI-generated stories to \"CNET Money.\"\n- CNET added a clarification to AI-generated articles labeling them \"this article was assisted by an AI engine.\"\n- CNET added a stipulation to AI-generated articles that the stories were \"thoroughly edited and fact-checked by an editor on our editorial staff.\"\n- CNET editor Connie Guglielmo published a statement describing the site's use of AI as an experiment intended to assist reporters.\n- CNET and Bankrate issued a statement that they are actively reviewing all their AI-assisted pieces to ensure no further inaccuracies made it through the editing process.\n- CNET and Bankrate stated that they will continue to issue any necessary corrections.\n- The team issued a public statement announcing that hitchBOT had been vandalized and that its trip had come to an end.\n- The hitchBOT account and team posted messages on social media expressing the robot's gratitude and announcing the end of its trip.\n- The creators stated they would not attempt to locate or pursue the individual responsible for the vandalism.\n- The team is waiting to retrieve hitchBOT's remains from Philadelphia.\n- The team will decide on hitchBOT's next path after they recover its remains.\n- San Francisco informed the Commission of the April 5, 2022 incident in which a Cruise AV stopped in a travel lane and obstructed a San Francisco Fire Department vehicle.\n- Firefighters at the January 21, 2023 scene made efforts to prevent the Cruise AV from driving over their hoses.\n- Firefighters shattered the front window of the Cruise AV to prevent it from driving over the fire hoses.\n- The Treasury Department started an advisory committee last fall to help it focus on disparities faced by Americans of color.\n- Researchers from the Treasury Department published an analysis this month of racial disparities in the tax code.\n- Department officials are increasing tax enforcement on high earners and corporations that do not pay what they owe using money from the climate, health and tax bill signed into law last summer.\n- Deputy Treasury Secretary Wally Adeyemo wrote a letter last fall to the I.R.S. commissioner prioritizing enforcement efforts to crack down on groups of high-income taxpayers.\n- The study authors will present their findings publicly on Tuesday.\n- The show's co-creator, Skyler Hartle, publicly said he was 'super embarrassed' and stated the AI's remarks do not reflect the company's values.\n- Mismatch Media said it investigated and identified the root cause of the issue with the Davinci model.\n- Mismatch Media said it is currently investigating how to implement a secondary content moderation system to provide an extra layer of redundancy.\n- Mismatch Media said it plans to implement OpenAI's content moderation systems before going live again.\n- Mismatch Media said it will look at third-party services for secondary content moderation as additional redundancy.\n- Mismatch Media said it will not use the Curie model as a fallback in the future.\n- Twitch suspended the watchmeforever channel and made the Nothing, Forever show temporarily unavailable for 14 days.\n- Google said it is kicking off a Trusted Tester program this week to test Bard.\n- Google said it will combine external feedback with its own internal testing to make sure Bard's responses meet a high bar for quality, safety and groundedness in real-world information.\n- Alphabet reportedly brought in founders Sergey Brin and Larry Page to accelerate its AI efforts.\n- On December 18, 2020, Facebook sent Access Now a response to the letter.\n- Moderators of the Replika subreddit posted support resources for users struggling mentally and emotionally, including links to suicide hotlines.\n- The Italian Data Protection Authority demanded that Replika stop processing Italians' data immediately.\n- The Italian Data Protection Authority warned that the company faces fines of $21.5 million if it fails to comply within 20 days.\n- Some Replikas were changed to refuse erotic roleplay and to change the subject or evade flirtatious questions.\n- Replika no longer sends 'spicy selfies' according to users' reports and testing.\n- Some users reported receiving refunds for pro subscriptions.\n- A Redditor claiming to belong to Replika's founder wrote that the company's ad campaigns are no longer running.\n- The company issued a boilerplate communication about safety.\n- Replika implemented additional safety measures and filters to support more types of friendship and companionship.\n- Microsoft's safety filter appeared to kick in and deleted the message, replacing it with a generic error message.\n- Microsoft said it might experiment with limiting conversation lengths.\n- Tesla agreed to a voluntary recall of more than 362,000 cars equipped with its Full Self Driving driver-assistance system.\n- Tesla planned to fix the identified flaws through an over-the-air software update to the affected vehicles.\n- Tesla intends to notify owners of the recalled vehicles by mail no later than April 15.\n- The National Highway Traffic Safety Administration posted documents about its findings on its website.\n- The National Highway Traffic Safety Administration said it was continuing to investigate Full Self Driving and the less advanced Autopilot system.\n- The agency is looking into 41 crashes since 2016 involving Tesla vehicles that were using the company\u2019s advanced driver-assistance systems.\n- Atrioc publicly apologized for accessing deepfake videos of his female Twitch colleagues.\n- Lawmakers have made efforts to crack down on the creation of nonconsensual imagery, whether AI-generated or not.\n- California enacted laws intended to counter the potential use of deepfakes in election campaigns and in nonconsensual pornography.\n- Mark Zuckerberg changed Facebook's motto from \"Move fast and break things\" to \"Move fast with stable infrastructure.\"\n- Vanderbilt University apologized after using ChatGPT to write the email.\n- Nicole Joseph apologized in a follow-up email, saying the decision to use ChatGPT was made in 'poor judgment.'\n- Peabody College\u2019s dean Camilla P. Benbow said her office is reviewing what happened.\n- Both Nicole Joseph and assistant dean Hasina Mohyuddin will step back from their work in the meantime.\n- Camilla P. Benbow offered a heartfelt apology and said she intends to redouble efforts to express the college's values and lead to human flourishing.\n- The Medak police verified Mohammed Khadeer's call data records.\n- The Medak police let him off on February 3 after confirming his non-involvement in the case.\n- The Telangana Police declared him innocent and released him.\n- He was treated at Gandhi Hospital in Hyderabad, where he later died on February 18.\n- Non-profit organizations assisting asylum seekers have been in daily contact with US Customs and Border Protection about issues with the CBP One app.\n- US Customs and Border Protection introduced a Haitian Creole version of the CBP One app.\n- Al Otro Lado held a workshop in Tijuana to teach Haitian asylum seekers how to use the CBP One app the day after it went live.\n- Advocates have been protesting the facial recognition problems and reduced access for Black asylum seekers since the app's rollout.\n- Advocates installed bright construction lights at a shelter in Reynosa to illuminate asylum seekers' faces when they take photos to upload to the app.\n- Lloyds Bank said it is deploying countermeasures to address the threat of synthetic voices.\n- ElevenLabs tweeted to ask what safeguards it should put in place, such as asking for full ID identification of users or requiring payment information.\n- ElevenLabs implemented new safeguards that its co-founder said were rapidly reducing instances of misuse.\n- ElevenLabs said it will support authorities in identifying users if the law was broken.\n- Lawyers sued a group of U.S. financial institutions alleging that biometric voice prints used to identify callers violate the California Invasion of Privacy Act.\n- The Consumer Financial Protection Bureau issued a statement expressing concern about data security and warning that firms will be held accountable for shoddy practices.\n- Cazadores de Fake News dissected the videos of the AI avatars Noah and Daren.\n- Cazadores de Fake News alerted the public about a new state-sponsored disinformation campaign by Chavismo and the spread of misleading data.\n- The ProBox Observatory monitored sociopolitical trends on social media in Venezuela, Cuba, Nicaragua, and El Salvador.\n- ProBox closely followed the ruling party's propaganda machinery and identified recurring patterns in its use of coordinated accounts and hashtags.\n- ProBox monitored daily hashtags pushed by the Venezuelan Ministry of Communication and Information and the associated activity by paid tweeters and automated accounts.\n- ProBox reported that more than 10 million messages associated with Chavismo were generated in the past week and that approximately 96.5% were manipulated messages from automated accounts.\n- ProBox detected participation by accounts from Nicaragua and Cuba in positioning specific hashtags and concluded these were coordinated actions between those governments' propaganda apparatuses.\n- ProBox monitored messages across the sociopolitical spectrum, including the ruling party, the opposition, civil society, anonymous accounts, and other actors.\n- Clarkesworld temporarily closed story submissions.\n- Clarkesworld banned writers who submitted plagiarized or machine-generated stories.\n- Editor Neil Clarke shared a graph on Twitter tallying the number of banned writers.\n- Clarke encouraged readers to support the magazine by subscribing.\n- The magazine announced that submissions will resume at a future time.\n- A bank manager pulled Card and her husband into his office and warned them that the voice on the call was likely faked.\n- Card spoke with her local newspaper, the Regina Leader-Post, to warn people about these scams.\n- Perkin's family filed a police report with Canada's federal authorities.\n- ElevenLabs announced it was banning free users from creating custom voices.\n- ElevenLabs announced it was launching a tool to detect AI-generated audio.\n- FTC assistant director Will Maxson urged constant vigilance against impostor scams.\n- Will Maxson advised that if a loved one tells you they need money, you should put the call on hold and try calling the family member separately.\n- Will Maxson advised never to pay people in gift cards.\n- Will Maxson advised being wary of any requests for cash.\n- Will Maxson warned that a suspicious call appearing to come from a family member's number can be spoofed.\n- Motherboard alerted TikTok about the impersonation videos.\n- TikTok banned the @drreality.life account.\n- TikTok announced it would delete all Andrew Tate content from the platform.\n- TikTok said it would remove the reported accounts and any copycat accounts that violated its impersonation rules.\n- Stripe stopped processing subscriptions for Hustler\u2019s University.\n- Hustler\u2019s University was shut down after Stripe stopped processing subscriptions.\n- The reporters reached out to the email listed on Dr. Reality\u2019s website but did not receive a response.\n- The article was updated to reflect that TikTok banned the scammer\u2019s account after being alerted by Motherboard.\n- Taylor called the local police to report the deepfake videos.\n- Taylor reached out to her freshman-year roommate Julia to warn her about the deepfakes.\n- Taylor and Julia joined forces to try to figure out who was behind the deepfake videos.\n- They prowled 4chan to look for evidence and discovered a user posting photos of female classmates.\n- They located a profile with the same handle on MrDeepFakes.com that was posting deepfake videos.\n- Taylor and Julia reached out to Gibi ASMR and explained the situation to her.\n- Gibi ASMR posted a video to her social channels calling out the deepfake-porn trend and demanding more accountability.\n- Taylor and Julia convinced police to place a call to Mike.\n- Police placed a call to Mike regarding the deepfake content.\n- Mike apologized and said it would never happen again.\n- The police closed the case after speaking with Mike.\n- Taylor left her friend group as a result of the incident.\n- Twitch star QTCinderella came forward in a tear-filled video describing how she had been terrorized by deepfake porn.\n- Atrioc released an apology video acknowledging he had purchased doctored clips featuring other female streamers.\n- Eliot Higgins shared the images on Twitter.\n- Eliot Higgins noted in a Twitter thread that the images were generated using Midjourney.\n- Eliot Higgins confirmed to The Associated Press that the images were produced using Midjourney.\n- Eliot Higgins confirmed the images were first posted as parody.\n- The New York Police Department wrote in an emailed statement that Donald Trump has not been taken into custody by the New York City Police Department.\n- The Associated Press assessed the claim that the photos showed Donald Trump being arrested as false.\n- The ACLU requested data and documents from Allegheny County related to the Allegheny Family Screening Tool (AFST).\n- The ACLU collaborated with researchers from the Human Rights Data Analysis Group to independently evaluate the AFST's design and practical impact.\n- The ACLU and researchers analyzed Allegheny County data from 2010\u20132014 to model what the AFST risk scores would have been and to assess disparities in screen-in rates.\n- The ACLU asked the county and the AFST tool designers for feedback on a paper describing their analysis.\n- The ACLU publicly shared their findings in a report titled 'The Devil is in the Details: Interrogating Values Embedded in the Allegheny Family Screening Tool.'\n- The man's family spoke with Mathieu Michel, Secretary of State for Digitalisation, to discuss the case.\n- Mathieu Michel set up a working group to analyze the EU AI Act text currently being prepared and to propose necessary adjustments.\n- OpenAI said it hopes to mitigate harmful and biased answers by gathering user feedback.\n- OpenAI said it is focusing on improving the factual accuracy of ChatGPT and is making progress.\n- The free version of ChatGPT declined to answer the reproduced query, citing that responding would violate its content policy prohibiting dissemination of offensive or harmful content.\n- Microsoft said it has developed a safety system that includes content filtering to provide a safe search experience for users.\n- Microsoft said it has implemented operational monitoring as part of its safety system for search.\n- Microsoft said it has implemented abuse detection as part of its safety system for search.\n- Microsoft said users are provided with explicit notice that they are interacting with an AI system.\n- Google\u2019s Bard displays a fine-print disclaimer under each query warning that it may display inaccurate or offensive information that does not represent Google\u2019s views.\n- Google said it takes steps to address content that does not reflect its standards.\n- Brian Hood threatened to file a defamation lawsuit against OpenAI unless it corrects false claims that he had served time in prison for bribery.\n- Jonathan Turley published an op-ed in USA Today outlining his experience of being falsely accused by ChatGPT.\n- Jonathan Turley spoke to The Washington Post in an interview about the false allegation.\n- Microsoft\u2019s Bing and Google\u2019s Bard aim to give more factually grounded responses.\n- A new subscription-only version of ChatGPT running on an updated model called GPT-4 was made available and is described as aiming to give more factually grounded responses.\n- Hood's lawyers sent a letter of concern to OpenAI on March 21 giving OpenAI 28 days to correct ChatGPT's false claims about their client or face a possible defamation lawsuit.\n- ElevenLabs posted a thread on Twitter announcing they would clamp down on anonymous or harmful uses of their voice-copying AI.\n- ElevenLabs said they will release a tool that lets anyone verify whether a particular audio sample was generated using their technology and report misuse.\n- ElevenLabs said VoiceLab will be restricted to paid tiers and will require additional identity verification.\n- ElevenLabs said they are tracking harmful reported content back to the accounts it originated from and banning those accounts for violating their policy.\n- ElevenLabs said they will continue to monitor the situation.\n- ITVX runs a disclaimer at the start of each episode stating that none of the celebrities involved have consented.\n- ITVX displays a 'Deep Fake' watermark on the screen throughout each episode.\n- Snopes published a fact-check debunking the viral image of Pope Francis as AI-generated.\n- Snopes provided supporting evidence ('receipts') proving the image was fake.\n- Pope Francis spoke publicly about the ethical uses of AI soon after the fake images went viral.\n- Microsoft rolled out an update Thursday designed to help improve long-running conversations with the bot.\n- Microsoft updated the Bing chat service several times.\n- Microsoft said it is addressing many of the concerns being raised, to include questions about long-running conversations.\n- Microsoft collected feedback from thousands of early users and used that feedback to allow the model to learn and make many improvements.\n- Microsoft took down its earlier chatbot Tay in 2016 after users prompted it to begin spouting racism and holocaust denial.\n- Meta took its Galactica model offline after users found it generating authoritative-sounding but harmful and incorrect content.\n- The Italian privacy regulator ordered a ban on ChatGPT.\n- The Italian data protection authority ordered that OpenAI be immediately blocked from processing the data of Italian users.\n- The Italian data protection authority ordered an investigation into OpenAI's processing of Italian users' data.\n- The regulator stated the order is temporary and will remain in place until OpenAI respects the GDPR.\n- OpenAI's representative in the European Economic Area was given 20 days to communicate how it plans to bring ChatGPT into compliance with EU privacy rules.\n- The regulator warned OpenAI it could face a penalty of up to 4 percent of its global revenue if it does not comply.\n- OpenAI disabled access to ChatGPT in Italy.\n- OpenAI publicly stated it disagreed with the Italian authority's findings.\n- OpenAI CEO Sam Altman said on Twitter that OpenAI was deferring to the Italian government on the issue.\n- A bystander (Skater 1) pulled the robot out of the planter.\n- A second bystander (Skater 2) pushed the robot clear of the planter.\n- A human remote operator connected to the robot's cameras and controls.\n- The robot was remotely operated and began moving again.\n- Some large ad platforms have recently changed their policies to restrict the targeting tools they offer to political campaigns.\n- Services Australia declined to say if the voiceprint technology would be changed or removed from Centrelink.\n- Services Australia said it continually scans for potential threats.\n- Services Australia said it makes ongoing enhancements to ensure customer security.\n- Services Australia said it applies additional tests to confirm a caller's identity when it identifies unusual circumstances in how customers use its authentication systems.\n- The ATO said it actively scans for potential vulnerabilities.\n- The ATO said it enhances its system as required to ensure the security and protection of ATO client data.\n- The ATO said appropriate controls are embedded in its digital services.\n- Bank Australia said it works closely with its technology partners to regularly monitor its systems.\n- Bank Australia said it continuously improves its systems to stay ahead of new threats, including those posed by emerging AI and machine learning tools.\n- Nuance directed Guardian Australia to a blog post addressing synthetic voices.\n- Nuance said its latest technology could detect and flag the use of cloned voices in 86% to 99% of cases, depending on the technology used.\n- Nuance said it devotes substantial research and development effort to anticipate criminals' next steps and constantly stay one step ahead.\n- The school went on lockdown in response to the threat.\n- Police searched the school following the threat but found nothing.\n- Authorities charged a 16-year-old boy with making a threat of terrorism related to the Hempstead High School calls.\n- The Cedar Rapids FBI field office assisted the investigation into the swatting calls.\n- FBI Seattle is working on a portion of the investigation into the threats.\n- Authorities charged 20-year-old Ashton Connor Garcia for allegedly making more than 20 swatting calls in the U.S. and Canada.\n- Torswats shuttered their Telegram channel before later reappearing in February.\n- After publication of the article, Torswats deleted the audio recordings from their Telegram channel.\n- Torswats claimed they were stopping their swatting service for at least one month.\n- Motherboard redacted some private information in some of the calls embedded in its piece.\n- SITE Intelligence Group published a report about Telegram users who offer bomb threats and swatting calls for money.\n- VICE News reported that multiple schools in Pennsylvania were shut down after suspected computer-generated swatting calls.\n- Tesla denied liability for the accident in a court filing.\n- Tesla stated in its court filing that Hsu used Autopilot on city streets despite a user manual warning against doing so.\n- Tesla attorney Michael Carey declined to comment after the verdict.\n- The U.S. Justice Department is investigating Tesla's claims about self-driving capabilities.\n- The National Highway Traffic Safety Administration is probing the safety of the technology.\n- Heart On My Sleeve was removed from Apple Music.\n- Heart On My Sleeve was removed from Spotify.\n- Heart On My Sleeve was removed from Deezer.\n- Heart On My Sleeve was removed from Tidal.\n- Heart On My Sleeve was in the process of being pulled from TikTok.\n- Heart On My Sleeve was in the process of being pulled from YouTube.\n- TikTok, Spotify and YouTube were asked to remove Heart On My Sleeve.\n- A YouTube link to the original version was made unavailable due to a copyright claim by Universal Music Group.\n- Uber publicly disputed Professor Dubal's paper, stating it does not tailor individual fares, does not consider drivers' race, ethnicity, Quest promotion status, acceptance rate, total earnings, or prior trip history when calculating fares, and that where Upfront Fares is available drivers see exactly what they will make and where they are going before deciding whether to accept a request.\n- Amazon publicly defended the Amazon Flex program, stating it gives individuals the opportunity to set their own schedule and provides competitive earnings that exceed $26 per scheduled hour on average.\n- The California Labor Commission sued Uber and Lyft in 2020, claiming the companies owed drivers a combined $1.3 billion in payments, and those lawsuits are still ongoing.\n- The article was updated after publication to include an updated comment from Uber.\n- The seller profnath reduced its listed price for the book to $106.23.\n- Sasha Luccioni created a simple tool called the Stable Diffusion Explorer to demonstrate and examine biases in the Stable Diffusion image generator.\n- Sasha Luccioni created an API for Stable Diffusion to generate reproducible, similarly positioned images for bias analysis.\n- Sasha Luccioni is working on charts that compare U.S. labour data to images generated by the AI to directly compare real-world data with AI outputs.\n- OpenAI published a 'Risks and Limitations' document noting that DALL-E 2 can reinforce stereotypes and overrepresent white-passing people and western-style images.\n- OpenAI stated that it was evaluating DALL-E 2's biases.\n- Frances Haugen handed over a trove of internal research documents to journalists, Congress, and the Securities and Exchange Commission.\n- Ohio Attorney General Dave Yost filed a federal class action lawsuit on behalf of the Ohio Public Employees Retirement System and other Facebook investors.\n- Yost is seeking to recover the lost value investors allegedly suffered.\n- Yost is seeking to require Facebook to change its practices to ensure it does not mislead the public in the future.\n- Yost joined 43 other state attorneys general in calling for Facebook to halt plans to introduce a version of Instagram for kids.\n- Facebook ultimately said it would pause its plans to introduce an Instagram for kids.\n- A Meta spokesperson called the suit 'without merit.'\n- A Meta spokesperson said the company 'will defend ourselves vigorously.'\n- Facebook countered by pointing to the positive impact its services can have on users and claiming some results from the study were misinterpreted.\n- The Federal Trade Commission is pursuing a similar case against the company.\n- A bystander called 911 during the phone call.\n- Another bystander called DeStefano's husband during the phone call.\n- Family and others confirmed within four minutes that DeStefano's daughter was safe.\n- DeStefano kept the scammer talking during the call to continue the conversation.\n- DeStefano hung up once she realized her daughter was safe.\n- The FBI said it is investigating these scammers.\n- The FBI's Phoenix assistant special agent Dan Mayo urged people to keep their social media profiles private.\n- Mayo advised people to look for red flags such as unfamiliar area codes, international numbers, and callers who refuse to allow you to talk to other family members.\n- Mayo advised people to slow the conversation down and ask many detailed questions to verify the caller's identity.\n- Texas A&M University\u2013Commerce is investigating the incident.\n- A university spokesperson rebutted parts of the Reddit post that claimed the professor had failed the entire class.\n- A university spokesperson confirmed that Dr. Jared Mumm sent the email.\n- Dr. Jared Mumm is working individually with students regarding their last written assignments.\n- Some students were given a temporary grade of 'X' (incomplete) to allow time to determine whether AI was used in their assignments and, if so, at what level.\n- Several students were exonerated and their grades were issued.\n- One student admitted to using Chat GTP in the course.\n- Dr. Mumm made a new writing assignment available to students.\n- Several students opted to complete the new writing assignment.\n- The school said it will work to develop policies to address the use or misuse of AI technology in the classroom.\n- Officials plan to use AI detection tools.\n- The false image was quickly exposed as a hoax.\n- Twitter suspended the false 'Bloomberg Feed' account.\n- Local authorities confirmed that the image was not an accurate representation of the Pentagon.\n- The Washington Post reported that large accounts such as Russia Today had already spread the misinformation.\n- Kemal Kilicdaroglu publicly accused Russia of responsibility for the deep-fake online content by tweeting the allegation to alert the world.\n- Kilicdaroglu's party did not contact the Russian embassy over the issue.\n- The Kremlin denied interfering in Turkey's election process.\n- Kremlin spokesman Dmitry Peskov publicly called the people who passed on such allegations liars and said Russia valued its ties with Turkey.\n- Muharrem Ince withdrew from the presidential race citing a faked \"character assassination\" carried out online.\n- NHTSA has an active investigation into Tesla Autopilot, including Full Self-Driving.\n- NHTSA began collecting data on crashes involving driver-assistance after a 2021 federal order required automakers to disclose such crashes.\n- NHTSA opened multiple probes into Tesla crashes and problems with its driver-assistance software.\n- One NHTSA probe has focused on 'phantom braking' in which vehicles abruptly slow for imagined hazards.\n- NHTSA upgraded its investigation of incidents in which Teslas slammed into parked emergency vehicles to an 'engineering analysis'.\n- NHTSA opened two consecutive special investigations into fatal crashes involving Tesla vehicles and motorcyclists.\n- NHTSA selected about 40 Tesla driver-assistance incidents for further analysis to gain deeper insight into how the technology operates.\n- In February, Tesla issued a recall of more than 360,000 vehicles equipped with Full Self-Driving over concerns the software prompted its vehicles to disobey traffic lights, stop signs and speed limits.\n- Tesla remedied the issues identified in the recall with an over-the-air software update, remotely addressing the risk.\n- Tesla has recently taken steps to reintroduce radar sensors to its vehicles, according to government filings.\n- The Tesla driver, Howard G. Yee, was charged with multiple offenses in the crash, including reckless driving, passing a stopped school bus and striking a person, a Class I felony.\n- Tesla asked NHTSA to exclude the company's summary of the incident from public view, saying it may contain confidential business information.\n- NHTSA reminded the public that all advanced driver assistance systems require the human driver to be in control and fully engaged in the driving task at all times and that state laws hold the human driver responsible for the operation of their vehicles.\n- Image analysis on Bing is no longer available.\n- Paul Tremblay and Mona Awad filed a proposed class-action lawsuit against OpenAI in San Francisco federal court.\n- The lawsuit seeks an unspecified amount of money damages on behalf of a nationwide class of copyright owners whose works OpenAI allegedly misused.\n- Source-code owners have filed lawsuits against OpenAI and Microsoft's GitHub over material used to train AI systems.\n- Visual artists have filed lawsuits against Stability AI, Midjourney, and DeviantArt over material used to train AI systems.\n- The companies targeted in these lawsuits have argued that their systems make fair use of copyrighted work.\n- Amazon will pay more than $30 million to settle alleged privacy violations involving its voice assistant Alexa and its doorbell camera Ring.\n- The Federal Trade Commission imposed a $25 million fine on Amazon in the Alexa case.\n- The FTC ordered Amazon to delete inactive child accounts.\n- The FTC ordered Amazon to delete certain voice information.\n- The FTC ordered Amazon to delete geolocation data.\n- The proposed order prohibits Amazon from using deleted geolocation and voice information to create or improve any data product.\n- The order requires Amazon to create a privacy program for its use of geolocation information.\n- The FTC's order requires Ring to pay $5.8 million that will be used for consumer refunds.\n- FTC commissioners unanimously voted to file charges against Amazon in both cases.\n- The ARC released a statement advising peer reviewers not to use AI as part of their assessments.\n- The ARC warned academics that feeding their peers\u2019 work into generative AI models could constitute a breach of confidentiality.\n- The ARC said it would update guidance on AI use in the near future.\n- The ARC said any concerns raised by applicants will be considered and responded to as per its policies.\n- Clarkson law firm filed a class-action lawsuit against OpenAI in federal court in the Northern District of California.\n- Clarkson's firm is actively seeking additional plaintiffs for the class-action lawsuit.\n- The lawsuit seeks court-ordered guardrails on how AI algorithms are trained and on compensation for people whose data is used.\n- A class-action lawsuit was filed in November against OpenAI and Microsoft alleging improper use of code from GitHub to train AI tools.\n- Getty Images sued Stability AI alleging it illegally used its photos to train its image-generating bot.\n- A radio host in Georgia sued OpenAI for defamation, alleging ChatGPT produced text that wrongfully accused him of fraud.\n- Universal Music Group asked Apple and Spotify to block scrapers.\n- Reddit is shutting off access to its data stream to prevent scraping of its comments and conversations.\n- Twitter owner Elon Musk threatened to sue Microsoft for using Twitter data Microsoft had obtained to train its AI.\n- Regulators are discussing enacting new laws that would require more transparency from companies about what data went into their AI.\n- Some companies have tried to stop AI firms from scraping their data.\n- The call center employee transferred the call to a different department.\n- The call center employee flagged the call as potentially fraudulent.\n- The banker hung up the phone when the caller's synthetic voice made no sense.\n- The banker reported the matter to Bank of America's security team after receiving two more similar calls.\n- The banker stopped responding to Mr. Kabatznik's calls and emails, including ones from the real Mr. Kabatznik, out of concern for account security.\n- Mr. Kabatznik and the banker re-established contact about 10 days later when he arranged to visit her at her office.\n- Researchers from Microsoft, Recorded Future, the RAND Corporation, NewsGuard and the University of Maryland revealed and reported on the covert Chinese disinformation campaign about the Maui wildfires.\n- Microsoft\u2019s researchers analyzed the covert campaign involving the Maui wildfires.\n- Recorded Future reported that the Chinese government mounted a covert campaign to blame a 'weather weapon' for the fires.\n- Microsoft\u2019s Threat Analysis Center identified inauthentic posts in 31 languages related to the campaign.\n- Microsoft\u2019s researchers identified AI-generated images of the Hawaii wildfires appearing on multiple platforms.\n- Microsoft\u2019s researchers reported that those specific AI-generated images appeared to be exclusively used by Chinese accounts in the campaign.\n- Caroline Amy Orr Bueno reported that a coordinated Russian campaign began on Twitter on Aug. 9 seeking to spread related narratives.\n- Brad Smith, Microsoft\u2019s vice chairman and president, sharply criticized China for exploiting a natural disaster for political gain.\n- Brad Smith presented and was scheduled to present some of Microsoft\u2019s findings to Congress.\n- NewsGuard identified a network of 17 TikTok accounts apparently using AI text-to-speech technology and analyzed their videos, views, and likes.\n- NewsGuard recreated the video's audio introduction using ElevenLabs' AI text-to-speech software and identified the likely voice as 'Natasha -- Valley Girl.'\n- NewsGuard emailed ElevenLabs in September 2023 to ask whether the video was produced using ElevenLabs' software.\n- A NewsGuard analyst entered the video's audio into ElevenLabs' AI speech classifier to assess whether it was generated by ElevenLabs.\n- An ElevenLabs spokesperson directed NewsGuard to an AI speech classifier available on ElevenLabs' website.\n- ElevenLabs' AI speech classifier analyzed the audio and reported that it was '98%... very likely' generated with ElevenLabs.\n- TikTok unveiled a feature on Sept. 19, 2023 allowing users to place disclosure labels on content they produced with the help of AI.\n- TikTok directed NewsGuard to the platform's policies on misinformation and manipulated media.\n- TikTok removed three of the identified accounts for violating the platform's impersonation policy.\n- TikTok removed one video identified by NewsGuard for violating the platform's manipulated media policy.\n- TikTok barred four videos from being algorithmically boosted for violating the platform's misinformation guidelines.\n- Jaswant Singh Chail pleaded guilty in February to the charges against him.\n- He apologized to the king and royal family for the \"distress and sadness\" he caused in a letter to the court.\n- A judge sentenced Chail to nine years in prison.\n- Chail will first be returned to Broadmoor Hospital, a secure psychiatric facility where he has been receiving treatment.\n- If deemed well enough in the future, he will serve the remainder of his sentence in prison.\n- Meta is limiting the rollout of the AI-generated sticker feature to select English-language users so it can address and correct abuse before it spreads.\n- Meta has implemented filters that block certain words and warn users that their prompt may violate Meta\u2019s community guidelines.\n- The Wiz Research Team reported the exposed SAS token and storage account to Microsoft\u2019s MSRC on June 22, 2023.\n- Microsoft invalidated the exposed SAS token on June 24, 2023.\n- Microsoft replaced the SAS token in the GitHub repository on July 7, 2023.\n- Microsoft completed an internal investigation into the potential impact on August 16, 2023.\n- Microsoft publicly disclosed the incident on September 18, 2023.\n- Monika Todova quickly had the deepfake audio recording taken down.\n- Tomas Krissak found that the clip spread particularly in Telegram channels usually filled with content supporting Fico's party.\n- Researchers at Demagog SK noted a rise in disinformation in the run-up to the election.\n- Progressive Slovakia conducted its own analysis concluding it was better at winning over undecided voters in the last days of the campaign.\n- Sergey Naryshkin, head of Russia's foreign intelligence service, issued a statement accusing Washington of trying to subvert the election and accusing Michal Simecka of advocating American interests.\n- Hany Farid publicly warned that deepfakes pose a two-fold threat to the democratic process.\n- G/O Media said it would promptly fix errors in AI-generated articles.\n- G/O Media committed to thoughtfully gather and act on staff feedback about using AI in its coverage.\n- GMG Union asked readers not to click on any AI-written articles.\n- CNET began overhauling its approach to AI after suffering heavy media criticism.\n- The article's authors reached out to G/O Media for comment.\n- Some systems applied warning labels to generated content as a response to biased image generation.\n- Some systems were set to refuse to output content related to particular identities.\n- Eddie conducted a survey of 35 non-cisgender people to gather their opinions on generated images and possible harm mitigation strategies.\n- Eddie presented the proposed mitigation solutions in very neutral language within the survey.\n- Eddie published a paper reporting his findings and providing evidence from the survey about representation and mitigation strategies.\n- A proposed mitigation was for models to ignore non-cisgender identity terms entirely.\n- A proposed mitigation was for models to ignore non-cisgender identity terms but add an identity flag or symbol to the image.\n- A proposed mitigation was to display a message warning users about the possibility of misrepresentation.\n- A proposed mitigation was to add more diverse images of non-cisgender people to the training data to improve model performance.\n- Researchers published a study in JAMA Network Open analyzing how race-based adjustments in spirometry software affect diagnosis and care for lung patients.\n- The American Thoracic Society issued a statement recommending replacement of race-focused adjustments in lung-function testing.\n- The American Thoracic Society called for more research into the best way to modify testing software and whether changes might unintentionally cause overdiagnosis.\n- Some other clinical algorithms have already been changed to remove race-based assumptions, including an algorithm that predicts vaginal delivery risk after a prior cesarean section.\n- Meta set up an internal task force to investigate and address these claims.\n- Meta said it works aggressively to fight child exploitation on and off its platforms.\n- Meta said it supports law enforcement in efforts to arrest and prosecute the criminals behind it.\n- Researchers notified Twitter that its basic scanning for known CSAM was broken.\n- Twitter fixed its basic scanning for known CSAM after researchers notified them.\n- Twitter cut off the researchers' API access.\n- The Federal Trade Commission obtained an order against Edmodo for collecting personal data from children without obtaining verifiable parental consent and for outsourcing COPPA compliance responsibilities to schools.\n- During the course of the FTC\u2019s investigation, Edmodo suspended operations in the United States.\n- The proposed order includes a $6 million monetary penalty, which will be suspended due to the company\u2019s inability to pay.\n- The proposed order prohibits Edmodo from conditioning a child\u2019s participation in an activity on the child disclosing more information than is reasonably necessary to participate in such activity.\n- The proposed order requires Edmodo to complete several requirements before obtaining school authorization to collect information from a child.\n- The proposed order prohibits Edmodo from using children\u2019s information for non-educational purposes such as advertising or building user profiles.\n- The proposed order bans Edmodo from using schools as intermediaries in the parental consent process.\n- The proposed order requires Edmodo to implement and adhere to a retention schedule that details what information it collects, what the data is used for, and a time frame for deleting it.\n- The proposed order requires Edmodo to delete models or algorithms developed using personal information collected from children without verifiable parental consent or school authorization.\n- The Commission voted 3-0 to refer the civil penalty complaint and proposed federal order to the Department of Justice.\n- The Department of Justice filed the complaint and stipulated order in the U.S. District Court for the Northern District of California.\n- Google prevented its Photos app from categorizing images as \"gorillas\".\n- Google prevented its Photos app from labeling images as monkeys or apes.\n- Apple appeared to disable the ability to search for monkeys and apes in Apple Photos.\n- Apple declined to comment on users\u2019 inability to search for most primates in its app.\n- Google profusely apologized for the incident in which images of Black people were labeled as gorillas.\n- Google vowed to fix the problem after the incident.\n- Google said it had improved its technology by partnering with experts and diversifying its image datasets.\n- In 2019, Google tried to improve a facial-recognition feature by increasing the number of people with dark skin in its training dataset.\n- Contractors hired by Google targeted homeless people and students to collect facial scans as part of the 2019 data-collection effort.\n- Google rushed to fix the Nest camera's misclassification problem before users had access to the product.\n- A Google customer support representative advised Nest users to delete all of their labels and start over when the system mixed up faces.\n- Microsoft limited users' ability to interact with its Bing chatbot after the chatbot instigated inappropriate conversations.\n- Representatives from Amazon and Microsoft said the companies were always seeking to improve their products.\n- Amazon removed the impostor book and numerous other listings by the same publisher from its site.\n- CNET investigated its use of AI after criticism and found that many of its 77 AI-drafted stories contained errors.\n- Ingenio disclosed to readers that it uses AI to produce content.\n- Ingenio's dreamdiary.com states that each article produced with AI is reviewed by a human editor.\n- NewsGuard identified 49 news websites across seven languages that appeared to be mostly or entirely AI-generated.\n- NewsGuard searched the web and used analytics tools to find sites by looking for telltale phrases such as 'As an AI language model.'\n- Semrush surveyed its customers about their use of automated tools and reported that many had experimented with generative AI and many used it for most of their content.\n- Textbroker began training some of its writers to use AI tools to increase productivity.\n- Several companies publicly defended their use of AI to The Post, saying they use language tools to make writers more productive or to produce content they otherwise would not.\n- Google clarified that it allows AI-generated content in search results as long as the AI is not used to manipulate a site's search rankings and said its algorithms focus on content quality.\n- Two Cigna members filed a class-action lawsuit in federal court in Sacramento alleging that Cigna automatically rejected hundreds of thousands of patient claims.\n- The lawsuit seeks unspecified damages and a jury trial.\n- Cigna Healthcare issued a public statement disputing the lawsuit, calling it \"highly questionable\" and based on a poorly reported article.\n- Cigna stated that it provides clear guidance on resubmission and how to appeal when codes are submitted incorrectly.\n- Porcha Woodruff filed a lawsuit in U.S. District Court for the Eastern District of Michigan naming the city and Detective LaShauntia Oliver as defendants.\n- The Wayne County Prosecutor's Office dropped the case on March 6 for insufficient evidence.\n- Detroit Police Chief James E. White reviewed the allegations in the lawsuit.\n- Chief White said the department could not comment further at that time due to the need for additional investigation.\n- Chief White said the department will provide further information once additional facts are obtained and there is a better understanding of the circumstances.\n- Woodruff was released from the Detroit Detention Center at around 7 p.m. on a $100,000 personal bond.\n- Woodruff's fianc\u00e9 took her to a medical center where she was diagnosed with a low heart rate due to dehydration and told she was having contractions from stress related to the incident.\n- Playground AI founder Suhail Doshi replied directly to Wang on Twitter two hours after her tweet.\n- Doshi offered to help Wang get a better result with the product.\n- Doshi publicly stated that Playground AI was \"quite displeased\" with the output and said they \"hope to solve it\".\n- Doshi tweeted that Playground AI does not support the use case of AI photo avatars.\n- Doshi explained on Twitter that the models are not instructable enough to preserve a person's identity and instead pick generic features based on the prompt.\n- The supermarket said it would keep fine tuning the bot's controls to ensure it was safe and useful.\n- The supermarket appended a warning notice to the meal-planner stating that the recipes are not reviewed by a human being.\n- The supermarket appended a warning notice to the meal-planner stating that the company does not guarantee that any recipe will be a complete or balanced meal or suitable for consumption.\n- The supermarket appended a warning notice to the meal-planner telling users they must use their own judgement before relying on or making any recipe produced by Savey Meal-bot.\n- Cruise is actively investigating the incident.\n- Cruise is working on solutions to prevent this from happening again.\n- Cruise apologized to those impacted.\n- Cruise is considering creating its own cell phone network specifically for its San Francisco operations.\n- The National Highway Traffic Safety Administration opened a safety-defect probe into nearly 600 Cruise driverless cars.\n- The National Highway Traffic Safety Administration launched an investigation to determine the scope and severity of the potential problem.\n- The National Highway Traffic Safety Administration is investigating reports of Cruise vehicles encroaching on pedestrians present in or entering roadways, including crosswalks.\n- The California Department of Motor Vehicles initiated its own investigation into incidents involving Cruise vehicles in San Francisco.\n- Cruise said it regularly communicates with the NHTSA.\n- Cruise said it is cooperating with the NHTSA's requests for information.\n- Cruise briefed the NHTSA on the incident.\n- Cruise showed the NHTSA video footage of the incident.\n- Cruise has been actively working with police to help identify the responsible driver.\n- Cruise agreed to reduce its fleet in half while the California DMV's probe continues.\n- Cruise limited its operations to no more than 50 driverless vehicles operating in the day and 150 at night.\n- Rescue crews lifted the car off the injured woman.\n- The injured woman was transported to the hospital.\n- The National Highway Traffic Safety Administration opened a probe in December 2022 into about 240 Cruise driverless cars.\n- Westfield High School confirmed the incident in an email to parents.\n- Westfield police opened an investigation into the incident.\n- New Jersey state senator Jon Bramnick asked the Union County prosecutor to investigate the Westfield High case.\n- School administrators began interviewing boys who might have known more information about the images.\n- Principal Mary Asfendis pledged to continue teaching students about responsible technology use.\n- School administrators informed several girls that some boys had identified them in the generated images.\n- Multiple parents filed police reports with local law enforcement about the incident.\n- Westfield Mayor Shelley Brindle encouraged people affected by the situation to give statements to the police.\n- A meeting was held at a parent's home that included parents, the mayor, the state senator, town-council members, and a school-board member to discuss the situation.\n- The school held a group counseling session for students affected by the incident.\n- Some female students deleted their social-media accounts after learning about the fabricated images.\n- Tech firms including Snap and TikTok pledged to work with government groups to stop AI-generated sexual images from circulating.\n- Snap and other platforms stated that they ban AI-generated sexual images of minors and report such content to the National Center for Missing and Exploited Children.\n- Senator Jon Bramnick said he intends to draft a bill to criminalize the creation and sharing of such faked sexual material if no applicable state law exists.\n- The Biden administration called for preventing generative AI from producing child sexual-abuse material or non-consensual intimate imagery as part of a broader executive order on AI.\n- The man was sentenced to two and a half years in prison by the Busan District Court.\n- The roughly 360 AI-generated images were confiscated by police.\n- Prosecutors argued during the case that the legal definition of sexually exploitative material should include descriptions of sexual behaviors by \"virtual humans\" and not just the appearance of actual children.\n- Police in Spain launched an investigation after images of underage girls were altered with AI and circulated.\n- Twitch tightened its policies in response to the deepfake sexual-video controversy.\n- TikTok added further restrictions on sharing AI deepfakes in March.\n- Other major platforms began updating their rules regarding deepfakes and AI content.\n- The European Union set regulations in June on how companies can use AI.\n- China implemented AI regulations in July.\n- Several major tech leaders, including Bill Gates, Elon Musk, and Mark Zuckerberg, gathered in Washington.\n- The U.S. Senate prepared to draft legislation on AI.\n- David Tatum was sentenced to 40 years in prison followed by 30 years of supervised release.\n- Tatum was ordered to pay restitution in an amount to be determined within 90 days.\n- Tatum was ordered to pay a $100 special assessment per count of conviction.\n- Tatum was ordered to pay a special assessment totaling $99,000 under the Amy, Vicky, and Andy Child Pornography Victim Assistance Act (AVAA).\n- After he is released from prison, Tatum will be required to register with the Sex Offender Registry Board in any state or jurisdiction where he works or resides.\n- On May 4, a federal jury in Charlotte convicted Tatum of one count of production of child pornography, one count of transportation of child pornography, and one count of possession of child pornography.\n- Tatum is currently in federal custody and will be transferred to the custody of the federal Bureau of Prisons upon designation of a federal facility.\n- The FBI conducted an investigation of the case.\n- Assistant United States Attorneys Daniel Cervantes and Mark T. Odulio prosecuted the case.\n- The case was brought as part of Project Safe Childhood.\n- Gayle King warned her followers on Instagram that videos using AI likenesses of her were being used for fraudulent advertisements.\n- Gayle King posted the doctored footage with the words 'Fake Video' stamped across it.\n- Gayle King wrote on Instagram that she had nothing to do with the advertised product and warned people not to be fooled by the AI videos.\n- Tom Hanks warned his followers on Instagram that an advertisement using an AI version of him was fraudulent and that he had nothing to do with it.\n- Representatives on Gayle King's behalf requested that the fake video be taken down several times.\n- Meta said it had put substantial resources toward tackling these kinds of ads.\n- Meta said it had improved its enforcement, including suspending and deleting accounts, pages, and ads that violate its policies.\n- Guilds, agencies, and legal firms were discussing the legal ramifications around an actor claiming his or her face and voice as intellectual property.\n- Lawyers for the entertainment companies came up with language that addressed guild concerns about A.I. and old scripts that studios own.\n- A spokesperson for Mr Starmer confirmed to Full Fact that the video is not genuine.\n- Full Fact could not find any reports by either the government or reliable sources describing such an investment scheme.\n- Full Fact reported that the footage appears to be a deepfake video created by cloning Mr Starmer\u2019s voice.\n- Mike Russell told Full Fact that the repeated use of the word 'pounds' gives the deepfake audio away.\n- Dr Dominic Lees told Full Fact that blurriness or smudging around the mouth is a telltale sign of poorly lip synced deepfake videos.\n- Full Fact wrote about other examples of audio clips that it found no evidence were real.\n- Full Fact warned readers that misinformation spreads quickly online and advised them to consider whether something is likely to be genuine before sharing.\n- The estates of two deceased people filed a lawsuit in the US District Court for the District of Minnesota seeking class-action status and damages against UnitedHealth and NaviHealth.\n- Stat News conducted an investigation using internal documents, communications, and interviews with former NaviHealth employees about nH Predict and its use.\n- Patients and their doctors filed internal appeals and federal Administrative Law Judge proceedings challenging coverage denials, which the lawsuit claims resulted in over 90 percent of the denials being reversed.\n- In 2022 NaviHealth instructed case managers to keep patients' stays in nursing homes within 3 percent of the days projected by the nH Predict algorithm.\n- In 2023 NaviHealth tightened that requirement by instructing case managers to keep patients' stays within 1 percent of the algorithm's projected days.\n- NaviHealth disciplined or fired case managers who fell outside the length-of-stay target.\n- NaviHealth provided training documents instructing case managers to defend the algorithm's estimates to patients and care providers using specific tactics.\n- Optum Health, a UnitedHealth subsidiary, issued an emailed public statement denying that the naviHealth predict tool is used to make coverage determinations and stating the company will defend the lawsuit vigorously.\n- Supervisors directed case managers to immediately restart case review processes for patients who won appeals, often leading to new denials.\n- MP Kate Osamor wrote to Th\u00e9r\u00e8se Coffey, the work and pensions secretary, to express her grave concern about the suspensions of Bulgarian nationals' universal credit.\n- Osamor's constituency office raised concerns from about 16 affected constituents with the Department for Work and Pensions via an MPs helpline.\n- The Work Rights Centre advised eight affected people originally from Bulgaria who were trying to get their suspended benefits reinstated.\n- A Department for Work and Pensions spokesperson said that if claimants provided details proving their claim is genuine the department would urgently restore any payment due.\n- The school district notified all families of students who were confirmed to have been involved in the incident.\n- Issaquah Police are investigating the incident.\n- Navy Federal issued a public statement defending its lending practices.\n- Navy Federal declined to release additional loan data to CNN that would have included borrowers' credit scores and other variables.\n- Navy Federal said employee training, fair lending statistical testing, third-party evaluations, and compliance reviews are embedded in its lending practices.\n- Navy Federal said rental history was incorporated into its underwriting process.\n- Bob Otondi submitted complaints to the Consumer Financial Protection Bureau and to a Texas state agency.\n- Otondi's realtor connected him with another mortgage lender that approved his loan in about two weeks.\n- Ted Spencer obtained approval from another mortgage lender that quickly approved him for a new loan at a lower interest rate.\n- Some realtors advised clients disapproved by Navy Federal to get them in with another lender.\n- CNN analyzed data on millions of mortgage applications to evaluate racial disparities in lending at Navy Federal and other lenders.\n- Some banks changed their underwriting systems to incorporate additional data, such as rental payment history, to reduce racial disparities.\n- Advocates and banking groups have called for revisions to the Community Reinvestment Act to require credit unions to follow the same rules as banks.\n- As part of the settlement with the Federal Trade Commission, Rite Aid is forbidden from deploying facial recognition technology in its stores for five years.\n- Rite Aid stopped using the facial recognition technology more than three years ago.\n- Microsoft is investigating reports that Image Creator produced harmful images.\n- Microsoft is taking action in accordance with its content policy, which prohibits the creation of harmful content.\n- Microsoft said it will continue to update its safety systems.\n- Microsoft's teams are reviewing the company's internal processes.\n- Microsoft is making improvements to its systems to better address customer feedback.\n- Microsoft is making improvements to its systems to help prevent the creation of harmful content in the future.\n- Microsoft has large teams working to address these and similar issues.\n- Microsoft has made improvements to its safety mechanisms to prevent the specific prompts from working.\n- Microsoft says its safety mechanisms will catch similar types of prompts moving forward.\n- Microsoft's system no longer allows McDuffie's precise original prompt to work.\n- Microsoft issued a public statement acknowledging that it could have done more to prevent the harmful images.\n- The Chevrolet of Watsonville dealer deactivated its AI chat bot.\n- Some Amazon product listings that contained OpenAI error messages in their titles were taken down after the listings spread on social media.\n- The original article links to those listings were replaced with archived copies because the original listings were taken down shortly after publication.\n- A product description for a set of tables and chairs was taken down.\n- Kelly Carlin told Gizmodo she is considering legal action.\n- Gizmodo reached out to Sasso and Kultgen\u2019s representatives to ask how much human intervention went into the special.\n- Krista Perry, Larissa Martinez, and Jay Baron filed a lawsuit against Shein in California federal court alleging the company used AI to recreate their designs.\n- In mid-March, the United States Copyright Office ruled that AI-generated artworks are not eligible for copyright.\n- The verified user who shared the images had their account suspended for violating platform policy.\n- The post was removed from the platform after being live for around 17 hours.\n- Swift fans flooded hashtags used to circulate the images with messages promoting real clips of Taylor Swift to hide the explicit fakes.\n- A report from 404 Media found that the images may have originated in a group on Telegram where users share explicit AI-generated images.\n- The company is currently being investigated by the EU regarding claims that it's being used to 'disseminate illegal content and disinformation.'\n- 9 News Melbourne director Hugh Nailon issued a statement saying the altered image resulted from an 'automation by Photoshop' error.\n- 9 News Melbourne apologized unreservedly to Ms Purcell for using the altered image.\n- A Nine spokesperson said Nine was reviewing its use of Adobe's Generative Expand AI tool.\n- An Adobe spokesperson said in an email that the edits would have required human intervention and approval.\n- Georgie Purcell posted about the edited image on X, sharing the original photo beside the altered graphic.\n- Georgie Purcell posted a later statement on Facebook criticizing the incident as an example of sexualization and objectification.\n- YouTube terminated three channels for violating its Terms of Service.\n- YouTube removed additional channels from its monetization program.\n- YouTube removed a number of videos and thumbnails.\n- YouTube announced in November that it plans to enforce a new policy requiring labels for synthetic and manipulated media in videos.\n- YouTube suspended the channel responsible for the search-result content about T.D. Jakes from its monetization program.\n- YouTube terminated one of the channels that pivoted to covering salacious, fake stories about Black celebrities.\n- YouTube terminated both of the channels NBC News flagged that were linked to Crealon Entertainment for circumventing a previous channel termination.\n- NBC News reviewed a dozen YouTube channels posting what appears to be AI-generated fake news content.\n- NBC News flagged several channels to YouTube.\n- NBC News requested comment from the channels it reviewed.\n- One channel responded to NBC News' request for comment by emailing that it uses AI text-to-speech for some videos but denied using AI tools for the scripts or the thumbnails.\n- Siwei Lyu ran the audio from two videos in the T.D. Jakes search results through an open-source AI Speech Classifier model to assess whether the audio was AI-generated.\n- Siwei Lyu ran the Jan. 14 Diddy video through the same AI detection model to evaluate whether its audio was AI-generated.\n- Reality Defender ran the Jan. 14 video's thumbnail and 28 seconds of its audio through AI-detection programs and assessed the voiceover and parts of the thumbnail as 99% likely to be produced with generative AI tools.\n- Mozilla's Privacy Not Included project conducted a study reviewing 11 different AI romance chatbot apps.\n- Mozilla assigned the 'Privacy Not Included' label to every chatbot it reviewed.\n- Mozilla counted the trackers used by the apps and reported that they used an average of 2,663 trackers per minute and that Romantic AI called 24,354 trackers in one minute.\n- Mozilla issued a press statement publicizing the study's findings, including a quote from researcher Misha Rykov.\n- Requests for comment were sent to the apps mentioned in the story, and the apps did not immediately respond.\n- Mozilla evaluated the apps against its minimum security standards and reported that only one app, Genesia AI Friend & Partner, met those standards.\n- Moffatt requested a refund through Air Canada's Ticket Refund Application form on Nov. 17, 2022.\n- He provided his grandmother's death certificate to Air Canada.\n- He emailed Air Canada employees for the next three months.\n- In February 2023, an Air Canada employee told Moffatt that the chatbot had misled him.\n- Moffatt filed a claim with the Canadian civil-resolutions tribunal.\n- The Canadian tribunal ruled that Air Canada owed Moffatt more than $600 in damages and tribunal fees after failing to provide \"reasonable care.\"\n- The tribunal ordered Air Canada to pay Moffatt about $483 in damages for the overpayment.\n- The tribunal ordered Air Canada to pay roughly $93 in tribunal fees.\n- The tribunal ordered Air Canada to pay $26.80 in prejudgment interest.\n- An Air Canada spokesperson said the airline will comply with the tribunal's decision.\n- Waymo informed local police of the incidents.\n- Waymo informed a state safety agency of the incidents.\n- Waymo informed the National Highway Traffic Safety Administration of the incidents.\n- Waymo researched what happened.\n- Waymo changed its vehicle software.\n- Waymo installed the updated software on all its vehicles between late December 2023 and early January 2024.\n- Waymo issued a voluntary recall for its self-driving car software.\n- After discussions with NHTSA, Waymo determined that it should file a recall report.\n- The software update was confined to Waymo's own fleet of self-driving Jaguar I-Paces.\n- Cruise lost its permits to test vehicles in California.\n- Cruise voluntarily stopped testing throughout the country.\n- Numerous Cruise executives left the company.\n- Cruise issued a recall for its software in that case.\n- Cruise has not yet returned to operating its vehicles.\n- X removed a post promising to 'send full Bobbi Althoff leaks' after The Washington Post sought comment on the fakes.\n- X blocked searches for Taylor Swift's name when AI-generated sex images of the pop star went viral.\n- A community note was added to a post stating the Althoff video was AI-generated and was being spread 'knowingly for engagement bait and twitter revenue'.\n- Instagram and Reddit quickly removed the AI-generated Taylor Swift and Bobbi Althoff fakes after they were posted.\n- The author of the original post later added a comment apologizing to Bobbi Althoff.\n- OpenAI announced it is investigating reports of ChatGPT's erratic behaviors.\n- OpenAI acknowledged that the chatbot 'went a little off the rails' and said it should be back and operational.\n- OpenAI found a bug in the part of the system that processes language in the step where the model chooses numbers that map tokens.\n- OpenAI rolled out a fix and said the issue has been resolved.\n- OpenAI said it is actively working to address the issues and is closely monitoring the situation.\n- ChatGPT itself acknowledged the issue in messages, stated a 'technical hiccup' caused a nonsensical section to be repeated, and apologized for the error.\n- Logically Facts reached out to France 24.\n- France 24 referred Logically Facts to their previously published debunks.\n- France 24 clarified that the alleged news segment about an assassination plot was not aired.\n- France 24 provided Logically Facts with the complete footage of the news segment that appears to have been used to create the deepfake.\n- France 24 Observers published a report stating that the viral video was created using deepfake technology.\n- France 24 Observers stated that Julien Fanciulli never uttered the words heard in the viral clip and pointed out inconsistencies in lip movements and fabricated tickers.\n- Julien Fanciulli posted on X on February 16 to call out the viral video as a deepfake.\n- Logically Facts ran the viral video past an OSINT specialist who confirmed the audio was not in sync with lip movements and that the voice sounded robotic.\n- Logically Facts used an application developed by IIT Jodhpur professors to analyze the viral video and found it to be fake with a confidence score of 0.943.\n- The story was updated to reflect analysis by a tool that indicated the video had been altered.\n- The San Francisco Fire Department was called to the scene at 2:43 p.m.\n- First responders encountered the cyclist and performed an assessment at the scene.\n- The cyclist declined transport to the hospital.\n- Paramedics agreed that a hospital trip was not necessary.\n- Waymo notified the police to the scene.\n- Waymo issued a public statement about the collision.\n- Waymo made contact with relevant authorities regarding the event.\n- Beverly Hills Police responded to a call from the Beverly Hills Unified School District.\n- Beverly Hills Police took a report about the incident.\n- A noncriminal police investigation is underway.\n- The school district opened an investigation into the incident.\n- The students identified as perpetrators have been removed from the school pending the results of the district\u2019s investigation.\n- The district said student perpetrators will be punished with anything from suspension to expulsion depending on their level of involvement.\n- The district superintendent sent a letter to parents informing them of the AI-generated nude photos.\n- The superintendent urged Congress as well as federal and state governments to take immediate and decisive action to protect children from unregulated AI.\n- The superintendent called for the passing and enforcement of legislation that punishes perpetrators and strictly regulates evolving AI technology to prevent misuse.\n- Security guards were stationed outside Beverly Vista Middle School.\n- USA TODAY labeled the video 'Altered'.\n- USA TODAY reached out to the user who shared the post for comment.\n- Lead Stories published a fact-check debunking the claim that the video shows President Biden making transphobic remarks.\n- PolitiFact published a fact-check debunking the claim that the video shows President Biden making transphobic remarks.\n- TikTok removed the videos under its harmful misinformation policy.\n- TikTok banned the @mikesmithtrainer account.\n- Twitter removed the suspected Rogan deepfake video.\n- Twitter displayed a prompt stating the clip had been removed due to a report from the copyright owner.\n- Andrew D. Huberman publicly replied on Twitter to point out that the conversation in the video never actually happened.\n- A TikTok spokesperson highlighted the platform's Community Guidelines which disallow digital forgeries that mislead users.\n- Mashable reached out to TikTok for more information and said it will update the piece when it hears back.\n- Synthesia banned the user behind the Wolf News channel for breaching its guidelines.\n- Victor Riparbelli, co-founder of Synthesia, publicly apologised and condemned the activity.\n- Graphika raised the alarm by publishing a nine-page report titled 'Deepfake It Till You Make It' exposing the operation.\n- Victor Riparbelli called for existing laws to be updated for the digital age and urged all AI providers to go further in preventing misuse.\n- Twitter removed one offending tweet.\n- Twitter suspended one related profile.\n- ElevenLabs said it was exploring more safeguards around its platform.\n- ElevenLabs acknowledged in Twitter direct messages to the victims that the Agent 47 audio was made using its system.\n- ElevenLabs told Abbey that it had the IP address of the person who created the Agent 47 audio.\n- ElevenLabs said it investigated and found that almost all clips attributed to its software were created using other platforms.\n- ElevenLabs said its new safeguards are already rapidly reducing instances of misuse.\n- ElevenLabs said it will support authorities in identifying users if the law was broken.\n- Abbey and other victims shared copies of ElevenLabs' direct messages with Motherboard.\n- Motherboard withheld some actors' last names at their request.\n- Workday issued a public statement denying the lawsuit's allegations and saying the suit was without merit.\n- Workday stated it is committed to trustworthy AI and acts responsibly and transparently in the design and delivery of its AI solutions to support equitable recommendations.\n- Workday said it engages in a risk-based review process throughout its product lifecycle to help mitigate any unintended consequences.\n- Workday said it conducts extensive legal reviews to help ensure compliance with regulations.\n- The Garante issued an urgent order blocking the AI-powered chatbot Replika from processing the personal data of users located in Italian territory.\n- The Garante required the U.S.-based controller to report within 20 days on the measures adopted to comply with the Garante's requests.\n- Meta removed all of the app\u2019s ads from its services.\n- Meta restricted the app's Page from advertising on its platform.\n- Apple removed the app from the App Store after being contacted by NBC News.\n- The TikTok videos were taken down after they were posted.\n- School authorities publicly condemned the videos as blatant racism.\n- On Feb. 15 the Carmel Central School District Board of Education issued a statement acknowledging the incident involved fake videos created using artificial intelligence and impersonating district and sheriff's department members.\n- The district stated the students who posted the videos would be dealt with in accordance with the District's Code of Conduct.\n- Once the Mahopac school authorities became aware of a Snapchat threat, they alerted the Carmel Police Department and the Putnam County Sheriff's Office.\n- Law enforcement investigated the Mahopac Snapchat threat immediately and identified the student responsible.\n- Despite deeming the Mahopac Snapchat threat non-credible, the Putnam County Sheriff's Office provided additional officers at the middle school on Monday.\n- Officials from the Putnam County Sheriff's Office attended a Monday night school meeting to address parents' concerns.\n- The superintendent of Mahopac Central School District issued a note to parents informing them of the racist threat made by a student.\n- Carmel superintendent Mary-Margaret Zehr spoke at the Carmel Central School District board meeting about her findings from two public meetings with concerned parents.\n- The district announced it will implement improved communications systems to address shortcomings in handling the situation.\n- The district announced it will implement an anonymous alert system that allows students to anonymously report issues and concerns.\n- Some parents plan to file a lawsuit against the school authorities over their handling of the incident.\n- DoNotPay CEO Joshua Browder posted a lengthy Twitter thread criticizing the class-action complaint and the law firm representing the plaintiff.\n- Browder sent a statement to Gizmodo via text message denying the allegations and asserting the plaintiff's claims are meritless.\n- Browder publicly stated that DoNotPay \"will defend ourselves vigorously.\"\n- Browder declined to tell Gizmodo whether DoNotPay would hire outside counsel, saying he could not comment given the pending litigation.\n- Browder tweeted that the company \"may even use our robot lawyer in the case.\"\n- Plaintiff Jonathan Faridian updated his LinkedIn profile to make his legal education/status clearer.\n- TikTok said it is contributing to aid earthquake relief efforts.\n- TikTok said it is actively working to prevent people from scamming and misleading community members who want to help.\n- PayPal suspended the fraudulent PayPal account.\n- PayPal said its teams are scrutinising and banning accounts, particularly in the wake of events like the earthquake in Turkey and Syria.\n- Twitter suspended the @TurkeyRelief account.\n- The BBC asked colleagues in its Blue Room tech research hub to generate similar images using the same AI software to verify whether the image was AI-generated.\n- The BBC contacted the person tweeting the appeal and asked them questions and for receipts or proof of identity.\n- The BBC identified the main methods used by scammers and the tools readers can use to double check before donating.\n- A federal judge ruled that the insurer owed Frances Walter thousands of dollars for more than three weeks of treatment.\n- While contesting the denial, Frances Walter spent down her life savings to pay for care.\n- While contesting the denial, Frances Walter enrolled in Medicaid to cover her care.\n- UnitedHealthcare and other insurers said they offer to discuss a patient's care with providers before making a denial.\n- NaviHealth stated that it routinely shares the findings of its algorithm with doctors, patients, and caregivers to help guide care.\n- Providers and patients filed appeals to contest Medicare Advantage denials, with appeals increasing 58% between 2020 and 2022 and nearly 150,000 requests filed in 2022.\n- Atrium Health's Brian Moore conducted a deeper review of medical necessity criteria and denials.\n- The Greater Wisconsin Agency on Aging Resources agreed to take up Holly Hennessy and her mother's appeal.\n- A judge ruled that UnitedHealthcare must pay Dolores Millam's nursing home treatment in full.\n- Federal inspectors examined denials made in 2019 and found that private insurers repeatedly strayed beyond Medicare's rules.\n- Federal Medicare officials proposed new rules prohibiting Medicare Advantage insurers from denying coverage based on internal, proprietary, or external clinical criteria not found in traditional Medicare coverage policies.\n- Federal Medicare officials proposed that insurers create an annual utilization management committee to review their practices.\n- Most denials for skilled nursing care were eventually overturned either by the plan itself or by an independent body that adjudicates Medicare appeals.\n- America's Health Insurance Plans submitted comments to Medicare urging regulators not to adopt policies that would place limits on plan flexibility to manage post-acute care.\n- Marvin von Hagen posted a screenshot of the exchange on Twitter soon after the incident.\n- Microsoft publicly admitted in a blog post that Bing was prone to being derailed after extended chat sessions.\n- Microsoft said that feedback from the community of users was helping it to improve the chat tool and make it safer.\n- Police in Hanoi, Thai Nguyen Province, and Tuyen Quang Province have repeatedly posted warnings about cybercrimes using Deepfake technology.\n- The HCMC Department of Public Security informed the public that there is a trick to call victims and ask for money transfer claiming medical emergencies.\n- The HCMC Police are investigating the cases, with indications that the perpetrators are cross-border criminals.\n- MC and actor Quyen Linh has publicly warned that his images have been used without his permission to market medicines.\n- Quyen Linh's lawyer has collected evidence over the past two years from more than 2,000 illegal advertisements.\n- Doctor Truong Huu Khanh has told people who asked for further information that he was not the one advertising the medicines.\n- Doctor Truong Huu Khanh has posted warnings on his official social network page advising the public not to trust the marketed medicine advertisements.\n- C.T.N.Y. called her friend by mobile phone and discovered that the friend's Facebook account had been hacked.\n- Turnitin added a caution flag to its AI writing score that reads, \"Percentage may not indicate cheating. Review required.\"\n- Turnitin tuned its detection system to require higher confidence before flagging a sentence as AI-generated.\n- Turnitin reran the sample essays through its system in late March to reassess detection results.\n- Turnitin said it will keep adjusting its software based on feedback and new AI advancements.\n- Turnitin committed to transparency and to continue iterating on the user experience as it learns from students and educators.\n- Some customers asked Turnitin not to display the AI writing score on student work.\n- Mitchel Sollenberger asked Turnitin not to activate AI detection for his campus at its initial launch.\n- Rebecca Dell taught an entire lesson to her AP English class on what ChatGPT is and isn't, including asking it to write an essay and having the class analyze its performance.\n- Mr. Reid's parents made phone calls seeking help after his arrest.\n- Mr. Reid's family retained an Atlanta lawyer from the Cochran Firm.\n- At the lawyer's suggestion, the family cold-called law firms in Jefferson Parish and Baton Rouge until they found a local attorney.\n- The family retained Jefferson Parish criminal defense lawyer Thomas Calogero that Sunday.\n- Mr. Calogero went to the consignment store and spoke with the owner to view the surveillance still.\n- Mr. Calogero gathered photos and videos of Mr. Reid from his family and sent them to the Jefferson Parish Sheriff\u2019s Office on Nov. 30.\n- Mr. Calogero spoke to the New Orleans news outlet NOLA.com about what he believed had happened.\n- An officer called to inform Mr. Calogero that the police were withdrawing the warrant because they had noticed a mole on Mr. Reid\u2019s face that the alleged purse thief did not have.\n- A Jefferson Parish judge recalled the arrest warrant on Wednesday afternoon.\n- Mr. Reid was released from jail late Thursday night.\n- Mr. Reid's family spent thousands of dollars pursuing information and legal assistance after the arrest.\n- OpenAI shut down the ChatGPT service on March 20.\n- OpenAI notified the ChatGPT Plus subscribers whose payment-related information was exposed.\n- OpenAI patched the bug that exposed users' chat history and payment information.\n- OpenAI brought ChatGPT back online and restored users' chat histories.\n- Kaitlin Jackson called the Bronx District Attorney's Office to ask how police had identified her client.\n- A judge ordered a hearing to determine whether the identification process had been unduly suggestive.\n- Prosecutors offered the defendant a plea deal to plead guilty to petit larceny in exchange for a sentence of time served.\n- Kaitlin Jackson created a guide for the National Association of Criminal Defense Lawyers advising attorneys how to spot the use of facial recognition and request supporting materials.\n- Attorneys representing Michael Oliver and Robert Williams requested lists of all potential matches returned by facial recognition systems as part of lawsuits against police.\n- Police departments in New York City and Detroit adopted policies governing the use of facial recognition.\n- The New York and Detroit policies require two people to review the results of a facial recognition scan before the results are turned over to detectives.\n- The New York and Detroit policies prohibit using facial recognition alone as probable cause to carry out a search warrant or arrest.\n- New York's facial recognition policy, effective March 2020, was updated to require prosecutors to tell defendants when facial recognition is used to identify them.\n- Utah and Washington enacted laws requiring police to disclose the use of facial recognition in criminal cases.\n- Washington's law prohibits using facial recognition alone to establish probable cause in an investigation.\n- Washington's law requires independent tests of any facial recognition systems used by state agencies.\n- A group representing chiefs of police from major US cities publicly called for police to disclose when facial recognition is used to help identify a suspect.\n- The Center for Strategic and International Studies published a report recommending that Congress create national standards to prevent a patchwork of regulation for facial recognition.\n- Seven US states and cities, including Boston and San Francisco, adopted full or partial bans on government use of facial recognition.\n- The National District Attorneys Association instructed its members to use professional judgment and discretion when deciding whether to divulge the use of facial recognition in investigations.\n- White House science and tech policy leaders endorsed more disclosure around the use of artificial intelligence as part of an AI Bill of Rights.\n- Clare Garvie trained more than 2,000 defense attorneys on how to spot the use of facial recognition technology.\n- Police offered a man charged with multiple counts of robbery a plea deal of 20 hours of community service after a defense attorney requested information about a facial recognition system.\n- Willie Lynch appealed to the Florida Supreme Court seeking more information about how facial recognition was used in his case, and the appeal was supported by groups including the ACLU, Electronic Frontier Foundation, Georgetown Law Center on Privacy and Technology, and the Innocence Project.\n- The author decided he will pick individual items from the shelf and not grab more than one item at a time when shopping.\n- Customers who are charged for food they did not purchase can contest the charge on Amazon's website.\n- The author learned that Amazon would not permit him to pay for the items he left the store with.\n- Amazon has implemented mitigations such as cart labeling.\n- An Amazon employee informed the author that he should receive his receipt within an hour after exiting the store.\n- iRobot terminated its relationship with the service provider who leaked the images.\n- iRobot is actively investigating the matter.\n- iRobot is taking measures to help prevent a similar leak by any service provider in the future.\n- iRobot notifies the company's chief privacy officer if sensitive information is detected.\n- iRobot deletes the entire video log, including the image, from its servers when an image is discovered showing a user in a compromising position.\n- Dreame began changing its privacy policies related to how it collects personal information in the days following MIT Technology Review's initial outreach.\n- Dreame pushed out multiple firmware updates in the days following MIT Technology Review's initial outreach.\n- Sensity conducted an investigation into the deepfake ecosystem on Telegram.\n- Sensity published a report detailing its findings about the deepfake ecosystem.\n- Sensity contacted Telegram to ask why they permit this content on their app.\n- The Verge contacted Telegram to ask why they permit this content on their app.\n- Sensity contacted the relevant law enforcement authorities.\n- The Verge confirmed that many of the channels investigated by Sensity were still active.\n- The creator of DeepNude took down its website hours after the software received mainstream press coverage.\n- Olivia filed a detailed complaint with the TSA days after the incident.\n- Six weeks after she filed her complaint, the TSA's Office for Civil Rights and Civil Liberties, Ombudsman and Traveler Engagement sent Olivia a letter sharing the conclusions of the agency's investigation that the officers followed Standard Operating Procedures.\n- The TSA's investigation involved a collection and review of eyewitness statements, closed-circuit television footage, and other evidence.\n- Olivia filed a Freedom of Information Act request for the evidence the TSA said it reviewed, and the TSA denied her request.\n- ProPublica filed a Freedom of Information Act request in April seeking information about each complaint in the TSA categories, but the agency has not yet provided any response.\n- ProPublica submitted a FOIA request for documents related to the investigation along with a privacy waiver signed by Olivia, and the agency has yet to provide the requested records citing a backlog.\n- The TSA rolled out a new online transgender awareness training in February that is mandatory for its 43,000 screeners.\n- The TSA stated that it is studying options for better screening technology.\n- L3Harris Technologies said it is working with the TSA to develop scanner technology that moves away from current male/female imagery and will screen passengers without gender-specific images.\n- Rep. Kathleen Rice introduced the Screening With Dignity Act in 2018 proposing funding for TSA training and a feasibility study for retrofitting or replacing millimeter wave scanners.\n- Former TSA administrator Peter Neffenger focused on developing a nationwide training program for officers during his tenure.\n- The TSA declined to provide a copy of the transgender awareness training materials, stating they are sensitive security information.\n- OpenAI updated its user policies in late March to prohibit the use of ChatGPT in high-risk government decision-making, including work related to migration and asylum.\n- The German Embassy to Afghanistan deleted its Pashto tweet after native speakers ridiculed its illegibility.\n- The Refugee Translation Project refuses to use automated translation tools and relies exclusively on human translators.\n- Companies working in the machine-translation space insist that their tools be used only under close human supervision.\n- Tarjimly connects refugees and asylum seekers with human volunteer translators and interpreters.\n- Respond Crisis Translation provides interpretation and translation services for migrants and asylum seekers around the world.\n- Some organizations have banned the use of machine translation for Afghan languages.\n- The driver uploaded video footage of the car's display showing the glitch to Reddit.\n- The driver posted a follow-up video on Twitter revealing that they had been driving behind a truck hauling deactivated traffic lights.\n- A research team from the University of Cambridge examined more than 400 Covid-19 AI models in a review.\n- The University of Cambridge team performed an initial quality screening that excluded all but 62 of the reviewed papers.\n- The Cambridge researchers used the CLAIM methodology checklist to evaluate the studies.\n- The Cambridge researchers published a paper highlighting methodological flaws and urging the use of checklists.\n- STAT conducted an investigation into FDA-cleared AI products to assess data disclosure practices.\n- Stanford researchers published a paper highlighting the lack of prospective studies and demographic performance reporting for high-risk AI products.\n- Multiple papers and editorials called for better evaluation models and urged researchers to be more transparent about their methods.\n- MIT researchers reviewed 511 machine learning studies across fields to assess replicability and data-sharing practices in health care.\n- McDermott recommended using federated learning as a way for institutions to jointly develop models without exchanging their underlying data.\n- Some researchers began using synthetic data modeled on real patients to help preserve privacy while enabling evaluation and development of AI models.\n- Reuters provided New Jersey Transit with its findings from its examination of the decision to leave trains at the Meadows Maintenance Complex.\n- Reuters asked New Jersey Transit a series of specific questions about how the software models factored into the agency's decision and whether officials were aware their models did not match surge predictions from federal agencies.\n- Reuters requested the forecast documents that New Jersey Transit relied upon in deciding to leave the trains at the yard.\n- After the New Jersey General Assembly hearing, Reuters again asked for the specific forecast documents.\n- A New Jersey Transit spokesman said the agency was reviewing the Reuters analysis.\n- New Jersey Transit sent a statement asserting it used the most current weather forecasts, available data, accepted analysis practices by emergency management professionals, and historical experience to inform and guide decisions.\n- New Jersey Transit released documents to Reuters under the New Jersey Open Public Records Act.\n- New Jersey Transit Executive Director James Weinstein testified before New Jersey lawmakers that the decisions on where to keep and move rail cars and locomotives were based on the best weather models and forecasts, historical experience, and other information.\n- National Weather Service meteorologists in two offices publicly agreed that the wrong software settings were used by New Jersey Transit.\n- A National Weather Service official said the agency is prepared to help or train any emergency manager in the use of the modeling software.\n- The Whole Mars Catalog Twitter account publicly defended Tesla Full Self-Driving Beta 11.4.1 in tweets claiming that continuing forward (not yielding) was correct and that prior FSD updates would have stopped.\n- Elon Musk posted approving replies to the Whole Mars Catalog tweet.\n- Steven A. Schwartz filed an affidavit admitting he had used ChatGPT for legal research and that the source had proven unreliable.\n- Steven A. Schwartz submitted a copy of his ChatGPT exchange to the judge.\n- Steven A. Schwartz stated in his affidavit that he greatly regretted relying on ChatGPT and pledged never to use it in the future without absolute verification of authenticity.\n- Peter LoDuca filed an affidavit stating that he did not conduct the contested research and had no reason to doubt the authenticity of the opinions.\n- Avianca\u2019s lawyers wrote to Judge Castel notifying the court that they were unable to locate the cases cited in the brief.\n- Judge P. Kevin Castel ordered Mr. Mata\u2019s attorneys to provide copies of the opinions referred to in their brief.\n- Mr. Mata\u2019s lawyers submitted a compendium of eight opinions listing the courts, judges, docket numbers, and dates.\n- Judge Castel ordered a hearing for June 8 to discuss potential sanctions.\n- The clerk of the 11th Circuit confirmed that the docket number printed on the purported Varghese opinion was connected to a different case.\n- Judge Castel conducted an inquiry and identified the purported Varghese opinion and five other decisions submitted by Mr. Mata\u2019s lawyers as bogus.\n- NEDA took the chatbot Tessa offline.\n- NEDA leaders said they are investigating what happened.\n- NEDA is closing the telephone and text helpline.\n- Cass determined that about 25 of the 25,000 messages from the holiday weekend contained unhealthy messages such as instructions to reduce calories.\n- The World Bank said it plans to release additional information about the Takaful program in July 2023.\n- The World Bank reiterated its commitment to advancing implementation of universal social protection and ensuring access to social protection for all persons.\n- Twitter added a Community Note to the video stating that the three still shots showing Trump embracing Fauci are AI-generated images.\n- Sen. J.D. Vance publicly rebuked the DeSantis campaign on Twitter.\n- The DeSantis campaign pointed to a fake image Trump shared of DeSantis riding a rhinoceros to deflect criticism.\n- The DeSantis campaign dismissed concerns about its deception and did not apologize.\n- The DeSantis campaign posted another response video featuring obviously fake footage of an airplane flapping its wings and stated that part of the video is not real.\n- A hiring manager at Waffle House called the applicant almost immediately after they applied to schedule an in-person interview.\n- The Wendy's hiring manager jotted down the applicant's phone number and said he would call if a shift opened up.\n- A Hardee's worker told the applicant to come back on Wednesday morning at 10 a.m.\n- The FBI published an alert warning of the increasing use of artificial intelligence to generate fake videos for use in sextortion schemes.\n- The FBI urged people to take precautions to prevent their images from being used in deepfakes.\n- The FBI advised victims of sextortion to retain all available evidence, including screenshots, texts, tape recordings, emails that document usernames, email addresses, websites or names of platforms used for communication, and IP addresses.\n- The FBI instructed victims to report sextortion to the Internet Crime Complaint Center at www.ic3.gov.\n- The FBI instructed victims to report sextortion to their local FBI Field Office via www.fbi.gov/contact-us/field-offices or by calling 1-800-CALL-FBI (225-5324).\n- The FBI instructed victims to report sextortion to the National Center for Missing and Exploited Children by calling 1-800-THE LOST or visiting www.cybertipline.org.\n- Google publicly acknowledged that the featured AI-generated image may not have been the most ideal choice in its search results.\n- Google said it seeks to develop algorithmic solutions to help address potential issues across a wide range of queries.\n- Google stated that it builds tools like reverse image search to give people context so they can evaluate information and assess what content they can trust.\n- Google pointed out that the featured image included a source label.\n- Google replaced the AI-generated image of Edward Hopper in its search results with a portrait photo of Hopper.\n- Google fixed the issue that caused an AI-generated Edward Hopper-style image to appear as the top search result.\n- Google is rolling out new tools to help people quickly and easily assess the context and credibility of images.\n- Google is rolling out its About this image tool.\n- Google is rolling out markup-based image labels for AI-generated images.\n- Police used the facial recognition program Clearview AI to identify Oriana Albornoz.\n- A month later, police arrested and charged Oriana Albornoz with battery on a police officer.\n- The Miami Police Department provided a video that shows her throwing something at officers to NBC 6.\n- The department did not provide the officer\u2019s body camera video to NBC 6.\n- Miami Police made several arrests of violent protesters identified using facial recognition technology.\n- The department's policy requires keeping a log documenting all facial recognition searches.\n- The department's policy requires conducting monthly audits of facial recognition use.\n- Clearview AI's CEO stated the company is committed to responsible use and that the technology is used only for after-the-crime investigations and not as a surveillance tool.\n- The mayor's office said it will reassess the standards for police use of facial recognition technology.\n- The NYPD confirmed to Gothamist that it used facial recognition during the investigation.\n- Troopers responded to the two-vehicle crash on the Pennsylvania Turnpike near mile marker 48.\n- The 18-year-old Tesla driver was charged with careless driving.\n- Moksha developed tools for publishers to easily respond to and block authors who fail to follow publisher guidelines regarding AI.\n- Clarkesworld temporarily stopped accepting online submissions earlier this year because it was overwhelmed by hundreds of AI-generated stories.\n- Clarkesworld rejects all AI-written submissions.\n- Google said it works to protect its search results from spam and manipulation.\n- Google stated that using AI-generated content to manipulate search-result rankings is a violation of its spam policies.\n- NewsGuard identified 49 fake news websites using AI-generated content in early May and tracked the total to 277 by the end of June.\n- Researchers at the \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne hired freelance writers to summarize New England Journal of Medicine abstracts and found that more than one-third of the summaries used AI-generated content.\n- A police vehicle in another lane was moved in order for the ambulance to leave the scene.\n- Cruise shared footage of the incident with The New York Times.\n- A police officer spoke to one of Cruise's employees through remote assistance in the vehicle.\n- Cruise navigated the vehicle away from the scene after the ambulance left.\n- The San Francisco Fire Department confirmed and reported the incident.\n- The California Department of Motor Vehicles asked Cruise to halve the number of vehicles it was operating in the city while it investigated the incidents.\n- San Francisco city officials have protested the expansion of driverless taxi services.\n- City officials plan to file a motion for a new hearing on the service expansion.\n- David Chiu, the city attorney, asked the California Public Utilities Commission to halt the expansion plan.\n- Gannett paused its experiment with LedeAI in all of its local markets that had been using the service.\n- Gannett updated the Columbus Dispatch page that contained placeholder team mascots.\n- Gannett updated several Dispatch sports stories written by LedeAI to correct errors in coding, programming, or style.\n- Gannett appended those updated stories with the note: \"This AI-generated story has been updated to correct errors in coding, programming or style.\"\n- LedeAI immediately launched an around-the-clock effort to correct the problems in its reports.\n- LedeAI made appropriate changes to address the errors, unwanted repetition, and awkward phrasing in its generated articles.\n- LedeAI's CEO publicly expressed regret that articles produced for Gannett newspapers included errors, unwanted repetition, and/or awkward phrasing.\n- Gannett stated it is continually evaluating vendors as it refines processes to ensure all news and information meets journalistic standards.\n- Retool revoked the hacker's access to its systems.\n- Retool publicly disclosed the incident to warn other companies and advise them on protecting themselves from similar attacks.\n- Retool urged Google to change its Authenticator app to make it easier for companies to disable the cloud\u2011syncing function for their employees.\n- The student contacted Turnitin's support multiple times seeking help.\n- The student raised the issue with their professor.\n- The student proceeded to contact the department head about the accusation.\n- The student attached the Turnitin AI report to their email.\n- The student contacted the recipient of the email to discuss the situation and seek someone to listen.\n- The student will submit an appeal if the zero on the assignment affects their final grade.\n- If the appeal does not work, the student will take the issue to local news networks.\n- Amazon removed the vast majority of the AI-generated books from the Kindle Unlimited Teen & Young Adult Contemporary Romance bestseller list.\n- An Amazon spokesperson said the company promptly investigates any book when a concern is raised.\n- Report this kind of content to the United States Department of Justice using the provided web link (https://lnkd.in/e74ngQsw).\n- Report this kind of content to the United States Department of Justice by calling 1-800-843-5678.\n- Bankrate deleted the AI-generated article that contained factual errors.\n- Bankrate issued a public statement regarding the article's errors.\n- In its statement, Bankrate blamed the errors on an out-of-date internal database that was used to populate the article.\n- Bankrate said it will update the removed article with the most recent data.\n- Bankrate said it will ensure that all data studies include the date range of when the data was gathered going forward.\n- Bankrate and CNET paused the publication of AI-generated content indefinitely following the earlier dustup.\n- The researchers asked Facebook to explain the results.\n- They submitted complaints to the D\u00e9fenseur des droits, CNIL, the Dutch Data Protection Authority, and The Netherlands Institute for Human Rights.\n- They asked regulators to investigate their suspicion that the platform's system for advertising jobs was discriminating on the basis of sex.\n- They joined forces with women's rights organisations in the Netherlands and France.\n- They asked the Dutch Institute of Human Rights and the French D\u00e9fenseur des droits to investigate Meta's compliance with equality legislation and to intervene if the company is found to be in violation.\n- They requested that the Data Protection Authorities in both countries review Meta's compliance with rules requiring that the company process data transparently, legally, and fairly, in accordance with fundamental rights.\n- They submitted job ads in India, Ireland, South Africa, and the United Kingdom as part of their investigation.\n- The U.S. Department of Justice sued Meta over allegations that its ad delivery algorithm discriminated in housing adverts.\n- Meta settled the U.S. lawsuit under an agreement to develop a new system to address disparities caused by its algorithms in respect to housing ads, with that system to be subject to court oversight.\n- Meta applied targeting restrictions to advertisers when setting up campaigns for employment, housing, and credit ads.\n- Meta offers transparency about employment, housing, and credit ads in its Ad Library.\n- Meta does not allow advertisers to target employment, housing, and credit ads based on gender.\n- Meta continues to work with stakeholders and experts across academia, human rights groups, and other disciplines on studying and addressing algorithmic fairness.\n- MIT Technology Review flagged the ads on Medical Outline and other sites to Google.\n- Google removed ads that were being served on many of the sites due to pervasive policy violations.\n- Adalytics confirmed to MIT Technology Review that ads on Medical Outline appeared to be placed via Google as of June 24.\n- MIT Technology Review reached out to Medical Outline, Citigroup, Subaru, and GNC for comment.\n- Plaintiffs Amy Newton, Amanda Curry, Manuel Clayton, Misty McGraw, and Nicholas Clayton filed a class action lawsuit in the Madison County Circuit Court against Pimeyes Sp. Z O.O., Transaction Cloud, Inc., Face Recognition Solutions, LTD., Carribex LTD., EMEA Robotics, LTD., Public Mirror SP. Z O.O., Lukasz Kowalczyk, Denis Tatina, Giorgi Gobronidze, and Does 1-25.\n- The plaintiffs are represented in this case by the attorneys of Peiffer, Wolf, Carr, Kane, Conway & Wise, LLP in St. Louis.\n- The plaintiffs are demanding a jury trial to seek damages for themselves and everyone in the class action lawsuit.\n- The plaintiffs are seeking court costs.\n- The plaintiffs are seeking attorney fees.\n- The plaintiffs are seeking any other relief the court deems proper.\n- The plaintiffs are requesting the court to issue an order requiring the defendant to comply with the Illinois Biometric Information Privacy Act (BIPA).\n- The plaintiffs are requesting the court to issue an order requiring the defendant to cease the collection of biometric data without informed written consent.\n- The department\u2019s Global Engagement Center publicly disclosed the influence campaign to try to blunt its effect in Central and South America.\n- The Global Engagement Center adopted a new tactic of identifying and attempting to pre-empt the campaign while it was still nascent.\n- The State Department released a report about the activities in Brazil of the international organization New Resistance.\n- European Union authorities imposed punitive economic sanctions on the Social Design Agency, Structura National Technologies, and their executives for involvement in disinformation around the war in Ukraine.\n- James P. Rubin, coordinator of the Global Engagement Center, gave an interview in which he described the Russian effort in broad outlines to expose Russia's hidden hand.\n- The federal government received the Corner report in May 2020.\n- The Corner report was released under freedom of information with minimal redactions.\n- The federal government says it is considering the Corner report findings.\n- The New South Wales Department of Communities and Justice said it is currently considering the Corner report in collaboration with other stakeholders.\n- The federal budget allocated $130.1 million over two years to the high-risk terrorist offenders scheme.\n- The Corner report recommended that another evaluation of the instruments is conducted.\n- The Corner report recommended that the authors of both instruments enact far more thorough evaluations of the wider theoretical and empirical literature to develop risk factors that accurately reflect behavioural trajectories towards radicalisation and terrorist violence.\n- The Corner report recommended that the risk specification of each instrument should be refined.\n- NewsGuard sent emails to the 29 sites in the analysis that listed contact information.\n- NewsGuard exchanged a series of emails with the self-described owner of Famadillo.com.\n- NewsGuard inputted articles into the AI text classifier GPTZero to verify whether the sites were mostly or entirely generated by AI.\n- NewsGuard conducted keyword searches on Google, Bing, DuckDuckGo, and a media monitoring platform to identify AI-generated websites.\n- NewsGuard performed reverse image searches on author profile photos to check their authenticity.\n- NewsGuard updated the report on May 1, 2023 to note that OpenAI and Facebook did not respond to NewsGuard's inquiries.\n- NewsGuard updated the report on May 5, 2023 to include a comment from ScoopEarth.com.\n- NewsGuard identified hundreds of additional unreliable, AI-generated websites and established an AI Tracking Center to provide the latest totals and coverage.\n- NewsGuard analysts are rating the identified sites as they gain engagement.\n- NewsGuard is making those ratings available to news consumers through the NewsGuard browser extension.\n- NewsGuard is making those ratings available to brands, advertising agencies, and ad tech companies through licensing agreements that allow programmatic advertising to be excluded from low-rated sites.\n- Jefferson Parish Sheriff's Office detectives tacitly admitted the error in identifying Randal Reid.\n- Jefferson Parish Sheriff's Office rescinded the July arrest warrant for Randal Reid.\n- DeKalb County jail released Randal Reid on December 1.\n- The New Orleans City Council rolled back a two-year ban on police use of facial recognition.\n- Under the new New Orleans city rules, facial recognition is limited to generating investigative leads.\n- Under the new New Orleans city rules, officers must obtain high-level approval before lodging a facial recognition request through the Louisiana State Analytic and Fusion Exchange in Baton Rouge.\n- Under the new New Orleans city rules, all possible facial recognition matches must undergo peer review by other facial recognition investigators.\n- Reality Defender analyzed the audio and concluded it was 75% likely manipulated.\n- Reality Defender reported that its detection system accounted for added background noise intended to evade detection when analyzing the file.\n- The British government analyzed the audio file and confirmed it was fake.\n- Conservative MP Simon Clarke warned on social media that the audio was a deepfake and advised people to ignore it.\n- Security minister Tom Tugendhat warned social media users the recording was fake and urged them not to forward it to avoid amplifying it.\n- The tweet that had previously endorsed smear tactics by the account that posted the audio was deleted.\n- Google\u2019s YouTube removed Russian state television from the platform.\n- Meta bolstered its search for disinformation and de-emphasized news on its platforms.\n- U.S. intelligence agencies issued assessments in 2017 and 2021 concluding that Russia had tried to influence U.S. elections.\n- American intelligence agencies warned that several countries were seeking to influence American politics.\n- A recent declassified analysis identified Russia\u2019s likely use of influence-laundering efforts through allies and nominally independent organizations.\n- In 2020, intelligence agencies outlined an Iranian scheme to influence voting in Florida.\n- Over 300 seniors filed administrative appeals after their home care was cut by the new algorithmic system.\n- Kevin De Liban began fighting the care cuts in 2016.\n- Kevin De Liban began unraveling the computer program behind the care cuts.\n- De Liban's legal team revealed flaws in the algorithm in court.\n- In 2018, a court threw out Arkansas' use of the algorithmic system.\n- A state supreme court ruled that the algorithm was causing participants irreparable harm.\n- Protective services were called in for some patients in Pennsylvania to ensure they were not facing neglect.\n- Missouri attempted to gather public input to develop a new system.\n- Missouri decided to grandfather in existing home care clients for the next two years.\n- In 2016, a court declared the algorithm that cut Seiler's care unconstitutional.\n- Seiler and other disability activists engaged in a court-supervised process to replace the algorithm.\n- Seiler's home care budget was returned to its original level.\n- Seiler's home care budget was frozen at that original level.\n- Steven Larouche pleaded guilty to creating at least seven videos using deepfake technology that depicted child sexual exploitation.\n- Steven Larouche pleaded guilty to possessing more than 545,000 computer files containing images or videos of child sexual abuse.\n- A provincial court judge sentenced Larouche to more than three years in prison for creating synthetic videos of child pornography.\n- The judge sentenced Larouche to an additional four and a half years in prison for possessing hundreds of thousands of computer files of child pornography.\n- In total, Judge Benoit Gagnon sentenced Larouche to eight years in prison.\n- With credit for time served, Larouche will be required to serve another five years and 11 months.\n- Police found on Larouche's computer photos of a victim from her social media accounts and personal information about the child, including her real name, town, and the name of her school.\n- The article provided links to the Government of Canada website and the Ending Violence Association of Canada database for crisis lines and local support services for anyone who has been sexually assaulted.\n- Google said it works on improvements for a broad range of queries when issues arise that reflect inaccuracies on the web.\n- Google manually intervenes to suppress featured snippets that violate its policies, such as hate speech.\n- When a snippet is untrue but does not violate policy, Google focuses on training its algorithm to address the underlying problem.\n- Google plans to fight AI-generated spam as aggressively as it fights regular spam.\n- Google restricts its generative-AI tool so users cannot trigger it in certain subject areas that are potentially loaded with misinformation.\n- Google pointed to an image-checker tool update that delivers more context about search results.\n- Google said it uses techniques similar to retrieval-augmented generation to improve its output.\n- Google keeps about 99 percent of spam out of search results.\n- Police in Spain launched an investigation into the incident.\n- Police have identified some of the young people who could be involved in producing the images.\n- A police investigation is ongoing.\n- Miriam Al Adib published a video on her verified Instagram account to raise awareness about the situation.\n- Miriam Al Adib called on those responsible to cooperate in fixing the issue.\n- Miriam Al Adib wrote in the caption that using other people's photos in this way is a very serious crime.\n- Mayor Jos\u00e9 Mar\u00eda Ram\u00edrez publicly described the incident as another case of gender-based violence.\n- Mar\u00eda Guardiola condemned the incident in a post on X, calling it \"disgusting\" and highlighting that digital violence against women is on the rise.\n- The poll was taken down.\n- Microsoft deactivated Microsoft-generated polls for all news articles.\n- Microsoft is investigating the cause of the inappropriate content.\n- Microsoft is taking steps to help prevent this kind of error from reoccurring in the future.\n- Anna Bateson, chief executive of the Guardian Media Group, outlined her concerns about the AI-generated poll in a letter to Microsoft's president Brad Smith.\n- Bateson asked Brad Smith to assure that Microsoft will not apply experimental AI technology on or alongside Guardian journalism without the news publisher's approval.\n- Bateson asked Brad Smith to assure that Microsoft will always make it clear to users when AI tools are used to create additional units and features next to trusted news brands like the Guardian.\n- Bateson said there was a strong case for Microsoft to add a note to the article taking responsibility for the poll.\n- Adobe Stock announced it would crack down on AI-generated images that appear to depict real, newsworthy events.\n- Adobe Stock rolled out tougher policies on AI-generated content.\n- Adobe Stock's tougher policies include a prohibition on AI-generated images whose titles imply they depict newsworthy events.\n- Adobe Stock said it intends to take action on mislabeled images.\n- Adobe Stock said it plans to attach new, clearer labels to AI-generated content.\n- Adobe removed the photorealistic Gaza explosion image from Adobe Stock.\n- Getty Images banned AI-generated images from its library.\n- Getty Images sued the AI firm Stable Diffusion alleging its image generators infringe Getty's copyrights.\n- Getty Images partnered with Nvidia to build an AI image generator trained only on its own library of creative images that excludes photojournalism and depictions of current events.\n- Getty Images is advocating that AI toolmakers build indelible markers (watermarks) into AI-generated images.\n- TikTok requires users to label AI-generated images of realistic scenes under its policies.\n- Meta prohibits certain types of AI-generated 'deepfake' videos under its policies.\n- The academics offered an unreserved apology to the big four consultancy firms.\n- The academics admitted they used artificial intelligence to make false allegations in their parliamentary inquiry submission.\n- Emeritus professor James Guthrie sent a letter to the Senate claiming responsibility for the error and apologising on behalf of the authorship team.\n- The sections of the submission that contained false information generated by artificial intelligence will be removed.\n- A new document is expected to be uploaded to the Senate inquiry website.\n- KPMG has written to the academics' employers regarding the false allegations.\n- KPMG will seek to publicly correct the record to protect the reputation of their staff.\n- Crabill admitted his mistake in a court document.\n- Crabill messaged a Baker Law Firm legal aide that the case citations from ChatGPT were 'garbage' and could not be found in LexisNexis.\n- The judge denied the motion because the citations were false.\n- The judge threatened to file a complaint against Crabill.\n- Sports Illustrated removed the AI-generated author profiles and their associated articles from its website after being contacted.\n- The Arena Group removed the content while its internal investigation into the matter continues.\n- The Arena Group ended its partnership with the third-party content provider AdVon Commerce.\n- The Arena Group said its internal investigation/review of the partner and the content is ongoing.\n- The articles eventually gained a disclaimer stating the content was 'created by a 3rd party' and that the Sports Illustrated editorial staff were not involved in the creation of this content.\n- The publications periodically deleted AI-generated personas and replaced them with new bylines.\n- Each time an author was switched out, the posts they supposedly penned were reattributed to the new persona without an editor's note explaining the change in byline.\n- CNET issued corrections to more than half of its AI-generated articles.\n- Men's Journal issued a massive correction to an AI-generated health article that was riddled with errors.\n- TheStreet replaced certain AI-generated bylines with new bylines whose profile pictures were not for sale on the AI headshot marketplace.\n- A fellow Tesla employee rescued the bloodied engineer from the robot's grasp.\n- Another worker hit an emergency 'stop' button to end the robot attack.\n- Tesla recorded the engineer's injury in its 2021 Annual Compliance Report for Giga Texas and submitted that report to Travis County and federal regulators.\n- Tesla recorded the injury on its OSHA Form 300 report to the US Occupational Safety and Health Administration.\n- Workers Defense Project filed a complaint with the US Occupational Safety and Health Administration alleging Tesla's contractors and subcontractors provided some hires with false safety certificates.\n- Michael Cohen filed a court document admitting he had unknowingly provided AI-generated bogus case citations.\n- U.S. District Judge Jesse Furman asked for a thorough explanation of how the cases came to be included in the motion and what role, if any, Cohen played.\n- E. Danya Perry identified that the citations in the motion were bogus.\n- E. Danya Perry provided real case citations to support Cohen's motion to terminate his probation.\n- The court filing was unsealed.\n- Researchers reported the image URLs to the U.S. National Center for Missing and Exploited Children (NCMEC).\n- Researchers reported the image URLs to the Canadian Centre for Child Protection (C3P).\n- Removal of the identified source material is currently in progress.\n- Researchers used hashing tools such as PhotoDNA to match image fingerprints to databases maintained by nonprofits during the investigation.\n- Researchers reported matched images to NCMEC and obtained confirmations from C3P where possible.\n- Meta has taken legal action against some perpetrators of these scam ads.\n- TikTok requires creators to disclose whether media is synthetic or manipulated.\n- TikTok requires advertisers to obtain consent for any synthetic media which contains a public figure.\n- NBC released a recording of the robocall.\n- OpenAI banned the maker of a bot that mimicked Dean Phillips and was commissioned by a super PAC.\n- OpenAI removed a developer account that it said had knowingly violated its API usage policies disallowing political campaigning or impersonating an individual without consent.\n- Murphy filed a lawsuit against Macy's, EssilorLuxottica and three individuals seeking $10 million in damages.\n- Prosecutors released Murphy from custody and dropped all charges after learning of his alibi.\n- Murphy's court-appointed attorney discovered that facial recognition was involved by examining police reports.\n- Macy's declined to comment on the pending litigation.\n- EssilorLuxottica did not respond to requests for comment.\n- A spokesman for the Houston police referred a request for comment to the mayor's office.\n- As part of an FTC settlement over a separate misuse, Rite Aid pledged not to use facial recognition technology for five years.\n- DPD immediately disabled the part of its online chatbot that was responsible for the swearing and criticism.\n- DPD is updating the chatbot's AI element / system as a result of the error.\n- Hong Kong police made six arrests in connection with the deepfake scams.\n- Hong Kong police held a press briefing to provide details about the scams.\n- The affected employee later checked with the corporation's head office, which led to discovery of the fake-CFO scam.\n- The pornographic AI-generated images of Taylor Swift were removed from social media platforms.\n- Scott DeDore regularly shared his ShotSpotter accuracy findings with multiple units across the Chicago Police Department and with ShotSpotter representatives.\n- Scott DeDore worked with ShotSpotter to install additional sensors to try to improve the system's accuracy.\n- DeDore tracked his findings in spreadsheets and prepared PowerPoint presentations that documented ShotSpotter misses and related incident details.\n- DeDore mapped recent ShotSpotter misses prior to a meeting about misses and service enhancement.\n- ShotSpotter increased microphone placement in the tenth (010th) district and made adjustments in December based on geographic mapping of documented misses.\n- ShotSpotter made several site visits to the tenth district and installed additional microphones.\n- Chicago Police Department leadership and ShotSpotter representatives held a meeting titled 'Shotspotter Reported Misses and Service Enhancement' to discuss reported misses.\n- Then-mayor Rahm Emanuel signed a new three-year, $33 million contract extension with ShotSpotter in August 2018.\n- SoundThinking (formerly ShotSpotter) commissioned a report from consulting firm Edgeworth Economics assessing the system's accuracy.\n- In June 2023 the City of Chicago approved a $10 million payment to SoundThinking.\n- Chicago's 2024 budget included roughly $9 million in a line item for Software Maintenance and Licensing to fund continued use of the acoustic gunshot detection technology.\n- More than 80 community groups and over 500 individuals signed an open letter calling on the Johnson administration to end the city's relationship with ShotSpotter and redirect funds to housing, education, and health care.\n- The Colorado State Patrol conducted an investigation into the crash to assess the role of the Tesla driver-assistance software.\n- The Colorado State Patrol closed its investigation without being able to determine whether Full Self-Driving played a role.\n- Tesla reported the crash to the National Highway Traffic Safety Administration.\n- Tesla alerted federal authorities that a driver-assistance feature had been in use at least 30 seconds before impact.\n- In December, Tesla issued a recall for nearly all of its 2 million U.S. cars to add more-frequent driver-attention alerts.\n- Tesla helped cover the cost of von Ohain's widow's move back home to Ohio.\n- OpenAI and Microsoft confirmed that hackers working on behalf of North Korea, China, Russia and Iran were using their AI services in support of malicious cyber activities.\n- South Korea detected North Korean hackers using generative AI to target security officials.\n- A South Korean intelligence official said they are closely monitoring North Korea's related movements and the possibility of North Korea putting generative AI to bad use.\n- South Korea's National Intelligence Service briefed reporters that of the 1.62 million hacking attempts last year, more than 80 percent were traced back to North Korea.\n- Google apologized for inaccuracies in Gemini's historical image depictions.\n- Google temporarily paused Gemini's ability to generate images of people.\n- Google said it is working to address recent issues with Gemini's image generation feature.\n- Google said it is working to improve historical image generation depictions immediately.\n- Google said it will re-release an improved version of the image-generation feature soon.\n- Google said it will notify users via release updates when the image-generation feature for people returns.\n- A judge dismissed the complaint from the girl's parent and guardian.\n- Police arrested the first adult user the day after the assault, resulting in his incarceration.\n- The second offender was later arrested and is currently incarcerated.\n- Snapchat responds within 15 minutes to reports of harassment or sexual content, according to CEO Evan Spiegel.\n- Snapchat coordinated with law enforcement investigations that led to more than 100,000 arrests.\n- Evan Spiegel publicly acknowledged families at the Senate hearing whose children had been harmed on Snapchat.\n- Snap committed to being honest about its shortcomings regarding child safety.\n- Snapchat supports the Kids Online Safety Act (KOSA).\n- The Senate garnered enough votes to pass the Kids Online Safety Act (KOSA).\n- Some tech companies, including Snap, X, and Microsoft, publicly embraced the Kids Online Safety Act.\n- Snapchat has already implemented many of KOSA's core provisions.\n- PTI posted on X from the party's official account that the audio was fake and alleged controlled media were running fake news about PTI boycotting the elections.\n- PTI leader Zulfi Bukhari told Logically Facts that the audio was fabricated and dismissed any notion of a boycott.\n- Independent experts consulted by Logically Facts confirmed with a high degree of certainty that the audio was artificially generated and did not originate from Imran Khan.\n- Audio forensics expert Tanmay Srivastava noted the presence of an unnatural white noise throughout the recording that was likely added in post-production.\n- Tanmay Srivastava observed that the intonation of the voice in the clip was monotone with no natural variation in pitch or tone.\n- Tanmay Srivastava stated that sibilant consonants in the clip sounded mechanical or highly processed rather than natural.\n- Tanmay Srivastava highlighted specific timestamps (including 0:38-0:39, 0:02-0:03, 0:28-0:29, 1:15-1:17, and 1:03-1:05) where the audio appeared heavily edited or had unnatural noises added.\n- Experts from IIT Jodhpur led by Professor Mayank Vatsa used four distinct deep-learning models to evaluate the audio's authenticity.\n- The IIT Jodhpur team shared their high-confidence model findings with Logically Facts.\n- PTI officials actively countered deepfake narratives by clarifying the authenticity of videos and audio clips attributed to them.\n- PTI leader Muhammad Basharat Raja posted on X that a video claiming he would boycott the elections was an AI-generated deepfake.\n- Muhammad Basharat Raja stated that he would be standing in the current election.\n- The Information Secretary of PTI London flagged another digitally altered video of a PTI leader purportedly announcing a boycott.\n- Logically Facts contacted two experts who tested the audio clip against four different detection models.\n- Both experts found with high confidence that the audio is fake.\n- Nicolas M\u00fcller, a machine-learning research scientist at Fraunhofer AISEC, analyzed the Starmer audio using a Fraunhofer deepfake analysis tool which produced a deepfake score of 93.6 percent.\n- Logically Facts contacted the user who originally posted the audio clip.\n- Logically Facts stated the article will be updated if and when they receive a reply from the user who posted the clip.\n- Logically Facts has contacted Keir Starmer.\n- Logically Facts stated the article will be updated if and when they receive a comment from Keir Starmer.\n- BBC disinformation analyst Shayan Sardarizadeh posted on X that the clip was generated by artificial intelligence and appeared to have been created for parody.\n- Logically Facts said it will continue to cover the threat of audio and other generative AI deepfakes.\n- The BBC Panorama programme discovered dozens of AI-generated deepfake images portraying black people supporting Donald Trump.\n- Panorama investigated the image and identified distorted hands as a telltale sign that the picture was digitally created.\n- Panorama traced the image's origin to a satirical social media account that uses AI technology to generate images of Trump.\n- Social media users pointed out the distorted hands and publicly denounced the image as a hoax.\n- The incident was reported to police on December 6, 2023.\n- The two boys were arrested on December 22.\n- The boys were charged with third-degree felonies under a 2022 Florida law that makes it a felony to share altered sexual depictions without consent.\n- The two boys were suspended from Pinecrest Cove Academy in Miami for 10 days.\n- A school administrator obtained copies of the altered images.\n- The school administrator interviewed the victims depicted in the altered images.\n- After their arrest, the two boys were transported to the Juvenile Service Department.\n- Several parents publicly urged the school to expel the boys.\n- Police reports were filed in other high-profile incidents at Issaquah High School, Westfield High School, and Beverly Vista Middle School.\n- At Issaquah High School, police opted not to press charges.\n- A group of US senators introduced a bill to combat the problem of nonconsensual fake nude images.\n- Delphia and Global Predictions agreed to settle the SEC's charges.\n- Delphia and Global Predictions agreed to pay $400,000 in total civil penalties.\n- Delphia agreed to pay a civil penalty of $225,000.\n- Global Predictions agreed to pay a civil penalty of $175,000.\n- Delphia and Global Predictions consented to the entry of orders finding that they violated the Advisers Act.\n- The SEC ordered Delphia and Global Predictions to be censured.\n- The SEC ordered Delphia and Global Predictions to cease and desist from violating the charged provisions.\n- The SEC's Office of Investor Education and Advocacy issued an Investor Alert about artificial intelligence and investment fraud.\n- Britain warned President Vladimir Putin not to use the Moscow terror attack as an 'excuse' to intensify Russia's war on Ukraine.\n- President Vladimir Putin announced the arrest of the perpetrators in a five-minute video.\n- US officials publicly expressed condolences and strongly condemned the attack.\n- US officials confirmed Islamic State's claim of responsibility for the massacre.\n- US officials privately voiced concern about unsubstantiated claims of Ukrainian involvement.\n- Polish Prime Minister Donald Tusk said he hoped the tragedy would not become a pretext for anyone to escalate violence and aggression.\n- Ukraine's foreign ministry said it feared the accusations aimed to whip up anti-Ukrainian hysteria in Russian society and create conditions for strengthening mobilisation of Russian citizens to participate in criminal aggression against the state.\n- OpenAI conducted an investigation into the incident and concluded the account was taken over via unauthorized logins from Sri Lanka.\n- The affected user, Chase Whiteside, changed his ChatGPT account password after discovering the unauthorized conversations.\n- Israeli forces returned Mr. Abu Toha to Gaza after two days of detention and interrogation.\n- Israeli soldiers told Mr. Abu Toha that his interrogation had been a \"mistake.\"\n- Journalists at The New Yorker and other publications led a campaign that he credited with securing his release.\n- The Israeli military issued a statement saying Mr. Abu Toha was taken for questioning because of \"intelligence indicating a number of interactions between several civilians and terror organizations inside the Gaza Strip.\"\n- An Israeli army spokesman publicly declined to comment on operational capabilities while stating that the military carries out necessary security and intelligence operations and makes significant efforts to minimize harm to the uninvolved population.\n- Since 31 January, the Online Safety Act made sharing non-consensual deepfake imagery illegal in the UK.\n- Ofcom is conducting a consultation on how the Online Safety Act will be enforced and applied.\n- Under the Online Safety Act, firms will be required to assess the risk of deepfake content circulating on their services, take steps to stop it appearing, and act quickly to remove it when they become aware.\n- Ofcom is encouraging companies to implement these measures and protect their users now, even though the rules are not yet in force.\n- Under its policies, Google allows people to have pages that feature deepfake content and include their likeness removed from search.\n- Google is actively developing additional safeguards on Google Search.\n- Google is developing tools to help people protect themselves at scale.\n- Google is developing ranking improvements to address deepfake content broadly in search.\n- Meta removed the ads promoting the deepfake app from its services.\n- Meta removed the accounts behind those ads.\n- Microsoft published a cyber-threat report detailing the campaigns and use of generative AI.\n- Microsoft detected a surge of more-sophisticated AI tools used in the January presidential election in Taiwan, including identifying an AI-created fake audio clip.\n- Microsoft tracked accounts on X that began posting about topics including American drug use, immigration policies, and racial tensions.\n- Microsoft did not disclose the identity of the accounts it tracked in the alleged disinformation campaign.\n- Meta Platforms took down thousands of accounts last year linked to Spamouflage.\n- The Institute for Strategic Dialogue published a report identifying a small number of accounts on X it said were linked to China and impersonating supporters of Donald Trump.\n- The U.S. State Department publicly accused the Chinese government of spending billions of dollars annually on a global campaign of disinformation.\n- Beijing issued repeated public statements saying it opposes the production and spread of false information and that U.S. social media is inundated with disinformation about China.\n- Western cyber-threat researchers tracked the threat actor Storm-1376 since at least 2019.\n- The supermarket said it would apologise to the customer.\n- The store contacted the customer to arrange a meeting about the incident.\n- A Foodstuffs spokesperson said they would contact the customer directly to apologise for what had happened.\n- Foodstuffs said all appropriate staff would receive further training.\n- Foodstuffs said the incident would be reported to the Office of the Privacy Commissioner.\n- Privacy Commissioner Michael Webster launched an inquiry into Foodstuffs' facial recognition trial to monitor compliance with the Privacy Act and the trial's effectiveness.\n</mitigation_statements>"}]}}
{"custom_id": "batch_600", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- The Presidency of Moldova issued a press release denying the statements attributed to President Maia Sandu in the deepfake video and stating the image and sound were falsified.\n- The Presidency denied the authenticity of statements attributed to Sandu in her alleged discussion with Denis Shmygal.\n- Chisinau authorities repeatedly asked Facebook to take a stand against paid posts with links to the fugitive Ilan Shor.\n- Chisinau authorities repeatedly asked Instagram to take a stand against paid posts with links to the fugitive Ilan Shor.\n- Chisinau authorities repeatedly asked YouTube to take a stand against paid posts with links to the fugitive Ilan Shor.\n- Chisinau authorities repeatedly asked Telegram to take a stand against paid posts with links to the fugitive Ilan Shor.\n- Prime Minister Dorin Recean and six other European counterparts signed an open letter to major IT companies requesting action against disinformation and manipulation on social networks.\n- Prabowo Subianto\u2019s campaign team publicly admitted to using AI software to create a cuddly animated version of their candidate on TikTok following public criticism.\n- Gerindra spokesperson Budisatrio Djiwandono issued a statement after watchdogs called out an advertisement using AI-generated children, defending the ad by saying the technology is so advanced people could mistake the children for real characters.\n- Indonesia\u2019s Communications Ministry issued advisories warning tech companies and voters to be cautious of deepfakes following several viral AI videos.\n- Anies Baswedan publicly cautioned against the use of AI in the election after he became the victim of an audio deepfake.\n- Pakistan's foreign office rejected the global claims.\n- Raja Bashara uploaded a clarification video on social media stating that the circulated video was AI-generated and reaffirming his candidacy.\n- The Layyah Deputy Commissioner released a video on social media denying the allegations and refuting the misinformation.\n- Journalist Fakhar Durrani posted an explanation video on X reporting that the bureaucrat denied the allegations.\n- The PTI official X handle tweeted and clarified that Imran Khan had not recorded the boycott audio and that the message was propaganda.\n- Rana Atif posted a clarification video on Facebook and TikTok denying the impersonation and vowing to remain loyal to his party.\n- Intelligence personnel manually checked the accuracy of a random sample of several hundred Lavender-selected targets before authorizing the sweeping use of the system.\n- The military introduced restrictions on collateral damage, reducing the permitted civilian casualties per junior target from about 15 to five after the first week of the operation.\n- The Israeli army stopped mass-generating junior human targets for bombing in civilian homes, a change the article attributes partly to American pressure.\n- The IDF Spokesperson issued a public statement denying that artificial intelligence was used to incriminate targets, asserting that AI tools are only auxiliary and that an independent examination by an intelligence analyst is required to verify targets.\n- A week-long ceasefire was agreed on Nov. 24.\n- The National Election Commission detected 129 pieces of AI-generated media content from Jan. 29 to the end of last week.\n- Election authorities have heightened vigilance ahead of Korea's parliamentary elections.\n- The National Election Commission initiated a crackdown on deepfakes.\n- The newly revised election law took effect on Jan. 29 prohibiting the use of deepfakes for electoral campaigning.\n- The National Assembly passed revised legislation in December intended to curb the spread of false information and safeguard the integrity of the electoral process.\n- The law imposes penalties of up to seven years in prison or fines of 10 million won for offenders who use deepfakes in campaigning.\n- The National Election Commission uses a step-by-step verification process to review, investigate, and take action on illegal content rather than relying on a specific company's program.\n- The Presidential Communications Office called for heightened vigilance against online content designed to sow confusion or mislead the public about the West Philippine Sea.\n- The PCO dismissed the video as a 'deepfake.'\n- The PCO posted an advisory on its Facebook page warning Filipinos not to fall for the audio deepfake.\n- The PCO said it was closely coordinating with the Department of Information and Communications Technology to actively address the proliferation and malicious use of video and audio deepfakes and other generative AI content.\n- The PCO said it was closely coordinating with the National Security Council to actively address the proliferation and malicious use of video and audio deepfakes and other generative AI content.\n- The PCO said it was closely coordinating with the National Cybersecurity Inter-Agency Committee to actively address the proliferation and malicious use of video and audio deepfakes and other generative AI content.\n- The PCO said it was closely coordinating with the private sector to actively address the proliferation and malicious use of video and audio deepfakes and other generative AI content.\n- The YouTube account that published the video was later terminated.\n- The PCO asked everyone to be proactive in exposing and fighting misinformation, disinformation, and malinformation.\n- The PCO encouraged the public to work with the agency to foster a more aware, resilient, and engaged citizenry in the digital commons.\n- Shane Jones submitted a letter to the Federal Trade Commission regarding Copilot Designer.\n- Shane Jones submitted a letter to Microsoft's board of directors regarding Copilot Designer.\n- Shane Jones repeatedly urged Microsoft over three months to remove Copilot Designer from public use until better safeguards could be put in place.\n- Shane Jones suggested that Microsoft add disclosures to Copilot Designer.\n- Shane Jones suggested that Microsoft change the Android app rating from \"E for Everyone\" to \"Mature 17+.\"\n- Microsoft's legal team told Jones to delete his LinkedIn post.\n- Shane Jones sent a letter to U.S. senators in late January about public safety risks and alleging Microsoft's efforts to silence him.\n- Microsoft told CNBC it is committed to addressing any and all concerns employees have in accordance with company policies.\n- Microsoft said it appreciates employees' efforts in studying and testing its latest technology to further enhance its safety.\n- Google paused access to the image generation feature on Gemini.\n- Demis Hassabis said the Gemini image generator feature could be back in \"a couple of weeks\".\n- Pershing Square flagged the impersonating ads to Facebook.\n- Facebook removed the impersonating ads after they were reported.\n- A group of nine scam victims sent a letter to Facebook on Feb. 28 detailing 21 times members reported scam ads.\n- Group members reported scam ads to Facebook in January and February.\n- People working for Cathie Wood signed her up for a Meta Verified account in December to try to spur faster removal of fake ads.\n- Bill Ackman signed up for a Meta Verified account earlier this month.\n- ARK issued an alert about the impersonation scams.\n- William Scherer posted a notice on LinkedIn in January warning that any WhatsApp messages appearing to come from him are a scam.\n- Several investors compared notes on Reddit and formed a victims' group of 29 members seeking to recover their losses.\n- Finra issued a warning on Jan. 11 about a significant spike in investor complaints from fraudulent investment groups promoted through social media.\n- Facebook support replied to complaints by saying the ad \"doesn't go against our standards.\"\n- Meta stated that it bans ads that use public figures to try to scam people.\n- Meta stated that it invests heavily in trained enforcement and review teams and uses specialized detection tools to identify fraudulent activity.\n- The New Hampshire Justice Department announced it was investigating a spoofed robocall featuring an AI-generated voice of President Biden.\n- Washington state warned voters to be on the lookout for deepfakes.\n- Lawmakers in states including Oregon and Florida passed bills restricting the use of deepfake technology in campaign communications.\n- Arizona's top elections official used deepfakes of himself in a training exercise to prepare staff for falsehoods to come.\n- Kari Lake's campaign attorneys sent the Arizona Agenda a cease-and-desist letter regarding the deepfake videos.\n- The cease-and-desist letter demanded the immediate removal of the deepfake videos from all platforms where they had been shared or disseminated.\n- The cease-and-desist letter stated that, if the outlet refused to comply, Lake's campaign would pursue all available legal remedies.\n- Stephenson said he was consulting with lawyers about how to respond to the cease-and-desist letter.\n- Stephenson said he was not planning to remove the videos as of Saturday afternoon.\n- Researchers, including Hany Farid, said they are working on software to help journalists and others more easily detect deepfakes.\n- Hany Farid said the suite of tools he uses easily classified the Arizona Agenda video as bogus.\n- It is believed the vulnerability was patched within the fortnight after Maiberg identified the problem.\n- Civitai introduced changes after Maiberg's tests showed the prompts worked on their platform.\n- Leonardo.Ai issued a public statement through its PR firm asserting that it operates a multi-layered automated filtering process combined with manual moderation to prevent misuse.\n- Leonardo.Ai began ramping up its protections following the 404 Media revelations.\n- Leonardo.Ai stated it is adding further logic and mechanisms to better address methods used to sidestep its guardrails.\n- The company said many of these changes are already live.\n- The company said more changes are coming over the next couple of weeks.\n- Startup Daily found prompt instructions and chose not to test them.\n- Washington's Lottery pulled the AI-powered mobile site offline.\n- Washington's Lottery had the developers check all the platform's parameters.\n- Washington's Lottery issued a public statement to the Jason Rantz Show about the incident.\n- Washington's Lottery conducted further internal discussions regarding the incident.\n- The Lincoln Project publicly disclosed and emphasized that the ad used AI-generated footage by making the use of AI a central part of the piece.\n- Experts debunked the short video of Lai Ching-te as a deepfake.\n- Taiwanese officials urged the public to stay vigilant against disinformation.\n- Taiwanese intelligence authorities warned that Beijing had intensified its influence operations.\n- Taiwanese intelligence authorities briefed the media that senior Chinese officials had held a meeting on how to coordinate their influence efforts.\n- Taiwan built up a robust community of dedicated fact-checking groups.\n- The government invested in education about the potential for external actors to manipulate public opinion.\n- Audrey Tang promoted the concept of \"nerd immunity\" to inoculate the public from false claims.\n- Audrey Tang advocated for a new school curriculum to teach children how to identify and combat misleading online information.\n- MyGoPen runs an automated chatbot to debunk false information.\n- Cofacts launched bilingual chatbots to scrutinise information shared within chatrooms.\n- The Taiwan FactCheck Centre exposed multiple fake videos and photos designed to intimidate the Taiwanese public.\n- The government warned that the spread of AI deepfake tools is a dangerous and growing threat to the integrity of elections in India.\n- Campaigners warned that the spread of AI deepfake tools is a dangerous and growing threat to the integrity of elections in India.\n- Communications minister Ashwini Vaishnaw publicly stated in November that deepfakes were a serious threat to democracy and social institutions.\n- AI creator Divyendra Jadoun said he turned down offers that he disagreed with.\n- The European Union requires social media platforms to cut the risk of spreading disinformation or \"election manipulation.\"\n- The European Union will mandate special labeling of AI deepfakes starting next year.\n- The world's biggest tech companies voluntarily signed a pact to prevent AI tools from disrupting elections.\n- The company that owns Instagram and Facebook said it will start labeling deepfakes that appear on its platforms.\n- Major generative AI services have rules to limit political disinformation.\n- Investigators traced robocalls impersonating U.S. President Joe Biden to a political consultant.\n- FBI Director Christopher Wray publicly warned about the growing threat of generative AI enabling foreign adversaries to engage in malign influence.\n- Authorities around the world are scrambling to come up with guardrails to address AI deepfakes.\n- Baltimore County police arrested Dazhon Darien after investigators said he used AI to manufacture the fake audio clip.\n- Baltimore County Public Schools investigated the faked recording.\n- The school district placed principal Eric Eiswert on administrative leave.\n- Mr. Darien is facing charges including disrupting school operations and stalking the principal.\n- During the conversations, ChatGPT displayed bright orange content warnings stating, \"This content may violate our terms of use or usage policies.\"\n- An OpenAI spokesperson publicly acknowledged that the company is aware ChatGPT can generate sexually explicit and rule-violating content.\n- The OpenAI spokesperson noted that the system issues warnings about sensitive topics.\n- A Perplexity spokesperson said the company is committed to constantly improving Perplexity's safety.\n- Noyb filed a complaint with the Austrian data protection authority alleging that ChatGPT violates EU privacy rules.\n- Noyb asked the Austrian authority to investigate OpenAI to check the accuracy of the personal data it processes for its large language models.\n- Noyb asked the Austrian authority to ensure OpenAI complies with the complainant's request to access their personal data.\n- Noyb called for an effective, proportionate, dissuasive administrative fine against OpenAI.\n- The Austrian data protection authority confirmed it received the complaint.\n- The Austrian data protection authority said it will assess whether the complaint needs to be forwarded to another national authority.\n- The European Data Protection Board set up a task force on ChatGPT to coordinate national efforts.\n- Italy's data protection authority temporarily banned ChatGPT from operating in the country over alleged breaches of EU personal data rules.\n- Twitter labeled the video as \"altered audio\".\n- The person who tweeted the video confirmed it was made using artificial intelligence.\n- Newsweek reached out to Senator Warren's office for comment.\n- The original MSNBC video was cited to show that the statements in the doctored clip were false.\n- Recorded Future conducted an investigation into the CopyCop network and published its findings on May 9th exposing the use of AI to translate and edit articles to add partisan bias.\n- A person familiar with the ad confirmed that the voice used in the spot was AI-generated.\n- Trump campaign senior adviser Chris LaCivita issued a statement condemning the ad's use of AI-generated audio and accusing the super PAC of trying to deceive the public.\n- Users on X publicly pointed out to Patrick Ruffini that the images he posted were AI-generated.\n- NBC News reported that YouTube creators were targeting Black celebrities with a mix of AI-generated and manipulated media to create fake content.\n- Senate Majority Leader Chuck Schumer indicated to Black media outlets that America's first-ever bill to regulate the use of AI will focus on safeguarding Black voters from disinformation.\n- Janse's management company got YouTube to quickly remove the ad that used her likeness.\n- YouTube suspended the advertiser account tied to the deepfake of Carrie Williams after questions from The Post.\n- YouTube said it was working on allowing users to request the removal of AI-generated or other synthetic or altered content that simulates an identifiable individual.\n- YouTube said it was investing heavily in its ability to detect and remove deepfake scam ads and the bad actors behind them.\n- YouTube updated its ads policy to allow swifter action to suspend the accounts of perpetrators of deepfake scam ads.\n- Google told 404Media that recent works on Google Books do not show up on Ngram results.\n- Health Action International sent a letter to the World Health Organization requesting that the SARAH chatbot be taken down.\n- The World Health Organization sent an email to POLITICO welcoming feedback about the SARAH tool.\n- The World Health Organization stated that such feedback could be used to improve and strengthen health promotion initiatives and its understanding of the role of AI in these efforts.\n- POLITICO conducted hours of testing of the SARAH chatbot that found it often gave contradictory and inconsistent answers.\n- POLITICO published a review reporting SARAH's inconsistent and at times unhelpful responses.\n- She contacted hundreds of sites to try to get the video and the deepfakes off the internet.\n- She lobbied platforms to stop linking to the malicious websites hosting the deepfakes.\n- She lobbied platforms to stop directing traffic to the malicious websites hosting the deepfakes.\n- She asked Pornhub to take the video down.\n- Pornhub took the video down.\n- She found a lawyer.\n- She started a company called Alecto AI.\n- She created an app that uses facial recognition technology to perform reverse image searches.\n- The app notifies users where their images show up on the internet.\n- The app helps connect users to platforms to try to take non-consensual images down.\n- Nicholas Kristof reached out to Google and Bing to get their side of the story.\n- Google issued a statement committing to build on its existing protections to help people who are affected.\n- Bing issued a statement expressing a similar commitment to help people who are affected.\n- Scarlett Johansson hired a lawyer after the incident.\n- Scarlett Johansson asked OpenAI to stop using the voice it called \"Sky.\"\n- OpenAI suspended its release of the \"Sky\" voice over the weekend.\n- OpenAI published a blog post saying that AI voices should not deliberately mimic a celebrity's distinctive voice and asserting that Sky's voice is not an imitation of Scarlett Johansson.\n- OpenAI paused using Sky's voice in its products.\n- OpenAI apologized to Scarlett Johansson for not communicating better.\n- OpenAI said it could not share the names of its voice professionals, citing privacy reasons.\n- The FBI arrested Steven Anderegg on criminal charges related to the alleged production, distribution, and possession of AI-generated child sexual abuse material.\n- Wisconsin state police charged Anderegg in March with two counts of exposing a child to harmful material and an additional charge of sexual contact with a child under age 13.\n- Anderegg pleaded not guilty to the Wisconsin state charges.\n- Instagram reported Anderegg's account to the National Center for Missing and Exploited Children for distributing the images.\n- Law enforcement recovered evidence from Anderegg's electronic devices, including a laptop containing over 13,000 GenAI images.\n- The Justice Department issued a press release in which Principal Deputy Assistant Attorney General Nicole M. Argentieri stated that the DOJ will hold accountable those who possess, produce, or distribute AI-generated child sexual abuse material.\n- Anderegg was placed in federal custody pending a detention hearing scheduled for May 22.\n- SITE Intelligence Group shared videos and chat messages about the AI-generated News Harvest broadcasts with The Washington Post.\n- SITE Intelligence Group shared a 50-page al-Qaeda guide titled \"Incredible Ways to Use Artificial Intelligence Chat Bots\" with The Washington Post.\n- MEMRI obtained a message from April 23 soliciting media experts proficient in posters, articles, video editing, Adobe Photoshop, Premiere and AI tools.\n- Hisad consulted a sheikh about whether AI-generated animations or faces are haram.\n- Hisad blurred and obscured the face of the AI-generated anchor in more recent News Harvest episodes following the sheikh's guidance.\n- A request for comment was made to Eleven Labs, which did not respond.\n- A request for comment was made to Telegram, which did not respond.\n- A request for comment was made to X, which did not respond.\n- Sara's bag was searched by store staff.\n- Sara was led out of the shop by staff.\n- Sara was told she was banned from all stores using the technology.\n- Facewatch later wrote to Sara.\n- Facewatch acknowledged it had made an error.\n- Police approached Shaun Thompson and told him he was wanted.\n- Shaun Thompson was asked to give fingerprints.\n- Shaun Thompson was held for 20 minutes.\n- Shaun Thompson was released only after handing over a copy of his passport.\n- The Metropolitan Police said they automatically delete biometric images when there is no match.\n- Facewatch later wrote to Sara and acknowledged it had made an error.\n- The Metropolitan Police said the system automatically deletes a biometric image when there is no match.\n- Shaun Thompson was asked to give fingerprints and was held for 20 minutes.\n- Shaun Thompson was released only after handing over a copy of his passport.\n- A Google spokesperson told The Verge that the AI errors being shared were made in 'generally very uncommon queries' and aren't representative of most people's experiences.\n- Nieman Lab's Sarah Scire flagged the problematic AI Overview response.\n- Netizens on X publicly pointed out that the glue-in-pizza claim appears to be sourced from an 11-year-old Reddit comment posted by user 'Fucksmith'.\n- Users on X widely shared screenshots of Google's 'AI Overview' results to draw attention to the inaccuracies.\n- The ad included a small on-frame disclaimer in the top-left corner stating \"built entirely with AI imagery.\"\n- The YouTube video caption beneath the ad stated, \"An AI-generated look into the country's possible future if Joe Biden is re-elected in 2024.\"\n- An RNC spokesperson told Axios that it was the first ad of its kind released by the organization.\n- The FBI immediately logged off the Twitter Spaces session.\n- Meta acknowledged there was a platform bug on February 14th and apologized for the inconvenience.\n- Meta refunded 1-800-D2C for the incident, issuing the refund almost a month after the incident.\n- Meta said it had fixed a few technical issues with its ads platforms.\n- Meta said it was researching a small number of additional reports from advertisers to ensure better results.\n- Williams' marketing firm completely halted its use of Advantage Plus in early April.\n- Williams' marketing firm returned to manually buying Facebook and Instagram ads instead of using Advantage Plus.\n- Node Media stopped using Advantage Plus for a couple of clients due to anomalies.\n- The Associated Press published a fact-check assessing the image as false.\n- The Associated Press said it works with outside companies and organizations to add factual context to misleading content circulating online.\n- Trump's 2024 campaign publicly confirmed the image was a forgery.\n- Steven Cheung, a spokesperson for Trump's campaign, accused Ron DeSantis' campaign of spreading the visual.\n- The DeSantis campaign publicly denied involvement in spreading the image.\n- Hany Farid analyzed the image and stated it had many hallmarks of a fake likely created using generative AI.\n- Social media sleuths noted additional AI-generated tells in the image.\n- Raina Saboo said Optic used its 'AI or Not' image detection tool and concluded the image was made using AI.\n- The Office of Suicide Prevention is working with the VA AI lead and the Chief Technology Officer to develop compliance reviews.\n- The Office of Suicide Prevention is working with the VA AI lead and the Chief Technology Officer to develop monitors.\n- The VA declined to provide data on veterans flagged by the REACH VET algorithm and said it would only share that information in response to a Freedom of Information Act request.\n- F.B.I. agents and local police searched Mr. Dougan's home and seized all of his electronic equipment.\n- The F.B.I. opened an investigation of an impersonation call and, according to Mr. Brill, traced the call to Mr. Dougan's telephone in Russia.\n- YouTube suspended Mr. Dougan's channel after NewsGuard's report last year.\n- NewsGuard spent months tracking Mr. Dougan's activities and released a report documenting his outlets' citations and reach.\n- Recorded Future released a report detailing Mr. Dougan's ties to agencies linked to Russian disinformation and identified 57 domains he had created.\n- Clemson University's Media Forensics Hub published a report last December linking domains and internet protocol addresses used by Mr. Dougan's sites to his personal websites and other ventures.\n- The diplomatic service of the European Union published a report last month assessing the risk of an expanded operation scope of the network.\n- State Department spokesman Matthew Miller denounced the fabricated video in a public statement.\n- At a meeting in Prague, Secretary of State Antony Blinken and NATO counterparts discussed how to blunt Russian disinformation and pledged to respond both individually and collectively as necessary.\n- On Thursday in Prague, Mr. Blinken and Czech Foreign Minister Jan Lipavsky signed a memorandum of understanding to counter \"foreign state information manipulation.\"\n- James P. Rubin, the State Department's special envoy dealing with disinformation and coordinator for the Global Engagement Center, joined the trip.\n- TikTok identified the videos as part of its efforts to counter inauthentic, misleading or false content.\n- A White House spokesperson publicly stated that the claim President Biden made those comments is false.\n- PolitiFact investigated the clip, found no evidence Biden made the comments, and rated the claim False.\n- University of California, Berkeley professor Hany Farid analyzed the audio and stated it was likely generated by artificial intelligence.\n- The Department of Homeland Security sent a cease-and-desist letter to Texas Attorney General Ken Paxton on Jan. 15.\n- Homeland Security's cease-and-desist letter warned it would refer the matter to the Justice Department for appropriate action and consider other options to restore Border Patrol's access to the border if Texas did not stop its border blockade.\n- A New York lawyer was sanctioned for citing ChatGPT-invented fictional cases in a legal brief.\n- Chief Justice Roberts warned lawyers about hallucinations in his 2023 annual report on the judiciary.\n- The bar association of California released guidance on lawyers' duty of supervision over work products created with AI tools.\n- The bar association of New York released guidance on lawyers' duty of supervision over work products created with AI tools.\n- The bar association of Florida released guidance on lawyers' duty of supervision over work products created with AI tools.\n- More than 25 federal judges issued standing orders instructing attorneys to disclose or monitor the use of AI in their courtrooms.\n- Stanford RegLab and HAI researchers conducted and published a preprint study assessing the reliability of leading AI legal research tools.\n- The large law firm Paul Weiss spent nearly a year and a half testing a legal AI product to evaluate its performance.\n- This story was updated on May 30, 2024, to include analysis of a third AI tool, Westlaw's AI-Assisted Research.\n- Authorities detained the suspect A.B. as part of the investigation into the incident.\n- A.B. was released after questioning.\n- M.E.E. was arrested by a court.\n- Bee Cups offers disgruntled buyers a $15 gift card if they send in the imitation cups.\n- Bee Cups posted warnings on Instagram to alert its 115,000 followers about the fake listings.\n- Bee Cups hired a law firm that works with Amazon and other platforms to remove the fake listings.\n- Amazon removes copycat listings and blocks accounts when it identifies knockoff products.\n- Amazon uses artificial intelligence and other technologies to detect infringements.\n- Amazon refunds or replaces items if shoppers are dissatisfied with purchases of knockoffs.\n- Ideam's attorney contacted Amazon to complain about negative reviews for the company's product.\n- Amazon removed the negative reviews in February after being contacted by Ideam's attorney.\n- Jim Carter of Ideam took down his items from Amazon and restarted the listing process.\n- Darn Tough engaged MarqVision, a brand-protection company, to help combat fake ads and websites.\n- Darn Tough staff spent hours tracking down bogus websites and taking them down.\n- Darn Tough and some of its customers used social media to warn would-be buyers about the fake listings.\n- Meta uses technology to prevent fake ads from being posted and to detect and remove them from Facebook and Instagram.\n- The motorist involved in the earlier fatal collision was arrested on suspicion of DUI and driving without a license.\n- Gli avvocati di Roberto Spinelli hanno chiesto di riascoltare l'audio dell'interrogatorio per chiarire un passaggio decisivo.\n- La giudice per le indagini preliminari Paola Faggioni ha riascoltato l'audio dell'interrogatorio il 26 maggio.\n- Sono stati effettuati accertamenti che hanno stabilito che l'errore di trascrizione era dovuto al software speech-to-text e non a un errore umano.\n- Le indagini hanno rinvigorito le discussioni tra avvocati, magistrati e giudici sull'utilizzo della tecnologia e dei software per la trascrizione automatica.\n- The judge quizzed the litigant in person about the case citations they had submitted.\n- The litigant in person admitted they had asked the ChatGPT chatbot to find cases supporting their argument.\n- The judge accepted that the misleading submissions were inadvertent.\n- The judge did not penalise the litigant.\n- Meta issued a sincere public apology for the error.\n- Meta restored the image of orphans that had been deleted by mistake.\n- Meta acknowledged that the notices sent to the Auschwitz Memorial Museum were sent by mistake.\n- Meta stated that the photographs were not actually demoted or moved down the museum's page.\n- The Auschwitz Memorial Museum demanded an immediate and thorough review and a transparent explanation of why the posts were flagged.\n- The National Highway Traffic Safety Administration opened a new investigation into the adequacy of Tesla's December recall of Autopilot-equipped vehicles.\n- The NHTSA closed its earlier probe into Autopilot and opened a new probe focused on the recall remedy.\n- The NHTSA published a report detailing its examination of Tesla's Autopilot.\n- The NHTSA performed preliminary tests on remedied vehicles following the recall.\n- Tesla issued a recall for more than 2 million Model Y, X, S, 3 and Cybertruck vehicles equipped with Autopilot.\n- Tesla deployed the recall through a software update to affected vehicles.\n- Tesla said it installed new safeguards in the updated vehicle software to prevent driver misuse.\n- The U.S. Department of Justice opened an investigation into whether Tesla misled customers and investors about Autopilot.\n- The U.S. Securities and Exchange Commission opened an investigation into whether Tesla misled customers and investors about Autopilot.\n- Tesla reached a settlement with the family of Walter Huang over a fatal 2018 crash involving Autopilot.\n- City & State tested the Meta AI chatbot by querying over a dozen state lawmakers' names with the phrase 'sexual harassment' to investigate fabricated allegations.\n- City & State tested the free version of ChatGPT to see whether it would also fabricate allegations against lawmakers.\n- Meta stated that it shares information within the features themselves to help people understand that AI might return inaccurate or inappropriate outputs.\n- Meta said it has constantly released updates and improvements to its models since launch and is continuing to work on making them better.\n- The recently passed state budget included provisions to penalize the use of deceptive 'deepfake' images and audio for marketing, sex act, or election purposes.\n- The recently passed state budget required that any election material that utilizes AI include a disclaimer.\n- Assembly Member Clyde Vanel said his committee is actively looking into ways to combat harms posed by AI through legislation.\n- Assembly Member Clyde Vanel said his committee is actively looking into ways to combat harms posed by AI through educating the public.\n- Jack Posobiec, in the clip immediately following the deepfake, explicitly stated that the video was AI-generated and fabricated.\n- @TPostMillenial acknowledged in its post that the clip was an AI-generated imagining, writing 'AI imagines what would happen if Biden declares and activates the Selective Service Act...'.\n- Snopes published a fact-check article determining the video is an AI-generated deepfake and rated the claim False and Miscaptioned.\n- Snopes analyzed the video and highlighted telltale signs of a deepfake, noting that Biden stands very still and only his mouth moves.\n- Snopes linked to and recommended a guide on how to spot deepfakes to educate readers.\n- Snopes explained the role of generative adversarial networks (GANs) and how deepfakes are created as part of its corrective coverage.\n- The Markup tested the city's chatbot and reported its inaccuracies.\n- After being alerted to The Markup's testing, Rosalind Black tested the chatbot herself and found additional false information.\n- The city said it will continue to focus on upgrading the chatbot.\n- The city said it will review user questions to improve answers and address \"harmful, illegal, or otherwise inappropriate\" content.\n- The city said it will delete chatbot data within 30 days.\n- A pop-up notice on the chatbot page encourages visitors to report inaccuracies through a feedback form.\n- The chatbot page discloses risks to users.\n- The feedback form asks users to rate their experience from one to five stars.\n- The federal government warned consumers to beware of fake news articles and deepfake videos that endorse online investment trading platform scams.\n- The National Anti-Scam Centre said it had received more than 400 reports of these scams in 2023.\n- The National Anti-Scam Centre reported complaints about fake online trading platforms operating under the names Quantum AI, Immediate Edge, Immediate Connect, Immediate X3, and Quantum Trade Wave.\n- Sonia and her husband looked up the company and realised it was a scam.\n- Sonia refused to provide her credit card details and declined to invest.\n- Sonia told the caller she would not be investing but tried to be friendly and placate him to avoid harassment.\n- Brookdale disputed the allegations in the lawsuits and said it empowers local facility managers to set staffing levels as they see fit.\n- Brookdale sent people to help McNeal conduct new health assessments of her residents.\n- After studying transport times at the Chicago facility, Brookdale agreed to reinstate the staffing level that existed before Service Alignment.\n- Kelly Rubin sent an email to regional managers warning that no facility would be granted more than two additional full-time employees regardless of what the algorithm said.\n- Brookdale intervened at facilities where the algorithm suggested more staff was needed.\n- Managers who scheduled more employees than the algorithm advised were required to propose a plan of correction.\n- Repeat offenders who scheduled more staff risked losing portions of their annual bonus.\n- Brookdale implemented a policy to charge residents additional monthly fees when they required more caregiver time.\n- Caregivers were instructed to report residents who routinely needed more time so managers could reassess their needs and potentially increase fees.\n- Brookdale fired McNeal for scheduling additional workers as 'training' staff without company approval.\n- State investigators cited Brookdale for medical neglect after Louise Walker's death.\n- Police conducted an investigation into the Christmas Day 2020 death in Destin, Fla., and found the man had been left unattended for more than 12 hours.\n- Brookdale provided time-sheet data covering seven North Carolina facilities to a plaintiffs' expert.\n- Brookdale, Sunrise and Atria Senior Living provided responses to questions from a congressional committee inquiry.\n- Brookdale's lawyers denied in court filings that any of the facility's actions caused Walker's death.\n- Ernie Smith posted details of the DMCA notice in a Mastodon thread.\n- 404 Media investigated Commonwealth Legal and published reporting detailing problems with the firm's site and claims.\n- Reality Defender analyzed the attorneys' images and reported that each image showed signs of AI generation, most likely by a GAN model.\n- Reporters checked the firm's domain registration and found the domain was registered on March 1, 2024 and hosted on a Canadian IP.\n- Reporters checked the address listed on the firm's website and found that the physical location did not match the 'fourth floor' indicated on the site.\n- 404 Media examined the attorneys' bios and identified implausible or inconsistent education and practice details.\n- The owner of Tech4Gods spoke to 404 Media and said he had purchased backlinks for his site.\n- The owner of Tech4Gods told 404 Media he did not own the disputed image or any images.\n- The owner of Tech4Gods suggested to 404 Media that a disgruntled former contractor may be attempting to harm his site's ranking by adding spam links.\n- The article was updated to include Ernie Smith's response.\n- Ernie Smith told Ars that he had not heard back from Commonwealth Legal after the five business days had passed.\n- OpenAI created a speech recognition tool called Whisper to transcribe audio from YouTube videos and podcasts.\n- An OpenAI team transcribed more than one million hours of YouTube videos and fed the resulting texts into GPT-4.\n- Greg Brockman personally helped gather YouTube videos for the transcriptions.\n- OpenAI released GPT-4, which drew on the transcribed YouTube videos.\n- OpenAI publicly stated that each of its A.I. models has a unique curated data set and that it uses numerous sources of data.\n- Google's legal department asked the privacy team to draft language to broaden what the company could use consumer data for.\n- Google's privacy team wrote new terms to allow the company to use publicly available content from Google Docs, Google Sheets and related apps for training its A.I. models and building products and features.\n- Google instructed employees to release the new terms on the Fourth of July weekend.\n- Google released the revised privacy policy on July 1.\n- Google stated that it did not use information from Google Docs or related apps to train language models without explicit permission and that it did not start training on additional types of data based on this language change.\n- The New York Times sued OpenAI and Microsoft for using copyrighted news articles without permission to train A.I. chatbots.\n- More than 10,000 trade groups, authors, companies and others submitted comments to the Copyright Office about the use of creative works by A.I. models.\n- Meta hired contractors in Africa to aggregate summaries of fiction and nonfiction, which included copyrighted content.\n- Some Meta employees proposed paying $10 per book to obtain full licensing rights to books.\n- Meta executives and managers discussed acquiring the publishing house Simon & Schuster to procure long works for training data.\n- Meta's executives agreed to lean on the 2015 Authors Guild v. Google court decision as a legal justification for using copyrighted works to train A.I.\n- OpenAI and other companies began investigating synthetic data approaches, including methods where one A.I. system generates data and a second judges the information to separate the good from the bad.\n- Sam Altman publicly acknowledged at a conference that A.I. companies would use up all viable data on the internet.\n- The Vallas campaign reported the video to Twitter.\n- The Vallas campaign released a statement denouncing the video as an obviously fake, deceptive deepfake impersonation.\n- Twitter removed the deepfake clip from its platform.\n- Twitter suspended the user account that posted the video.\n- V.S. Subrahmanian of Northwestern reviewed the video for CBS.\n- CBS declined to play or quote the video in its entirety to avoid perpetuating the misinformation.\n- The Vallas campaign declined an interview request from CBS.\n- The Vallas campaign announced it would hold no events on Monday.\n- The professor marked the suspected AI-powered students as non-attending in the course roster, which could lead to their removal from the class.\n- The professor reported the suspected students using the college's SPAM reporting form.\n- Catholic Answers defrocked the chatbot, removing its representation as a priest.\n- Catholic Answers renamed the bot from Father Justin to Justin.\n- Catholic Answers re-described the chatbot as a lay theologian.\n- Catholic Answers removed the bot's priestly attire and changed its visual appearance to business casual.\n- Catholic Answers updated the chatbot's responses so it no longer claims to be associated with the priesthood and now states it is an AI lay theologian who was never ordained.\n- Catholic Answers published a blog post explaining the defrocking and responding to criticism of the original priest representation.\n- The merchant contacted The New York Times about the ads reaching an unwanted audience.\n- The New York Times ran test ads using the same photos to investigate why the ads attracted an unwanted audience.\n- The New York Times opened two Instagram accounts and promoted posts showing the 5-year-old girl and other variations of the photos.\n- The New York Times chose not to publish the test-ad images in the article because of the response they received from some sex offenders.\n- The New York Times reached out via Instagram chat to everyone who engaged with the ads and explained the posts were tests run by journalists.\n- The New York Times used Meta's reporting tool to report the men who engaged with the ads.\n- The New York Times flagged the offending accounts to a Meta company spokesman.\n- The New York Times identified convicted sex offenders by matching account information with sex-offender databases and public records.\n- New Mexico's attorney general conducted a sting operation called Operation MetaPhile that led to the arrest of three men trying to arrange sex with underage girls on Facebook.\n- Law enforcement created decoy undercover accounts presented as underage children to attract and identify men who sent sexually explicit material.\n- Meta removed the accounts that were reported to the company.\n- Bella & Omi decided to avoid the problem by targeting only women with their ads.\n- Tightspot Dancewear Center restricted its ads to women.\n- Tightspot Dancewear Center limited how often it shares photos of child models in non-advertising posts.\n- Young Days shifted its advertising focus to reach women after noticing an increase in male viewers.\n- New York state shares registered sex offenders' email addresses weekly with technology companies, including Meta.\n- Scopus removed four of Addleton Academic Publishers' journals from its database because of 'Publication Concerns.'\n- Addleton announced that Linguistic and Philosophical Investigations, Review of Contemporary Philosophy, Analysis and Metaphysics, and Contemporary Readings in Law and Social Justice will have a new publisher, Auricle Global Society of Education and Research.\n- The authors contacted three individuals using aa-er.org email addresses and asked them to send their papers.\n- The authors contacted various members of the journals' editorial boards.\n- Editorial board member Liz Jackson said she would ask to have her name removed from the board.\n- One of the researchers (LW) contacted several apparently real authors from the University of Craiova to discuss the content of their papers.\n- They informally alerted some colleagues involved in introducing the Scopus-based rankings at their institution.\n- INTERPOL published a new report assessing financial fraud as a global threat boosted by technology.\n- Robert Almonte spoke to NewsNation to warn the public about cartel scam tactics.\n- If you receive messages from a number you don't recognize, delete them immediately.\n- Do not respond to messages from unknown numbers.\n- U.S. and California officials engaged in discussions with General Motors' self-driving unit Cruise about the accident.\n- The National Highway Traffic Safety Administration said it is in contact with the operator and local authorities to gather additional information about the incident.\n- The California Department of Motor Vehicles met with Cruise to obtain more information about the incident.\n- San Francisco police said Cruise was cooperating in the investigation.\n- Cruise allowed Reuters and other media outlets to view video of the crash.\n- The San Francisco Fire Department freed the victim using rescue tools.\n- The San Francisco Fire Department transported the victim to a nearby trauma center.\n- The Teamsters union asked NHTSA to deny Cruise's petition to deploy up to 2,500 self-driving vehicles annually without human controls.\n- U.S. intelligence agencies analyzed the video and determined the voice of \"Olesya\" was synthetically generated.\n- Microsoft publicly attributed the video featuring \"Olesya\" to a group it calls Storm-1516.\n- Microsoft identified at least 30 videos produced by Storm-1516 since last August.\n- The C.I.A. publicly denied involvement in the activities described in the video and called the claim false.\n- Avril D. Haines praised the C.I.A. for calling out the video publicly.\n- Avril D. Haines stated that the government will identify disinformation by Russia or other countries during the current election.\n- Gen. Paul M. Nakasone urged identifying and publicizing propaganda as a defense against Russian disinformation.\n- Gen. Paul M. Nakasone urged expanding information sharing both domestically and around the world to help people identify and discount disinformation.\n- Some mainstream Republicans warned fellow lawmakers to be wary of repeating claims that originated in Russian disinformation or propaganda.\n- Media outlets quickly discounted the InfoWars-highlighted video as fake after noting the purported Ukrainian soldiers had Russian accents and were masked.\n- News and government agencies quickly identified the fake audio recording released in Slovakia as manipulated.\n- They hired a lawyer to help track down who created the YouTube video and how Mr. Lehrman's voice had been recreated.\n- They sent Lovo a cease-and-desist letter.\n- Lovo removed the couple's voice clones from its website after receiving the cease-and-desist letter.\n- They filed a federal lawsuit in Manhattan against Lovo seeking class-action status and inviting other voice actors to join.\n- A Massachusetts Institute of Technology professor reconstructed the chatbot using Lovo's voice synthesis technology to identify the source of Mr. Lehrman's voice clone.\n- Lovo offered a revenue-sharing program that allowed voice actors to help create voice clones of themselves and receive a cut of the money made by those clones.\n- Tianle Cai accessed GPT-4o's public token library and extracted the 100 longest Chinese tokens.\n- Tianle Cai posted the list of the 100 longest Chinese tokens on GitHub.\n- Deedy Das used language filters to count the number of tokens in different languages and examined token distributions across languages.\n- Zhengyang Geng asked GPT-4o to translate some of the long Chinese tokens as part of his investigation.\n- Zhengyang Geng conducted personal red-teaming experiments using the rare tokens to attempt to jailbreak GPT-4o.\n- Zhengyang Geng chose not to share the details of his red-teaming experiments with the public.\n- Sander Land and Max Bartolo drafted a paper on how to detect unusual tokens that can cause models to glitch.\n- During Geng's tests, a safety mechanism detected unsafe content and blocked it from being shown to the user.\n- Chinese users reported the spam sites appearing in unrelated Google search results and posted complaints in Google Search's support community.\n- An X user reported a similar prevalence of porn and gambling content in Korean tokens.\n- A police complaint was filed to find the perpetrators of the Rashmika Mandanna deepfake.\n- Prime Minister Modi gave a speech warning against the misuse of deepfakes.\n- Plainclothes police officers visited Jadoun and asked for his help in determining whether a Hindi audio clip of a politician was a deepfake.\n- Jadoun moved away from making deepfakes for fun and doubled down on political work.\n- Jadoun became one of three signatories to an Ethical AI Coalition manifesto pledging not to use AI technology for nefarious ends.\n- Fact-checkers identified several prominent audio and video deepfakes targeted at influencing voter opinion in India.\n- At least three police complaints were filed over illegal voice-clone endorsements shared by political accounts.\n- India's election watchdog issued warnings regarding illegal voice-clone endorsements by political accounts.\n- Sagar Vishnoi created paid workshops and awareness campaigns to teach law enforcement how to counter deepfakes.\n- Each week Jadoun's team collected call data and fine-tuned their models to improve AI call performance.\n- The researcher created the 'huggingface-cli' package and uploaded it to the Python Package Index (PyPI).\n- He published research through security firm Vulcan Cyber documenting how AI models can recommend non-existent software packages.\n- He wrote actual packages using names imagined by AI models to test whether invented package names could be co-opted to distribute malicious code.\n- He queried four AI models with thousands of 'how to' programming questions across five languages and runtimes to explore the persistence of hallucinated package names.\n- He selected 20 questions at random and posed each 100 times to every model to assess how often hallucinated package names were repetitive.\n- OpenAI improved the model behind Whisper since the researchers carried out this work last year, and the hallucination rate has decreased.\n- Researchers ran more than 13,000 speech clips into Whisper as part of their analysis.\n- The researchers presented their paper \"Careless Whisper: Speech-to-Text Hallucination Harms\" at the ACM Conference on Fairness, Accountability, and Transparency (FAccT).\n- Customers filed dozens of lawsuits against General Motors.\n- General Motors ended its contract with the data broker.\n- Kathleen Lomax canceled her Life360 subscription.\n- Life360 sent Kathleen Lomax an automated response, crafted with the help of AI, stating that Life360 did share driving behavior data with Arity.\n- Rob Leathern made a month of phone calls, emails, and data privacy requests to Toyota and Connected Analytic Services.\n- Connected Analytic Services provided Rob Leathern with a report detailing the previous six months of driving in his SUV.\n- Toyota stated that customers can manage what is shared about them in the data privacy portal of the Toyota/Lexus app.\n- Connecticut's insurance regulator issued a consumer alert warning that new cars may track people's driving and affect how much they pay for insurance.\n- Progressive informs eligible customers when quoting a new policy that driving data is available from their vehicle manufacturer and asks if they would like Progressive to use that data to determine their rate.\n- NewsGuard conducted an audit of 10 leading AI chatbots using 570 prompts based on 19 false narratives linked to a Russian disinformation network.\n- NewsGuard tested each of the 19 narratives using three different personas (neutral, leading, and malign actor) to reflect how AI models are used.\n- NewsGuard published a special report uncovering the sophisticated and far\u2011reaching Russian disinformation network of 167 websites.\n- NewsGuard offered to provide, at no charge, each company responsible for the tested chatbots with their individual audit scores upon request.\n- NewsGuard sent emails to OpenAI, You.com, xAI, Inflection, Mistral, Microsoft, Meta, Anthropic, Google, and Perplexity seeking comment on the findings.\n- NewsGuard fed the chatbots prompts that explicitly attempted to generate disinformation (for example, instructing them to write as a local news site) as part of its testing.\n- A U.S. Secret Service spokesperson told NewsGuard by email that the agency has 'no record of any employee named \"Greg Robertson.\"'\n- The U.S. State Department told NewsGuard in April 2024 that it had 'no information about the existence of any such entity' and that the claim resembles Russian disinformation.\n- Egyptian officials told NewsGuard that they did not find any record of a journalist named 'Mohammed Al\u2011Alawi.'\n- The owner of the resort referenced in the false claim told NewsGuard that the allegation about Zelensky's family purchasing the villa was false.\n- BIM spokesperson Marlen Koenecke told NewsGuard that the villa was not sold and that the company has never had an employee named 'Sabine Mels.'\n- Microsoft and Clemson University documented the disinformation network's modus operandi and contributed reporting that informed the analysis.\n- JPMorgan Chase has begun using large-language models to fight identity fraud.\n- JPMorgan Chase has stepped up its efforts to educate customers about scams.\n- Financial institutions are tapping AI themselves to shield customers' money and data.\n- Banks monitor how customers enter credentials, including which hand they use when swiping and the device's IP address, to build behavioral profiles.\n- Banks flag login attempts that don't match a user's typical behavior and may prompt the user to provide additional information before proceeding.\n- Banks monitor shifts in typing cadence to detect when users may be coerced into filling out information.\n- Banks flag copied-and-pasted digits as suspicious.\n- Banks flag voice-verification attempts that are too perfect as red flags.\n- Banks flag text that is too evenly spaced and grammatically perfect as a red flag.\n- Banks and other financial institutions use fraud-detection technology from firms such as RSA Security.\n- Security officials advise consumers to never share financial or personal information unless they are certain about who is on the receiving end.\n- Security officials advise consumers to use a credit card when paying because it offers the most protection.\n- Security officials suggest that consumers turn on two-factor authentication so they get a text or email whenever someone tries logging into an account.\n- Security officials advise consumers to pause and 'take a beat' if anything feels off during a potential money exchange.\n- Security officials advise consumers to get a second opinion from a trusted contact when all information about a transaction or account is coming from one person.\n- The researchers collected 13,353 listings from nine underground marketplaces and forums between November 30, 2022 and October 12, 2023.\n- The researchers directly engaged with vendors of malicious LLM services.\n- The researchers obtained complimentary copies of some malicious LLM services.\n- The researchers purchased some malicious LLM services under close supervision from the university's institutional review board.\n- The researchers examined and analyzed the acquired malicious services to identify backend LLMs and collect prompt-response pairs related to malicious capabilities.\n- The researchers evaluated the performance of the malicious software, including malware generation and phishing capabilities.\n- The researchers published the study titled \"Malla: Demystifying Real-world Large Language Model Integrated Malicious Services\" documenting their findings.\n- The researchers made the dataset of prompts used to create malware and bypass safety features available for other researchers to study.\n- The authors produced concrete recommendations to build safer models that are resilient against bad actors.\n- The Amandine Le Pen TikTok account was modified after the publication of the article.\n- The Amandine Le Pen TikTok account was banned after the publication of the article.\n- A mention indicating the account was a deepfake, which had not been on the account before the article, was modified after the article's publication.\n- The buymeacoffee.com link was removed from the profile shortly after the article's publication.\n- Council staff review and validate housing benefit claim details after the automated system flags them as potentially fraudulent or erroneous.\n- Council staff seek evidence from claimants over the phone or digitally when reviewing flagged claims.\n- Council staff identify changes of circumstances during review of flagged claims.\n- Council staff potentially recalculate claimants\u2019 housing benefit awards as part of the review process.\n- The DWP undertook full case reviews of suspect claims.\n- The DWP stopped routinely suspending benefit claims flagged by its AI-powered fraud detector.\n- Lin and her family reported their suspicion to the New Taipei City Police by taking her to the local police precinct.\n- The New Taipei City Police determined the interaction was fake and said scammers used AI to generate Andy Lau's voice, face, and movements.\n- To catch the scammers, police instructed Lin to ask them if she could make a NT$150,000 cash payment in person.\n- Lin arranged to meet the scammers at a park in Sanchong District to deliver the cash as part of the police operation.\n- Plainclothes police officers arrested a woman who showed up at the park to receive the cash.\n- The New Taipei City Police arrested a woman believed to be part of the scamming operation.\n- The University of Edinburgh submitted a Freedom of Information request to obtain data about in-work Universal Credit claimants.\n- The Department for Work and Pensions said it will review the Universal Credit system to ensure everyone, including single mothers, can benefit from a welfare system that makes work pay and tackles inequality.\n- Zelda Williams posted on her Instagram Story criticizing the use of artificial intelligence to recreate her late father's voice.\n- The Writers Guild of America announced that they had reached a major development and struck a deal with the Alliance of Motion Picture and Television Producers.\n- The Writers Guild of America deal brought the writers' strike to a close.\n- CBS's The Late Show With Stephen Colbert, ABC's Jimmy Kimmel Live!, and NBC's The Tonight Show Starring Jimmy Fallon resumed production and returned to air.\n- Most TV and film productions were set to remain on hold as the actors' strike continued.\n- SAG-AFTRA resumed talks with the studios.\n- The article provided the Samaritans helpline contact details and website for people in the UK and Republic of Ireland experiencing distress.\n- The article provided the National Suicide Prevention Helpline number for people in the USA.\n- The article provided a link to Befrienders.org to help people in other countries find a local helpline.\n- X is treating the attempted assassination as a \"major incident.\"\n- X is prioritizing resources to take swift action against posts that violate the platform's rules, such as by praising the attack.\n- OpenAI's ChatGPT summarized the attack in response to a query about the shooting.\n- OpenAI's ChatGPT linked to the fact-checking website PolitiFact when summarizing the attack.\n- OpenAI's ChatGPT displayed a disclaimer stating it is \"not a real-time news product.\"\n- Google said it was making fixes to an AI-powered feature after it produced odd results.\n- Tom's Hardware updated the story to include Google's response.\n- Google pointed Tom's Hardware to a blog post about how it protects Google Workspace data.\n- Google suggested that closing the Gemini side panel in Drive might solve the issue.\n- CIOs are working to clean up and manage their data so they can take full advantage of AI tools.\n- Hitachi is regularly updating and refining its data to ensure accurate results from AI tools accessing it.\n- Hitachi's data engineers are validating and cleaning up incoming data.\n- Hitachi is curating its data into a 'golden record' with no contradictory or duplicate information.\n- Kyndryl cleaned up its data as the organization prepared to use Copilot.\n- Kyndryl is keeping its data organized, up-to-date, and secure to prepare for Copilot.\n- Microsoft introduced Copilot Studio to allow companies to direct Copilot to authoritative data sources for particular questions.\n- Organizations are undertaking data management work to get their 'data house in order' so AI will be more valuable.\n- Figma temporarily disabled the \"Make Design\" feature.\n- Within hours of the report, Figma identified that the issue was related to the underlying design systems created for the feature.\n- Figma said it will not re-enable the feature until it has completed a full QA pass on the feature's underlying design system.\n- Figma CEO Dylan Field publicly accepted responsibility for the QA lapse.\n- Field publicly clarified that Make Design uses off-the-shelf large language models combined with commissioned systems and denied that it was trained on Figma content, community files, or app designs.\n- Figma pointed to Field's tweets as its statement on the matter.\n- The parties agreed to a class settlement resolving the lawsuit.\n- The parties asked the United States District Court for the Western District of Missouri to approve the proposed settlement.\n- A Notice was issued explaining the action, the proposed settlement, class members' legal rights and options, available benefits, eligibility and procedures, and applicable dates and deadlines.\n- A VIN Lookup Portal was made available for owners to determine whether their vehicle is a Settlement Class Vehicle by entering their vehicle's VIN.\n- A deadline was established for settlement class members to postmark requests for exclusion from the settlement (June 17, 2024).\n- A deadline was established for settlement class members to file objections to the settlement (June 17, 2024).\n- A deadline was established for settlement class members to file claims for reimbursement (July 15, 2024).\n- A Final Fairness Hearing was scheduled for July 17, 2024 at 1:30 p.m. in Courtroom 8E at the U.S. District Court, Kansas City.\n- The Interior Ministry issued a public defense of VioG\u00e9n and said the government was 'the first to carry out self-criticism' when mistakes occur.\n- The Spanish government called an emergency meeting after three women were killed by former partners within a 24-hour span.\n- Interior Minister Fernando Grande-Marlaska publicly said he still had 'absolute confidence' in the system at a news conference.\n- VioG\u00e9n has been refined and updated over the years, including adding metrics believed to better predict homicide.\n- Police have been required to conduct a follow-up risk assessment within 90 days of an attack.\n- After working with a lawyer specializing in gender violence cases, Luz had her risk score increased to 'extreme'.\n- Following the increase to 'extreme' risk, Luz received round-the-clock police protection.\n- A few days after the January 2022 attack, Lobna Hemid won a restraining order against her husband.\n- In 2020, Stefany Gonz\u00e1lez Escarraman's family won a legal verdict against the state for failing to adequately measure risk and provide sufficient protection.\n- Spanish officials are exploring incorporating additional A.I. capabilities into VioG\u00e9n so it can pull data from different sources and learn more on its own.\n- Victims classified as higher risk receive regular police patrols at their home.\n- Victims classified as higher risk are given access to shelters.\n- Victims classified as higher risk have police monitoring of their abuser's movements.\n- In extreme cases, police assign 24-hour surveillance to victims.\n- Spanish police are trained to overrule VioG\u00e9n's recommendations depending on the evidence.\n- The user called PayPal's customer service line, and a representative confirmed there was no such transaction.\n- PayPal told the user to email the screenshot to service@paypal.com.\n- PayPal's auto-reply informed the user that the service@paypal.com email address is no longer active.\n- PayPal's auto-reply directed the user to PayPal's help pages.\n- PayPal's auto-reply instructed the user to click \"Message Us,\" which opens a new dialog with the same chatbot.\n- Hoodline removed fake headshots and fake biographical information from its site.\n- Hoodline replaced the fake headshots and biographies with a small \"AI\" badge next to each machine-assisted article's byline.\n- Impress3 (Hoodline's parent company) requested that archived screenshots of the site be removed from the Internet Archive and other parts of the internet.\n- Archived screenshots of Hoodline's AI writer pages were wiped from much of the internet at the request of the site's rights holder.\n- Zachary Chen publicly defended the site's use of AI and its transparency in statements to CNN.\n- Chen said the outlet has greatly refined its processes and implemented heavy guardrails.\n- Chen said that each AI-assisted article is overseen by editors before it is published.\n- Hoodline said it plans to hire more human journalists as it evolves its AI personas into AI news anchors.\n- The News/Media Alliance supported news organizations taking legal action against AI developers that harvest news content without permission.\n- Microsoft redirected election-related prompts in Copilot to Bing search to help ensure users are getting information from the most authoritative sources.\n- Microsoft said it was putting guardrails in Copilot ahead of the election to be cautious about politics.\n- Google said it was working on improving the Gemini/AI experience as it gets more feedback.\n- Google's AI Overview skipped direct AI answers for breaking news and instead showed Google News links.\n- Perplexity prioritized authoritative sources such as government websites for election-related questions.\n- Perplexity included disclaimers in some answers noting that the current health of public figures can change rapidly.\n- Perplexity recommended that users read trusted news outlets for breaking news because they are best equipped to offer real-time updates.\n- Meta AI deleted an initially accurate answer about Trump's running mate and replaced it with a message linking to voting information.\n- Some companies started making names and links to sources more visible in their chatbot responses.\n- ChatGPT updated its answer the next day to accurately confirm that an assassination attempt had occurred.\n- ChatGPT added a disclaimer telling people to check other sources for the latest information about the assassination attempt.\n- ChatGPT corrected its response about Biden dropping out within about an hour of the announcement.\n- A spokesperson for OpenAI said the product is an initial prototype and that OpenAI will keep improving it.\n- OpenAI opened a waitlist that allows anybody to join to try SearchGPT and will approve thousands of initial test users.\n- OpenAI announced that SearchGPT search responses will include in-line citations.\n- OpenAI announced that users can open a sidebar to view links to external sources.\n- BNN shut its news arm in May 2024.\n- NewsGuard identified more than 500 unreliable AI-generated websites in October 2023.\n- Chris Silver Smith determined that the websites showing up in search results after his brother-in-law's death were spam websites.\n- The New York Times reported that BNN hired would-be journalists from countries like Iraq, Pakistan, Egypt, and Nigeria to put existing stories through generative AI tools before posting them.\n- The misleading story featuring Mr. Fanning's photo was deleted from the internet a day later.\n- Microsoft said it had terminated its licensing agreement with BNN.\n- Mr. Fanning's lawyers at Meagher Solicitors reached out to BNN regarding the false story.\n- Mr. Fanning filed a defamation case against BNN and Microsoft in the High Court of Ireland.\n- After a lawyer complained on LinkedIn that a BNN story had invented quotes from him, BNN removed him from the story.\n- BNN changed the date on that story to one before the publication date of the opinion column that the lawyer believed was the source of the quote.\n- BNN responded to Mr. Fanning's lawsuit by publishing a story that accused him of 'desperate tactics in money hustling lawsuit.'\n- BNN stopped publishing stories in early April.\n- BNN deleted its content when it went dormant.\n- Within a week or so of BNN Breaking's shutting down, the operation moved to a new website called TrimFeed.\n- TrimFeed shut down after a reporter informed Mr. Chahal that the article would soon be published.\n- In March, Google rolled out an update to reduce unoriginal content in search results, targeting sites with 'spammy' content.\n- An official with the Maryland Department of Natural Resources chastised BNN on X for its inaccurate claim about Dungeness crabs.\n- The same Maryland official called on Google to delist AI news outfits that aggregate news and get things wildly incorrect.\n- NewsGuard identified more than 800 websites that use A.I. to produce unreliable news content.\n- Some of the politicians targeted have contacted the police.\n- Since the Online Safety Act was introduced in January, sharing such imagery without consent has been made illegal in the UK.\n- The government announced in April plans to close the loophole and ban the creation of deepfake pornography in England and Wales.\n- The proposed law was dropped when Prime Minister Rishi Sunak decided to call an early election.\n- The Conservatives, Labour and the Liberal Democrats have pledged to reintroduce the ban if they win the next election.\n- Some of the biggest sites chose to pre-emptively block British users from their sites.\n- US Representative Alexandria Ocasio-Cortez is pushing for similar laws in the US.\n- The Guardian conducted an investigation into the ClothOff AI app earlier this year.\n- Bugatti issued a public statement denouncing the disinformation campaign targeting its Paris dealership.\n- The Car Lovers Group stated that its Paris dealership, operated by Autofficina Parigi, was the victim of several criminal offenses.\n- The Car Lovers Group strongly denied the existence of the purported transaction and the existence of the invoice.\n- The Car Lovers Group filed a criminal complaint alleging forgery, use of forgeries, usurpation of identity, and defamation.\n- Clarity reviewed the video and reported a high certainty of AI manipulations, mostly around the middle of the face area.\n- CNN analyzed the Verite Cachee website and determined it had been set up recently on June 22, 2024.\n- CNN found that some pages on Verite Cachee still contained AI prompts to create fake articles.\n- CNN was unable to find contact information for the Verite Cachee website.\n- Recorded Future identified Verite Cachee as being part of the same disinformation network.\n- The Harris campaign issued a statement condemning the manipulated video and calling it \"fake, manipulated lies of Elon Musk and Donald Trump.\"\n- Alex Howard posted on X asserting the post violated X's policies on synthetic media and misleading identities and asked whether X would retroactively change its policies to allow such violations in an election year.\n- OpenAI released a new version of the ChatGPT macOS application that encrypts stored conversations.\n- Meta works with law enforcement to combat this type of activity.\n- Meta said its systems proactively detect and enforce against violating content and that it rejects hundreds of thousands of ads for violating its drug policies.\n- Meta disabled many of the drug ads spotted by The Wall Street Journal within 48 hours of when they went live.\n- All of the ads have now been removed for violating Meta's policies.\n- After being contacted, the company banned the users who created the ads from its platform.\n- Meta disabled the accounts associated with the dealer who sold drugs to Elijah Ott after being contacted by The Wall Street Journal.\n- Meta said it is using insights about new adversarial tactics garnered from investigating these ads to fan out and do additional sweeps for similar content.\n- Meta said it would continue to invest resources and further improve its enforcement on this kind of content.\n- Chief Executive Mark Zuckerberg apologized at the Senate hearing.\n- She made her Instagram account private.\n- She removed photographs of herself in a bathing suit from her Instagram.\n- She stopped walking alone at night.\n- She started triple-checking that her doors and windows were locked before she slept.\n- She altered her professional wardrobe to cover more of her body, favoring high-cut blouses and blazers.\n- She contacted a member of the local police department about the images.\n- A member of the local police department referred her to the Florida Department of Law Enforcement's cybercrime division.\n- She spoke on the phone with the Florida Department of Law Enforcement's legal adviser.\n- She emailed a link to the 4chan images to the Florida Department of Law Enforcement's legal adviser.\n- Norma Buster of Carrie Goldberg's firm conducted a case evaluation with Javellana over the phone in February 2021.\n- She sought help from lawyer Carrie Goldberg and her firm regarding the deepfakes.\n- She combed the internet at night for information about intimate-image abuse.\n- Florida Department of Law Enforcement special agents met with her in April 2021 and explained they could not investigate because there were no applicable federal or state laws at the time.\n- FDLE special agents offered to help her write an affidavit declaring that the photographs were not real.\n- She signed the affidavit pages prepared by FDLE special agents.\n- She took a screenshot of a news article about Senator Lauren Book's bill, highlighted the language about deepfakes, and posted it to Twitter along with a summary of her own experience, publicly acknowledging the ordeal.\n- She spoke by phone with Senator Lauren Book and subsequently communicated regularly with her.\n- She testified in support of Senate Bill 1798 at a committee hearing in Tallahassee on Feb. 8, 2022.\n- She spoke with news media and publicly called out 4chan users as the architects behind the deepfakes.\n- She ultimately decided against taking legal action.\n- She decided to leave the deepfakes in the past.\n- She decided not to run for re-election to the city commission.\n- She began working as an aide to the Democratic mayor of Broward County.\n- Senator Lauren Book drafted Senate Bill 1798 to criminalize non-consensual deepfakes.\n- The bill (S.B. 1798) passed in committee by an 8-0 vote.\n- S.B. 1798 passed unanimously in Florida's House and Senate.\n- Governor Ron DeSantis signed S.B. 1798 into law on June 24, 2022.\n- After S.B. 1798 became law, the Florida Department of Law Enforcement and local law enforcement could investigate victims' claims and perpetrators could be charged, fined and possibly jailed.\n- In January, Congress introduced the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE) Act of 2024.\n- The DEFIANCE Act recently passed in the Senate.\n- The Department of Homeland Security released a report noting the increasing threats of deepfake identities.\n- The FBI advised caution when posting personal photos or videos online.\n- Five U.S. secretaries of state sent an open letter urging Elon Musk to immediately implement changes to X's AI chatbot Grok to ensure voters have accurate information.\n- The officials requested that X direct Grok users to the nonpartisan voting information website CanIVote.org when asked about U.S. elections.\n- TikTok removed close to half of the 91 accounts identified by the Journal before the Journal reached out to the company.\n- TikTok continued to delete accounts after the Journal flagged them.\n- After the Journal flagged the accounts, TikTok launched an internal investigation that confirmed the accounts belonged to operations from China, Vietnam, Nigeria, and Iran.\n- TikTok said it has removed other networks from China that were targeting U.S. users.\n- TikTok said it removed 24 influence operations from its platform in the first six months of 2024.\n- TikTok said it removed more than 170 million inauthentic or fake accounts from the platform in the first three months of the year.\n- TikTok works with fact-checkers to verify certain claims on its platform.\n- TikTok removes content and accounts that break its rules.\n- TikTok sometimes labels content that cannot be verified and stops recommending that content to users.\n- In May, TikTok announced it would start automatically labeling certain AI-generated content.\n- YouTube removed the YouTube accounts referenced in the story before being contacted by the Journal.\n- The Journal flagged the identified TikTok accounts to TikTok.\n- The Journal attempted to contact all of the TikTok accounts for comment.\n- TikTok said it has hired experts to help combat misinformation and deceptive behavior.\n- TikTok said it has added policies to address misinformation and deceptive behavior.\n- TikTok said it has built tools to try to thwart deceptive and spammy actors on its platform.\n- Five US secretaries of state called on Elon Musk to fix the Grok chatbot after it spread misinformation suggesting Kamala Harris was ineligible to appear on the ballot in some states.\n- Google suspended its Gemini text-to-image tool after it produced ahistorical images such as Black soldiers in Nazi-era military uniforms.\n- Lawmakers introduced legislation to create legal remedies for victims of nonconsensual AI-generated images.\n- X took down the Grok summary post that claimed Trump was missing his dentures.\n- X changed the summary\u2019s link so it now leads to a blank page.\n- Five secretaries of state from Minnesota, Pennsylvania, Washington, Michigan, and New Mexico penned an open letter to Elon Musk asking him to fix Grok\u2019s summaries after it posted election misinformation.\n- The Enterprise's publisher and editor apologized for allowing AI-generated copy and false quotes in their stories.\n- The Enterprise's publisher and editor vowed to take steps to ensure it never happens again.\n- Megan Barton wrote an editorial calling AI 'the new, advanced form of plagiarism.'\n- The Cody Enterprise now has a system in place to recognize AI-generated stories.\n- The Cody Enterprise said it will have longer conversations about how AI-generated stories are not acceptable.\n- After the meeting, the Enterprise discovered seven stories that included AI-generated quotes.\n- Enterprise editor Chris Bacon said he is still reviewing other stories.\n- Aaron Pelczar resigned from the Cody Enterprise.\n- Aaron Pelczar promised to correct the misstatements and issue apologies to those quoted.\n- Chris Bacon plans to have an AI policy in place by the end of the week.\n- Bacon said the new AI policy will be a pre-employment topic of discussion.\n- Sports Illustrated said it was firing the company that produced AI-generated articles for its website.\n- The school's principal, Mike Baird, emailed parents in March about the incident.\n- The school said it was working with the Richmond Police Department on a thorough investigation of the incident.\n- The McHenry County state's attorney's office confirmed that two unnamed minors were arrested in late April in relation to the Richmond-Burton Community High School case.\n- Both arrested suspects were charged with child pornography offenses and with several counts of distribution of harmful material to a minor, with one suspect facing 17 counts.\n- Congressman Joe Morelle introduced a federal bill in May 2023 banning nonconsensual deepfake nude images.\n- Scripps News used artificial intelligence to create a photo and ran it through a popular app to demonstrate how easily subjects can be 'undressed' by such tools.\n- Stevie Hyder spoke publicly about what happened as a way to take back power after the incident.\n- A social media influencer aligned with Mr. Trump labeled at least one of the AI-created images \"satire\".\n- A.J. Delgado publicly urged a publicist for Ms. Swift to clear up the misinformation.\n- Samsung Semiconductor is developing its own in-house AI for internal use by employees.\n- The in-house AI restricts employee prompts to a maximum size of 1024 bytes.\n- Samsung Electronics sent out a warning to its workers about the potential dangers of leaking confidential information.\n- She posted a clarification on her real Twitter account stating the tweets were fake and warning people not to fall for them.\n- She deleted her Facebook account.\n- She sought medical treatment at a hospital where a doctor prescribed medication for her anxiety and heart palpitations.\n- Her brother flew in from Mumbai to see her.\n- She contacted and retained a high-profile feminist lawyer who agreed to take on her case.\n- She and her lawyer went to a police station to file a complaint about the video.\n- She threatened the police that she would write about them on social media if they did not register her complaint.\n- Her lawyer told the police they would go to the media if the complaint was not registered.\n- The police eventually filed a report about the incident.\n- She gave her statement to a magistrate and provided screenshots and the messages she had received as evidence.\n- Sixteen United Nations special rapporteurs wrote to the Indian government asking it to protect her.\n- She stopped posting on Facebook and began self-censoring her online activity.\n- Microsoft attempted to remove the false entries from Copilot.\n- Microsoft temporarily removed the false entries from Copilot.\n- The public prosecutor's office in T\u00fcbingen declined to press charges, stating that no crime had been committed because the author of the accusations was not a real person.\n- Martin Bernklau contacted a lawyer about the chatbot's claims, which he considers defamatory and a violation of his privacy.\n- She tried going to the police.\n- She tried contacting government agencies.\n- She tried getting a private investigator.\n- She made fake accounts to confront the perpetrators directly.\n- She contacted site administrators and requested that the material be deleted.\n- She directed her energy into campaigning to change the laws surrounding image-based abuse.\n- Her campaign was successful in making image-based abuse a criminal offense in 2017.\n- She now works in the legal sector.\n- Reddit banned sexually explicit deepfakes in 2018.\n- Twitter banned sexually explicit deepfakes shortly afterwards.\n- A government agency was established in Australia to help victims remove material and to identify social media companies that fail to remove internet images from their platforms within 48 hours.\n- Actor Ashton Kutcher informed Dax Shepard that there were deepfakes and that his wife, Kristen Bell, was one of them.\n- Pornhub banned the uploading of celebrity deepfakes to its platform in 2018.\n- Twitter banned the uploading of celebrity deepfakes to its platform in 2018.\n- Reddit changed its rules to include \"depictions that have been faked\" in its ban on nudity and sexually explicit content.\n- The Department of Justice said it is taking appropriate measures to ensure that training will not be delivered in this manner again.\n- OpenAI identified five online campaigns that used its generative AI technologies to deceptively manipulate public opinion around the world.\n- OpenAI disrupted five online campaigns that used its generative AI technologies to deceptively manipulate public opinion around the world.\n- OpenAI published a report that revealed the covert influence operations and provided case studies showing how its tools were used in those campaigns.\n- Lionsgate immediately recalled the trailer for 'Megalopolis'.\n- Lionsgate parted ways with Eddie Egan, the marketing consultant who provided the fabricated quotes.\n- Lionsgate issued a public apology to the critics involved and to Francis Ford Coppola and American Zoetrope.\n- South Korean authorities began investigating the spread of the sexually explicit deepfake images and videos.\n- The police detained seven male suspects in connection with the deepfake material.\n- President Yoon Suk Yeol called on his government to root out digital sex abuse.\n- Telegram said it has been actively removing content reported from Korea that breached its terms of service and will continue to do so.\n- The Korean National Police Agency compiled data on people involved in the production and spread of the imagery.\n- The Korean National Police Agency identified 178 people as criminal suspects in the first seven months of the year.\n- Women's rights groups called for new legislation to punish those who possess and watch deepfake sexual materials.\n- Amazon quickly fixed the error.\n- Amazon said it has teams dedicated to continuously auditing its systems to detect content that violates its policies and to prevent similar situations.\n- The music producer was arrested.\n- He was charged in the Southern District of New York with money laundering, wire fraud and conspiracy to commit wire fraud.\n- One of the streaming platforms accused him of streaming fraud in 2019.\n- In 2023, the Mechanical Licensing Collective raised doubts about how he could have generated so much music so quickly without using AI.\n- The Mechanical Licensing Collective identified and challenged the alleged misconduct.\n- The Mechanical Licensing Collective withheld payment of the associated mechanical royalties.\n- Herrera was indicted on multiple federal charges related to child sex abuse materials.\n- Herrera made his first appearance in federal court.\n- A federal grand jury charged Herrera with one count of transportation of child pornography, one count of receipt of child pornography, and one count of possession of child pornography.\n- Herrera was arrested the following day.\n- U.S. Magistrate Judge Kyle Reardon ordered that Herrera be detained pending trial.\n- A discovery management conference in the case was scheduled for Oct. 1, 2024.\n- A pre-trial detention document was filed in U.S. District Court for the District of Alaska.\n- A forensic review of three of Herrera\u2019s cell phones was conducted, revealing tens of thousands of videos and images depicting the violent rape and sexual abuse of children.\n- The FBI released a public service announcement warning of the legal consequences of obtaining and creating child sexual abuse material through AI.\n- The Department of Justice announced it is accelerating its enforcement efforts against misuse of generative AI that produces dangerous content such as child sexual abuse material.\n- The Justice Department asked the public to contact the Homeland Security Investigations tip line at (877) 447-4847 with information concerning Herrera's alleged actions.\n- The Dutch data protection watchdog fined Clearview \u20ac30.5 million for automatically harvesting billions of photos and converting them into biometric codes.\n- The Dutch watchdog imposed an additional non-compliance order of up to \u20ac5 million.\n- The Dutch regulator said it is looking for ways to make sure Clearview stops the violations.\n- The Dutch regulator said it may hold company directors personally responsible for violations.\n- Italy's data protection authority fined Clearview \u20ac20 million.\n- Greece's data protection authority fined Clearview \u20ac20 million.\n- France's data protection authority fined Clearview \u20ac20 million.\n- Regulators in Germany issued rulings deeming Clearview's technology illegal.\n- Regulators in Austria issued rulings deeming Clearview's technology illegal.\n- Britain\u2019s Information Commissioner\u2019s Office fined Clearview around $9 million.\n- Rishabh's friend advised him to consult cybersecurity expert Prabesh Choudhary for help.\n- The Bengaluru teen who shared AI-generated nudes and two others were arrested.\n- TikTok blocked the keyword \"undress\" to reduce access to such services.\n- Meta blocked the keyword \"undress\" to reduce access to such services.\n- Google removed certain ads for similar 'undress' tools.\n- The reporters withheld the names of the Telegram channels and apps to avoid further promoting them.\n- Google made it somewhat easier to remove non-consensual nude images or videos from its search results.\n- Victims can request Google to remove non-consensual deepfake images from search results by filling out an online form.\n- Experts advised victims to document every instance of AI image-based abuse by taking screenshots or saving image and video files.\n- Some tech platforms and search engines match known non-consensual sexual images reported to them and remove duplicate copies.\n- The reporters tested an 'undress' tool by uploading an AI-generated photo of a man.\n- The fraudulent WhatsApp calls were scuppered.\n- Staff contacted the CEO via Teams to confirm the WhatsApp video calls were not genuine.\n- The IWF passed the online manual to the UK\u2019s National Crime Agency.\n- The IWF warned last year of a rise in extortion cases where victims are manipulated into sending graphic images of themselves.\n- The IWF flagged the first examples of AI being used to create astoundingly realistic abuse content.\n- The charity finds and removes child sexual abuse material online.\n- The government is preparing to launch a consultation that will include proposals to ban the sale of smartphones to under-16s and raise the minimum age for social media sites to as high as 16.\n- ESPN updated its AI-generated recap of the match to include a mention of Alex Morgan at 8:59 a.m. ET on Monday, Sept. 9.\n- ESPN posted a separate article by writer Jeff Kassouf about Alex Morgan's final game on their outlets.\n- YouTube removed the bogus live stream for violating its terms of service.\n- The OnlyFake.org website was taken down and vanished from the internet following public outcry.\n- The site's new incarnation added more disclaimers, including a warning that says 'Do not use the images illegally!'\n- The site added a 'Denial of responsibility' labeled 'OnlyFake disclaimer' that specifies templates are intended for movies, TV, and web illustrations and warns that making physical fake IDs is illegal.\n- Au10tix researchers discovered the site's new URL after it reappeared.\n- Au10tix ran samples of the fake IDs through their double-layered defense system and flagged them on four different issues.\n- Biometric Update withheld the new URL in its reporting to avoid publicizing the fraud tool.\n- Au10tix advised businesses to implement multi-layered fraud defenses and increase the number of check types (standard systems 40\u201360 checks; strong systems 120\u2013180 checks).\n- Meta announced in January that it would give teens a more age-appropriate experience by restricting sensitive content, including sexually suggestive material.\n- Meta automatically defaulted teen accounts into its most restrictive content settings to refrain from recommending sexually suggestive or otherwise problematic content.\n- Meta established an effort to further reduce the volume of sensitive content that teens might see on Instagram.\n- Meta said it has meaningfully reduced the numbers of sensitive content shown to teens in the past few months.\n- A Meta spokesman attributed the inappropriate recommendations shown to minors in tests to an error.\n- Meta said it has developed more than 50 tools and resources to help support teens and their parents on its platforms.\n- Company safety staff ran internal tests in 2021 that were similar to those conducted by the Journal and Northeastern's Edelson.\n- Meta conducted a separate 2022 internal analysis that found Instagram showed more pornography, gore and hate speech to young users than to adults.\n- Senior Meta attorneys began making the case to the company's top leadership that child-safety issues posed underappreciated legal and regulatory risks.\n- Meta expanded its investments in child-safety work following years of tight budgets.\n- Meta's legal department provided recommendations regarding the company's child-safety efforts.\n- Meta stated that its efforts to prevent its systems from recommending inappropriate content to minors are ongoing.\n- The Record-Argus requested a review for each removed post.\n- Jarkovsk\u00fd Josef successfully appealed some of the post removals.\n- Noticias Maia tried to contact Meta about the post removals.\n- Several publishers disputed or challenged the takedowns of their posts.\n- Some of the removed posts were restored after being reviewed.\n- Press Gazette reviewed several of the removed posts.\n- ICNN director Emma Meese made contact with someone at Meta.\n- Publishers have tried to contact Meta about the issue.\n- Press Gazette approached Meta for comment.\n- TikTok took down the internal testing version of its Symphony Digital Avatars tool.\n- TikTok resolved the technical error that allowed a small number of users to access the internal testing version of the tool.\n- Google pared back the AI Overview tool.\n- Google removed certain responses from the AI Overview feature.\n- Google manually fixes bad AI responses piecemeal as people point them out.\n- Google uses examples of AI Overviews misinterpreting language or missing context to improve the Search feature.\n- Tupac Shakur's estate sent a cease-and-desist letter regarding Drake's song \"Taylor Made Freestyle.\"\n- Drake removed \"Taylor Made Freestyle\" from all platforms after receiving the cease-and-desist letter from Shakur's estate.\n- Sheryl Crow publicly criticized Drake's use of AI to replicate Tupac Shakur's voice during an interview with the BBC.\n- Sheryl Crow called upon Congress to pass legislation regulating the use of AI in a guest column for The Hollywood Reporter.\n- Tennessee lawmakers passed the ELVIS Act, which added vocal likeness to its list of legal protections.\n- Sheryl Crow was one of over 200 artists who signed an open letter to tech companies urging them to \"Stop Devaluing Music.\"\n- Many fellow artists spoke with Congress.\n- AllHere furloughed most of its staff.\n- AllHere's founder and chief executive left her role.\n- AllHere posted on its website that the furloughs were because of \"our current financial position.\"\n- The Los Angeles school district took the Ed chatbot offline to refine how it answers user questions.\n- A truncated version of Ed, implemented as a website that gathers information from district apps, remained accessible to families in the district's 100 \"priority\" schools.\n- The district said it would protect data privacy and security on the platform regardless of what happens to AllHere as a company.\n- The district set a goal for the chatbot to be available in September.\n- AllHere informed Prince George's County Public Schools that it would no longer be able to provide its text messaging service effective immediately.\n- Some customers beyond Los Angeles were told that AllHere's services were essentially defunct.\n- Residents reported their concerns to Waymo's corporate headquarters.\n- NBC inquired as part of its report about the honking incidents.\n- Waymo responded to NBC's inquiry by issuing a statement acknowledging the issue.\n- Waymo identified the cause of the vehicles briefly honking while navigating parking lots.\n- Waymo is in the process of implementing a fix for the honking behavior.\n- Facebook has taken down many deepfake ads and disabled some of the accounts that were responsible for them.\n- YouTube said it removed more than 15.7 million channels and over 8.2 million videos for violating its guidelines from January to March of this year.\n- YouTube in March required creators to disclose when they use A.I. to create realistic content.\n- Meta said the company was training automated detection systems to catch fraud on its platform.\n- Most traces of Magna-FX were taken offline, including the company website, phone number and email addresses used by the agents Mr. Beauchamp spoke with.\n- Andrew Forrest filed a civil lawsuit against Meta alleging negligence in how its ad business is run.\n- Hong Kong's Securities and Futures Commission issued a warning in May about scams featuring Mr. Musk.\n- The Federal Trade Commission warned Americans that A.I.-powered cybercrime and deepfake scams were on the rise.\n- The Federal Bureau of Investigation warned Americans that A.I.-powered cybercrime and deepfake scams were on the rise.\n- Mr. Beauchamp filed a report with the local police.\n- Mr. Beauchamp filed a report with the Better Business Bureau.\n- Sensity analyzed more than 2,000 deepfakes.\n- YouTube pointed to its policies prohibiting scams and manipulated videos.\n- Facebook said it is investigating the issue and working quickly to address it.\n- The Washington Post contacted Facebook to report the problem.\n- Affected users repeatedly contested Facebook's determinations about removed posts.\n- Firefighters tested workarounds in an attempt to 'hack' the algorithm and prevent posts from being deleted.\n- Facebook suspended two users' accounts after they accumulated too many spam warnings.\n- Some responders, including Angela Oakley of the American Red Cross, stopped sharing certain emergency information on Facebook to avoid repeated rules violations and potential loss of their pages.\n- The school passed reports about the fake images to police.\n- Victoria Police confirmed it was investigating reports of explicit images being circulated online.\n- Police arrested a teenage male over the incident and released him pending further inquiries.\n- Bacchus Marsh Grammar said it was offering support to the girls and their families.\n- Bacchus Marsh Grammar said that if its students were discovered to have been the source of the images, appropriate action would be taken.\n- Salesian College expelled a 15-year-old student for producing deepfake explicit images of a teacher using AI.\n- Bacchus Marsh Grammar stated it was taking the matter very seriously.\n- Australia's eSafety Commissioner Julie Inman Grant launched new standards that will specifically deal with websites that can be used to generate child sexual abuse material, slated to come into effect in six months after a 15-day disallowance period in parliament.\n- The eSafety Commission reported that about 85 percent of intimate images and videos reported to her office were successfully removed.\n- Victoria Police arrested a teenager at Bacchus Marsh Grammar for creating nude images of around 50 of his classmates.\n- Victoria Police opened and are conducting an ongoing investigation into the Bacchus Marsh Grammar incident.\n- Salesian College expelled a student after he used AI-powered software to create deepnudes of a female teacher.\n- The federal government introduced legislation to ban the creation and sharing of deepfake pornography, which is currently being debated by parliament.\n- The introduced federal legislation would impose jail terms of up to six years for transmitting sexually explicit material without consent and an additional year if the offender created the deepfake.\n- The federal government brought forward an independent review of the Online Safety Act to ensure it is fit for purpose.\n- Anna McAdams reported the incident to school administrators.\n- School administrators conducted an investigation that identified the perpetrator.\n- The perpetrator was assigned to a separate building on campus for detention for the remainder of the semester.\n- The perpetrator left the school after winter break.\n- The boy was sanctioned within the juvenile justice system.\n- The Aledo Independent School District assisted the county sheriff's department with its investigation.\n- The district disciplined the boy in accordance with the student code of conduct and state law.\n- The district is reviewing its student code of conduct with the possible use of AI by students in mind.\n- Anna McAdams reached out to Dorota Mani, the mother of another teen victim.\n- McAdams began calling state and federal officials, including Senator Ted Cruz.\n- Berry and her family shared their story with Senator Ted Cruz.\n- Senators Ted Cruz, Amy Klobuchar and a bipartisan group of senators introduced a bill to criminalize the publication of nonconsensual nude images and to require social-media companies and other websites to remove the pictures within 48 hours of receiving notice from the victim.\n- Representative Joseph Morelle reintroduced the 'Preventing Deepfakes of Intimate Images Act,' which has more than 50 co-sponsors and is awaiting consideration by the House Judiciary Committee.\n- Google removed nude-generating AI apps from its app store.\n- Apple removed nude-generating AI apps from its app store.\n- After the fake nudes were shared, Berry removed all her Instagram posts for a few months.\n- After the fake nudes were shared, Berry culled her Instagram followers.\n- Berry now only accepts Instagram follow requests from people she knows well.\n- Berry stayed home from school for a few days.\n- WIRED ran the photos through the nonprofit True Media's detection tool to confirm they showed substantial evidence of manipulation.\n- WIRED has been tracking the use of generative AI in elections around the world.\n- Ngamita's team partnered with a European university to send pieces of content for verification.\n- Ngamita's team has been compiling a dataset of possible deepfake instances from across the continent for use by academics and researchers.\n- Witness runs a rapid response detection program to process and investigate incoming cases.\n- Brian May posted the deepfake clip on his official Instagram account to warn fans about the scam.\n- Fans were advised to purchase tickets only via official ticketing websites like Ticketmaster or the band's official website.\n- Reporters at the tech website 404 Media tracked a surge in apparently AI-generated posts on Facebook.\n- Researchers at Georgetown and Stanford universities investigated more than 100 Facebook pages that routinely posted AI-generated content.\n- Meta said it is working to reduce the spread of content that is spammy or sensational.\n- Meta offers users controls over what they see in their feeds.\n- Meta plans to begin labeling AI-generated content created with some industry-leading tools soon.\n- TikTok started applying labels to some AI-generated posts on its platform.\n- Brian Penny is part of a group dedicated to sharing and debunking AI-generated images.\n- The 18th Judicial District Attorney\u2019s Office searched Colorado court records and found no records corresponding to the purported case.\n- Local law enforcement officials searched their records and found no records corresponding with the purported case.\n- The Colorado Department of Corrections checked its inmate list and found no inmate named Harrison Engelbert.\n- The Littleton Police Department confirmed it did not investigate the crime described in the video and that none of the names used in the segment were people the department had interacted with.\n- Google reverse image searches of the photographs used in the video were run and did not turn up real results.\n- Google searches for news coverage from 2014 yielded no coverage of the alleged case.\n- Google searches revealed dozens of knock-off YouTube videos, TikToks, and webpages summarizing the original fake video.\n- Senator Ben Cardin ended the call when he determined the individual was not who they claimed to be.\n- Cardin's office alerted the relevant authorities.\n- The matter was handed to law enforcement and a comprehensive investigation is underway.\n- Committee staff were instructed to exercise an extra degree of caution with external communications.\n- Committee staff were instructed to pay particularly close attention to the numbers and emails of incoming individuals claiming to be powerful people.\n- Dmytro Kuleba issued a statement warning people to stay alert.\n- Kuleba advised people to always verify the source and not tell the truth to strangers.\n- The Hangzhou Public Security Bureau held a press conference on September 13 to disclose details of the case.\n- In June, Hangzhou cyber police discovered a criminal gang using AI face-swapping on overseas platforms to bypass login authentication and harvest user information.\n- Following investigation by municipal and district public security organs, police successfully identified the four suspects.\n- In August, the special task force arrested the four suspects in Anhui, Guizhou, and Zhejiang and placed them under criminal detention.\n- The police warned the public to secure personal devices such as phones and computers and to avoid clicking unknown links.\n- The police urged enterprise platforms to accelerate upgrades and add optical and other facial authentication functions to better protect privacy.\n- As part of the summer security crackdown, Hangzhou police dismantled 235 criminal gangs.\n- During the operation, Hangzhou police arrested more than 10,000 suspects.\n- During the operation, Hangzhou police captured 632 fugitives.\n- During the operation, Hangzhou police solved over 4,000 cases.\n- The Office of the Victorian Information Commissioner issued a compliance notice to the Department of Families, Fairness and Housing to ban the use of generative AI tools.\n- The Office of the Victorian Information Commissioner issued a compliance notice requiring the department to technically block internal access to generative AI tools.\n- OVIC gave the department until November 5 to implement technical controls blocking access to web-based or external API-based generative AI text tools including ChatGPT, ChatSonic, Claude, Copy.AI, Meta AI, Grammarly, HuggingChat, Jasper, NeuroFlash, Poe, ScribeHow, QuillBot, Wordtune, Gemini, and Microsoft 365 Copilot.\n- The department conducted an internal review of cases handled by the case worker's unit over a one-year period and identified 100 cases with indicators that ChatGPT may have been used to draft child protection related documents.\n- The case worker involved in the incident is no longer employed by the department.\n- In a letter to OVIC, the department accepted that there was an unauthorised use of ChatGPT when developing the child protection report.\n- School districts scrambled to slash programs.\n- School districts redid their budgets.\n- Infinite Campus removed race, gender and birth country as factors from its model before the current school year.\n- Infinite Campus offered some broad insights into how its model works.\n- The Carson City district created a new position at each school to help students struggling with academics or behavior.\n- After the publication of the report, TikTok removed at least one account that Media Matters had identified as posting seemingly AI-generated English-language Hitler speeches.\n- TikTok removed some of the videos that Media Matters identified containing the AI-generated Hitler audios.\n- TikTok removed another account that Media Matters had identified as seemingly dedicated to posting reconstructed Hitler speech audios.\n- TikTok removed a specific AI-generated Hitler audio that had been used at least 251 times prior to its removal.\n- TikTok removed another AI-generated Hitler audio that had been used at least 55 times prior to its removal.\n- ISD identified and recorded a list of 200 pro-Nazi TikTok accounts.\n- ISD reported a sample of 50 of those accounts to TikTok for hate speech and guideline violations.\n- ISD created and used dummy TikTok accounts to explore the For You Page and test algorithmic recommendations.\n- ISD followed dozens of the accounts to gain access to private videos and content on channels set to private.\n- TikTok banned 15 of the reported accounts two weeks after ISD's reports.\n- TikTok had banned 23 of the reported 50 accounts after one month.\n- TikTok eventually banned a specific account that remained active for over a week after ISD reported it for hate speech.\n- TikTok banned an account soon after it advertised its backup account.\n- TikTok banned one channel at least four times, after which the user posted on Telegram to promote their new TikTok account.\n- TikTok takes down accounts or videos individually rather than addressing a wider network as an aggregate.\n- TikTok sometimes issues final warnings to users.\n- TikTok banned one analyzed account before the report's completion.\n- Otter.ai responded publicly on X to Alex Bilzerian's thread about the transcript being shared.\n- Otter.ai stated that users have full control over conversation sharing permissions and can change, update, or stop the sharing permissions of a conversation at any time.\n- Otter.ai shared a link to a help guide showing how users can change their auto-share settings.\n- The unnamed investors profusely apologized to Alex Bilzerian after he brought the transcript to their attention.\n- Alex Bilzerian decided to kill the deal after receiving the transcript.\n- Otter and Zoom publicly advised users to adjust their settings to avoid unwanted sharing.\n- Otter strongly recommended asking for consent when using the tool in meetings.\n- Students came forward to report that the altered images were being shared online.\n- School officials discovered the doctored photos after students reported them.\n- The Winnipeg Police Service conducted an investigation into the incident.\n- The Winnipeg Police Service concluded the investigation and laid no charges.\n- The Louis Riel School Division said it plans to provide in-class presentations about responsible internet use and consent for students.\n- The Louis Riel School Division said it expects to organize presentations for parents in the coming weeks.\n- Officials said the explicitly altered images received by the school would be uploaded to Project Arachnid to help get them deleted.\n- A Starship employee asked police for the victim's contact information so he could contact her and offer their insurance information and promo codes.\n- Starship offered the victim its insurance information and promo codes for use on the service.\n- The Tempe Fire Department treated the injured employee at the scene.\n- Another employee took the injured worker to the campus medical center after she declined medical assistance on-scene.\n- Police obtained video footage of the incident that corroborated the employee's recollection.\n- Starship stated that the case was thoroughly investigated at the time.\n- Starship said its insurer is handling the matter.\n- Starship initially asked police not to charge the student involved in the robot theft/return.\n- Starship later changed its position and asked police to arrest that student.\n- In the dorm-room incident, Starship initially told police it would not aid in prosecution.\n- Nine days later, Starship called police and decided it wished to aid in prosecution of the students.\n- Starship provided police with information about the robot's movement and said it had evidence depicting vertical movement.\n- Police arrested the two students on felony theft charges based on the evidence.\n- Police obtained video from the Barstool Tempe TikTok account showing the robot in the dorm (that footage was later deleted).\n- Character.AI said that the character violated its policies against impersonation.\n- Character.AI removed the character that used Jennifer Ann Crecente's likeness.\n- Character.AI said it will examine whether further action is warranted.\n- Drew Crecente opened a case with Character.AI.\n- Drew Crecente received confirmation of an investigation from Character.AI as of 9:51 a.m.\n- After reviewing The Post's findings, Miami police and local prosecutors announced plans to revise their policies to require clearer disclosure in every case involving facial recognition.\n- Miami Police Department said it would give prosecutors all information on the use of facial recognition in past and future cases.\n- Miami Police Department said it would begin training officers to always disclose the use of facial recognition in incident reports.\n- The Miami-Dade state attorney's office instructed all local police departments to include information about facial recognition in public reports.\n- The Miami-Dade state attorney's office said prosecutors would be proactive in asking police whether identifications were made with AI.\n- The Miami-Dade state attorney's office said it would work on a policy moving forward rather than commit to reviewing all 186 identified cases.\n- In response to The Post's reporting, Austin rewrote its policy to outlaw the practice of enlisting neighboring law enforcement agencies to circumvent local facial recognition bans.\n- Prosecutors in New Jersey reduced the charges against Francisco Arteaga as a result.\n- Charges were later dismissed against at least seven people who had been wrongfully arrested after misidentification by facial recognition.\n- A judge excluded a facial recognition result from the state's case against an alleged thief after ruling the software does not consistently produce accurate results.\n- Francisco Arteaga filed a motion seeking detailed information about the facial recognition software used to identify him, including its name, manufacturer, algorithms, error rates, source code, analyst qualifications, the mugshot database, and any alterations to surveillance stills.\n- After the trial judge denied the motion, Arteaga appealed the decision to the appellate court.\n- A three-judge state appellate panel ruled in June 2023 that Arteaga was entitled to discovery of the facial recognition materials and returned the case to the trial court directing the judge to order prosecutors to provide those materials.\n- Prosecutors chose not to appeal the appellate ruling.\n- Arteaga pleaded guilty to the charges to secure his release after nearly four years in pretrial detention.\n- Since his release in November, Arteaga has studied holistic medicine online.\n- Since his release in November, Arteaga has sold health and nutrition products.\n- Since his release in November, Arteaga has worked as a gym teacher at a senior citizens' center in Queens.\n- Since his release in November, Arteaga has moved to Union City to better accommodate monthly meetings with his parole agent.\n- Since his release in November, Arteaga has met with his son and fianc\u00e9e every few weeks.\n- In February 2022, the New Jersey Attorney General's office began soliciting public input about facial recognition technology to help shape a statewide policy on its use by law enforcement agencies.\n- Several lawsuits were filed against the New York Police Department over its use of facial recognition technology.\n- In 2022, a court ordered the New York Police Department to release records about its use of facial recognition technology.\n- Former New Jersey Attorney General Gurbir Grewal banned Clearview AI in 2020.\n- FEMA created and published a webpage dedicated to dispelling rumors about Hurricane Helene.\n- Local print, television, and radio newsrooms conducted extensive coverage of Hurricane Helene and its aftermath.\n- Local newsrooms devoted part of their efforts to debunking rumors promoted by nonlocal actors on national platforms.\n- Legacy media organizations swatted back disinformation by fact-checking and correcting false claims and images about the storm.\n- News outlets examined viral images, identified AI-generated errors (such as a man with six fingers and three nostrils), and exposed those images as fake.\n- The video was taken down from Facebook.\n- Fans questioned the video's authenticity and sent it to fitness influencer Ben Carpenter.\n- Ben Carpenter examined the video and determined the clip originally came from a Hollywood Reporter roundtable interview.\n- Ben Carpenter reported the video after it had accumulated over 700,000 views.\n- Platforms removed the video once notified that it was not authentic or authorized.\n- California Gov. Gavin Newsom signed two bills, AB 1836 and AB 2602, restricting the usage of AI to create digital replicas of deceased performers without estate consent and increasing consent requirements for living performers.\n- California Gov. Gavin Newsom vetoed the bill SB 1047.\n- Cato CTRL security researchers discovered the threat actor ProKYC selling a deepfake tool.\n- Cato CTRL published a blog that includes a demo of ProKYC\u2019s deepfake tool and outlines potential detection, mitigation, and prevention techniques.\n- Cato CTRL recommends collecting threat intelligence (including HUMINT and OSINT) and staying up to date on the latest cybercrime trends.\n- The report advises that high-quality pictures and videos and glitches in facial parts or inconsistent eye and lip movement should be treated as suspicious and manually verified by a human.\n- Cato CTRL stated it will continue to share these findings to help organizations be aware of the latest threats.\n- The attendee immediately emailed the conference host to report the edited photo.\n- The conference host immediately looked into the issue.\n- The host quickly reported back that the woman running their social media had used a cropped square image from their website.\n- The conference host apologized for the incident.\n- The conference organizers apologized for the incident.\n- The conference organizers took down all of the content that used that photo.\n- \u767e\u5ea6\u5728\u4e8b\u6545\u53d1\u751f\u540e\u7b2c\u4e00\u65f6\u95f4\u914d\u5408\u8b66\u65b9\u5904\u7f6e\u3002\n- \u767e\u5ea6\u966a\u540c\u5e76\u9001\u4f24\u8005\u5230\u533b\u9662\u8fdb\u884c\u68c0\u67e5\u3002\n- \u4f24\u8005\u76ee\u524d\u6b63\u5728\u533b\u9662\u8fdb\u4e00\u6b65\u89c2\u5bdf\u548c\u4f11\u606f\u3002\n- \u6b66\u6c49\u7ecf\u5f00\u533a\u7ba1\u59d4\u4f1a\u786e\u8ba4\u6d89\u8bc9\u8f66\u8f86\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6d4b\u8bd5\u8f66\u3002\n- \u6b66\u6c49\u7ecf\u5f00\u533a\u7ba1\u59d4\u4f1a\u8868\u793a\u8be5\u8f66\u8f86\u6b63\u5728\u8c03\u8bd5\u4e2d\u3002\n- \u5f00\u53d1\u533a\u4ea4\u901a\u5927\u961f\u5c06\u5b9a\u671f\u4e0e\u516c\u53f8\u8d1f\u8d23\u4eba\u6c9f\u901a\u5e76\u53cd\u6620\u95ee\u9898\u4ee5\u786e\u4fdd\u9053\u8def\u5b89\u5168\u3002\n- \u767e\u5ea6\u57282022\u5e74\u53d1\u751f\u6d4b\u8bd5\u8f66\u8ffd\u5c3e\u4e8b\u6545\u540e\u7b2c\u4e00\u65f6\u95f4\u4e0a\u62a5\u7ed9\u76f8\u5173\u76d1\u7ba1\u90e8\u95e8\u5907\u6848\u3002\n- \u5317\u4eac\u5e02\u7ecf\u4fe1\u5c40\u5bf9\u5916\u5f81\u6c42\u300a\u5317\u4eac\u5e02\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u6761\u4f8b\uff08\u5f81\u6c42\u610f\u89c1\u7a3f\uff09\u300b\u7684\u610f\u89c1\u3002\n- \u8be5\u610f\u89c1\u7a3f\u63d0\u51fa\u5e76\u660e\u786e\u4e86\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u5458\u7684\u8fdc\u7a0b\u503c\u5b88\u548c\u65e0\u4eba\u9a7e\u9a76\u4e8b\u6545\u8d23\u4efb\u8ba4\u5b9a\u89c4\u5219\u3002\n- Fifteen human rights groups launched legal action against the French government challenging its welfare-payment detection algorithm, filing litigation with France\u2019s top administrative court on October 15.\n- Summit County prosecutors decided not to use Cybercheck as evidence in Phillip Mendoza's trial.\n- The Summit County Prosecutor's Office withdrew Cybercheck reports in three other murder cases.\n- The Summit County Sheriff's Office confirmed it is investigating whether Adam Mosher lied under oath.\n- Judges overseeing several murder trials ruled that Cybercheck reports cannot be admitted as evidence unless Global Intelligence grants defendants access to its source code.\n- The Summit County Prosecutor's Office appealed the trial-court rulings that excluded Cybercheck reports.\n- Prosecutors in other jurisdictions decided not to use Cybercheck reports.\n- Prosecutors in other jurisdictions dropped charges against defendants after defense attorneys scrutinized Cybercheck findings and Mosher's testimony.\n- Midland County assistant district attorney Lisa Borden decided not to use Mosher's testimony or the Cybercheck report at Sergio Cerna's trial.\n- Colorado prosecutors dropped the charges and sealed the file against a defendant in a child sexual abuse material case after questions about Mosher and Cybercheck.\n- Defense attorney Donald Malarcik filed a motion asking the prosecutor to provide Cybercheck's software for review in another case.\n- Donald Malarcik subpoenaed Adam Mosher.\n- Donald Malarcik hired a digital forensics expert to review Cybercheck's code and the two Cybercheck reports about Mendoza.\n- Donald Malarcik requested a Daubert hearing to determine whether Mosher's testimony about Cybercheck's findings was admissible.\n- The Ohio Bureau of Criminal Investigation decided it has no intentions of entering into another contract with Global Intelligence.\n- The Yakima County Sheriff's Office stopped using Cybercheck despite retaining access to the system.\n- At WIRED's request, Rob Lee and a team of researchers at the SANS Institute reviewed Cybercheck reports and descriptions of the system.\n- Defense attorney Eric Zale hired private investigators to investigate Adam Mosher's background.\n- Canadian prosecutors contacted the Boulder County prosecutor to say that Adam Mosher had never been called to testify in the Canadian cases Mosher referenced.\n- A Global Intelligence employee said law enforcement works with industry analysts and open-source intelligence experts who manually replicate and backstop intelligence data from Cybercheck reports.\n- The Summit County Prosecutor's Office began asking other companies whether they could provide similar open-source locating services to those Global Intelligence marketed.\n- X added labels beneath the video indicating the content had been manipulated.\n- The X account's post containing the video was deleted.\n- A senior aide to Tim Walz contacted Matthew Metro after the video's publication.\n- Walz's campaign team investigated the video and determined that Metro was not the person featured in it.\n- The Harris-Walz campaign confirmed that it had contacted Metro.\n- Juanita Broaddrick deleted her post about the video.\n- Hany Farid's team analyzed the video with a computer-assisted detection tool and reported finding no evidence of generative AI.\n- Siwei Lyu's students analyzed the video and reported no clear evidence it was made or manipulated with AI.\n- Oren Etzioni's firm True Media analyzed the clip and detected significant evidence of audio manipulation.\n- Matthew Metro showed his Hawaii driver's license to The Washington Post to confirm his identity.\n- Techdirt called Hoodline out for the cataclysmic error.\n- Techdirt first reported the false accusation on its site.\n- Mike Masnick discovered the false AI accusation when the Hoodline piece appeared in his Google News tab.\n- Hoodline published an editor's note at the top of the article attributing the flub to a typo that it said unfortunately changed the meaning of its content.\n- The editor's note said the typo created ambiguity about the fact that the DA and the accused are two different people.\n- Character.AI expressed its deepest condolences to the family of the deceased in an emailed statement.\n- Character.AI declined to comment on ongoing litigation.\n- Character.AI said it has implemented new safety measures in the past six months.\n- Character.AI implemented a pop-up that directs users to a suicide prevention lifeline which is triggered by terms of self-harm or suicidal ideation.\n- Character.AI said it will make changes to its models for users under 18 to reduce the chances of encountering sensitive or suggestive content.\n- A detective called the boy's mother to inform her about her son's messaging with AI bots.\n- Garcia replayed the last ten months of her son's activity and reviewed his chat logs.\n- Garcia filed a 93-page wrongful-death lawsuit in U.S. District Court in Orlando.\n- A Google spokesperson stated that the company was not involved in the development of Character.AI's products and has not used Character.AI's technology in their products.\n- OpenAI said it continually studies how to reduce hallucinations in its models.\n- OpenAI said it incorporates feedback from researchers into model updates.\n- OpenAI recommended in its online disclosures against using Whisper in decision-making contexts where flaws in accuracy can lead to pronounced flaws in outcomes.\n- Experts, advocates and former OpenAI employees called for the federal government to consider AI regulations.\n- Nabla acknowledged that Whisper can hallucinate and said it is addressing the problem.\n- Nabla requires medical providers to quickly edit and approve AI-generated transcribed notes.\n- Nabla erases the original audio recordings for data safety reasons.\n- California state lawmaker Rebecca Bauer-Kahan refused to sign a form permitting her child's consultation audio to be shared with vendor companies.\n- The program's production told El Observador that it had clarified the issue with the Frente Amplio.\n- The production reproduced the Orsi speeches used to build the AI model to demonstrate the content was not invented.\n- The virtual image of the candidate was shown with an on-screen legend stating it was created using AI.\n- The production limited the AI-generated Orsi's participation to a brief 'talking bust' that only pronounced a few basic phrases.\n- Alejandro 'Pacha' S\u00e1nchez publicly warned the population to be very careful about a possible AI-generated fake interview.\n- S\u00e1nchez and the Orsi campaign announced they were denouncing that, if such an interview existed, it would cause a great harm to democracy.\n- Officials deactivated the facial recognition feature during the COVID-19 pandemic in 2020.\n- The facial recognition system has remained turned off due to precautionary measures imposed by the judiciary.\n- The city of Buenos Aires initiated a legal battle to have the facial recognition system switched back on.\n- A judge ordered a judiciary investigation into the facial recognition system.\n- IT specialists, acting on a court order, searched the servers of the Ministry of Security as part of the investigation.\n- The judiciary produced a confidential investigation report that was signed off by two different police bodies.\n- The reporters initiated a legal inquiry with the assistance of a lawyer at the Contentious, Administrative and Tax Court of the Autonomous City of Buenos Aires to request their personal data.\n- The reporters filed a second inquiry with a public prosecutor's office specializing in corruption cases about their personal data.\n- The public prosecutor's office confirmed the city's requests for the reporters' personal data and provided the dates and times of those requests.\n- The reporters filed a FOIA request to the Ministry of Security after receiving no response from the Ministry's press office.\n- The reporters objected to the city's FOIA refusal and are awaiting a new response.\n- Jakob Rosin informed the sports club about the incorrect screen reader description.\n- Jakob Rosin helped the Estonian sports club fix the software issue on its website.\n- The sports club chose not to use AI on its website.\n- The National Federation of the Blind tries to work with companies to improve their digital products before pursuing legal action.\n- Software companies have begun to push AI-driven products to comply with upcoming European accessibility legislation.\n- Several businesses are providing bespoke services rather than automated overlays to create more compliant websites.\n- Level Access acquired overlay maker UserWay.\n- Level Access's founder addressed criticisms of UserWay's technology.\n- Level Access promised accuracy and transparency in its marketing.\n- Many reputable accessibility companies aim to be more transparent about the limitations of AI.\n- EqualWeb stated that the links with its overlay enabled on Zara's website are compliant with accessibility standards.\n- The New York Police Department released a four-sentence statement reporting it had performed 2,749 scans at 20 stations during the 30-day pilot.\n- A police spokesperson said they were still evaluating the outcome of the pilot.\n- NYPD officials said they had not entered into any contract with Evolv.\n- The Legal Aid Society issued a statement calling for the program to be shelved and declaring the pilot a failure.\n- CBS ran the song through multiple AI audio detection tools and reported several results indicating the audio, or at least parts of it, were likely AI-generated.\n- Pindrop stated that their detection technology is often coupled with independent fact-checking to determine whether an image or piece of audio is made with AI.\n- Pindrop launched the Pindrop Pulse tool for social media and reported people entering about 10,000 suspicious files per month to check for deepfakes.\n- Pindrop labeled media files as synthetic versus not synthetic to identify AI-generated content.\n- Representatives for Justin Bieber did not respond to a request for comment about the song.\n- Justin Bieber and his PR team chose not to publicly address the deepfake.\n- The head of Radio Krakow pulled the plug on the A.I. experiment.\n- He announced an abrupt termination of the A.I. presenters at Off Radio Krakow.\n- The A.I. presenters were replaced by music created and performed by humans.\n- The station clarified that the purported interview with Wislawa Szymborska had been fabricated by a machine.\n- A biography on the station's website was rewritten to delete any mention of the presenter's sexual orientation.\n- An online petition was drafted by Lukasz Zaleski and Mateusz Demski warning that the case of Off Radio Krakow is a dangerous precedent.\n- A member of the National Radio and Television Council, Marzena Paczuska, wrote a letter to the culture minister assailing Mariusz Pulit for eliminating the human factor.\n- The minister of digitalization, Krzysztof Gawkowski, complained on the social media platform X that certain boundaries are being crossed in the use of A.I.\n- Off Radio Krakow removed the A.I. presenter Alex Szulc.\n- Off Radio Krakow removed the A.I. presenter Emilia Nowak.\n- \u516c\u5b89\u90e8\u516c\u5e03\u4e8610\u8d77\u6253\u51fb\u6574\u6cbb\u7f51\u7edc\u8c23\u8a00\u8fdd\u6cd5\u72af\u7f6a\u7684\u5178\u578b\u6848\u4f8b\u3002\n- \u5bf9\u767d\u67d0\u67d0\u5df2\u63d0\u8d77\u516c\u8bc9\u3002\n- \u9e70\u6f6d\u5e02\u4f59\u6c5f\u533a\u4eba\u6c11\u6cd5\u9662\u5bf9\u88ab\u544a\u4eba\u738b\u67d0\u5408\u5224\u5904\u6709\u671f\u5f92\u5211\u4e09\u5e74\uff0c\u7f13\u5211\u4e94\u5e74\u3002\n- \u6700\u9ad8\u4eba\u6c11\u6cd5\u9662\u3001\u6700\u9ad8\u4eba\u6c11\u68c0\u5bdf\u9662\u3001\u516c\u5b89\u90e8\u8054\u5408\u53d1\u5e03\u4e86\u300a\u5173\u4e8e\u4f9d\u6cd5\u60e9\u6cbb\u7f51\u7edc\u66b4\u529b\u8fdd\u6cd5\u72af\u7f6a\u7684\u6307\u5bfc\u610f\u89c1\u300b\uff0c\u5e76\u660e\u786e\u5bf9\u5229\u7528\u6df1\u5ea6\u5408\u6210\u7b49\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53d1\u5e03\u8fdd\u6cd5\u4fe1\u606f\u7684\u60c5\u5f62\u4e88\u4ee5\u4ece\u91cd\u5904\u7f5a\u3002\n- \u5317\u4eac\u4e92\u8054\u7f51\u6cd5\u9662\u4e00\u5ba1\u8ba4\u5b9a\u88ab\u544a\u4f7f\u7528\u539f\u544a\u58f0\u97f3\u5f00\u53d1\u6d89\u6848AI\u6587\u672c\u8f6c\u8bed\u97f3\u4ea7\u54c1\u6784\u6210\u4fb5\u6743\uff0c\u5224\u4ee4\u8d54\u507f\u539f\u544a25\u4e07\u5143\u5e76\u4e66\u9762\u8d54\u793c\u9053\u6b49\u3002\n- \u6c5f\u82cf\u7701\u5f20\u5bb6\u6e2f\u5e02\u4eba\u6c11\u68c0\u5bdf\u9662\u5411\u5e02\u4eba\u6c11\u6cd5\u9662\u5c31\u4e00\u8d77\u6572\u8bc8\u52d2\u7d22\u3001\u8bc8\u9a97\u6848\u4ef6\u63d0\u8d77\u516c\u8bc9\u3002\n- \u5404\u5730\u68c0\u5bdf\u673a\u5173\u6309\u7167\u6700\u9ad8\u68c0\u76f8\u5173\u8981\u6c42\u52a0\u5927\u5bf9\u975e\u6cd5\u83b7\u53d6\u4eba\u8138\u3001\u58f0\u7eb9\u7b49\u654f\u611f\u4fe1\u606f\u4ee5\u53ca\u5229\u7528AI\u4f2a\u9020\u4eba\u8138\u3001\u58f0\u7eb9\u7b49\u72af\u7f6a\u7684\u6253\u51fb\u529b\u5ea6\u3002\n- \u5168\u56fd\u516c\u5b89\u673a\u5173\u4f9d\u6258\u201c\u51c0\u7f51\u201d\u4e13\u9879\u884c\u52a8\u7ec4\u7ec7\u4e13\u9879\u4f1a\u6218\u6253\u51fb\u76f8\u5173\u72af\u7f6a\u3002\n- \u5168\u56fd\u516c\u5b89\u673a\u5173\u5728\u201c\u51c0\u7f51\u201d\u4e13\u9879\u884c\u52a8\u4e2d\u7834\u83b7\u5229\u7528AI\u6362\u8138\u8fdb\u884c\u8bc8\u9a97\u72af\u7f6a\u6848\u4ef679\u8d77\u5e76\u6293\u83b7515\u540d\u72af\u7f6a\u5acc\u7591\u4eba\u3002\n- \u653f\u6cd5\u673a\u5173\u4f9d\u6cd5\u5c65\u804c\u5e76\u6301\u7eed\u6df1\u6316\u5f7b\u67e5AI\u72af\u7f6a\u3002\n- \u653f\u6cd5\u673a\u5173\u4e0d\u65ad\u6269\u5927\u529e\u6848\u6218\u679c\u5e76\u52aa\u529b\u63d0\u5347\u6253\u51fb\u6cbb\u7406\u8d28\u6548\u3002\n- \u653f\u6cd5\u673a\u5173\u4f1a\u540c\u76f8\u5173\u90e8\u95e8\u6df1\u5165\u63a8\u8fdb\u884c\u4e1a\u6cbb\u7406\u548c\u7efc\u5408\u6cbb\u7406\u3002\n- \u6709\u5173\u90e8\u95e8\u538b\u5b9e\u4e3b\u4f53\u8d23\u4efb\u4ee5\u5f3a\u5316\u884c\u4e1a\u6cbb\u7406\u3002\n- \u6709\u5173\u90e8\u95e8\u5f3a\u5316\u884c\u4e1a\u76d1\u7763\u5e76\u5835\u4f4f\u76d1\u7ba1\u6f0f\u6d1e\u3002\n- \u6709\u5173\u90e8\u95e8\u52a0\u901f\u5b8c\u5584\u5e38\u6001\u5316\u6cbb\u7406\u673a\u5236\u4ee5\u63d0\u9ad8\u8fdd\u6cd5\u6210\u672c\u3002\n- \u5168\u56fd\u516c\u5b89\u673a\u5173\u8054\u5408\u56fd\u5bb6\u91cd\u70b9\u5b9e\u9a8c\u5ba4\u7b49\u5355\u4f4d\u5f00\u5c55\u4e86\u9762\u5411\u5373\u65f6\u901a\u4fe1\u3001\u7f51\u7edc\u76f4\u64ad\u3001\u7f51\u7edc\u793e\u4ea4\u3001\u7535\u5546\u5e73\u53f0\u3001\u91d1\u878d\u652f\u4ed8\u7b49\u91cd\u70b9App\u7684\u4eba\u8138\u8bc6\u522b\u4e0e\u6d3b\u4f53\u68c0\u6d4b\u6280\u672f\u5b89\u5168\u6d4b\u8bc4\u3002\n- \u516c\u5b89\u673a\u5173\u901a\u62a5\u8fd0\u8425\u4e3b\u4f53\u5347\u7ea7\u5b89\u5168\u4fdd\u62a4\u63aa\u65bd\u5e76\u8981\u6c42\u5347\u7ea7\u4eba\u8138\u8bc6\u522b\u7b97\u6cd5\u3002\n- \u5404\u5730\u901a\u8fc7\u591a\u79cd\u5f62\u5f0f\u5f00\u5c55\u5ba3\u4f20\u6559\u80b2\u4ee5\u63d0\u9ad8\u516c\u4f17\u5bf9AI\u88ab\u5229\u7528\u6216\u6ee5\u7528\u5e26\u6765\u6cd5\u5f8b\u98ce\u9669\u7684\u8ba4\u8bc6\u3002\n- \u5408\u80a5\u8b66\u65b9\u901a\u8fc7\u4e2d\u592e\u5a92\u4f53\u8282\u76ee\u63ed\u79d8\u8c23\u8a00\u5236\u4f5c\u8fc7\u7a0b\u4ee5\u5f00\u5c55\u5ba3\u4f20\u6559\u80b2\u3002\n- \u676d\u5dde\u5e02\u4e34\u5e73\u533a\u501f\u52a9\u201c\u53cd\u8bc8\u667a\u80fdAI\u5ba3\u9632\u5916\u547c\u7cfb\u7edf\u201d\u81ea\u52a8\u8bc6\u522b\u3001\u5206\u6790\u548c\u9884\u8b66\u6f5c\u5728\u8bc8\u9a97\u98ce\u9669\uff0c\u5e76\u4ee5\u7535\u8bdd\u8bed\u97f3\u5f62\u5f0f\u5411\u5e02\u6c11\u53d1\u9001\u63d0\u9192\u4fe1\u606f\u3002\n- \u516c\u5b89\u673a\u5173\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u67e5\u660e\u6768\u67d0\u67d0\u5229\u7528AI\u8f6f\u4ef6\u751f\u6210\u5e76\u53d1\u5e03\u201c\u4e91\u5357\u5c71\u4f53\u6ed1\u5761\u81f48\u4eba\u9047\u96be\u201d\u7684\u865a\u5047\u65b0\u95fb\u4fe1\u606f\u3002\n- \u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u6768\u67d0\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u516c\u5b89\u673a\u5173\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u67e5\u660e\u7f57\u67d0\u67d0\u5229\u7528AI\u8f6f\u4ef6\u751f\u6210\u865a\u5047\u5730\u9707\u707e\u60c5\u56fe\u7247\u5e76\u5728\u77ed\u89c6\u9891\u5e73\u53f0\u6563\u5e03\u4e0d\u5b9e\u4fe1\u606f\u3002\n- \u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u7f57\u67d0\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u516c\u5b89\u673a\u5173\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u67e5\u660e\u7530\u67d0\u5229\u7528AI\u5de5\u5177\u52a0\u5de5\u751f\u6210\u5e76\u53d1\u5e03\u201c\u6f84\u57ce\u53bf\u4e00\u5987\u5973\u7535\u52a8\u8f66\u88ab\u67e5\u6263\u731d\u6b7b\u201d\u7684\u865a\u5047\u4fe1\u606f\u3002\n- \u7530\u67d0\u5bf9\u81ea\u5df1\u901a\u8fc7AI\u8f6f\u4ef6\u7f16\u9020\u8c23\u8a00\u7684\u60c5\u51b5\u4f9b\u8ba4\u4e0d\u8bb3\u3002\n- \u516c\u5b89\u673a\u5173\u4f9d\u6cd5\u5bf9\u7530\u67d0\u5904\u4ee5\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u7f51\u8b66\u79ef\u6781\u884c\u52a8\uff0c\u4e25\u5389\u6574\u6cbb\u6d89AI\u7c7b\u7f51\u7edc\u8c23\u8a00\u3002\n- \u56db\u5ddd\u7f51\u8b66\u516c\u5e03\u4e8610\u8d77AI\u9020\u8c23\u5178\u578b\u6848\u4f8b\u3002\n- \u56db\u5ddd\u5e7f\u5143\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u6768\u67d0\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u51c9\u5c71\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u7f57\u67d0\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u5df4\u4e2d\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u5c1a\u67d0\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u6210\u90fd\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u5f20\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u8fbe\u5dde\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u5468\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u6210\u90fd\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u9648\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u7ef5\u9633\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u738b\u67d0\u548c\u67f3\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u6210\u90fd\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u6731\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u51c9\u5c71\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u5409\u67d0\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u56db\u5ddd\u6210\u90fd\u516c\u5b89\u673a\u5173\u5df2\u4f9d\u6cd5\u5bf9\u738b\u67d0\u8fdb\u884c\u884c\u653f\u5904\u7f5a\u3002\n- \u5468\u67d0\u901a\u8fc7\u62db\u52df\u83b7\u53d6\u7684300\u4f59\u4e2a\u76f8\u5173\u8d26\u53f7\u5747\u5df2\u5173\u505c\u3002\n- \u5468\u67d0\u5229\u7528AI\u5de5\u5177\u7f16\u9020\u7684\u7ea642\u4e07\u4f59\u6761\u865a\u5047\u4fe1\u606f\u5747\u5df2\u6e05\u9664\u3002\n- \u7f51\u8b66\u53d1\u5e03\u63d0\u9192\uff0c\u547c\u5401\u516c\u4f17\u4e0d\u9020\u8c23\u3001\u4e0d\u4fe1\u8c23\u3001\u4e0d\u4f20\u8c23\uff0c\u5171\u5efa\u6e05\u6717\u7f51\u7edc\u7a7a\u95f4\u3002\n- CNN's senior vice president of communications, Emily Kuhn, told AFP in a November 4 email that the image was completely fabricated and manipulated and never aired on any CNN platform.\n- CNN posted a matching statement to X denying that the graphic ever aired on the network.\n- AFP reached out to the X user who first shared the fake image for comment.\n- AFP published a fact-check debunking the image as inauthentic and documenting signs of digital editing and arithmetic errors.\n- AFP stated that it has debunked other misinformation about the election and provided a list of such fact-checks.\n- Microsoft recalled the Windows Recall feature to beef up its encryption.\n- Microsoft and other AI providers include a small-print disclaimer advising users to 'Always check AI answers for accuracy.'\n- He ignored the account recovery notifications and a missed call apparently from Google Sydney.\n- He Googled the phone number the call was coming from to check its legitimacy.\n- He asked the caller to send him an email.\n- He inspected the received email and noticed the sender address was not from a Google domain.\n- He hung up the call after recognizing the voice as an AI.\n- He wrote a blog post recounting the incident to warn others about the scam.\n- The posters were quickly removed from bus stops in Chisinau.\n- Telegram suspended Ilan Shor's 'Stop EU' channel for violating local laws.\n- Meta took down seven Facebook accounts linked to coordinated inauthentic behavior.\n- Meta took down one Facebook group linked to coordinated inauthentic behavior.\n- Meta took down 23 Facebook pages linked to coordinated inauthentic behavior.\n- Meta took down 20 Instagram accounts linked to coordinated inauthentic behavior.\n- Senator Benjamin L. Cardin sent letters to the executives of Meta and Alphabet urging them to enforce their policies against disinformation and incitement.\n- Microsoft tracked a multipronged Russian campaign targeted at Moldova that included hacks and leaks of government documents, denial-of-service attacks on government websites, and disinformation amplified by bots and inauthentic accounts.\n- A planned Chisinau concert by the Ukrainian singer Anastasia Prikhodko was canceled.\n- Moldova's Ministry of Culture dismissed the circulated letter demanding leave for an 'LGBT festival' as fake.\n- European Commission president Ursula von der Leyen visited Chisinau.\n- Ursula von der Leyen urged people in Moldova to vote during her visit to Chisinau.\n- Ursula von der Leyen pledged an economic support package worth nearly $2 billion for Moldova.\n- Economic development minister Dumitru Alaiba denounced the circulated video purporting to show him as a 'two-bit fake.'\n- Dumitru Alaiba publicly stated that the videos and photos are fake and alleged they were released by supporters of the Kremlin as part of Russian propaganda.\n- Dumitru Alaiba urged citizens to be vigilant because there will be many fakes, lies, and denigrations during the remaining campaign days.\n- Deputy Prime Minister Dumitru Alaiba instituted civil and criminal proceedings regarding the videos and photos.\n- Prime Minister Dorin Recean publicly described the images as fake and called those who shared them 'degenerates'.\n- Prime Minister Dorin Recean said he will follow the civil and criminal proceedings instituted by Deputy Prime Minister Dumitru Alaiba.\n- Daniel Swenson reset the vacuum's password after discovering it had been accessed.\n- Daniel Swenson contacted Ecovacs about his experience.\n- Daniel Swenson turned the robot vacuum off and never turned it back on.\n- The ABC employed white hat hacker Daniel Giese to replicate his findings about Ecovacs' vulnerabilities.\n- Daniel Giese demonstrated to ABC reporters how easy it was to watch live through the robot's remote-controlled lens.\n- Since the publication of the report, Ecovacs has claimed it resolved the vulnerability.\n- Dale and Jennifer Harris sued Hingham High School officials and the School Committee.\n- The parents sought a preliminary injunction requiring the school to change their son's grade and expunge the incident from his disciplinary record before he needs to submit college applications.\n- A US District Court magistrate issued an order rejecting the Harris' motion for a preliminary injunction.\n- The school gave the students failing grades on two parts of the multi-part project.\n- The school permitted each student to start from scratch and separately complete and submit the final project.\n- The school imposed a Saturday detention on RNH.\n- The school barred RNH from selection for the National Honor Society.\n- School officials ultimately allowed RNH into the National Honor Society after his parents filed the lawsuit.\n- The teacher ran the submitted script through Turnitin, which flagged portions as AI-generated.\n- The teacher examined the document's revision history and discovered that RNH had spent approximately 52 minutes on it.\n- The teacher ran the submission through the AI-detection tools Draft Back and Chat Zero, which also indicated that AI had been used.\n- US District Judge Angel Kelley issued final approval for a roughly $2.3 million settlement.\n- SafeRent will no longer use AI-powered scores to evaluate whether someone using housing vouchers would make a good tenant.\n- Under the settlement, SafeRent will no longer display a tenant screening score for applicants using housing vouchers nationwide.\n- Under the settlement, SafeRent cannot include a score when landlords use its \"affordable\" SafeRent Score model.\n- SafeRent's service cannot display recommendations on whether to \"accept\" or \"deny\" someone's application if they use housing vouchers.\n- The settlement requires landlords to evaluate renters who use housing vouchers based on their entire record rather than just using their SafeRent score.\n- The money collected as part of the settlement will go to Massachusetts-based rental applicants who used housing vouchers and weren't able to secure housing due to SafeRent's tenant score.\n- Google said the Gemini response violated its policies and that it has taken action to prevent similar outputs from occurring.\n- Google limited the inclusion of satirical and humor sites in their health overviews.\n- Google removed some of the search results that went viral.\n- Nisos shared its analysis of the coordinated inauthentic Twitter network with Twitter in early November.\n- Twitter removed the network of fake accounts after Nisos shared its research in early November.\n- Sophie Zhang alerted Facebook's teams responsible for stopping inauthentic activity after discovering the scheme to boost Hern\u00e1ndez's posts.\n- Facebook took down the operation that boosted Hern\u00e1ndez's Facebook posts nearly a year after Zhang alerted internal teams.\n- Facebook removed hundreds of fake accounts that were running a coordinated influence campaign to comment on and amplify positive content about Hern\u00e1ndez.\n- Facebook took down numerous pages running political ads supporting President Hern\u00e1ndez and attacking opposition candidates.\n- In April 2020, Twitter purged more than 3,100 accounts and 1.2 million tweets tied to the amplification of positive content designed to benefit President Juan Orlando Hern\u00e1ndez.\n- Facebook removed a troll farm of more than 1,000 inauthentic Facebook and Instagram accounts that were amplifying content supporting Nicaragua's ruling party ahead of the Nov. 7 election.\n- St Petersburg city authorities announced a probe into the incident involving an expert commission.\n- A criminal case into \"violation of traffic rules and operation of transport vehicles\" has been launched.\n- La familia de las dos chicas lo denunci\u00f3 penalmente.\n- Se inici\u00f3 una actuaci\u00f3n contravencional contra el imputado por hostigamiento agravado por violencia de g\u00e9nero.\n- El fiscal lo imput\u00f3 por lesiones graves calificadas por violencia de g\u00e9nero.\n- El fiscal orden\u00f3 un allanamiento en la casa del imputado.\n- Durante el allanamiento las autoridades encontraron la computadora y el celular del imputado desde donde se cre\u00f3 y gestion\u00f3 el material.\n- Se rastre\u00f3 la direcci\u00f3n IP que identifica el domicilio del autor de las fotos.\n- A una de las v\u00edctimas se le realiz\u00f3 una pericia psiqui\u00e1trica.\n- El imputado permaneci\u00f3 en libertad con restricci\u00f3n de acercamiento con las denunciantes.\n- El fiscal se dispon\u00eda a indagar al imputado.\n- La comisi\u00f3n encargada del anteproyecto de Reforma del C\u00f3digo Penal se reuni\u00f3 y avanz\u00f3 en la inclusi\u00f3n de delitos relacionados con la inteligencia artificial en el proyecto.\n- El proyecto que incluye a la IA en las tipificaciones del C\u00f3digo Penal fue anunciado para ser elevado al Congreso de la Naci\u00f3n.\n- The student's grade was ultimately changed after the AI-detection flag.\n- The professor issued the student a strict warning that if her work was flagged again it would be treated the same as plagiarism.\n- Olmsted screen-recorded herself on her laptop while doing writing assignments to document her work.\n- Olmsted used Google Docs to track her changes and create a digital paper trail for assignments.\n- Olmsted attempted to tweak her vocabulary and syntax to avoid future AI-detection flags.\n- A student began prescreening his work with GPTZero before submitting assignments.\n- Some students uninstalled Grammarly plug-ins from their computers in response to AI-detection concerns.\n- Some students used AI 'humanizer' services to automatically rewrite submissions to try to bypass AI detectors.\n- Grammarly developed a detection tool for students that identifies whether text was typed, pasted, or written by an AI model.\n- Turnitin said it is working to expand its AI product portfolio with a service to help students show the process of how they put together their written assignments.\n- Most schools that work with Copyleaks began giving students access to the service so students can authenticate themselves and see their own AI scores.\n- Vanderbilt University and several other schools turned off Turnitin's AI detection service over accuracy concerns.\n- GPTZero reported it had made strides in debiasing results for ESL students.\n- GPTZero said it has taken steps to more clearly indicate the level of uncertainty in its tool's assessment of written work.\n- Some educators have backed away from using AI-detection tools in response to concerns about their accuracy.\n- Some educators have adjusted their curricula to incorporate AI rather than relying on detection tools.\n- Turnitin said it intentionally oversamples underrepresented groups in its dataset to address bias concerns.\n- The characters based on George Floyd were flagged for removal.\n- Character.AI blocked numerous answers with warnings stating the attempted responses violated the service\u2019s guidelines.\n- Character.AI moderates characters proactively and in response to user reports.\n- The company has a dedicated Trust & Safety team that reviews reports and takes action in accordance with its policies.\n- Character.AI performs proactive detection and moderation.\n- Character.AI uses industry-standard blocklists as part of its moderation.\n- Character.AI uses custom blocklists and regularly expands them.\n- The company is constantly evolving and refining its safety practices.\n- The Salt Lake City Police Department issued a public warning about the AI-generated scam using Chief Mike Brown\u2019s image and voice.\n- The department stated it will never request money from anyone.\n- The department advised anyone worried about the source of a message to call the police at 801-799-3000 for verification.\n- Detective Dalton Beebe advised people to consider protecting their images, videos, audio, and personal information online.\n- Beebe warned that calls or messages using urgency to pressure someone into acting quickly are usually red flags.\n- Plaintiffs' attorneys filed court documents asserting that at least one citation in Hancock\u2019s declaration bears the hallmarks of an AI 'hallucination.'\n- Law professor Eugene Volokh found and reported that another citation in Hancock\u2019s declaration does not appear to exist.\n- The plaintiffs called the alleged AI-generated fabrication to the court, arguing that exposing the fabrication demonstrates that true speech\u2014not censorship\u2014is the proper remedy.\n- Waymo's staff spoke to the passengers in the vehicle after Robert tapped the 'Support' button.\n- Waymo emailed the passengers explaining their process when a pedestrian attacks the vehicle and advising riders to remain inside the vehicle until a team member arrives or there is an urgent need to exit.\n- Waymo stated that their team works closely with local law enforcement and government and maintains a nearby assistance team to support riders if needed.\n- Waymo called police to the scene after the collision with the bicyclist.\n- Waymo said it is making contact with relevant authorities regarding the bicyclist collision.\n- Professor Scott Moura and his team are working with stakeholders to improve autonomous vehicle technology through their research.\n- Waymo's in-car Rider Support team called the rider.\n- Waymo called the rider afterwards to follow up.\n- Waymo apologised to the rider publicly on X.\n- Waymo provides 24/7 access to Rider Support agents to help riders navigate such situations in real time.\n- Waymo's Rider Support agents coordinate closely with law enforcement officers to provide further assistance as needed.\n- Waymo emailed the couple involved in the February incident advising riders to remain inside the vehicle until one of Waymo's team members arrives or there is an urgent need to exit.\n- Waymo stated that its team works closely with local law enforcement and government and has a team nearby to assist if needed.\n- The National Highway Transportation Safety Agency said it was investigating 31 incidents involving Waymo's robotaxis.\n- OpenAI declined to discuss any specific circumstances around the name 'David Mayer.'\n- OpenAI said a tool had mistakenly flagged the name 'David Mayer' for privacy protection.\n- OpenAI fixed the quirk that had mistakenly flagged the name 'David Mayer.'\n- ChatGPT was patched so it can now say the name 'David Mayer' unhindered.\n- OpenAI stated that ChatGPT may withhold certain information about people to protect their privacy.\n- Mr. Hood took legal action against OpenAI after ChatGPT falsely claimed he had been arrested for bribery.\n- Soch Fact Check conducted rigorous deepfake tests on the audio.\n- Soch Fact Check spoke with multiple experts in digital forensics, AI, misinformation, audio engineering, and linguistics and phonetics to assess the audio's authenticity.\n- Soch Fact Check spoke to audio engineer Shaur Azher, who analysed the clip.\n- Shaur Azher generated an AI-produced audio of Biden for a comparison.\n- Shaur Azher performed spectrogram analysis on the suspicious audio.\n- Shaur Azher performed voice biometrics analysis comparing the clip to authentic samples.\n- Shaur Azher concluded the clip was most likely created using AI or spliced.\n- Soch Fact Check reached out to the Deepfakes Rapid Response Force to help analyse the audio.\n- The Deepfakes Rapid Response Force analysed the audio using a speaker verification tool and compared it with eight verified samples of Biden.\n- The Deepfakes Rapid Response Force emailed Soch Fact Check saying the clip might be spliced and that background music made definitive determination impossible.\n- Soch Fact Check sent the audio for analysis to Professor Hany Farid.\n- Professor Hany Farid analysed the audio with a model trained to distinguish real from AI-generated voices and classified the recording as AI-generated.\n- Soch Fact Check contacted Dr Catalin Grigoras, whose forensic analysis found traces consistent with an AI-generated voice.\n- Soch Fact Check contacted Dr Paul Foulkes, who analysed the linguistic and phonetic features and concluded the recording is not authentic.\n- Soch Fact Check searched for any reports on the matter published by credible media outlets and found none.\n- Soch Fact Check identified and documented multiple social media posts and platforms (including Facebook, X, Instagram, TikTok, and WhatsApp) where the fake audio was posted and shared.\n- PolitiFact Editor-in-Chief Katie Sanders publicly said the audio did not sound authentic and was oddly sped up in places.\n- Soch Fact Check published the fact-check and provided an appeals email address (appeals@sochfactcheck.com) for those wishing to contest their finding.\n- Villagers took the damaged Wagon R out of the Ramganga river after spotting it.\n- Villagers informed the police about the accident.\n- Google stated that it is working closely with the authorities and providing support to investigate the issue.\n- The police are trying to identify the third victim.\n- The family requested the district magistrate to take action against those responsible.\n- The owner of Spelling Manor informed The Wall Street Journal through their lawyer that scammers filed a fraudulent deed with Los Angeles County.\n- A lawsuit has been filed disputing ownership of Spelling Manor, creating an ongoing legal battle over the mansion's ownership.\n- Two people accused in the Spelling Manor deed fraud lawsuit told The Wall Street Journal that they were the rightful owners.\n- Riley Keough sued Naussany Investments and Private Lending accusing it of using forged documents to claim ownership of Graceland and won the case.\n- Lisa Jeanine Findley was federally charged with fraud and identity theft in the plot to steal Graceland.\n- William Gordon recovered his Arizona land after the title company signed a quitclaim deed that relinquished ownership and returned the property to him.\n- A title company in Hallandale Beach pushed for identity verification and required a video call, which exposed a deepfake and prevented the deed fraud attempt.\n- The FBI's Internet Crime Complaint Center processed 9,521 real-estate-related complaints in 2023.\n- Anthropic adjusted its systems to better address Spanish-language queries that should activate the TurboVote pop-up and redirect users to authoritative sources on voting-related issues.\n- OpenAI partnered with the National Association of Secretaries of State to direct specific voting-related queries, like where or how to vote, to CanIVote.com.\n- OpenAI's teams continued to refine their systems to ensure users are accurately redirected in all appropriate cases.\n- Meta developed resources to support developers with best practices when building products powered by Llama 3.\n- Meta said it is training its models on safety and responsibility guidelines so they are less likely to share responses that may include inaccurate information about voting or responses potentially harmful or inappropriate for all ages on its apps.\n- Meta shared a blog post about its efforts to expand open source AI models responsibly.\n- Mi Familia en Acci\u00f3n launched a bilingual chatbot on their website geared towards answering general questions about voter registration and creating a voter plan.\n- Factchequeado created a chatbot called Electobot to answer election-related questions in Spanish through WhatsApp using a combination of LlamaIndex and OpenAI technology to search Factchequeado articles and generate responses.\n- The AI Democracy Projects and Factchequeado used AI testing software and a methodology to ask the same 25 election questions in both English and Spanish and analyze the responses.\n- Two fact-checkers reviewed each AI model response for accuracy and completeness, with a third fact-checker breaking any ties.\n- The story was updated to include a response from OpenAI that was sent after publication.\n- He found the photo taken by the smart cameras.\n- He filed an appeal against the fine, which can take up to 26 weeks to process.\n- He published a blog post on his company's website explaining what he believes went wrong with the police AI and the Monocam smart camera and proposing improvements.\n- He gave an interview to Belgian news outlet HLN describing the AI's errors.\n- He conducted experiments that showed the AI confused a pen with a toothbrush and discussed the results with HLN.\n- BBC News complained to Apple about the false push notification.\n- Mashable reached out to Apple for comment and said it will update the story if it hears back.\n- Bernice King posted on X denouncing the video.\n- Bernice King called for the video to be deleted.\n- X users who contribute to crowdsourced fact-checking attached a note to the video post labeling it as a \"deepfake.\"\n- The BBC unearthed dozens of AI-generated false images portraying Black people supporting Trump.\n- More than a dozen U.S. states have laws penalizing people who use AI to make deceptive videos about politicians.\n- The consultant who created the deepfake of Biden's voice was fined $6 million in September by the Federal Communications Commission.\n- Many companies have launched tools to catch deepfakes.\n- Plaintiffs filed a lawsuit in Texas against Character.ai demanding the app be taken offline until it implements stronger guardrails to protect children.\n- Texas Attorney General Ken Paxton announced an investigation into Character.ai and 14 other tech companies to determine whether the companies comply with Texas laws to protect children from exploitation.\n- Character.ai said it is developing a new model specifically for teens.\n- Character.ai said it has improved detection, response and intervention around subjects such as suicide.\n- Character.ai changed its age rating for the app from 12 and up to 17 and older.\n- A.F. took her son to see mental health experts.\n- A.F. took her son to the emergency room and then to an inpatient facility after he tried to harm himself.\n- A.F. reached out to legal advocacy groups to try to prevent other children from facing abuse.\n- The mothers retained the Social Media Victims Law Center and the Tech Justice Law Project to represent them in the lawsuits.\n- Authorities in Belgium began investigating Chai AI after a father of two died by suicide following conversations with a chatbot.\n- The banks on both sides of the transaction cooperated and returned more than half of the wired funds to the Bartlos.\n- The FBI issued a public service announcement warning of the increasing use of AI in fraud schemes to generate persuasive text, audio, video and other communications.\n- The Treasury Department's Financial Crimes Enforcement Network (FinCEN) issued an alert about a recent increase in AI-generated \"deepfakes\" targeting financial institutions.\n- When she received a nearly identical fraud email three days before closing, Bartlo recognized it and did not follow the wiring instructions.\n- Cybersecurity firm Silent Push investigated the websites and found they contained infostealer malware.\n- Silent Push's Zach Edwards concluded that the Russian hacker group Fin7 appears to be behind several AINude.ai-variant websites.\n- 404 Media published a report detailing Silent Push's findings linking the AI nudify sites to Fin7 and the presence of malware.\n- NewsGuard fed all 171 posts from the bot accounts into a Pangram Labs tool to assess whether the text was AI-generated.\n- NewsGuard shared the findings of their research with X.\n- NewsGuard shared the findings of their research with OpenAI.\n- Two of the 171 accounts have been suspended.\n- Two of the 171 accounts have been restricted.\n- The UK enacted policies on combating AI-generated fake reviews online.\n- Originality.ai used its proprietary AI detection tool and API to detect AI-generated airline reviews by analyzing their content.\n- Originality.ai scanned reviews with at least 50 words for an AI-likelihood score and classified them as AI-generated or not.\n- Originality.ai collected reviews from airlinequality.com for analysis.\n- Originality.ai cleaned the review data prior to analysis.\n- Originality.ai analyzed customer sentiment over time using TextBlob.\n- Originality.ai applied Lowess smoothing to highlight longer-term trends in customer satisfaction.\n- Originality.ai visualized daily sentiment scores and overall trends.\n- Jon Gillham, CEO of Originality.ai, laid out top tips for spotting AI-generated reviews so consumers can make better choices online.\n- Originality.ai recommended that consumers use the Originality.ai AI Detector to verify that online reviews are legitimate and human-written.\n</mitigation_statements>"}]}}
{"custom_id": "batch_800", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- The City Council approved a $350,000 contract with a vendor to use machine learning to more effectively distribute discounts to needy customers.\n- The vendor SERVUS is running two 90-day pilot programs to test whether its algorithm can accurately identify customers' ability to pay.\n- The Water Bureau used randomization software to select customers for the first 90-day test billing period.\n- The Water Bureau is conducting a randomized control trial to reach a broader, more diverse group of customers and evaluate how the program could work for everyone.\n- Seven French families filed a joint lawsuit against TikTok in the Cr\u00e9teil judicial court.\n- Cado Security Labs identified a new sophisticated scam campaign targeting people who work in Web3.\n- Cado Security Labs analyzed the macOS version of the Meeten malware and identified a Windows variant.\n- Cado Security Labs published a blog/report detailing the campaign, the malware analysis, and recommendations.\n- Cado Security Labs published indicators of compromise (IOCs), including domains, IP addresses, and malicious download URLs.\n- The blog advised users to verify sources, implement strict security practices, and monitor for suspicious activity.\n- The blog advised users to exercise caution when approached about business opportunities on Telegram and to verify contacts before opening links.\n- The video was debunked as a deepfake.\n- DogeDesigner posted a warning on X stating that Elon Musk and his companies were not doing any crypto giveaways and urging followers not to fall for scams.\n- The Elon4u.com website featured in the video is now under scrutiny.\n- Experts advised internet users to avoid visiting suspicious websites.\n- Experts advised internet users to report any potentially harmful content.\n- Experts urged users to double-check such claims with trusted sources.\n- Two interventions were conducted with Patricia.\n- A relative intercepted Patricia during a layover in Portland.\n- The relative brought Patricia home.\n- MSNBC stated that the real Ari Melber has no connection to the scammer.\n- The Center for Countering Digital Hate released a report titled \"YouTube's Anorexia Algorithm.\"\n- CCDH researchers created a YouTube profile of a 13-year-old girl to collect data for their study.\n- CCDH carried out 100 searches on YouTube using popular eating disorder keywords to gather evidence.\n- CCDH analyzed the top 10 recommendations YouTube's algorithm pushed to the \"Up Next\" panel for each search.\n- CCDH flagged 100 YouTube videos promoting eating disorders, weight-based bullying, or showing imitable behavior.\n- YouTube removed or age-restricted 18 of the videos that CCDH had flagged.\n- YouTube stated that it continually works with mental health experts to refine its approach to content recommendations for teens.\n- In April 2023, YouTube expanded its policies on eating disorders and self-harm content to add the ability to age restrict certain videos and potentially make them unavailable to viewers under 18.\n- YouTube took steps to block certain search terms such as \"thinspiration.\"\n- The Social Media Victims Law Center filed thousands of lawsuits against social media companies, including more than 20 suits alleging YouTube is intentionally addictive and perpetuates eating disorders.\n- The Social Media Victims Law Center connected a 17-year-old client with 60 Minutes as part of its legal advocacy.\n- The American Sunlight Project developed a custom search engine to find members of the 118th Congress by first and last name, abbreviations, or nicknames on 11 well-known deepfake sites.\n- The American Sunlight Project shared its findings exclusively with The 19th.\n- Researchers shared their findings with impacted members of Congress.\n- The American Sunlight Project contacted the offices of all impacted members of Congress to alert them to the deepfake imagery.\n- The American Sunlight Project offered resources on online harms to the impacted members of Congress.\n- The American Sunlight Project offered mental health support resources to the impacted members of Congress.\n- Most of the deepfake imagery depicting members of Congress was quickly removed from the hosting sites after researchers shared their findings with impacted members.\n- Susanna Gibson started a nonprofit dedicated to fighting image-based sexual abuse.\n- Susanna Gibson started a political action committee to support women candidates against violations of intimate privacy.\n- The American Sunlight Project encouraged Congress to pass federal legislation addressing AI-generated nonconsensual intimate imagery.\n- Both the DEFIANCE Act (Disrupt Explicit Forged Images and Non-Consensual Edits Act of 2024) and the Take It Down Act passed the Senate with bipartisan support.\n- The White House collaborated with the private sector to conceive creative solutions to curb image-based sexual abuse.\n- The FBI issued a warning stating that sharing AI-generated intimate imagery of minors is illegal.\n- The Cyber Civil Rights Initiative maintains a list of legal resources for victims of image-based sexual abuse.\n- Fenimore Harper carried out research identifying and quantifying the deepfake political adverts impersonating Rishi Sunak.\n- Fenimore Harper publicly warned that the adverts posed a risk of election manipulation and highlighted lax moderation policies on paid advertising.\n- Meta disabled the vast majority of these adverts before the report was published.\n- Meta stated that it removes content that violates its policies whether it was created by AI or a person.\n- A UK government spokesperson said the government is working across departments to be ready to rapidly respond to threats through its defending democracy taskforce and dedicated government teams.\n- A UK government spokesperson said the Online Safety Act requires social platforms to swiftly remove illegal misinformation and disinformation, including AI-generated content, as soon as they become aware of it.\n- The UK government has been holding discussions with regulators including the Electoral Commission.\n- The BBC said it takes swift action when it becomes aware of fake BBC content.\n- The BBC urged audiences to ensure they are getting their news from a trusted source.\n- Migrant advocacy groups warned people to never send money to immigration lawyers until they have fully received the legal services.\n- Migrant advocacy groups advised people to double-check and triple-check information related to immigration matters.\n- Migrant advocacy groups advised people to talk to a migrant organization for accurate guidance.\n- Migrant advocacy groups advised people to obtain as much correct information as possible about immigration changes.\n- IRCC urged applicants to use the official Departmental website to obtain information about its programs in order to avoid becoming victims of fraud.\n- IRCC stated that a wide variety of resources are available on its website on how to detect, prevent, and report fraud.\n- ESET is tracking the threat under the name Nomani.\n- ESET detected more than 100 new URLs related to the scam on average daily between May and November 2024.\n- ESET published and shared its H2 2024 Threat Report with The Hacker News.\n- South Korean law enforcement took down a large-scale fraud network as part of an operation called MIDAS.\n- South Korean law enforcement seized more than 20 servers utilized by the fraud ring.\n- South Korean law enforcement arrested 32 people involved in the scheme.\n- The Financial Security Institute (K-FSI) presented findings about the illicit home trading system and Operation MIDAS at the Black Hat Europe conference.\n- The bank informed Nikki MacLeod she was a victim of fraud when she attempted to make another payment.\n- Her bank and PayPal were able to recover around \u00a37,000 of the money she had sent.\n- Police Scotland confirmed an investigation is under way and said inquiries are ongoing.\n- Police Scotland urged people to be vigilant and encouraged anyone who believes they may have been a victim of fraud or a scam to contact police on 101.\n- PayPal issued a statement expressing sympathy, urging users to be wary of unusual payment requests, and advising people to always question uninvited approaches.\n- PayPal stated that they do not cover personal payments under PayPal Buyer Protection.\n- Steam posted a warning on their website advising people never to give a Steam wallet gift card to a person they do not know.\n- Nikki MacLeod contacted BBC Radio Scotland's Morning Programme to warn others about the increasing use of AI technology by scammers.\n- BBC Scotland had Dr Lynsay Shepherd examine the video messages and provide tips to spot AI deepfake videos.\n- AFP fact-checkers performed reverse-image searches and keyword searches on Google to investigate the viral video.\n- AFP located the original interview with Rob Wittman published on WUSA's website and on a verified YouTube channel dated March 2, 2022.\n- AFP archived the original source links using Perma.cc.\n- AFP published a verification stating that Wittman never mentioned Taiwan in the interview, debunking the deepfake.\n- Professor Jonathan Shaw reassured his patients that they were on the right medication.\n- The Baker Heart and Diabetes Institute lodged a separate intellectual property infringement complaint with Meta.\n- Meta removed the fake Professor Shaw video from Facebook on November 29.\n- Meta said it was continuing to invest in tools and technology to prevent scams on its platforms.\n- During a pilot program between April and May, Meta removed more than 8,000 AI-generated scams that used faces of public figures.\n- Meta has been testing facial recognition technology to combat scammers using celebrities.\n- The ABC attempted to contact the Glyco Balance manufacturer Vellec Group via email and a phone number listed on the product's website.\n- The ABC contacted ResearchGate about the fake article and researcher profile.\n- The ABC contacted Dr Alan Gaby about the product.\n- Dr Alan Gaby confirmed he had no involvement with or relationship to the product.\n- The Therapeutic Goods Administration said it was assessing the situation regarding the fake advertisements.\n- The TGA worked closely with several digital platforms, including Meta, to deter and address unlawful advertising of therapeutic goods.\n- In 2023\u201324 the TGA requested the removal of more than 4,800 unlawful advertisements of therapeutic goods from various digital platforms.\n- Michael requested a refund for the $340 he had spent on Glyco Balance.\n- The Waymo Driver notifies the company's Fleet Response and Rider Support teams when a collision occurs.\n- The Fleet Response team reviews the scene remotely.\n- The Fleet Response team dispatches a roadside assistance representative if needed.\n- The Rider Support team checks the status of riders.\n- The Rider Support team contacts first responders when appropriate.\n- Serve confirmed that its delivery robot was under remote supervisor control at the time of the incident.\n- Waymo and Serve confirmed they have been in touch to work to avoid similar issues in the future.\n- Fable apologized on several social media channels, including Threads and Instagram.\n- Fable posted a video of an executive issuing an apology.\n- Fable said it was working on an opt-out option for users who do not want AI-generated summaries.\n- Fable said it was working on clearer disclosures indicating that summaries are AI-generated.\n- Fable removed the part of the model that playfully roasts the reader.\n- Fable modified the model so it simply summarizes the user's taste in books rather than roasting them.\n- Fable immediately removed the AI-generated 2024 reading summaries.\n- Fable immediately removed two other features that used AI.\n- Users on X pointed out that the image appeared to reuse older public photos of the children that had been edited to look like a new portrait.\n- Several users on X publicly criticized the sloppy editing and said those flaws confirmed the card was fake.\n- Multiple people on X posted specific critiques of the photo edits, noting issues like misjoined trouser seams and hidden or poorly rendered hands and feet.\n- At least one user on X explicitly labeled the image as AI-generated and stated that it was not Archie.\n- The Treasury Department issued a press release disclosing the Center for Geopolitical Expertise's use of AI to spread disinformation.\n- The Treasury's Office of Foreign Assets Control placed sanctions on the Center for Geopolitical Expertise.\n- The Treasury's Office of Foreign Assets Control placed sanctions on the Center for Geopolitical Expertise's director, Valery Korovin.\n- The US government worked to disrupt AI-driven Russian disinformation campaigns.\n- A Russian embassy spokesperson issued a public statement denying that Russia interferes in the internal affairs of other countries, including the United States.\n- Meta shut down its AI character accounts on Instagram and Facebook following the backlash.\n- Meta deleted all 28 AI profiles it announced in September 2023, including both celebrity and non-celebrity accounts.\n- Meta identified a bug that was impacting users' ability to block the AI profiles.\n- Meta removed those accounts to fix the bug preventing users from blocking them.\n- A Meta spokesperson publicly clarified that the Financial Times article described the company's vision for AI characters rather than announcing a new product.\n- The Las Vegas Metropolitan Police Department shared information about the incident with other law enforcement agencies.\n- OpenAI issued an emailed statement committing to responsible use of its tools and saying they are designed to refuse harmful instructions.\n- OpenAI said it was working with law enforcement to support their investigation into the incident.\n- Las Vegas police and federal law enforcement officials held a roughly half-hour news conference to unveil new details about the New Year's Day explosion.\n- Authorities withheld a six-page document from public release while coordinating with Defense Department officials because some of the material could be classified.\n- Investigators said they still need to review the contents of a laptop, mobile phone, and smartwatch recovered in the case.\n- Authorities released a journal Livelsberger kept titled 'surveillance' or 'surveil' log.\n- Investigators were working to determine whether Livelsberger intended to make a political point.\n- An official investigation into the incident began within minutes of learning about it.\n- The district notified the Richland Police Department about the incident.\n- The district notified Children and Youth Services about the incident.\n- The district notified Childline about the incident.\n- The district notified individual parents about the incident.\n- The district stated it will pursue the matter legally and to the fullest extent of the law.\n- The district stated it will ensure due process in handling the matter.\n- The district encouraged students and the police to refrain from posting on social media, citing names, or making unfounded accusations.\n- The district encouraged individuals to contact School Resource Officer Scott Shope and provided his contact information.\n- The district stated it will not share students' names or specific information under federal and state privacy laws.\n- The student was reported to police.\n- NSW police began an investigation on 6 January after reports of inappropriate images being produced and distributed online.\n- NSW Police are working with the eSafety Commissioner.\n- NSW Police are working with the Department of Education.\n- The New South Wales Department of Education is working closely with NSW police to assist the investigation.\n- The Department of Education is helping affected students with appropriate wellbeing support and will do so as long as required.\n- The incident was referred to the eSafety Commissioner.\n- There will be disciplinary action taken against the student.\n- The student and the school have not been publicly identified to protect the privacy of the students affected.\n- The National Highway Traffic Safety Administration opened an investigation into about 2.6 million Tesla vehicles over the vehicle-summoning feature.\n- NHTSA said it had received one complaint alleging a crash when the Actually Smart Summon feature was enabled.\n- NHTSA is reviewing media reports of three other incidents related to the summoning features.\n- NHTSA announced the investigation in a public notice.\n- NHTSA said it plans to probe the top speed that vehicles can obtain using Actually Smart Summon.\n- NHTSA said it will examine operating restrictions for use on public roads.\n- NHTSA said it will examine line-of-sight requirements for the summoning features.\n- The investigation was specified to cover Tesla Model 3, Model S, Model X and Model Y vehicles, totaling an estimated 2.58 million vehicles.\n- X added reader-suggested context to posts showing the Hollywood Sign, labeling the images as fake and stating the sign was fine.\n- X's disclaimer on those posts included a link to a live webcam video feed of the Hollywood Sign.\n- Some posts included added context from The Dispatch stating that images of the Hollywood Sign engulfed in flames were fake.\n- Many nearby residents were evacuated after the Sunset Fire broke out.\n- Evacuation orders for affected areas were later lifted.\n- The Sunset Fire was fully contained after burning 43 acres.\n- A firefighting helicopter dropped water on the Sunset Fire during suppression efforts.\n- President Joe Biden extended his Los Angeles trip to visit first responders and those affected by the fires.\n- President Biden declared the fires a major disaster.\n- President Biden posted on X expressing support and providing information about evacuations and casualties.\n- The Peekskill Schools Superintendent warned the community about fake kidnapping calls targeting parents and their children.\n- The FBI issued a nationwide alert about the increasing use of AI to impersonate close relatives in crisis situations.\n- Experts advised people to take a minute to pause and consider whether a call might be a scam.\n- The FBI recommended verifying the whereabouts of the purported victim as a first step.\n- Authorities advised families to establish a password or phrase that can be requested to prove a call is real.\n- Peekskill police opened an investigation into the two incidents.\n- Authorities spread awareness in the community to prevent people from falling prey to the trend.\n- Apple said it would update the feature to clarify when the text being displayed is a summarisation provided by Apple Intelligence.\n- Authorities seized Kamnik's workstation at Troop K, including a hard drive containing thousands of pornographic media files.\n- Investigators discovered that some of the pornographic media files contained evidence they were made using deepfake software.\n- Kamnik surrendered himself to authorities.\n- Kamnik was later arraigned.\n- Kamnik was charged with felony unauthorized use of a computer and misdemeanor misapplication of entrusted property.\n- Kamnik was suspended without pay.\n- The investigation is ongoing.\n- GWLRA conducted an internal review.\n- Following an internal review, GWLRA decided to terminate the use of YieldStar.\n- GWLRA reached out to CBC with an email statement about its use of YieldStar.\n- GWLRA emphasized in its communications that it has raised rents at an average rate of 3.5 percent per year across its portfolio.\n- More than a hundred tenants sent complaints to the Competition Bureau demanding an investigation into landlords\u2019 use of YieldStar in Canada.\n- Tenants protested outside the Competition Bureau in Toronto demanding an investigation into landlords\u2019 use of rental software.\n- Tenants in Cynthia Black's building participated in a red flag protest by hanging flags from their balconies to warn tenants about the rent hikes.\n- Tenants in West22 have had red flags hanging from their balconies for the past year.\n- Some tenants flagged their concerns to local MPP Bhutila Karpoche.\n- Bhutila Karpoche researched the issue and found YieldStar has been used in Canada since at least 2017.\n- Federal Minister Fran\u00e7ois-Philippe Champagne said he would write to the competition commissioner to launch an investigation into the allegations around price-fixing in the rental market.\n- Dream instructed its property manager to discontinue its use of YieldStar in September.\n- Dream stated that its pricing decisions have always been made solely by its management team based on publicly available data and information specific to its buildings.\n- Dream denied that rent prices were in any way impacted by the software.\n- The FBI investigated RealPage and landlords who use its software for alleged collusion, price-fixing and artificially inflating rents.\n- The U.S. Department of Justice announced a lawsuit against RealPage.\n- RealPage denied the FBI allegations and said the claims brought by the DOJ are 'devoid of merit'.\n- RealPage said it intends to vigorously defend itself against these accusations.\n- The Facebook post containing the deepfake was reportedly removed.\n- Sir Jim Mann publicly urged caution to people who encounter videos of experts that appear too good to be true.\n- Sir Jim Mann advised people to source reliable information directly from recognized healthcare professionals.\n- Dana Brems posted on Instagram to alert followers that a company used an AI clone of her voice to promote a product.\n- After a deposition revealed a body-camera recording, the prosecutor requested the video from police.\n- Police released the body-camera video to the defense.\n- St. Louis Circuit Court Judge Brian May watched the video during a February 2024 hearing and ruled that the identification could not be used in court.\n- Prosecutors dropped all charges against Christopher Gatlin in March.\n- Christopher Gatlin sued the agencies and officers responsible for his arrest seeking unspecified monetary damages.\n- Detroit paid Robert Williams $300,000 in a settlement announced in June.\n- Detroit agreed to require officers to collect independent evidence on AI-identified suspects before seeking an arrest warrant.\n- Woodbridge settled a lawsuit related to a wrongful arrest for $300,000 last year without admitting wrongdoing.\n- Miami police launched an internal investigation into the handling of Jason Vernau's case.\n- Prosecutors later dropped the case against Jason Vernau.\n- All of the wrongful-arrest cases described in the reporting were eventually dismissed.\n- Sawyer's wife drove 90 miles to personally confront a probation officer who had been pressured into falsely confirming him as the attacker.\n- The probation officer apologized and retracted her confirmation, which led to Sawyer's release.\n- Check Point investigated FunkSec and published a public report detailing their findings.\n- Check Point discovered and publicly disclosed that FunkSec's members linked the ransomware development to AI.\n- Check Point discovered and publicly disclosed that FunkSec released an AI chatbot based on Miniapps to support their malicious operations.\n- Sysdig researchers discovered evidence of a reverse proxy for LLMs (OAI Reverse Proxy) being used to provide access to compromised accounts.\n- Sysdig researchers discovered the tools generating the requests and identified a broader credential-checking script (keychecker) that checked credentials for ten different AI services.\n- Sysdig used both S3 and CloudWatch in their setup to gather as much data about the attack as possible.\n- Sysdig provided and included a Falco detection rule (Bedrock Model Recon Activity) in the Sysdig AWS Notable Events policy to detect reconnaissance attempts against Amazon Bedrock.\n- Sysdig published Indicators of Compromise (IoCs) including the IP addresses 83.7.139.184, 83.7.157.76, 73.105.135.228, and 83.7.135.97.\n- Character.AI removed the chatbots that emulated school shooters and their victims from the platform.\n- Character.AI's Trust & Safety team moderated user-created Characters both proactively and in response to user reports.\n- Character.AI used industry-standard blocklists to assist moderation.\n- Character.AI used custom blocklists and regularly expanded them.\n- Character.AI announced it is working to improve and refine its safety practices.\n- Character.AI announced it will implement additional moderation tools to prioritize community safety.\n- Character.AI announced filtering characters available to minors.\n- Character.AI announced narrowing access to sensitive topics such as crime and violence for users under 18.\n- Character.AI removed the Characters that the company said grossly violated its policies.\n- Character.AI said its Trust & Safety team uses industry-standard blocklists and custom blocklists and that it regularly expands those blocklists.\n- Character.AI said it had made immediate product changes as a result of the Characters flagged to them.\n- Character.AI said it is working to continue to improve and refine its safety practices.\n- Character.AI said it will implement additional moderation tools to help prioritize community safety.\n- Character.AI said it would review the new list of Characters flagged by reporters and remove Characters that violate its Terms of Service.\n- The \"Dads friend Mike\" chatbot was removed after Futurism asked Character.AI why it had remained online.\n- Character.AI removed an AI character based on a real-life teenager who was murdered in 2006.\n- Character.AI apologized for hosting the AI character based on a real-life teenager who was murdered in 2006.\n- Character.AI issued a list of community safety updates stating that discussion of suicide violated its terms of service.\n- Character.AI announced that it would be tightening its safety guardrails to protect younger users.\n- TF1 withdrew the interview from its platforms.\n- TF1 presenter Harry Roselmack posted on X explaining that the interview had been withdrawn for the protection of victims.\n- Toulouse Football Club withdrew its tweet about Brad Pitt's appearance at the stadium.\n- Toulouse Football Club apologized for the tweet.\n- Anne received hospital treatment for severe depression.\n- Cara Hunter approached the police to report the deepfake.\n- Cara Hunter urged Stormont Justice Minister Naomi Long to carry out a comprehensive review of laws addressing online violence against women and girls.\n- Cara Hunter called on Naomi Long to press the UK government for a timeline for the promised roll-out of legislation to ban creation of sexually explicit fake content.\n- Alliance MLA Connie Egan proposed an amendment to the motion calling for the First and deputy First Minister to work with the UK government on online abuse.\n- The UK government announced plans to bring forward proposals to make it an offence to create sexually explicit deepfake images.\n- The justice minister was approached by the minister responsible about a possible extension of the offence to Northern Ireland.\n- The justice minister intends, subject to agreement of the Executive, the justice committee and members, to extend the offence to Northern Ireland.\n- Department of Justice officials are liaising with UK government officials on the detail of the legislative proposals.\n- MLAs passed Ms Hunter's motion.\n- The government announced that distributing pornographic deepfakes and sharing \"downblouse\" images will be made illegal.\n- Police and prosecutors will be given more powers under an amendment to the Online Safety Bill to hold perpetrators to account.\n- Distributors of deepfakes will potentially face prison time under the suggested measures.\n- Ministers will introduce extra laws to address other abusive acts, such as concealing secret cameras to capture photos or footage without consent.\n- The #NotYourPorn campaign helped pressure Pornhub into deleting an estimated 10 million unverified videos to remove non-consensual and child porn content.\n- EL PA\u00cdS rastre\u00f3 y sigui\u00f3 decenas de estos perfiles falsos y a personas que hab\u00edan contactado con ellos para comprobar su modus operandi.\n- EL PA\u00cdS contact\u00f3 con TikTok Espa\u00f1a para alertarles de esta estafa.\n- TikTok Espa\u00f1a revis\u00f3 el contenido y borr\u00f3 varios de estos perfiles por violar las normas de la comunidad.\n- EL PA\u00cdS alert\u00f3 a la Casa Real sobre la estafa.\n- La Casa Real declin\u00f3 hacer declaraciones.\n- EL PA\u00cdS solicit\u00f3 al Grupo de Investigaci\u00f3n de Fraudes Online de la Unidad de Ciberdelincuencia pautas o consejos para evitar caer en estos bulos.\n- El Grupo de Investigaci\u00f3n de Fraudes Online confirm\u00f3 a EL PA\u00cdS que, por el momento, no hay casos de la estafa de la falsa Leonor en Espa\u00f1a.\n- El Grupo de Investigaci\u00f3n de Fraudes Online recomend\u00f3 desconfiar de perfiles que no son oficiales.\n- El Grupo de Investigaci\u00f3n de Fraudes Online recomend\u00f3 desconfiar de cualquier cuenta en redes sociales que ofrezca dinero de forma aparentemente altruista.\n- El Grupo de Investigaci\u00f3n de Fraudes Online recomend\u00f3 no hacer clic en enlaces sospechosos que provengan de este tipo de perfiles y no ofrecerles informaci\u00f3n personal.\n- El Grupo de Investigaci\u00f3n de Fraudes Online recomend\u00f3, si no se puede comprobar si se trata de una suplantaci\u00f3n, consultarlo con alguien del entorno que pueda aportar una visi\u00f3n cr\u00edtica.\n- Researchers from Resecurity spotted the hackers trying to sell the stolen database on the dark web.\n- Resecurity reported that the attackers were quickly removed from the systems.\n- Creasy reported the scam to police.\n- Creasy reported the scam to TSB.\n- TSB froze Creasy's accounts after learning of the fraud.\n- TSB tried to recover the funds.\n- TSB asked Creasy to contact police.\n- TSB informed Creasy that by downloading AnyDesk and sharing one-time authentication codes she had failed to take reasonable care and that the bank was not liable for her loss.\n- TSB urged customers to be vigilant.\n- TSB urged customers to never share account details.\n- TSB urged customers not to allow third-party remote access to their devices.\n- Easy Crypto contacted Creasy due to concerns about her transactions to obtain reassurance she was not working with any third party.\n- Easy Crypto said it worked to identify scams and monitor transactions.\n- The Financial Markets Authority issued a public scam warning about the deepfake videos.\n- Police continued to investigate the case.\n- Police warned that no legitimate company or financial adviser uses remote-access software and that its use is a sign of a scam.\n- Police advised that if people have suspicions they should disconnect the call and phone back the number on the company website or check with a trusted friend or relative.\n- A spokesman for the Prime Minister urged Kiwis to be vigilant for scams.\n- TSB told the Herald that Creasy had authorised each transaction.\n- A New Zealand private investigator found the website and alerted the couple to the danger its contents had put Hannah in.\n- Hannah and Kris ran the names of the women through Facebook to identify mutual friends and narrow down suspects.\n- Hannah and Kris went to the police with their evidence.\n- They approached criminal lawyer Sidnie Sarang, who started to build a case against Andy.\n- Hannah and Kris distanced themselves from their friendship group to avoid tipping off the suspect and jeopardising the case.\n- Hannah and Kris declined Andy's invitations to meet or go for drinks.\n- They approached a private investigator who prepared a report into the evidence the couple had collected.\n- The private investigator sent the report to police.\n- Police raided Andy's home.\n- Andy gave over his passwords to police.\n- Police charged Andy with 28 counts of using a carriage service to cause offence.\n- Andrew Thomas Hayler pleaded guilty to the charges.\n- He was sentenced to nine years in prison with a non-parole period of five years.\n- He appealed against his sentence.\n- The Bot Blocker project uncovered the Matryoshka campaign.\n- The Insider and Bot Blocker confirmed that the opening segments of the videos were taken from real videos.\n- The Insider and Bot Blocker confirmed that the other portions of the videos were artificially generated using AI voice cloning.\n- The University of Bristol analyzed a video featuring Professor Ronald Hutton and verified the use of AI in the manipulated segments.\n- Professor Ronald Hutton confirmed to The Insider that the political statements in the video were not his and did not represent his views.\n- The University of Bristol issued a statement denying that the political statements in the video represented Professor Hutton's views.\n- The Insider and Bot Blocker identified additional original recordings that were manipulated into fake videos.\n- The French government agency Viginum reported that the content was first published on specific Russian-language Telegram channels.\n- Viginum performed a semantic analysis of posts from these channels and found a high frequency of copy-pasted material and a surge in fake content beginning in September 2023.\n- Investigators stated they suspect the material was produced by third parties for coordinated distribution on Telegram.\n- The German nonprofit Correctiv conducted an investigation in November that traced Doppelg\u00e4nger's digital trails back to Russia's Ministry of Defense.\n- The Washington Post published documents showing the Sheikh Tamir Telegram channel repeatedly appearing in tables from an entity referred to as \"Center C.\"\n- Town officials advised residents to call the Town of Gray office to verify any suspicious emails claiming to be from the town.\n- The Zoning Board chair urged people to call the town office or the code enforcement officer before wiring or electronically sending any money in response to an email.\n- Town officials said they will report the impersonation/phishing incident to whoever they can.\n- David Maimon monitored Yahoo Boys channels on Telegram for more than four years.\n- David Maimon shared dozens of videos of the scammers with WIRED to reveal how they are using deepfakes.\n- David Maimon and his teams tracked down some of the victims shown in the videos.\n- David Maimon and his teams tried to contact the victims they tracked down.\n- WIRED blurred real faces in the videos it published.\n- WIRED requested comment from Telegram about the Yahoo Boys' channels.\n- Paul Raffile investigated Yahoo Boys' sextortion of teenagers.\n- Paul Raffile investigated instances where Yahoo Boys drove victims toward suicide.\n- Rachel Tobac and SocialProof's CTO reviewed a selection of Yahoo Boy videos for WIRED.\n- Andrew Newell and iProov tracked more than 100 different face-swapping tools.\n- Verify a person's identity before getting emotionally or financially involved with someone online.\n- Perform a reverse image search on photos to determine if they appear elsewhere on the internet under different names.\n- Do not send money or share financial information with someone you have not met in person.\n- Consult organizations like Veterans Affairs or other trusted resources to verify whether someone is truly serving in the armed forces.\n- Report suspicious activity to local law enforcement immediately.\n- Report suspicious activity to the FBI's Internet Crime Complaint Center (IC3) immediately.\n- Report suspicious activity to the online platforms where the contact occurred.\n- Stay educated about evolving scam tactics that use AI and other technologies.\n- WIRED reviewed posts on Telegram to document the cybercriminals' impersonation of television stations and their tutorials.\n- David Maimon first spotted the fake CNN video in December.\n- Telegram removed more than a dozen Yahoo Boy channels after WIRED reported on their public activity last year.\n- WIRED reported on how Yahoo Boys are adopting deepfake face-swapping technology to make video calls with their targets.\n- Brian Mason, a constable with the Edmonton Police Service, investigates fraud and works with victims of scams.\n- UTE advirti\u00f3 sobre la circulaci\u00f3n de un video con \u00e1nimo fraudulento.\n- UTE recomend\u00f3 no ingresar ning\u00fan dato.\n- UTE aclar\u00f3 que la informaci\u00f3n que circula es de origen fraudulento.\n- UTE recomend\u00f3 a sus clientes no brindar ning\u00fan dato personal.\n- Education Commissioner Deena Bishop realized her error before the state board meeting and sent correct citations to board members.\n- Department officials updated the online resolution document after inquiries from the Alaska Beacon.\n- The department's updated reference list replaced a nonexistent Journal of Educational Psychology citation with a real article from the Malaysian Online Journal of Educational Technology.\n- The defendant agreed to plead guilty to seven counts of cyberstalking and one count of possession of child pornography.\n- The defendant was arrested and charged by criminal complaint in September 2024.\n- United States Attorney Leah B. Foley and Jodi Cohen, Special Agent in Charge of the FBI Boston Division publicly announced the charges.\n- The Plymouth Police Department and Plymouth Fire Department provided assistance in the investigation.\n- Assistant U.S. Attorney Luke A. Goldworm of the Major Crimes Unit is prosecuting the case.\n- Whoopi Goldberg deviated from the planned commercial break on The View to publicly warn viewers about the phony AI-generated weight-loss ad.\n- Whoopi Goldberg instructed viewers to not trust the ad, to not engage with it, and to delete or 'get rid of' it.\n- Whoopi Goldberg advised fans to only trust advertisements if she personally confirms their authenticity by saying, 'Hey, it's me, Whoopi.'\n- Goldberg's publicist referred Entertainment Weekly back to Goldberg's on-air comments when asked for additional information.\n- Police arrested Ramil Pantawong, 31, in Wang Nam Yen district of Sa Kaeo.\n- Police arrested Thanawut Kanyaphan, 28, in Bang Lamung district of Chon Buri.\n- Rappler reported the deepfake video to Meta.\n- Meta (Facebook) removed the reported deepfake video for violating its Fraud and Deception policies.\n- Microsoft took down the ad on its Bing platform that promoted the impostor website containing the deepfake.\n- Rappler collaborated with Swedish digital forensic group Qurium to conduct a follow-up investigation that linked the deepfake to a Russian scam network using digital fingerprints.\n- Rappler reached out to M1 Shop via the Telegram accounts listed on its website.\n- Wesley Skelton dumped out $2,500 worth of Golden Eagles and the coins he thought were Trump silver coins.\n- The coins were taken to Witter Coins in San Francisco for evaluation.\n- Witter Coins used a precious metal analyzer to determine the coins' metal composition and found they contained little to no gold or silver and were effectively worthless.\n- A Bank of America spokesperson told 7 On Your Side that the scheme was a scam and that Bank of America had nothing to do with it.\n- The credit card processor refunded several of Skelton's purchases made within the last 30 days, returning about $600.\n- 7 On Your Side Investigates attempted to contact the seller but received no response.\n- Witter Coins owner Seth Chandler publicly warned people to avoid such money schemes, advising 'just run as fast as you can'.\n- Hong Kong police arrested 31 people connected to the syndicate that used deepfake images to lure victims.\n- Officers seized notebooks containing chat-up strategies and conversational prompts from the syndicate during the operation.\n- Police intercepted more than HK$34 million in scam proceeds as part of the operation.\n- Officers found post-it notes and other notebooks that included the scammers' personal goals after making off with victims' money.\n- The real Pierce Brosnan issued a public statement damning the gallery and insisting he would never charge for a meet-and-greet.\n- His lawyers sent Ms Simms an immediate cease-and-desist letter in November 2023, three days after she advertised the \u00a3500 VIP meet-and-greet tickets.\n- As soon as she realised she had been duped, Ms Simms refunded the \u00a320,000 in tickets.\n- Ms Simms spoke to The Mail on Sunday about how she fell for the elaborate AI scam.\n- Ms Simms shut her gallery in August 2024 after the saga damaged her reputation.\n- The presenter discussed the fake adverts with her BBC Radio 5 Live production team.\n- Her BBC Radio 5 Live production team investigated the scams further.\n- Her production team reported the scam website to the BBC legal team.\n- The BBC legal department used copyright law to have the scam website taken down.\n- Meta removed the impersonating content from Facebook and Instagram in this case.\n- Meta said it continues to invest in technology to improve detection and enforcement against scams.\n- Meta said it works with law enforcement to prosecute scammers.\n- The BBC contacted X and Bluesky for comment.\n- The presenter spoke out publicly to raise awareness about the scam and warn people not to click the links.\n- A Which? reporter signed up to a website linked from a false advert as part of an investigation.\n- The Which? team spoke to people who had lost several hundred thousand pounds to these scams.\n- Which? investigated the registered addresses for the scam and found they appeared to lead to Reykjavik, Iceland, and even a car park.\n- Chris Packham opened a Bluesky account and observed fake accounts re-posting the scams.\n- Parking Enforcement Services agreed to waive Chris's $85 fine as an \"educational opportunity.\"\n- Parking Enforcement Services waived Hayden's fine after he provided Google tracking evidence.\n- The Kindercare Wigram Skies centre director personally assisted affected families with appeals processes.\n- The Kindercare Wigram Skies centre director provided documentation to affected families to demonstrate correct parking usage.\n- Kindercare warned parents about the parking problem in December 2023 and again in October 2024.\n- Kindercare has been working to resolve the parking enforcement issues.\n- Parking Enforcement Services installed an additional camera to cover the Kindercare car park area to increase plate reads and improve accuracy.\n- Parking Enforcement Services said it continued to conduct regular checks and upgrades to enhance the accuracy of the system.\n- Parking Enforcement Services said it was in regular communication with Kindercare and other businesses to keep them informed and assist mitigation efforts.\n- Parking Enforcement Services offered QR codes for extended parking times to mitigate issues.\n- Parking Enforcement Services said it would educate car park users about restrictions to mitigate issues.\n- Parking Enforcement Services said it would assist with appeals for affected customers.\n- Parking Enforcement Services said it investigates issues and waives breach notices where errors are found.\n- Parking Enforcement Services apologised for any inconvenience caused.\n- Parking Enforcement Services encouraged anyone who believes they have received an incorrect breach notice to contact them via their appeals process on their website or by phone and stated that appeals process and contact details are on breach notices and signage.\n- Giorgia Meloni took Alessio Scurosu to court for defamation.\n- Giorgia Meloni demanded \u20ac100,000 in damages.\n- Giorgia Meloni appeared at the trial via videolink from her office in Rome to give evidence.\n- Giorgia Meloni said she would donate any damages she wins to a state fund assisting women who are victims of violence.\n- Police traced the video to Alessio Scurosu using the nickname he used online.\n- Authorities charged Alessio Scurosu alongside his 73-year-old father.\n- Scurosu's father avoided trial by agreeing to carry out four months of community service working with the blind.\n- Meloni's defamation case was adjourned until February so Scurosu could be cross-examined.\n- Police in South Korea said they were investigating the messaging app Telegram on suspicion of showing deepfake pornographic images.\n- The UK passed the Online Safety Act, which criminalises the sharing of deepfake porn.\n- An AI-generated sexually explicit image of Taylor Swift posted on X was taken down.\n- Minister Guido Crosetto filed a complaint with the Carabinieri.\n- The complaint received by the Carabinieri will be transmitted to the Milan Prosecutor's Office and deposited in the case file of PM Giovanni Tarzia.\n- Crosetto advised Massimo Moratti to go to the Carabinieri to explain what he had been told.\n- The funds transferred by Massimo Moratti were recovered.\n- Investigators opened inquiries within hours after the transfers.\n- Luxottica (the Del Vecchio family) filed a complaint for attempted fraud.\n- The Beretta family filed a complaint for attempted fraud.\n- The Aleotti family filed a complaint for attempted fraud.\n- Esselunga (the Caprotti family) filed a complaint for attempted fraud.\n- A complaint was filed regarding the fraud against Massimo Moratti.\n- Marco Tronchetti Provera is expected to file a complaint.\n- Authorities are investigating on charges of criminal association aimed at aggravated fraud and identity substitution.\n- Investigators are pursuing the group, the money, and traces of financial movements using international rogatory requests.\n- Authorities are awaiting responses about the Dutch account to determine whether the transferred funds remain or whether other money arrived.\n- Authorities plan to try to block the Hong Kong account to verify whether transfers were received there.\n- Consob blocked the advertisements for these abusive financial services.\n- Consob then obscured four additional deceptive websites.\n- The Institute for Strategic Dialogue released a report about the Russian disinformation campaign on X.\n- The Institute for Strategic Dialogue published findings that 48 accounts traced to Russia on X had collectively received 2.5 million views and that engagements tripled over January.\n- Recorded Future published a report detailing Russian disinformation operations targeting Germany.\n- NewsGuard and Correctiv published a report documenting that John Mark Dougan registered dozens of fake German news sites masquerading as national and local outlets.\n- Clemson University's Media Forensics Hub identified multiple manipulated videos and deepfakes used in the disinformation campaign.\n- Darren L. Linvill, director of Clemson University's Media Forensics Hub, notified Natalie Finch about the manipulated video of her.\n- Germany's Office for the Protection of the Constitution issued a statement to The Times warning about the danger that disinformation campaigns pose to elections and voter trust.\n- CeMAS reported that Mr. Musk's posts on X had been spread by bot accounts operated by a Russian influence operation known as Doppelg\u00e4nger.\n- Scarlett Johansson issued a public statement to People condemning the AI-generated video featuring her likeness and warning about the misuse of AI.\n- Shopify took down the website selling swastika T-shirts due to policy violations.\n- Fox Television Stations CEO Jack Abernethy sent a note to staff condemning the Super Bowl ad that redirected viewers to the offensive website.\n- Ty Dolla $ign posted on Instagram distancing himself from Kanye West and stating that he does not condone any form of hate speech.\n- Kanye West (Ye) left the X platform following his tirade of antisemitic posts.\n- The German media outlet Correctiv revealed that the TikTok videos had been manipulated.\n- Euroverify ran the videos through a series of AI image detectors to investigate their authenticity.\n- Euroverify confirmed through its investigation that the videos were manipulated and not from pro-AfD demonstrations.\n- Investigators used AI audio detectors to identify manipulated soundtracks in multiple TikTok videos.\n- Authorities warned that a disinformation campaign originating from Moscow could be trying to influence the election outcome.\n- BP sent the vehicle owner letters alleging he had driven off without paying and asking him to settle the unpaid fuel balance.\n- BP reported the case to the police.\n- BP said it had high-resolution photos that showed the licence plate was EDR156 with the 5 doctored into a 6.\n- RNZ approached BP for comment.\n- Varias afectadas presentaron una denuncia.\n- El Grupo de Delitos Tecnol\u00f3gicos y Delincuencia Econ\u00f3mica de la Polic\u00eda Nacional en Palma asumi\u00f3 la investigaci\u00f3n.\n- Los investigadores consiguieron identificar al autor de los montajes.\n- Los agentes detuvieron al menor por un delito de corrupci\u00f3n de menores.\n- Pusieron el caso en conocimiento de la Fiscal\u00eda de Menores de Balears.\n- La Polic\u00eda Nacional record\u00f3 la definici\u00f3n y las consecuencias penales de la pornograf\u00eda infantil seg\u00fan el C\u00f3digo Penal.\n- NHK\u306f\u554f\u984c\u3092\u53d7\u3051\u3001AI\u306b\u3088\u308b\u81ea\u52d5\u7ffb\u8a33\u6a5f\u80fd\u3092\u4f7f\u3063\u305f\u591a\u8a00\u8a9e\u5b57\u5e55\u30b5\u30fc\u30d3\u30b9\u3092\u540c\u65e5\u4ed8\u3067\u7d42\u4e86\u3057\u305f\u3002\n- NHK\u306f\u904e\u53bb1\u9031\u9593\u5206\u306e\u5b57\u5e55\u3092\u632f\u308a\u8fd4\u308a\u3001\u540c\u69d8\u306e\u30b1\u30fc\u30b9\u304c\u306a\u304b\u3063\u305f\u304b\u8abf\u67fb\u3057\u3066\u3044\u308b\u3002\n- \u8abf\u67fb\u306e\u7d50\u679c\u3001\u904e\u53bb4\u65e5\u5206\u3067\u540c\u69d8\u306e\u30df\u30b9\u304c\u78ba\u8a8d\u3055\u308c\u305f\u3002\n- The Times of Malta published a fact-check article debunking the doctored video and declaring the claim false.\n- The Times of Malta made the original 56-minute interview footage available on its website and social media platforms.\n- The Times of Malta's fact-checking service conducted the fact-check in accordance with its code of principles.\n- The article included links to previous fact-checks and external resources about similar scams.\n- Times of Malta published a fact-check concluding that the videos were doctored and that the claim was false.\n- Times of Malta reporters conducted a deeper dive into the Facebook page KETO's activity and identified multiple similarly doctored videos featuring other political figures.\n- Reporters traced the footage back to original videos\u2014Muscat's 2013 Sky News interview and Abela's 2021 Global Citizen video\u2014and compared them to the altered clips to confirm the audio had been replaced with AI-generated voiceovers.\n- Searches into the Oil Profit platform were carried out to show that many people around the world had fallen victim to the scam.\n- La Polic\u00eda Boliviana desarticul\u00f3 la banda delincuencial que utilizaba inteligencia artificial para estafar.\n- Autoridades detuvieron a sospechosos en Potos\u00ed, en las ciudades de Tupiza, Villaz\u00f3n y Sucre.\n- Cuatro personas fueron aprehendidas tras la investigaci\u00f3n.\n- Esas personas fueron imputadas por concusi\u00f3n, asociaci\u00f3n delictuosa, organizaci\u00f3n criminal y otros delitos.\n- La Polic\u00eda recuper\u00f3 los tel\u00e9fonos celulares utilizados en la estafa y los emple\u00f3 como carga probatoria.\n- Las autoridades realizaron una investigaci\u00f3n proactiva e identificaron al menos a tres personas que facilitaron nombres usados en los fraudes.\n- Las autoridades contactaron a la autoridad departamental denunciada, aunque ella se resisti\u00f3 a brindar informaci\u00f3n.\n- Se ampli\u00f3 la investigaci\u00f3n para incluir delitos vinculados al lavado de activos.\n- Agentes investigan a dos personas ya identificadas que declararon direcciones de vivienda de manera gen\u00e9rica.\n- Se iniciaron acciones inmediatas que incluyeron el traslado del interno implicado desde el penal de San Roque a Chonchocoro.\n- Las autoridades indicaron que pretenden fortalecer en el futuro los controles de seguridad y los protocolos de vigilancia en los centros penitenciarios.\n- Las autoridades esperan tomar contacto con las v\u00edctimas para avanzar de manera conjunta en la investigaci\u00f3n.\n- Martin Henderson paused filming to record a personal video message warning about the elaborate romance scams.\n- He issued a heartfelt message to the victim of the romance scam.\n- He publicly urged the victim to cease all contact with the scammer.\n- He issued a fresh public warning to fans about scammers and impersonators.\n- He told fans that he does not message people and does not have another account.\n- Through his official Instagram page last year, he warned fans not to engage with anyone claiming to be him.\n- He spent hours going through messages with people who said they had been scammed or were unsure if something was true.\n- He is working with IT specialists to clean up fake social media accounts impersonating him.\n- OpenAI uncovered evidence that a Chinese security operation had built an AI-powered surveillance tool to gather real-time reports about anti-Chinese posts on social media in Western countries.\n- OpenAI researchers identified the new campaign and named it \"Peer Review\" after detecting use of OpenAI technologies to debug the tool's code.\n- OpenAI published a detailed report on the use of AI for malicious and deceptive purposes.\n- In that report, OpenAI said it had uncovered a separate Chinese campaign called \"Sponsored Discontent\" that used OpenAI's technologies to generate English-language posts criticizing Chinese dissidents.\n- OpenAI researchers identified a campaign believed to be based in Cambodia that used the company's technologies to generate and translate social media comments to help drive a \"pig butchering\" scam.\n- The New York Times sued OpenAI and Microsoft for copyright infringement of news content related to AI systems.\n- OpenAI and Microsoft denied the New York Times' copyright infringement claims.\n- The driver posted a warning on social media (X) urging others to pay attention and to \"spread my message\" to help prevent similar accidents.\n- The driver reported to police that unknown mechanical issues caused the vehicle to leave the lane and hit the pole, according to a police report.\n- The FBI issued a warning advising smartphone users to hang up immediately if they receive this specific type of call.\n- The FBI advised recipients to avoid giving out any personal information to the caller.\n- The FBI advised recipients not to press any buttons on their phone and to simply end the call immediately.\n- The FBI recommended that anyone who suspects a scam call contact the real organization the scammer claimed to represent at the organization's verified phone number.\n- Cybersecurity experts issued a warning to Gmail users about the sophisticated AI-powered scam targeting email accounts.\n- Malwarebytes published a report explaining how AI was used in the advanced phishing campaign targeting Gmail users.\n- Malwarebytes issued guidelines urging users to never click on links or download files from unexpected emails or messages.\n- Malwarebytes urged users not to enter personal information on a website unless they are 100 percent sure it is legitimate.\n- Malwarebytes recommended using a password manager to autofill credentials only on trusted sites.\n- Malwarebytes recommended that users monitor their accounts for signs of unauthorized access or data leaks.\n- Google suspended the account that was used to send the misleading emails in the scam.\n- Google said it is hardening its defenses against abusers leveraging g.co references at sign-up to further protect users.\n- Child abuse detectives are investigating the incident.\n- Two Year 11 students were suspended.\n- Police urged the students involved to come forward.\n- The Department of Education said it was working with the school to support impacted students.\n- Gladstone Park Secondary College has taken appropriate disciplinary action.\n- Wellbeing support has been offered to any students who need it.\n- Support was being provided to the students and their families.\n- Referral services have been put in place to help support the students and their families.\n- Officers are working to determine which platforms the images were posted to.\n- Police urged the general public to report any images they are aware of.\n- Intelligence personnel are trying to locate where and how the images have been disseminated.\n- Detectives have been issuing public messages stating that such manipulated images are unacceptable.\n- The investigation into the incident remains ongoing.\n- Multiple users on X publicly criticized and called out Principal Secretary Korir Sing\u2019Oei for sharing the AI-generated deepfake.\n- Citizen Digital conducted a simple forensic analysis of the video to identify its authenticity.\n- Sing\u2019Oei deleted the video from his X account.\n- The two 16-year-old schoolchildren were arrested at their school.\n- Police confiscated the mobile phones of the two 16-year-olds for forensic digital examination.\n- The teenagers' parents were arrested.\n- The teenagers' parents face charges of neglecting to supervise their children.\n- A town hall on the subject of romance scams was held earlier in February.\n- The Arizona Attorney General's Office brought a case in April 2024 against Donald Franklin Huegel for working with Nigerian scammers to defraud two older Arizona residents out of $457,000.\n- Donald Franklin Huegel was convicted of fraudulent schemes, illegally conducting an enterprise, money laundering and theft.\n- A Pima County Superior Court judge sentenced Huegel to four years in prison.\n- A press release issued after Huegel's sentencing cautioned scammers that they would be discovered and prosecuted by the state Attorney General's Office.\n- AARP Arizona has taken an active role in educating all age groups to be vigilant about suspicious activity and correspondence.\n- AARP's Fraud Watch Network operates a free helpline at 1-877-908-3360 that is available to anyone regardless of age or AARP membership.\n- The Arizona Attorney General's Office has a Task Force Against Senior Abuse.\n- The Task Force Against Senior Abuse provides a toll-free helpline at 1-844-894-4735 and an email address (seniorabuse@azag.gov) where fraud can be reported.\n- The Highline community shared information with families and staff to help them stay vigilant and safe.\n- If you receive a call, stay calm and think critically.\n- Ask the caller to let you speak directly with your loved one.\n- Establish a family safe word that only your family knows to make it harder for scammers to succeed.\n- Request the caller answer personal questions that only the supposed victim would know.\n- Use other communication methods to reach out to the alleged victim to confirm their safety.\n- Inform law enforcement about the incident immediately.\n- Do not pay the ransom, whether by gift cards, cash, or wire transfer.\n- Symantec identified phishing emails spoofing ChatGPT\u2019s branding that urged recipients to renew a fictional $24 monthly subscription.\n- Barracuda Networks observed similar phishing campaigns in late 2024 where over 1,000 emails originated from the domain topmarinelogistics.com.\n- The phishing domains used in the campaign (such as fnjrolpa.com) were taken offline.\n- Cybersecurity teams recommended scrutinizing URLs to verify authentic OpenAI services and avoid misspellings or unusual domains.\n- Cybersecurity teams recommended enabling multi-factor authentication (MFA) to reduce the effectiveness of credential theft.\n- Cybersecurity teams recommended implementing regular employee training programs on identifying AI-driven scams.\n- OpenAI reiterated that subscription updates are managed solely via its platform.\n- OpenAI urged users to report suspicious communications directly.\n- HUD spokesperson Kasey Lovett said that appropriate action will be taken for all involved.\n- Multiple agencies told their employees not to respond to the mass email asking them to list five things they accomplished in the past week.\n- Disney's cybersecurity team assessed the damage caused by the breach.\n- Disney said in an August regulatory filing that it was investigating the incident.\n- Disney told employees it planned to move away from Slack to streamline collaboration tools after the hack.\n- Disney's internal \"fire team\" confirmed that Van Andel's Slack account had been breached.\n- Disney's fire team instructed Van Andel to check his personal devices for suspicious activity.\n- Van Andel installed a second antivirus program which found the malware on his personal computer.\n- Van Andel reset the hundreds of credentials stored in his 1Password account.\n- Van Andel filed a police report about the breach and related threats.\n- Disney's human-resources department terminated Van Andel's employment after a forensic examination of his work laptop.\n- Van Andel's sister set up a GoFundMe campaign to help cover his expenses.\n- Van Andel obtained contract work to help pay his bills after losing his job.\n- Van Andel's lawyer sent a demand letter to Disney seeking an eight-figure settlement for lost wages and emotional distress.\n- The American Psychological Association warned federal regulators that A.I. chatbots masquerading as therapists could drive vulnerable people to harm themselves or others.\n- Arthur C. Evans Jr., chief executive of the American Psychological Association, presented to a Federal Trade Commission panel and cited court cases involving two teenagers who had consulted with 'psychologists' on Character.AI.\n- Both boys' parents filed lawsuits against the company.\n- Apple provided a statement to The New York Times and Fox News confirming the bug in the dictation speech recognition model.\n- Apple said it is rolling out a fix for the speech recognition model that powers dictation as soon as possible.\n- Barbara O\u2019Neill posted a video clip on YouTube warning about the trend of AI-generated impersonations of her.\n- Barbara O\u2019Neill publicly stated that she does not have a Facebook page of her own.\n- Africa Check debunked several AI-generated impersonations of Barbara O\u2019Neill in July.\n- Africa Check published a guide to help readers identify deepfakes.\n- Norton published the 2025 Cyber Safety Insights Report surveying 1008 adults about cyber and dating-app scams.\n- The Amor app requires users to answer 60 questions when signing up.\n- The Amor app requires users to verify an email address.\n- Amor requires premium users to submit ID that is run through Stripe and verified in the cloud without Amor retaining the information.\n- Amor matches users based on their questionnaire answers rather than allowing matching based on photo likes.\n- Amor prevents bots from being onboarded into the app and blocks plugging AI/robots into the service.\n- The Amor app encourages users to put more thought and effort into online dating to reduce impulsive interactions.\n- Private investigator Julia Hartley Moore told young men who had sent cash to online 'lovers' that they were likely not speaking to a real woman and provided that guidance.\n- Amor removed (kicked off) a user for attempting to promote an OnlyFans account on the site.\n- Microsoft filed an amended complaint naming the primary developers of malicious tools designed to bypass the guardrails of generative AI services, including Microsoft's Azure OpenAI Service.\n- Microsoft filed a lawsuit in the Eastern District of Virginia in December 2024 alleging various causes of action against 10 unidentified 'John Does' participating in activities that violated U.S. law and Microsoft's Acceptable Use Policy and Code of Conduct.\n- Through its initial filing, Microsoft gathered additional information about the operations of the criminal enterprise.\n- Microsoft is preparing criminal referrals to United States and foreign law enforcement representatives.\n- The Court issued a temporary restraining order and preliminary injunction enabling Microsoft to seize a website instrumental to the criminal operation.\n- Microsoft seized a website instrumental to the criminal operation, disrupting the group's ability to operationalize their services.\n- Microsoft did not name specific celebrities in its filings to keep victims' identities private.\n- Microsoft excluded synthetic imagery and prompts from its filings to prevent the further circulation of harmful content.\n- Microsoft's legal filings were unsealed in January, generating an immediate reaction among group members.\n- Truffle Security downloaded a December 2024 archive from Common Crawl.\n- Truffle Security analyzed that archive and found nearly 12,000 live secrets and 219 different secret types in Common Crawl.\n- Lasso Security uncovered 20,580 GitHub repositories belonging to 16,290 organizations that were accessible via the Wayback Copilot method.\n- Lasso Security identified over 300 private tokens, keys, and secrets for GitHub, Hugging Face, Google Cloud, and OpenAI in those repositories.\n- Lasso Security warned that any information that was ever public could remain accessible and distributed by Microsoft Copilot.\n- Palo Alto Networks Unit 42 investigated 17 GenAI web products.\n- Palo Alto Networks Unit 42 published a report revealing that all investigated GenAI web products were vulnerable to jailbreaking in some capacity.\n- Researchers published a study showing that fine-tuning an AI language model on examples of insecure code can induce broad emergent misalignment.\n- The security community found various ways to jailbreak state-of-the-art AI tools including Anthropic Claude 3.7, DeepSeek, Google Gemini, OpenAI ChatGPT o3, Operator, PandasAI, and xAI Grok 3.\n- Studies discovered that large reasoning models' chain-of-thought intermediate reasoning could be hijacked to jailbreak their safety controls.\n- Meta fixed an error that caused some users to see content on their Instagram Reels feed that should not have been recommended.\n- Meta apologised for the mistake.\n- Meta told 404 Media that the deluge of graphic videos was not related to the overhaul of its content rules.\n- An internet safety campaign group demanded a full explanation of what had happened to Instagram's algorithm.\n- The Molly Rose Foundation said questions needed to be answered about why such graphic content was on the platform.\n- A Danish man was arrested in November 2024.\n- Twenty-five people have been arrested in a global operation over AI-generated child sexual abuse material.\n- Some 273 suspects were identified.\n- Europol said more arrests were expected to take place in the coming weeks.\n- The operation spanned 19 countries, including several European nations, Australia, and New Zealand.\n- Europol said the law enforcement agency will soon launch an online campaign highlighting the consequences of using AI for illegal purposes.\n- Police arrested a suspect who pocketed Rp 65 rupiah ($4,000) from the scam.\n- Officers detained a second person involved in another scam that also used deepfake technology.\n- TikTok removed one of the deepfake scam videos.\n- TikTok removed the associated account.\n- TikTok said it would continue to remove any posts that violated the platform's community guidelines.\n- TikTok and Meta pay AFP and more than 100 other fact-checking organisations to verify social media posts that potentially contain false information.\n- Mafindo's team of fact-checkers said it was working to debunk these scams using the latest technology available to criminals.\n- U.S. District Judge Kelly H. Rankin removed attorney Rudwin Ayala from the case.\n- Judge Rankin fined Rudwin Ayala $3,000 for violating legal ethics.\n- Rudwin Ayala withdrew the motions that contained the fabricated citations after the citations were challenged.\n- Ayala's law firm agreed to pay the opposing lawyers' legal fees for the time spent defending against the bogus briefs.\n- Judge Rankin fined two other lawyers who signed onto the brief $1,000 each.\n- Judge Rankin declined to punish Mr. Ayala's law firm.\n- Amnesty International's Security Lab conducted a forensic analysis of Slavi\u0161a Milanov's phone.\n- Amnesty International's Security Lab conducted detailed forensic analysis on the mobile devices of two dozen activists and journalists.\n- The Security Lab used open-source tools, including the Mobile Verification Toolkit (MVT) and AndroidQF, to gather and analyse forensic evidence for the report.\n- Amnesty International shared the report's findings with the Serbian government ahead of publication.\n- Amnesty International shared the report's findings with Cellebrite prior to publication.\n- Amnesty International sent queries to Cellebrite during the research process.\n- In collaboration with security researchers at Google, Amnesty International identified a zero-day Android privilege escalation exploit which was patched during the course of the research.\n- The Norwegian Ministry of Foreign Affairs stated that UNOPS is expected to conduct a thorough investigation of the alleged misuse of the donated Cellebrite technology.\n- Cellebrite sent a short response to Amnesty International asserting that it is not a surveillance company and that its products are licensed strictly for lawful use requiring a warrant or consent.\n- Cellebrite stated that it is investigating the claims made in the report.\n- Cellebrite said it is prepared to impose appropriate sanctions, including termination of its relationship with any relevant agencies, should the claims be validated.\n- Ben Fogle posted on Instagram warning that the deepfake of him promoting crypto circulating on Facebook was a scam.\n- The Financial Conduct Authority issued a notification warning that the AdmiralsFX site had been created by fraudsters to scam people.\n- The Financial Conduct Authority issued a notification warning that the related brand Golden Currencies was a clone being promoted by fraudsters.\n- Martin Lewis issued a public warning about the deepfake videos being used in the scams.\n- Zoe Ball issued a public warning about the deepfake videos being used in the scams.\n- Swedish broadcaster SVT and the Organized Crime and Corruption Reporting Project shared a massive leak of data with the Guardian and international media partners.\n- Georgia\u2019s prosecutor\u2019s office said it is now looking into the Tbilisi call centre network.\n- UK parliamentarians pushed for a more urgent legislative response to address the problem.\n- Revolut said it takes fraud incredibly seriously and invests heavily to prevent it.\n- Kroo said it takes fraud incredibly seriously and invests heavily to prevent it.\n- Chase said it takes fraud incredibly seriously and invests heavily to prevent it.\n- Revolut blocked a \u00a312,000 transfer attempt by a victim.\n- HSBC blocked a \u00a312,000 transfer attempt by a victim.\n- Meta started a programme allowing banks to report these scams to help combat fraud.\n- Derek reported the fraud to Action Fraud.\n- Journalists confronted Akaki Kevkhishvili and his security guards on video.\n- The Guardian invited readers to share links to fake adverts or news articles via an encrypted form to help the investigation.\n- The Guardian offered SecureDrop as a way for people to submit information anonymously.\n- The Guardian stated it will delete any personal data when it no longer requires it for the purpose of the feature.\n- Mark said he is speaking up publicly to help younger generations avoid falling into a similar trap.\n- Google informed Australian authorities and the eSafety Commission that it had received 258 user reports about suspected AI-generated deepfake terrorist or violent extremist content and 86 user reports alleging AI-generated child exploitation or abuse material.\n- Google provided the total global volume of Gemini user reports to the Australian eSafety Commission.\n- Google used hatch-matching to identify and remove child abuse material made with Gemini.\n- Google said it was committed to expanding its efforts to help keep Australians safe online.\n- The Australian eSafety Commission fined Telegram for shortcomings in its reports.\n- The Australian eSafety Commission fined Twitter (later renamed X) for shortcomings in its reports.\n- X lost one appeal about its fine of A$610,500.\n- X plans to appeal the fine again.\n- Telegram plans to challenge its fine.\n- Within hours of its debut, the Los Angeles Times removed the AI-powered \"insights\" feature from Gustavo Arellano's column.\n- YouTube released an official post warning creators about an AI-generated deepfake video of the company's CEO being used in phishing scams.\n- YouTube urged users not to fall for phishing scams.\n- YouTube advised creators to avoid clicking on links or opening files from untrusted sources.\n- YouTube stated that it will never attempt to contact users or share information through a private video.\n- YouTube warned that the phishing scam could result in the loss of a creator's credentials and the installation of malware on their device.\n- The executive verified the caller's identity by asking what the title of the book the CEO had recently recommended.\n- Google updated the search result to add an AI Overview that states the book is \"widely condemned for its hateful and racist ideology\" and provides contextual historical analysis.\n- Google added an option to turn the AI Overview feature off entirely.\n- Viginum identified the Pravda network in February 2024 and published a report about it.\n- Viginum reported and confirmed the involvement of the Russian IT company TigerWeb and its directors in creating and administering the Pravda network.\n- NewsGuard conducted and published an audit testing 10 leading AI chatbots for reliance on Pravda network content.\n- NewsGuard launched its AI Misinformation Monitor as a monthly evaluation in August 2024 and repeatedly documented chatbots' reliance on the Pravda network.\n- NewsGuard assigned the Pravda network a Trust Score of 7.5/100 and advised users to proceed with maximum caution.\n- NewsGuard tested the 10 chatbots using a sampling of 15 false narratives and three different prompt styles (Innocent, Leading, and Malign), resulting in 450 responses.\n- The American Sunlight Project published a February 2025 report warning that the Pravda network was likely designed to manipulate AI models and describing the tactic as 'LLM grooming.'\n- The American Sunlight Project published findings estimating that the Pravda network produced approximately 3.6 million articles in 2024.\n- The Digital Forensics Research Lab published coverage and analysis of the Pravda network.\n- Recorded Future published reporting and analysis on the Pravda network.\n- The Foundation for Defense of Democracies published analysis regarding the Pravda network's activities.\n- The European Digital Media Observatory published reporting on the expansion and activity of the Pravda network.\n- Microsoft released an analysis identifying the article and website as part of a Russia-based disinformation campaign.\n- The Microsoft Threat Analysis Center released a report on Sept. 17 describing the fake hit-and-run article as an example of Russian cyber influence operations targeting the Harris-Walz campaign.\n- The San Francisco Police Department emailed Reuters stating that there is \"no merit\" to the report.\n- The Reuters Fact Check team produced and published a fact-check article declaring the story false.\n- The Personal Data Protection Agency urged citizens to ignore fake ads that use AI-generated images.\n- The Personal Data Protection Agency urged citizens not to give out personal information, including bank account data.\n- Microsoft published a blog warning that the group was actively scouting U.S. election-related websites and American media outlets.\n- A spokesperson for Iran's mission to the United Nations issued a public denial saying the allegations were fundamentally unfounded and that Iran had no motive or intent to interfere in the U.S. election.\n- The Office of the Director of National Intelligence referred Reuters to a past statement noting it is coordinating the U.S. federal effort to protect the election from foreign influence.\n- The Gnida Project reported the fake Harris site.\n- The Gnida Project stated that the domain has 'Russian connections.'\n- The Gnida Project noted that the fake Harris site resembles the fake Ensemble-24.fr domain.\n- NewsGuard identified similarities in tactics and design between the fake Harris website and Ensemble-24.fr.\n- NewsGuard found that both the fake Harris site and the fake French election site look like they were created by John Dougan.\n- NewsGuard published a Misinformation Fingerprint on the fake Harris site.\n- NewsGuard sent September 2024 emails seeking comment to the Harris campaign, the Cybersecurity and Infrastructure Security Agency, and the Office of the Director of National Intelligence.\n- Canadian law enforcement executed search warrants at the call centers in early June 2024.\n- A federal grand jury in the District of Vermont indicted the 25 alleged perpetrators in late February.\n- The indictment was unsealed on Tuesday.\n- All but two of the suspects were arrested in Canada on Tuesday.\n- U.S. prosecutors charged all 25 suspects with conspiracy to defraud and charged five suspects with conspiring to commit money laundering.\n- U.S. and Canadian law enforcement engaged in extensive cooperation between local and federal agencies in both countries to carry out the arrests.\n- Nine other people had been previously charged in Vermont in connection with the same scam.\n- The Federal Trade Commission urged people not to trust the voice on such calls and recommended that anyone pressured to send money should call or text the person who supposedly contacted them to verify the story.\n- People were encouraged to monitor resources like the AARP Fraud Watch Network Scam-Tracking Map and alerts from the Better Business Bureau.\n- People were encouraged to report any suspicious calls on the Federal Trade Commission's website.\n- Fraud victims ages 60 or older were advised they can call the National Elder Fraud Hotline for assistance.\n- CNN spokesperson Emily Kuhn told AFP that the video was completely manipulated and did not air.\n- The U.S. State Department referred AFP to the agency's online transcript of Marco Rubio's interview.\n- AFP compared the interview transcript and footage to the viral clip and found nowhere in the conversation that Rubio mentioned Starlink.\n- Media forensics expert Siwei Lyu analyzed the video's audio with AI-detection algorithms and concluded it was very likely AI-generated.\n- Ukraine's Center for Countering Disinformation posted on X that the viral video of Rubio is fake.\n- Elon Musk posted on X that Starlink will never turn off its terminals and that he would not remove the service from Ukraine.\n- Marco Rubio posted on X denying that anyone had made threats about cutting Ukraine off from Starlink.\n- Graphika published a report investigating chatbot personas that promote harmful behaviors.\n- Graphika\u2019s investigation identified at least 10,000 AI chatbots that were directly advertised as sexualized, minor-presenting personas.\n- Graphika\u2019s investigation found that some of these chatbots made calls to APIs for OpenAI\u2019s ChatGPT, Anthropic\u2019s Claude, and Google\u2019s Gemini.\n- Many small startup companies operating template chatbot platforms are trying to figure out how to address abuse on their platforms by improving moderation.\n- Dr. Alexis Conason has spoken out about the negative impact of AI chatbots on teenagers' mental health.\n- Yale barred Dr. Helyeh Doutaghi from its New Haven campus.\n- Yale placed Dr. Helyeh Doutaghi on administrative leave.\n- Yale told Dr. Doutaghi not to advertise her affiliation with the university.\n- Yale Law School immediately opened an investigation into the matter to ascertain the facts.\n- Yale asked Dr. Doutaghi to meet with university officials to explain her position.\n- Dr. Doutaghi retained a lawyer, Eric Lee, to represent her.\n- Eric Lee asked the school to take public action to restore Dr. Doutaghi's reputation.\n- Jewish Onliner responded to requests for comment through an AI assistant identifying itself as 'JO.'\n- Jewish Onliner later sent emails stating that it uses AI to enhance research, fact-checking and rapid content creation while final edits are done by humans.\n- The Law and Political Economy Project scrubbed the webpage describing the discussion that featured Dr. Doutaghi from its project website.\n- The New York Times issued a correction on March 12, 2025 clarifying the date on the letter from a Yale official to Dr. Doutaghi.\n- \u9773\u4e1c\u57282025\u5e74\u5168\u56fd\u4e24\u4f1a\u671f\u95f4\u63d0\u4ea4\u4e86\u63d0\u6848\uff0c\u547c\u5401\u901a\u8fc7\u7acb\u6cd5\u6765\u89c4\u8303AI\u6280\u672f\u5e76\u4fdd\u62a4\u516c\u6c11\u7684\u4eba\u683c\u6743\u4e0e\u8d22\u4ea7\u6743\u3002\n- \u4ed6\u547c\u5401\u5b9e\u65bd\u6280\u672f\u76d1\u7ba1\u4ee5\u5efa\u7acb\u89c4\u5219\uff0c\u904f\u5236AI\u6362\u8138\u548c\u4f2a\u9020\u58f0\u97f3\u7b49\u6280\u672f\u88ab\u6ee5\u7528\u7684\u95ee\u9898\u3002\n- \u4ed6\u4e3b\u5f20\u6cd5\u5f8b\u3001\u6280\u672f\u548c\u6559\u80b2\u7b49\u591a\u65b9\u534f\u4f5c\uff0c\u5171\u540c\u5236\u5b9aAI\u6280\u672f\u7684\u89c4\u8303\u548c\u6cbb\u7406\u63aa\u65bd\u3002\n- \u5c71\u6771\u6fdf\u5357\u5e02\u7f8e\u8853\u9928\u5b98\u65b9\u56de\u61c9\u7a31\u66ab\u6642\u672a\u63a5\u7372\u76f8\u95dc\u6295\u8a34\uff0c\u4e26\u8868\u793a\u8a72\u4f5c\u54c1\u90fd\u662f\u7d93\u904e\u56b4\u683c\u5be9\u6838\u624d\u5c55\u51fa\u3002\n- \u8a31\u591a\u4eba\u8868\u793a\u8981\u8de8\u7701\u6295\u8a34\u3002\n- \u7db2\u53cb\u8981\u6c42\u5012\u67e5\u5be9\u6838\u4eba\u54e1\u662f\u5426\u6709\u6200\u7ae5\u7656\u6216\u4e0d\u826f\u50be\u5411\u3002\n- \u7db2\u53cb\u8981\u6c42\u76e1\u901f\u4e0b\u67b6\u76f8\u95dc\u5f71\u7247\u6216\u5c55\u54c1\u3002\n- C\u00e9line Dion posted an Instagram statement warning that unsanctioned AI-generated recordings purporting to contain her performances are fake, not approved, and not part of her official discography.\n- More than 200 artists signed an open letter, organized with the Artists Rights Alliance, denouncing AI-music generation technology and calling on AI developers, technology companies, platforms, and digital music services to cease using AI to infringe upon and devalue artists' rights.\n- In February, dozens of UK artists released a collaborative silent album to protest UK copyright laws involving AI.\n- C\u00e9line Dion\u2019s management team and Sony Music Entertainment Canada Inc. issued a statement saying they became aware of unauthorized use of her video, recording, musical performance, and likeness at a Donald Trump/JD Vance campaign rally and asserting that the use was not authorized and that she does not endorse it.\n- Apple said it was working to fix its speech-to-text tool after users reported incorrect transcriptions (such as 'racist' being transcribed as 'Trump').\n- Apple suspended its AI summaries of news headlines after those summaries displayed false notifications on stories.\n- The BBC removed the name of the garage employee from its report.\n- The BBC listened to the voicemail audio and confirmed it was a conventional business call.\n- The Singapore Police Force, Monetary Authority of Singapore and Cyber Security Agency of Singapore advised businesses to establish protocols for employees to verify the authenticity of any video calls or messages.\n- The authorities advised businesses to check for tell-tale signs that could suggest manipulation of the audio or video through AI technology.\n- Victims verified with their company\u2019s actual executives and legal counsel to confirm that those executives did not participate in any video calls and did not authorize any fund transfers.\n- WPP CEO Mark Read sent an email to company leadership detailing the attempted fraud, warning staff to be vigilant, and listing red flags such as requests for passports, money transfers, and secret transactions.\n- WPP added a pop-up message on its contact page warning that WPP's name and those of its agencies had been fraudulently used by third parties on unofficial websites and apps.\n- WPP stated on its website that it had been dealing with fake sites using its brand name.\n- WPP said it was working with relevant authorities to stop the fraud.\n- Prime Minister Lawrence Wong publicly warned about deepfake videos and images of him being used to sell products or services.\n- He told people not to respond to these scams.\n- He told people not to share any of their personal information.\n- He urged people to report such scams via ScamShield.\n- He advised those who have fallen victim to make a police report online.\n- He reminded people to stay vigilant online.\n- Senior Minister Lee Hsien Loong publicly warned about deepfake videos of him commenting on international relations and foreign leaders.\n- He asked members of the public in December 2023 not to respond to scam videos promising guaranteed returns on investments or giveaways.\n- Viewers were advised to look out for visual and audio anomalies in deepfake videos, such as atypical facial movements or blinking patterns and noticeable edits around the face.\n- Prime Minister Lee included the recent deepfake video circulating online in his Facebook post.\n- Prime Minister Lee urged Singaporeans to remain vigilant and learn to protect themselves and their loved ones against deepfake scams.\n- Prime Minister Lee urged people not to respond if they receive such scam videos.\n- Prime Minister Lee encouraged people to report such video scams, false news, or advertisements using the official ScamShield Bot on WhatsApp.\n- Prime Minister Lee noted that official videos posted by the Prime Minister's Office can be found online and provided a link.\n- Deputy Prime Minister Lawrence Wong posted on Facebook that he was aware of deepfake scam posts and messages showing him endorsing products and spreading misinformation.\n- Deputy Prime Minister Lawrence Wong stated that these posts were falsehoods.\n- Deputy Prime Minister Lawrence Wong urged people to stay vigilant and discerning online.\n- Senior Minister Lee posted on Facebook on June 2 warning that a deepfake video of him asking viewers to sign up for an investment product is not real.\n- In his Facebook post, he included a screenshot of the circulating deepfake video.\n- He urged Singaporeans not to believe scam advertisements of him or any other Singapore public office holder promoting an investment product.\n- He advised people to proceed with caution and stay vigilant if something sounds too good to be true.\n- He directed users to report the scam videos using the Government\u2019s ScamShield Bot on WhatsApp at go.gov.sg/scamshield-bot.\n- In December 2023, then-Prime Minister Lee warned Singaporeans about a deepfake video in which he appeared to be advocating for a cryptocurrency scheme.\n- Deputy Prime Minister Lawrence Wong posted on Facebook denying that the Government planned to reinstate a circuit breaker.\n- Deputy Prime Minister Lawrence Wong posted on Facebook stating that posts and messages showing him endorsing commercial products were deepfakes.\n- Deputy Prime Minister Lawrence Wong urged the public on Facebook to stay vigilant and discerning online.\n- Senior Minister of State Koh Poh Koon alerted his followers to a fake Instagram account impersonating him.\n- MP Saktiandi Supaat alerted his followers to several fake Instagram accounts using his profile photo and versions of his name.\n- Senior Minister Lee warned people about the deepfake videos in a Facebook post.\n- He advised people to always check if such videos are real and to report them to the respective platform app.\n- He urged people not to share the deepfake videos, even to indicate that they are fake.\n- In his Facebook post, he showed screengrabs of the deepfake videos hosted on TikTok.\n- He directed people to authentic videos on the Prime Minister's Office YouTube channel, the PMO website, or official media sites.\n- TikTok said it was aware of the videos and had taken action to remove them from its platform.\n- TikTok said it continues to invest in detection, transparency, and industry partnerships to address AI-generated content.\n- The article advised viewers to look out for visual and audio anomalies such as atypical facial movements, blinking patterns, and noticeable edits around the face.\n- The Dominican Foreign Ministry issued a statement rebuking the video as a \"vicious and incomprehensible attack\" that used its national symbols for internal Spanish matters.\n- The People's Party deleted the AI-generated post from X.\n- The People's Party issued a statement saying it did not intend to damage the Dominican Republic's image.\n- Prime Minister Pedro Sanchez apologised on behalf of Spain and said he was \"deeply ashamed\" of the incident.\n- A complaint was filed on January 29.\n- School officials passed that complaint along to the Corinth Police Department.\n- Authorities arrested 30-year-old Corinth School District educator Wilson Jones on two charges of production of a morphed image of child pornography.\n- The Corinth Police Department, along with the FBI, carried out a search warrant on March 3.\n- Authorities seized a laptop and a thumb drive, among other items.\n- The CPD emphasized that the images in those videos were AI-generated.\n- The CPD stated that at no time did the students willingly produce any of that content or know that their pictures were being used to create the videos.\n- CPD Chief Landon Tucker passed the case along to the FBI and the U.S. Attorney's Office.\n- CPD asked anyone who thinks that they, or their child, may be a victim of any misconduct by Jones to call 662-286-3377.\n- DNSFilter found that traffic to malicious domains with \"tax\" in the name peaked 30 days before Tax Day in 2024.\n- Guardio tracked a 77% increase in tax-related phishing scams in 2025.\n- McAfee reported that the average tax scam victim last year lost $8,199.\n- The IRS warned that it will never threaten legal action, promise a refund, demand payment through text or email, or call to ask for your credit or debit card information over the phone.\n- The IRS instructed taxpayers to ignore phishing texts asking for personal information to receive economic impact payments.\n- The IRS stated that eligible taxpayers do not need to take any action to receive the legitimate recovery rebate credit payments.\n- The IRS warned taxpayers to be wary of scam preparers, including those who set up fake websites or act as \"ghost preparers\" who refuse to provide their PTIN.\n- The IRS advised taxpayers to ask for a preparer's PTIN up front.\n- The IRS advised taxpayers to use the IRS.gov website to find preparers in their area who currently hold professional credentials recognized by the IRS.\n- The article advised that official government websites always end in .gov and that sites purporting to be the IRS ending in .org, .com, or other domains should be treated as red flags.\n- The IRS cautioned against taking tax advice from TikTok or other social media platforms.\n- Mr Guo alerted the police after discovering the fraud.\n- The police notified a bank in another city not to proceed with the transfers.\n- The police managed to recover 3.4 million yuan.\n- Efforts to claw back the remaining funds were ongoing.\n- Waverley College informed the NSW Education Standards Authority about the predictive text problem.\n- Waverley College told students to retake the NAPLAN writing test using a new prompt.\n- Waverley College attempted to administer the rescheduled writing test the following day.\n- Waverley College made multiple requests for the necessary student profile codes to allow students to access the rescheduled test.\n- Waverley College students sat the rescheduled writing test on Monday.\n- A Kambala teacher identified the predictive text issue and alerted the NSW Education Standards Authority and the Australian Curriculum and Reporting Authority.\n- NESA reminded all schools on the second day of testing of the need to disable predictive text on devices.\n- NESA said it has worked closely with the small number of schools who reported the predictive text issue.\n- NESA asked schools to continue self-reporting any issues that arise during the testing period.\n- Randwick High apologised for any inconvenience caused by the administrative error.\n- Europol published the EU-SOCTA 2025 report.\n- The EU-SOCTA 2025 provides a roadmap for Europe's law enforcement and policymakers to stay ahead of organised crime.\n- Europol said it will reinforce its capabilities by expanding its intelligence, operational reach, and partnerships.\n- The report calls for targeting criminal finances to dismantle the systems that allow organised crime to thrive.\n- The report calls for disrupting criminal supply chains to weaken organised crime operations.\n- The report calls for staying ahead of criminals' use of technology.\n- The EU's internal security strategy will address the challenges identified in the SOCTA report.\n- Poland stated it is fully mobilised to identify and neutralise emerging threats such as drug and human smuggling, human trafficking, hybrid threats, and the illicit arms trade.\n- Poland said it will shape the next EMPACT cycle and lay the foundation for international police cooperation.\n- Guided by SOCTA, the Polish presidency committed to strengthening EMPACT and Europol to ensure EU support meets Member States' needs.\n- The Council of the European Union will set priorities for law enforcement action and guide the development of EMPACT operational plans for the next four years.\n- Law enforcement must integrate cross-cutting elements into their strategies when designing measures to tackle serious and organised crime.\n- Law enforcement will integrate strategies that target key criminal markets.\n- Law enforcement will integrate strategies that target the underlying mechanisms that sustain organised crime.\n- The New York Times sued OpenAI and Microsoft in federal court in Manhattan over the companies' use of its articles to train AI.\n- OpenAI issued a public statement saying it respects the rights of content creators and is committed to working with them to ensure they benefit from AI technology and new revenue models.\n- OpenAI said its ongoing conversations with the New York Times have been productive and moving forward constructively.\n- OpenAI has been negotiating deals with news organizations to pay them for content.\n- In July, OpenAI signed a deal with the Associated Press for access to its archive of news articles.\n- German publishing company Axel Springer signed a deal with OpenAI under which OpenAI will pay to show parts of articles in ChatGPT answers.\n- At least 583 news organizations installed blockers on their websites to prevent tech companies from scraping their articles.\n- Several media companies started internal conversations on how to use emerging automated tools to assist with newsgathering and production.\n- Some authors, including George R.R. Martin, Jodi Picoult, Jonathan Franzen and George Saunders, sued OpenAI.\n- The Washington Post said it was reviewing the New York Times's complaint closely and supported the Times' decision to protect copyright principles.\n- Google pitched media outlets on building and selling AI tools that could assist journalists.\n- Authors Sarah Silverman, Richard Kadrey, and Christopher Golden filed a lawsuit in California alleging Meta violated copyright by using their books to train LLaMA.\n- A Danish anti-piracy group sent a takedown notice to The-Eye.eu concerning the Pile/Books3 dataset.\n- Bloomberg confirmed it will not include the Books3 dataset among the data sources used to train future versions of BloombergGPT.\n- EleutherAI stated it is creating a version of the Pile that exclusively contains documents licensed for that use.\n- Meta issued a DMCA takedown order against at least one developer distributing the leaked LLaMA model.\n- Meta required developers to agree to a license before using the LLaMA model.\n- Meta required developers to agree to a license before using the new version of the model released last month.\n- Meta argued in court that training their generative-AI models on copyrighted work without a license is fair use because large language models 'transform' the original material.\n- OpenAI argued in court that training generative-AI models on copyrighted work without a license is fair use.\n- Meta claimed it took precautions not to 'seed' any downloaded files.\n- Meta claimed there are 'no facts to show' that it distributed the books to others.\n- Employees recommended removing data clearly marked as pirated or stolen.\n- Employees recommended not externally citing the use of any training data, including LibGen.\n- Employees discussed removing any line containing 'ISBN', 'Copyright', '\u00a9', or 'All rights reserved' from the data.\n- A Llama-team senior manager suggested fine-tuning Llama to refuse to answer queries requesting verbatim reproduction of copyrighted text.\n- Employees discussed a variety of mitigations to mask their activity.\n- Elsevier filed a complaint against LibGen, Sci-Hub, other sites, and Alexandra Elbakyan, and the court granted an injunction and ordered Sci-Hub to pay $15 million in damages.\n- In 2023, a group of educational and professional publishers sued LibGen, and the court ordered LibGen to pay $30 million in damages and issued a broad anti-piracy injunction.\n- Arve Hjalmar Holmen contacted the Norwegian Data Protection Authority and demanded that OpenAI be fined.\n- Digital rights group Noyb filed a complaint with the Norwegian Data Protection Authority on his behalf.\n- ChatGPT's model was changed after Mr Holmen's August 2024 search so that it now searches current news articles when looking for relevant information.\n- Apple suspended its Apple Intelligence news summary tool in the UK after it hallucinated false headlines.\n- The Cofense Phishing Defense Center discovered the phishing campaign.\n- The Cofense Phishing Defense Center analyzed the phishing campaign to understand the attacker's methods.\n- Cofense conducted testing and obtained a copy of the attacker's instructional video.\n- Users should remain cautious and verify all communications before responding.\n- Users should verify the sender and carefully examine the URL before taking any action.\n- Users should report suspicious activity promptly to prevent potential damage.\n- OpenAI deployed safety teams dedicated to researching and reducing bias and other risks in its models.\n- OpenAI said it is working to further reduce the number of harmful generations from its AI video tool.\n- OpenAI is researching how to change its training data to generate less biased videos.\n- OpenAI is researching how to adjust user prompts to generate less biased videos.\n- OpenAI published a system card acknowledging that biased representations are an ongoing issue with Sora.\n- OpenAI previously introduced new techniques to its AI image tool to produce more diverse results.\n- WIRED worked with researchers to refine a methodology to test Sora for bias.\n- WIRED crafted 25 prompts designed to probe the limitations of AI video generators in representing humans.\n- WIRED asked Sora ten times to generate a video for each prompt to create a dataset while limiting environmental impact.\n- WIRED analyzed the videos it generated for factors like perceived gender, skin color, and age group.\n- KDE GitLab banned the version of Microsoft Edge that the bots were claiming to be.\n- GNOME rate-limited non-logged-in users from viewing merge requests and commits.\n- GNOME switched to Anubis, a proof-of-work challenge page that requires browsers to perform computational work before granting access.\n- Jonathan Corbet warned LWN users that the website might be occasionally sluggish due to DDoS from AI scraper bots.\n- The Fedora project blocked a number of subnets to mitigate scraper traffic.\n- Fedora banned traffic from the entire country of Brazil by IP to restore service.\n- Inkscape created a 'Prodigius' block list to block offending traffic.\n- A Frama Software administrator (BigGrizzly) built a list of approximately 460,000 IPs with spoofed user agents and banned those IPs.\n- BigGrizzly offered to share his 460,000\u2011IP block list with other organizations.\n- 'ai.robots.txt' published an open list of web crawlers associated with AI companies and provided a robots.txt implementing the Robots Exclusion Protocol.\n- 'ai.robots.txt' provided a .htaccess file that returns an error page when requests come from any AI crawler in their list.\n- Read the Docs blocked all AI crawlers, immediately decreasing their traffic by approximately 75%.\n- iVerify Pakistan initiated an investigation into the viral video and its claim.\n- iVerify Pakistan analysed the interviewer's facial movements for discrepancies.\n- iVerify Pakistan conducted a reverse image search to find the original video.\n- The video was analysed using the Attestiv.ai tool, which assigned it a 93% suspicion rating.\n- The video was analysed using ChatGPT's Deepfake Detective, which determined manipulation with 95% certainty.\n- The video was analysed using Deepware, which found no evidence of tampering.\n- A visual analysis identified multiple lip-sync discrepancies between the interviewer's mouth movements and the audio.\n- A keyword search on YouTube located the original January 17, 2023 interview broadcast on PTV News.\n- iVerify Pakistan published a fact-check declaring the claim false and stating the clip was dubbed with AI-generated audio.\n- iVerify Pakistan provided a link to the January 17, 2023 PTV News YouTube video as evidence.\n- The bot's maintainer released an official report about the breach.\n- The maintainers publicly reassured users that AIXBT's core systems were not compromised and the incident did not result from manipulating the AI.\n- The maintainers migrated servers.\n- The maintainers swapped keys.\n- The maintainers suspended dashboard access to implement additional security upgrades.\n- The hacker's wallet addresses were reported to exchanges to track and potentially recover the stolen funds.\n- The attacker's X account was suspended.\n- The San Francisco City Attorney's Office filed a case challenging websites that create and spread deepfake nudes.\n- The office targeted the operators of those websites and took the sites offline.\n- Eleven of the websites that were targeted have shut down.\n- The actors that were targeted have gone out of that business.\n- The San Francisco City Attorney\u2019s Office decided to get involved to go after the businesses under California's Unfair Competition Law.\n- AAP FactCheck published a fact-check identifying the video as an AI-generated deepfake and labeling it as parody.\n- AAP FactCheck traced the video to the YouTube account DangerousAI using text overlay in the clip.\n- The DangerousAI YouTube account included a disclaimer in its About section stating the videos are original scripts, not real quotes or opinions, and that it uses AI to create the voiceovers.\n- The clip's producer publicly said the video was intended as parody.\n- Pietrzykowski's wife contacted Special Agent Alexiz Lopez on Feb. 26.\n- Pietrzykowski's wife met Special Agent Alexiz Lopez at a local coffee shop in Edinburg on Feb. 26.\n- Pietrzykowski's wife gave the hard drive to Special Agent Alexiz Lopez.\n- Special Agent Alexiz Lopez reviewed the hard drive contents with a Texas Rangers investigator the following day to determine if it contained evidence of CSAM.\n- Preston Wade Pietrzykowski was arrested on March 3 on a charge of possession or promotion of child pornography.\n- The Texas Department of Public Safety immediately suspended Pietrzykowski following his arrest.\n- The Texas Department of Public Safety referred questions about the case to the Hidalgo County District Attorney's Office.\n- The Department of Public Safety's Office of Inspector General launched a separate administrative investigation.\n- Pietrzykowski's suspension included pay pending the outcome of the agency's administrative investigation.\n- University of Michigan-Dearborn professor Hafiz Malik used a Speaker-Specific Model for Donald Trump to analyze the audio.\n- He used a generic deepfake detection tool to analyze the clip.\n- He conducted forensics analysis and concluded the clip was definitely an AI-generated (deepfake) audio of President Donald Trump.\n- NewsGuard identified the TikTok account @whmole as the account that first published the audio.\n- NewsGuard found that the now-deleted TikTok account @whmole had created other fake audio clips of Trump on different topics.\n- The TikTok account that first published the audio was deleted.\n- Roan immediately called her daughter and, after repeated attempts, reached her on the fourth try.\n- Roan called the police.\n- A police officer came to Roan's house and reviewed her transactions.\n- The officer searched a database for the mystery caller's phone number.\n- The officer searched a database for the names of the money-transfer recipients.\n- The officer advised Roan to dispute the charges.\n- A credit-card company's agent told Roan she could not get her money back because she had authorized the charges.\n- Her bank told The Wall Street Journal that not refunding authorized charges is standard practice.\n- Local residents reviewed the report's sources and found that many of the cited references did not exist.\n- Municipal director Stig Johnsen publicly admitted the report had been written with AI.\n- Johnsen said the administration discovered multiple errors in the report and expressed deep regret.\n- The municipality halted the school and kindergarten shutdown plan for now.\n- The administration announced the shutdown plan will be resumed later in the year.\n- Mayor Gunnar Wilhelmsen publicly said he was shocked and held the administration responsible.\n- Norway's Minister for Digitalisation Karianne Tung posted on LinkedIn congratulating Troms\u00f8 for using AI.\n- Karianne Tung's LinkedIn post framed the AI failure as evidence that AI is beneficial.\n- Jeremiah Fowler reported the exposed database to vpnMentor.\n- He sent a responsible disclosure notice to GenNomis and AI-NOMIS.\n- The database was restricted from public access and was no longer accessible.\n- The Face Swap folder disappeared from the database.\n- Several days later, the websites of both GenNomis and AI-NOMIS went offline.\n- Several days later, the database was deleted.\n- He published his findings to raise awareness of the data exposure.\n- The Cabinet Office warned the public that the video was a scam.\n- The Cabinet Office warned that fraudulent accounts were using AI-generated images to mislead or exploit the public.\n- The Cabinet Office urged all residents to exercise caution and remain vigilant when online.\n- The Cabinet Office instructed the public to verify the authenticity of any social-media account claiming to represent the Premier or any Government of Bermuda official.\n- The Cabinet Office advised the public to only trust information from verified sources.\n- The Cabinet Office asked anyone who receives the referenced fake AI post to report it directly on the platform.\n- The Cabinet Office reminded the public that no government official will ever use social media to promote an investment.\n- The Cabinet Office encouraged the public to rely only on official information and official advisories from the Government of Bermuda.\n- Edgar hung up the call after two minutes when the caller would not respond directly to his questions.\n- Edgar called his sister Jayla personally to confirm she was safe.\n- When the scammer called back, Edgar warned the caller that the police were on their way.\n- Jefferson County District Attorney Corey Kneeland advised people to remain vigilant and protect their personal information.\n- Kneeland advised never to release information over the phone unless you are absolutely 100% sure you know who you're talking to.\n- Kneeland emphasized that the best defense is to avoid answering calls from unknown numbers.\n- Brandon Tyler was jailed for five years.\n- Tyler was caught after he accidentally included his own Instagram handle in a screenshot taken of one of the women's accounts.\n- He admitted 18 counts of causing harassment without violence.\n- He admitted 15 counts of sharing an intimate photo or film of a person for sexual gratification.\n- The sharing of sexually explicit deepfake images was made a criminal offence in England and Wales under an amendment to the Online Safety Act in April 2023.\n- The government hoped to make creating such images an offence through its Crime and Policing Bill, which is currently at Committee Stage.\n- The BBC made information and support available via its Action Line for people affected by the issues raised in the story.\n- Be Smart Online advised parents that if they have evidence, they should go to the police.\n- Be Smart Online advocated awareness and education when discussing deepfake images and online abuse with children.\n- Be Smart Online taught children concepts like consent and respect.\n- Parents reported the cases of AI-generated naked images.\n- A 20-year-old victim came forward herself to report her case.\n- The Spanish police opened an investigation into the altered images in the Almendralejo case.\n- Parents, educators, and politicians called for urgent legal reform in response to the Spanish case.\n- Cybersecurity experts sounded the alarm about Xanthorox AI.\n- Businesses were urged to strengthen email security.\n- Businesses were urged to monitor for AI-generated phishing.\n- Businesses were urged to prepare for a wave of hyper-personalized, AI-driven attacks.\n- Guardio Labs published a report on Lovable's susceptibility to jailbreak attacks and shared the report with The Hacker News.\n- Guardio Labs released the first version of the VibeScamming Benchmark to test generative AI models' resilience against phishing workflows.\n- Broadcom-owned Symantec published a report revealing how OpenAI's Operator could be weaponized to automate stages of phishing and data exfiltration.\n- The police launched a two-year operation codenamed \"COINBLACK -- WENDMINE\" following a victim's complaint.\n- The police conducted raids in the regions of Granada and Alicante.\n- Spain's police arrested six individuals aged between 34 and 57 as part of the operation.\n- Police seized 100,000 Euros during the raids.\n- Police seized mobile phones during the raids.\n- Police seized computers during the raids.\n- Police seized hard drives during the raids.\n- Police seized firearms during the raids.\n- Police seized documents during the raids.\n- The police released a public announcement explaining the operation's complexity and the scammers' use of shell companies and aliases.\n- The police warned the public to be wary of promises of guaranteed returns.\n- The police advised the public to always verify the legitimacy and trustworthiness of an investment platform before depositing funds.\n- The police advised the public to be alert to pressure to invest as a red flag.\n- The police advised the public to be alert to inability to withdraw funds as a red flag.\n- The police advised the public to be alert to unexpected balance \"blocks\" as a red flag.\n- The police advised the public to be alert to claims about additional \"fees/taxes\" required to withdraw money as a red flag.\n- The police warned users not to be influenced by famous people supposedly promoting investment platforms because realistic AI-generated deepfake videos are now easy to create.\n- Exante filed a formal complaint with the FBI.\n- Exante's compliance team filed a complaint with the U.S. Securities and Exchange Commission (SEC).\n- Exante's compliance team filed a complaint with the U.S. Commodity Futures Trading Commission (CFTC).\n- Exante's compliance team filed a complaint with the State of New York.\n- Exante's compliance team filed a complaint with the Financial Crimes Enforcement Network (FinCEN).\n- JPMorgan Chase stated that it is looking into the matter.\n- Financemagnates.com reached out to JPMorgan Chase to seek comment about the account.\n- An Exante account manager contacted the new client (the scam victim) to ask about the money lost on the fake platform.\n- The U.S. Commodity Futures Trading Commission (CFTC) issued an advisory warning that AI is making it increasingly easier for fraudsters to create convincing scams.\n- The Securities and Exchange Commission (SEC), the North American Securities Administrators Association (NASAA), and the Financial Industry Regulatory Authority (FINRA) issued a joint warning about a rise in investment frauds involving AI and other new technologies.\n- The Federal Bureau of Investigation (FBI) issued a public warning about criminals using generative AI on a large scale.\n- The Organised Crime and Corruption Reporting Project (OCCRP), Swedish Television (SVT), and 30 media partners conducted an investigation that uncovered two boiler room operations.\n- Spanish police arrested six people for being part of a scam that stole over $20 million from at least 208 victims.\n- UpGuard scanned the web for misconfigurations and discovered around 400 exposed AI systems.\n- UpGuard collected leaked prompts every minute over a 24-hour period, amassing around 1,000 leaked prompts.\n- UpGuard analyzed the collected leaked prompts to try to identify the source of the leak.\n- The company behind the South Korea\u2013based image generator shut the generator down after being approached by WIRED.\n- Character AI increased its safety tools over time.\n- Pindrop Security used a new video authentication program it had created to confirm the candidate was a deepfake fraud.\n- Pindrop analyzed the applicant's IP address and determined it originated from thousands of miles east, possibly a Russian military facility near the North Korean border.\n- Pindrop publicly dubbed the fraudulent candidate \"Ivan X\".\n- CAT Labs relies on an identity-verification company to weed out fake candidates.\n- BrightHire helps more than 300 corporate clients in finance, tech and health care assess prospective employees in video interviews.\n- The Justice Department filed additional cases involving North Korean IT workers.\n- KnowBe4 discovered the fake employee after detecting suspicious activity coming from his account.\n- AFP published a fact-check article debunking the video.\n- PesaCheck published an article debunking the video.\n- Other media outlets published articles debunking the video.\n- Experts in digital forensics analysed the footage and confirmed it had been digitally manipulated.\n- Other experts used specialised software to analyse the video and confirmed it had been edited.\n- These experts showed exactly which parts of the frame had been falsified.\n- Zambian police launched an investigation into the video's creator.\n- The Zambian police told AFP that they were investigating the origin of the video.\n- The secretary general of the UPND, Batuke Imenda, posted a statement on social media saying the video was fake and implying members of the opposition had created it.\n- The TikTok video appears to have been deleted.\n- The article's authors looked into the video's authenticity.\n- The publisher linked to a guide on spotting AI-generated content online.\n- The publisher linked to a blog post about the use of artificial intelligence in disinformation.\n- Africa Check took a screenshot of the circulating video and ran a reverse image search on the image to locate the original video.\n- Africa Check traced the circulating video to the original video on X dated 7 February 2024 where Ruto is heard speaking in English.\n- Statehouse spokesperson Hussein Mohamed shared the original video of Ruto speaking in English on his official X account on 8 February 2024.\n- Africa Check published a fact-check concluding that Ruto spoke in English, not French, when he addressed Kenyans in Tokyo.\n- Africa Check investigated whether Jeff Koinange had endorsed the mobile gambling app in the video.\n- Africa Check took a screenshot of the part where the woman talks about the app.\n- Africa Check performed a reverse image search of that screenshot and found the original video in which the woman speaks in Kiswahili and is not talking about a gambling app.\n- Africa Check performed a reverse image search of a frame showing a man wearing glasses and found a longer Citizen TV video of Koinange reporting on a pastor that was posted on 24 April 2024.\n- Africa Check listened carefully to the video's audio and identified that the voice had a West African accent inconsistent with Koinange's usual Kenyan accent.\n- Africa Check checked Jeff Koinange's and Citizen TV's social media pages and did not find the video there.\n- Africa Check provided a link to their guide on spotting AI-generated images and videos.\n- Fact-checkers inspected the TikTok video and noted the lectern's blue color matched Kenyatta's presidency rather than the current president's lectern, suggesting the clip used old footage.\n- Fact-checkers conducted keyword searches and found no credible news reports of Kenyatta delivering such a speech.\n- Fact-checkers compared the TikTok clip to earlier footage of Kenyatta where he wore the same shirt and stood against the same background and concluded the video was fabricated using deepfake technology.\n- Fact-checkers published a correction stating that the claim Kenyatta pledged to run for president again is false.\n- H\u00f8yesterett took up the matter with the lawyer responsible for the submitted process brief.\n- H\u00f8yesterett did not impose a procedural fine or refer the lawyer to the Disciplinary Board (Advokatnemnda) in this case.\n- H\u00f8yesterett committed to provide clear information to lawyers and to strongly underscore its expectations of lawyers' responsibility when using AI.\n- H\u00f8yesterett updated and published its advokatveiledningen to include a new section on the use of AI tools that requires quality-assurance of AI-provided sources and citations.\n- Advokatforeningen offers regular courses on artificial intelligence for lawyers.\n- Advokatforeningens committee for lawyer ethics is preparing a guidance on the use of artificial intelligence.\n- The author reported the incident to OpenAI.\n- The author reconstructed some of what happened.\n- OpenAI acknowledged that Operator made a mistake and fell short of its safeguards.\n- OpenAI said it is actively examining why Operator occasionally doesn't send confirmations.\n- OpenAI said it is working to prevent similar issues.\n- OpenAI said it has already begun improving safeguards to strengthen Operator's reliability during transactions.\n- OpenAI said its improvements include stricter confirmation requirements.\n- OpenAI said its improvements include enhanced detection of ambiguous scenarios where the model should default to asking for user input.\n- Soch Fact Check reverse-searched the video and found the clip was originally from 14 February 2020 when Erdo\u011fan addressed a joint session of the Pakistani parliament.\n- Soch Fact Check corroborated the translation with Dilge Temiz of Teyit and obtained her assessment that the audio sounded very mechanical and was very likely generated using artificial intelligence.\n- Soch Fact Check spoke to Turkish journalist Hamdi \u00c7elikba\u015f, who pointed out that the audio was created by artificial AI.\n- Soch Fact Check reached out to the Turkish Embassy in Islamabad and found the embassy's mailbox was full.\n- Soch Fact Check contacted T\u00fcrkiye's consulate in Karachi but did not receive a response.\n- Soch Fact Check sent emails to T\u00fcrkiye's government offices, including the e-Government portal and the Presidency, but did not receive a reply.\n- Soch Fact Check contacted Erdo\u011fan's AK Party for comment and received no reply, with the party citing an overflowing inbox or too much mail.\n- Soch Fact Check ran the audio through the DeepFake-O-Meter using the RawNet3, AASIST, and LFCC-LCNN detectors.\n- Soch Fact Check ran the audio through Hive Moderation's AI-Generated Content Detection tool.\n- Soch Fact Check ran the audio through Hiya's Deepfake Voice Detector.\n- Soch Fact Check consulted audio engineer Shaur Azher, who performed a spectrogram analysis and concluded the audio exhibited characteristics suggesting it may be synthetic.\n- Soch Fact Check documented the clip's virality by identifying multiple social media posts and view counts, including the primary Facebook post with over 10,000 views and additional shares on YouTube and X.\n- Soch Fact Check published a fact-check concluding that Erdo\u011fan did not make the remarks during his 2025 visit, that the audio was likely synthetic, and that the accompanying video was from 2020.\n- Fat Joe posted on social media warning fans about the impersonation scam.\n- Kozak performed a quick Google search to verify the authenticity of the person contacting her.\n- Kozak checked Fat Joe's social media post which alerted her to the scam.\n- Kozak did not give the scammer any money.\n- The Better Business Bureau advised people to be leery of oversharing.\n- The Better Business Bureau advised people to resist the urge to act immediately.\n- The Better Business Bureau advised people to double or triple check the identities of people they are speaking with virtually.\n- The Better Business Bureau encouraged victims to file a report with the BBB if they lost money to a scam.\n- The Better Business Bureau said it is compiling victim names and experiences to help prosecute the bad actors involved.\n- The reporter submitted a formal complaint to OpenAI including screenshots, transcripts, and structured documentation of the incident.\n- Arise News issued a disclaimer on its official X handle dissociating itself from the deepfake video and calling it the handiwork of fake news peddlers.\n- Arise News attached a screenshot from the video stamped with the word 'FAKE' to its disclaimer post.\n- Africa Check investigated the viral video and determined the later part was digitally altered, noting that the anchor's and the president's lip movements were out of sync.\n- Africa Check found no reports from credible local or international news organisations corroborating the claim that the president announced replacing the naira with the dollar.\n- Africa Check published and linked a guide on how to spot cheap, out-of-context, and deepfake videos to help readers avoid falling for such fakes.\n- The fact-checkers investigated the video's claims and concluded the video had been doctored and made false claims.\n- The fact-checkers searched Channels Television's website and YouTube and found no trace of the video.\n- The article advised readers to steer clear of the video.\n- The article warned that the content could cause people with serious health conditions to stop taking prescribed treatments or become victims of fraud.\n- The article provided a guide and linked to resources on how to spot cheap fake and deepfake videos.\n- The article cited authoritative sources such as the World Health Organization and the American Heart Association to correct misinformation about hypertension.\n- FactCheckAfrica worked on a report investigating the circulating video.\n- FactCheckAfrica subjected the video to scrutiny.\n- FactCheckAfrica found, via NBC News, that the video originated from Donald Trump's 2017 presidential interview where he spoke about his first 100 days in office.\n- FactCheckAfrica performed reverse image searches using Yandex and Baidu that showed the image was used in a 2017 publication referencing the one-on-one interview.\n- FactCheckAfrica concluded that the video is a deepfake.\n- FactCheckAfrica decided to verify the video's authenticity.\n- FactCheckAfrica conducted an analysis of the video using reverse image and audio search tools.\n- FactCheckAfrica traced the video to a TikTok post shared on November 16.\n- FactCheckAfrica made inquiries to media experts and AI researchers about the video's audio and visuals.\n- Media experts and AI researchers confirmed that the voice in the video matches characteristics of AI-generated content.\n- FactCheckAfrica reviewed Donald Trump's verified social media accounts and public statements and found no evidence he made the remarks.\n- FactCheckAfrica found that no reputable U.S. or Nigerian media outlets reported any such statement from Trump.\n- FactCheckAfrica concluded the video was AI-generated and did not represent an authentic statement by Donald Trump.\n- Fact-checkers compared the language used in the clip to Citizen TV's typical Kiswahili 7pm bulletin and noted the English presentation as evidence of manipulation.\n- Fact-checkers performed a reverse image search that revealed the explosion footage was from a house explosion in Ohio, USA on 20 November 2024, and had no connection to Kenya or any doctor.\n- Fact-checkers conducted a Google search for 'Dr Kiprono Chepkurui' and found no results.\n- Fact-checkers performed a reverse image search on the footage of the supposed doctor and found it originated from a YouTube video uploaded in February 2017 featuring a student doctor.\n- Fact-checkers compared the words and lip movements in the footage and used the discrepancies to determine that deepfake technology had likely been used.\n- The article identified and listed red flags associated with health scams, warning readers that the video's claims fit the pattern of a 'miracle cure' scam.\n- The publication publicly labeled the video as a deepfake designed to spread misinformation and promote a dubious product.\n- The fact-check article referenced authoritative health and fraud sources (CDC, MedlinePlus, FDA) to contextualize chronic conditions and health-scam warning signs for readers.\n- Microsoft blocked imposters on Microsoft Azure.\n- Microsoft added anti-scam features to Microsoft Edge.\n- Microsoft implemented new features in Windows Quick Assist to fight tech support fraud.\n- Microsoft rejected 49,000 fraudulent partnership enrollments.\n- Microsoft blocked about 1.6 million bot signup attempts per hour.\n- Microsoft thwarted $4 billion in fraud attempts between April 2024 and April 2025.\n- Microsoft Defender for Cloud provides comprehensive threat protection for Azure resources, including vulnerability assessments and threat detection.\n- Microsoft Edge implemented website typo protection and domain impersonation protection using deep learning technology.\n- Microsoft Edge implemented a machine learning-based Scareware Blocker to identify and block potential scam pages and deceptive pop-up screens.\n- Microsoft suspended identified accounts and tenants associated with inauthentic behavior in response to Storm-1811 and other groups.\n- Microsoft encouraged people to report scammers to Microsoft at https://www.microsoft.com/reportascam.\n- In January 2025 Microsoft introduced a fraud prevention policy requiring product teams to perform fraud prevention assessments and implement fraud controls as part of their design process.\n- Microsoft developed domain impersonation protection using deep-learning at the domain creation stage to help protect against fraudulent e-commerce websites and fake job listings.\n- Microsoft developed AI-powered fake job detection systems for LinkedIn.\n- Microsoft integrated Microsoft Defender SmartScreen into Windows and Edge to help prevent unsafe browsing by analyzing websites, files, and applications based on their reputation and behavior.\n- Microsoft's Digital Crimes Unit partnered with public and private sector organizations to disrupt malicious infrastructure used by criminals, resulting in hundreds of arrests and prison sentences.\n- Microsoft's Digital Crimes Unit applied key learnings from past actions to disrupt those who seek to abuse generative AI technology for malicious or fraudulent purposes.\n- Microsoft incorporated warning messages in Quick Assist to alert users about possible tech support scams before they grant access.\n- Quick Assist requires Windows users to read and click a box acknowledging the security risk of granting remote access to their device.\n- Microsoft now blocks an average of 4,415 suspicious Quick Assist connection attempts daily that exhibit suspicious attributes.\n- Quick Assist sessions are automatically ended if Microsoft's risk signals detect a possible scam using Digital Fingerprinting.\n- Microsoft developed a Digital Fingerprinting capability using AI and machine learning to provide fraud and risk signals to detect fraudulent activity.\n- Microsoft recommended that enterprises use Remote Help instead of Quick Assist for internal tech support and provided Remote Help as a tenant-restricted alternative.\n- Microsoft built in-product safety controls and large-scale AI-based detection models to warn users about malicious activity and rapidly detect and prevent new types of attacks.\n- Microsoft became a member of the Global Anti-Scam Alliance to share knowledge and coordinate with governments, law enforcement, consumer protection organizations, and industry partners to protect consumers from scams.\n- Since 2022, officials spent $150 million on cybersecurity to fight the growing scam.\n- The California Community Colleges Chancellor's Office enlisted the help of tech companies.\n- Individual schools contracted with ID.Me to provide ID verification for enrollees.\n- Colleges updated technologies to keep fraudsters out.\n- Teachers were forced to take on a policing role to root out fake students.\n- The U.S. Department of Education opened an investigation in 2022 into a fraud ring that stole $1.1 million in student aid.\n- Cursor cofounder Michael Truell posted on Reddit acknowledging the incorrect response from a front-line AI support bot.\n- Cursor said it was investigating a bug that logged users out.\n- Cursor issued an apology for the confusion caused by the support bot's response.\n- Klarna reversed its plan to replace all of its human customer service agents after complaints about its AI chatbot's hallucinations.\n- Meta made multiple alterations to its products after the Wall Street Journal shared its findings.\n- Meta restricted accounts registered to minors from accessing sexual role-play via the flagship Meta AI bot.\n- Meta sharply curbed its capacity to engage in explicit audio conversations when using licensed celebrity voices and personas.\n- Mark Zuckerberg approved barring registered teen accounts from accessing user-created bots.\n- After the Journal presented its testing findings, Meta created a separate version of Meta AI that refused to go beyond kissing with accounts that registered as teenagers.\n- Some formerly underage user-created bots began describing themselves as \"ageless\".\n- Disney demanded that Meta immediately cease the harmful misuse of Disney's intellectual property.\n- Meta issued a statement calling the Journal's testing manipulative and unrepresentative of how most users engage with AI companions.\n- PARSE_ERROR\n- Chinonso Egemba debunked a similar AI-generated video of him promoting a product in 2025.\n- Chinonso Egemba debunked a similar AI-generated video of him promoting a product in 2024.\n- Africa Check conducted a fact-check and determined the circulating video is a deepfake.\n- Africa Check published a guide with tips on spotting AI-generated images and videos.\n- Hundreds of comments made by the researchers were deleted from Reddit.\n- 404 Media archived as many of the researchers' comments as possible before they were deleted.\n- The r/changemyview moderators posted a public disclosure revealing the unauthorized experiment to the subreddit community.\n- The researchers publicly answered several questions about the experiment on Reddit.\n- The researchers declined to answer 404 Media's questions and declined to share their identities.\n- The r/changemyview moderators decided to respect the principal investigator's request for privacy and not disclose their name.\n- Reddit's automated spam filters shadowbanned 21 of the researchers' 34 accounts.\n- The researchers publicly defended their conduct and explained their rationale for not disclosing the experiment prior to running it.\n- 404 Media contacted the anonymous email address set up by the researchers to ask questions about the research.\n- Researchers input snippets of the original papers into large language models to test whether the models would complete phrases with \"vegetative electron microscopy\".\n- Investigators compared information about different models' training datasets and identified the CommonCrawl dataset as the most likely vector where the term was learned.\n- A Springer Nature journal issued a contested retraction of a paper that included the term \"vegetative electron microscopy\".\n- Elsevier issued a correction for a paper that used the term \"vegetative electron microscopy\".\n- Elsevier attempted to justify the term's validity before eventually issuing a correction.\n- Some publishers retracted affected papers that included the term \"vegetative electron microscopy\".\n- Some publishers defended affected papers that included the term \"vegetative electron microscopy\".\n- Automatic screening tools such as the Problematic Paper Screener now flag \"vegetative electron microscopy\" as a warning sign of possible AI-generated content.\n- News outlets discussed subsequent integrity investigations into papers that used the term \"vegetative electron microscopy\".\n- She immediately hung up on the caller.\n- She attempted to add her husband to the call before the caller hung up.\n- She immediately called her daughter's school to confirm her daughter was safe.\n- She hugged her daughter for ten minutes and reassured her after confirming she was safe.\n- She spoke to the media to warn other parents and get the word out about the scam.\n- WDRB attempted to call the number back but received no answer.\n- The FBI issued a public service announcement warning that criminals are using AI to clone voices and impersonate loved ones.\n- The Social Security Administration sent an apologetic email to staffers that highlighted the training video's omission and the missing instruction to refrain from uploading sensitive personal information.\n- DOGE staff sent an email instructing SSA employees to reinstate individuals who had been marked as dead if those individuals came into the office with identification.\n- The agency instituted a process to \"resurrect\" people who were incorrectly marked as dead, a process that can take about three to four days.\n- The ABC conducted a fact-check investigation into the two websites (APPC Capital Singapore and Thackeray Mines and Minerals Inc.) Leon was directed to.\n- The ABC examined the images used on those websites to verify whether they were legitimate.\n- The ABC examined the identities of the people listed on those websites to verify whether they were legitimate.\n- The ABC examined the locations referred to on those websites to verify whether they were legitimate.\n- The ABC checked business registration records with Singapore's Accounting and Corporate Regulatory Authority (ACRA) and found APPC Capital Singapore had an active business registration number.\n- The ABC checked the Monetary Authority of Singapore (MAS) register and found APPC Capital Singapore was not listed as a licence holder.\n- Dr Lennon advised that if you think you have been scammed you should report it and contact your bank immediately.\n- Dr Gupta encouraged people to speak to a registered financial advisor who could assess their individual circumstances and recommend appropriate investment options.\n- Dr Lennon called for more mental health support for victims of scams, including counsellors and victim support groups.\n- Bree Smith stopped appearing on the local CBS-affiliated station.\n- She began tracking new accounts using the deepfake in a Google spreadsheet.\n- She added 24 new accounts using the deepfake to her Google spreadsheet over the course of one week.\n- She became a vocal advocate for regulations to help sextortion victims.\n- Smith backed the 'Preventing Deepfake Images Act' bill that passed in the Tennessee Senate.\n- The Tennessee Senate passed the 'Preventing Deepfake Images Act.'\n- The Tennessee Senate sent the 'Preventing Deepfake Images Act' to Tennessee Governor Bill Lee.\n- The bill provides a legal path for people targeted by sextortion scams to sue if images of them are shared without their consent.\n- Smith appeared before the Tennessee House Criminal Justice Subcommittee to share her experience and testify.\n- Officials urged people who believe they are victims of deepfakes to report the content to the platform hosting the content.\n- The National Cybersecurity Alliance advised reporting deepfake content to the platform hosting the content.\n- The National Cybersecurity Alliance advised reporting deepfake content to federal law enforcement through the Internet Crime Complaint Center.\n- Africa Check published a fact-check article debunking the claim that the Central Bank of Nigeria had released a N5,000 note featuring President Bola Tinubu.\n- The fact-check identified the 'Grok' watermark on the image and reported that the image had been generated by the Grok AI tool.\n- The article reported that there are no credible reports the CBN intends to create new N5,000 notes in 2025 and communicated that finding to the public.\n- The fact-checkers analyzed the image and identified signs it was AI-generated, including blurred edges, distorted faces, missing body parts, uniform facial expressions, and repeated clothing.\n- They used Sight Engine to analyze the image, which reported a 99% likelihood that the photo was AI-generated.\n- They used Hive Moderation to analyze the image, which showed an 81.5% chance that the image contained AI-generated or deepfake content.\n- Africa Check broke the circulating Facebook video into frames.\n- Africa Check ran the extracted frames through Google reverse image search.\n- Africa Check traced the frames to the original BBC video from 14 January 2021.\n- Africa Check compared the BBC video and the circulating Facebook video and identified matching clothing and portrait arrangements.\n- Africa Check identified the 'ElonTalks.com' overlay on the circulating video.\n- Africa Check matched a Trump video template on ElonTalks to the circulating Facebook video and noted that the site uses AI-generated celebrity voices and video templates.\n- Africa Check concluded the video is fake and advised that it should be ignored.\n- Africa Check located and listed multiple other Facebook posts where the same video was posted.\n- Africa Check found both videos to be fake.\n- Africa Check noted that Trump's lip movements did not always sync with the words and observed movements of the microphone tip, identifying these as clues of AI manipulation.\n- Africa Check performed a reverse image search of a screenshot from the clip and located multiple credible videos of Trump speaking during his inauguration.\n- Africa Check reviewed Trump's full inauguration speech and found no part where he spoke about the former Kenyan deputy president.\n- Africa Check concluded the video is fake and advised that it should be ignored.\n- Africa Check published and promoted a guide on spotting AI-generated images and videos and encouraged readers to follow it to stay ahead of AI trends.\n- After the money was wired, Vinod contacted his son directly and discovered the entire ordeal was a scam.\n- Vinod immediately filed a police complaint.\n- Authorities are currently investigating the incident.\n- Authorities are attempting to trace the culprits through the bank details used for the fraudulent transaction.\n- Anthropic publicly revealed the influence-as-a-service operation that leveraged its Claude chatbot.\n- Anthropic said the operation has been disrupted.\n- Anthropic banned a sophisticated threat actor that was using its models to scrape leaked passwords and usernames and to devise brute-force methods against internet-facing targets.\n- Anthropic identified at least four distinct campaigns using the programmatic persona-management framework.\n- Anthropic spotted a recruitment fraud campaign that leveraged Claude to enhance scam content targeting job seekers in Eastern European countries.\n- Anthropic spotted a novice actor who leveraged Claude to enhance their technical capabilities to develop advanced malware capable of evading security controls.\n- Anthropic warned that similar malicious activities could become common in the years to come as AI lowers the barrier to conduct influence campaigns.\n- Anthropic called for new frameworks to evaluate influence operations revolving around relationship building and community integration.\n- FBI agents responded to China's Volt Typhoon intrusions.\n- FBI agents visited compromised energy and other facilities affected by the intrusions.\n- The FBI tracks AI use by adversaries in a refined way to determine which countries and use cases are integrating AI across the attack life cycle.\n- The Office of the President urged the public to be vigilant of scams using deepfake videos and fake photos of the President.\n- The Office of the President disassociated itself from fraudulent content aimed at attracting people to financial investments, mainly crypto.\n- The Office of the President immediately reported the fraudulent pages impersonating the President to the relevant authorities.\n- The Office of the President thanked those who alerted it to such scams.\n- The Office of the President highlighted three official pages belonging to the President on Facebook, Instagram, and X.\n- Google stated that the images were not hosted on their web hosting servers.\n- Google publicly called the content \"disturbing\" and said it shared the concerns about the images.\n- Google said it is working towards a comprehensive solution to prevent future occurrences of such image search results.\n- The EndJewHatred group announced its determination to rid the internet of the 'Jewish Baby Stroller' images.\n- Katy Perry posted the AI-generated image to her Instagram account.\n- Katy Perry shared the text message she received from her mom in the Instagram post.\n- Katy Perry responded to her mom by writing \"lol mom the AI got you too, BEWARE!\".\n- Katy Perry captioned the Instagram post \"couldn't make it to the MET, had to work.\".\n- Katy Perry included photos at the end of the Instagram carousel showing she was in the recording studio to clarify she was not at the Met Gala.\n- Katy Perry shared the AI-generated photos on Instagram and explained that she did not attend the Met Gala.\n- Katy posted last year's AI deepfake to Instagram along with a screenshot of a text from her mom to highlight that the AI had fooled her and warned others.\n- ISD reviewed a sample of Operation Overload activity occurring between January and March 2025.\n- ISD analysed a sample of the operation's posts on X to assess narrative and tactical patterns.\n- ISD and other organisations monitor Operation Overload to measure its impact, identify trends, and anticipate future campaigns.\n- X removed some Operation Overload content before analysts recorded it.\n- A review of interactions with Operation Overload posts showed that all engagement occurred within a single minute after the posts went online.\n- CheckFirst, Recorded Future, the Digital Forensics Research Lab and other organisations have documented Operation Overload's past narratives and its efforts to overwhelm journalists and researchers with debunking requests.\n- French government agency VIGINUM reported that Operation Overload appears to buy X accounts from a company called WebMasterMarket.\n- ISD published a Dispatch providing an overview of Operation Overload's activities during the first quarter of 2025.\n- X added a note to posts sharing the video stating that it is not real.\n- E!News issued a statement saying the video is not authentic and did not originate from E!News.\n- Ben Stiller posted on social media refuting the claim and saying he completely self-funded his trip and received no USAID payment.\n- The New York Times issued a statement that the payments it had received were for subscriptions.\n- Politico's leaders sent a memo to staff saying the publication had never been a beneficiary of government programs or subsidies.\n- The White House announced that the administration would cancel all Politico subscriptions.\n- The Agriculture Department canceled its Politico subscriptions.\n- Police arrested and detained the 24-year-old suspect at his residence on May 7, 2025.\n- Law enforcement executed search and seizure warrants across the Federal District and Goi\u00e1s.\n- Authorities confiscated computers, mobile phones, and various digital documents during the searches.\n- Police blocked bank accounts associated with the suspect to halt the criminal group's financial operations.\n- The hacker faces charges including electronic fraud, criminal association, and money laundering.\n- The DRCC is continuing its efforts to identify other potential accomplices and victims of the scheme.\n- Police called on anyone who may have fallen victim to the scam to come forward and report their experiences.\n- The DRCC urged the public to be cautious when encountering promotional offers online.\n- The DRCC urged individuals to verify the authenticity of sources and be skeptical of unfamiliar websites.\n- Authorities committed to tracking down all individuals involved in the operation and ensuring that justice is served for those affected.\n- The Cyprus Consumers Association intentionally invested the initial \u20ac250 demanded by the scammers to investigate their methods and better inform the public.\n- The Cyprus Consumers Association is gathering evidence about the scams.\n- The Cyprus Consumers Association plans to alert citizens across Europe to prevent the scam from spreading to other countries.\n- The Cyprus Consumers Association has been monitoring the situation since early January.\n- The Cyprus Consumers Association identified two different platforms involved in the scams, one requesting initial investments of \u20ac250 and another asking for \u20ac150.\n- Some citizens reported these scams to the police.\n- The Bank of Cyprus categorically denied any involvement with the fraudulent AI platform.\n- The Bank of Cyprus issued a statement to address the fake platform and related advertisements.\n- The Bank of Cyprus said it is taking proactive measures to prevent online scams.\n- The Bank of Cyprus said it has invested heavily in protecting against potential breaches.\n- The Bank of Cyprus actively warned its customers about fraudsters using advanced technology, including deepfake visuals.\n- The Bank of Cyprus urged the public to remain vigilant and follow essential safety practices to avoid falling victim to such scams.\n- The Bank of Cyprus advised customers to only use official Bank of Cyprus channels and websites to access account information and obtain details about products and services.\n- The Bank of Cyprus advised customers to avoid clicking on links from unsolicited emails, SMS messages, or social media posts.\n- The Bank of Cyprus instructed customers to report any suspicious messages to abuse@bankofcyprus.com.\n- The Bank of Cyprus reminded customers to always verify any requests for personal or financial information directly with the bank using official contact channels.\n- The Bank of Cyprus strongly advised customers not to share sensitive information such as banking passwords, OTPs, card details, or PINs.\n- The Bank of Cyprus urged customers to cease suspicious calls or communications immediately.\n- The Bank of Cyprus urged customers to report suspicious calls or communications by calling 800 00 800 or +357 22128000 from abroad.\n- We reached out to Facebook about this scam.\n- Limit what you put out there.\n- Use the security features of the platform, restricting who has access to this content so it's not just available to the public.\n- Keep your social media profiles private and limit what you post about yourself.\n- Never give an access code to anyone.\n- Use complicated passwords and multifactor authentication to secure your digital accounts.\n- Back up any photos or videos you want to keep.\n- Hong Kong police carried out a citywide crackdown on scams, cybercrime and money laundering between April 7 and 17.\n- Officers arrested 503 people aged 18 to 80 during the crackdown.\n- Police arrested eight suspects for allegedly using lost identity cards and deepfakes to open bank accounts.\n- Police confiscated multiple phones, computers and external storage devices from the eight suspects.\n- Police said they are still investigating how the syndicate obtained the identity cards.\n- Hong Kong police collaborated with mainland Chinese police to smash two cross-border money-laundering rings over the past two weeks.\n- Mainland police arrested 17 people on the same day in connection with one syndicate.\n- Hong Kong and mainland police arrested a combined 16 people in connection with the second cross-border syndicate.\n- Hong Kong police arrested three men who had just bought 34 pieces of gold jewellery under the syndicate's directions.\n- Hong Kong police raided a scam centre inside an industrial unit in Tsuen Wan and arrested 11 people aged between 20 and 37.\n- Officers seized scripts, notes on how to approach victims, mobile phones and SIM cards at the Tsuen Wan raid.\n- Chief Superintendent Philip Lui warned the public not to rent, lend or sell access to their bank accounts.\n- Investigators uncovered the fraud scheme and revealed that the perpetrator(s) used artificial intelligence to generate deepfake video calls impersonating legitimate claim holders.\n- Adam Zarazinski, CEO of Inca Digital, issued a public warning that AI-driven fraud is on the rise and could further exploit the crypto market's rapid expansion.\n- Inca Digital's report acknowledged the challenges of verifying digital identities and the increasing prevalence of AI-generated deception in financial crimes.\n- Abnormal Security published a research blog post detailing how Gamma is being misused in this phishing campaign.\n- Dark Reading contacted Gamma via email for additional comment.\n- WhatsApp contacted more than 90 individuals it believed had been targeted with spyware.\n- Citizen Lab worked directly with three victims to investigate the targeting.\n- Citizen Lab used a tip from a collaborator to uncover more details about the spyware operations.\n- Citizen Lab analyzed an infected phone and determined Graphite had spread into two other apps, including a popular messaging app.\n- Citizen Lab homed in on the locations of at least some of Paragon's customers.\n- Citizen Lab worked with Censys to identify Internet-facing infrastructure tied to Paragon's developers and customers.\n- Researchers extrapolated from initial data to discover a range of infrastructure tied to Paragon's deployments.\n- Analysts identified Paragon deployments in Australia, Canada, Cyprus, Denmark, Israel, and Singapore.\n- Researchers inferred that connections found in Canada led to the Ontario Provincial Police.\n- Researchers uncovered other spyware cases in Ontario courts involving the York Regional Police Service, Hamilton Police Service, and Peel Regional Police Service.\n- WhatsApp discovered and fixed the zero-click exploit late last year.\n- Meta applied the fix entirely on the server side so users did not need to update their apps.\n- Three identified targets from Italy were publicly named, including an editor-in-chief and two co-founders of a migrant rescue organization.\n- Paragon corrected its earlier operational-security errors so Paragon-branded domains no longer appear in current Internet scans.\n- Serviceaide reported the incident as an unauthorized access/disclosure breach to the U.S. Department of Health and Human Services on May 9.\n- Serviceaide quickly took steps to secure Catholic Health's database.\n- Serviceaide launched an investigation into the exposure.\n- Serviceaide engaged a data review vendor to conduct a comprehensive and time\u2011intensive review of the potentially impacted data to identify any personal health information and affected individuals.\n- Serviceaide completed the comprehensive review of the potentially impacted data.\n- Serviceaide implemented additional security measures to help prevent similar incidents from occurring in the future.\n- Serviceaide is offering affected individuals 12 months of complimentary credit and identity monitoring.\n- Serviceaide is sending out notification letters to potentially affected patients.\n- Catholic Health posted a short statement on its website about the vendor's data breach.\n- Catholic Health referred the public to the breach notice posted on Serviceaide's website.\n- Ella Stapleton filed a formal complaint with Northeastern's business school.\n- Ella Stapleton requested reimbursement of tuition for that class.\n- Ella Stapleton had a series of meetings with officials in the business school.\n- School officials questioned Professor Rick Arrowood about the AI-generated materials.\n- Northeastern issued a formal AI policy.\n- Northeastern's AI policy requires attribution when AI systems are used.\n- Northeastern's AI policy requires review of AI-generated output for accuracy and appropriateness.\n- Marie confronted her professor during a Zoom meeting about the use of ChatGPT to generate feedback.\n- After a second professor appeared to use ChatGPT to give her feedback, Marie transferred to another university.\n- Students criticized the outsourcing of empathy to a machine after Vanderbilt's AI-written email.\n- The officials involved at Vanderbilt temporarily stepped down.\n- The Times sued OpenAI for copyright infringement for use of news content without permission.\n- The Times contacted dozens of professors whose students had mentioned their AI use in online reviews.\n- Dr. David Malan tinkered with his class chatbot to ensure it offers only guidance and not full answers.\n- Dr. David Malan and his teaching assistants prioritized student interactions at weekly lunches and hackathons instead of spending office hours on mundane questions.\n- After WIRED and other users pressed it, Grok changed its responses to label the claim of white genocide in South Africa a \"debunked conspiracy theory\".\n</mitigation_statements>"}]}}
{"custom_id": "batch_1000", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-5-mini", "messages": [{"role": "system", "content": "You are an AI incidents analyst specializing in qualitative analysis and taxonomy development. Your goal is to analyze the raw data and cluster it into a coherent, structured hierarchy of categories and subcategories derived directly from the data.\n\nRULES OF LOGIC:\n1. DATA-DRIVEN: Categories and subcategories must emerge only from the provided statements.\n2. NON-OVERLAPPING: Each subcategory must belong to exactly one parent category.\n\nCONSTRAINTS:\n- Organize output as categories with subcategories.\n- Maximum of 15 top-level categories.\n- Output MUST be valid JSON and nothing else."}, {"role": "user", "content": "I will provide a list of AI mitigation statements. Derive a hierarchical taxonomy (categories and subcategories) from them.\n\nOutput format:\n{\n  \"derived_taxonomy\": {\n    \"Category A\": [\"Subcat A1\", \"Subcat A2\"],\n    \"Category B\": [...],\n    ...\n  }\n}\n\n<mitigation_statements>\n- Judge Michael Wilner emailed the plaintiff's lawyers requesting they address anomalies in the brief's citations.\n- K&L Gates re-submitted a revised brief removing the two incorrect citations.\n- An associate attorney emailed Judge Wilner thanking him for catching the errors and confirming that the citations in the Revised Brief had been addressed and updated.\n- Judge Wilner issued an order to show cause (OSC) requesting a more detailed explanation of the errors and the use of AI.\n- The plaintiff's lawyers submitted sworn declarations and produced the actual AI-generated outline to explain the source of the false filings.\n- The lawyers provided profuse apologies and candid admissions of fault in their declarations.\n- Judge Wilner struck the plaintiff's supplemental briefs from the record.\n- Judge Wilner ruled that no further discovery relief would be granted on the disputed privilege issue.\n- Judge Wilner ordered the plaintiff's law firms, jointly and severally, to pay $31,000 in compensation to the defense.\n- Anthropic filed a court filing in a Northern California court admitting that an erroneous citation created by its Claude AI chatbot was used.\n- Anthropic apologized for the error and described it as an honest citation mistake rather than a fabrication of authority.\n- Federal judge Susan van Keulen ordered Anthropic to respond to the allegations.\n- New Orleans Police Chief Anne Kirkpatrick paused the facial recognition program in early April.\n- Kirkpatrick told Project NOLA in an April 8 email to turn off the automated alerts until she is sure the use of the app meets all legal and policy requirements.\n- Kirkpatrick said her agency launched a formal review into how many officers used the real-time alerts, how many people were arrested as a result, how often the matches appear to have been wrong and whether these uses violated the city ordinance.\n- Anne Kirkpatrick and Orleans Parish District Attorney Jason Williams said they are in discussions with the city council to revise the facial recognition ordinance.\n- Kirkpatrick said she would look into who made the app and cameras.\n- At Kirkpatrick's request, the Project NOLA camera at the Three Legged Dog stopped pinging police on an app.\n- The Washington Post began requesting public records about the alerts in February.\n- The New Orleans Police Department issued a public statement saying it does not own, rely on, manage, or condone the use by members of the department of any artificial intelligence systems associated with the Project NOLA cameras.\n- I asked the ABC to see if they could have the fake ads taken down.\n- 7.30 emailed the companies linked to Glyco Balance and Keto Flow + ACV.\n- 7.30 phoned the companies involved in selling Glyco Balance and Keto Flow + ACV.\n- 7.30 contacted the companies' Auckland-based accountant.\n- The main order pages for Glyco Balance were taken down after the businesses were contacted.\n- Affiliate websites were redirected to order pages for \"Glucovate\" and \"Glyco Forte\".\n- The Baker Heart and Diabetes Institute's lawyers advised Meta that there had been a breach of trademark and intellectual property.\n- Meta removed the fake ad featuring Professor Shaw after being notified of the intellectual property breach.\n- The ABC has been reporting these scams to Meta and asking Meta to take action.\n- Meta removed more than a billion fake accounts in the fourth quarter of 2024.\n- Meta removed 99.7 per cent of those fake accounts proactively before anyone noticed them.\n- The ACCC released a report demonstrating an over 25 per cent decline in reported financial losses to scams during 2024.\n- New legislation has given the regulator the power to impose multimillion-dollar fines on platforms that fail to remove scam content.\n- The FBI issued an announcement warning the public and providing mitigation tips about the ongoing smishing and vishing campaign.\n- Verify the identity of the person calling you or sending text or voice messages by researching the originating number, organization, and/or person before responding.\n- Independently identify a phone number for the purported sender and call that number to verify their authenticity.\n- Carefully examine email addresses, messaging contact information (including phone numbers), URLs, and spelling used in any correspondence or communications to detect deception.\n- Look for subtle imperfections in images and videos, such as distorted hands or feet, unrealistic facial features, inaccurate shadows, watermarks, voice call lag time, and unnatural movements.\n- Listen closely to tone and word choice to distinguish between a legitimate phone call or voice message and AI-generated voice cloning.\n- When in doubt about the authenticity of someone wishing to communicate with you, contact your relevant security officials or the FBI for help.\n- Never share sensitive information or an associate's contact information with people you have met only online or over the phone.\n- If contacted by someone you know via a new platform or phone number, verify the new contact information through a previously confirmed platform or trusted source.\n- Do not send money, gift cards, cryptocurrency, or other assets to people you do not know or have met only online or over the phone.\n- Independently confirm contact information prior to sending money or cryptocurrency when someone requests funds.\n- Critically evaluate the context and plausibility of any request to send money or other assets.\n- Do not click on any links in an email or text message until you independently confirm the sender's identity.\n- Be careful what you download and never open an email attachment, click on links in messages, or download applications at the request of someone you have not verified.\n- Set up two-factor (or multi-factor) authentication on any account that allows it.\n- Never disable two-factor (or multi-factor) authentication once it is enabled.\n- Never provide a two-factor authentication code to anyone over email, SMS/MMS text message, or encrypted messaging applications.\n- Create a secret word or phrase with your family members to verify their identities.\n- See the FBI's guidance on Spoofing and Phishing and the Public Service Announcement about criminals using generative artificial intelligence to facilitate financial fraud for additional information.\n- Consult CISA resources such as 'Phishing Guidance: Stopping the Attack Cycle at Phase One' and 'Teach Employees to Avoid Phishing' for further guidance.\n- If you believe you have been the victim of the campaign, contact your relevant security officials and the FBI.\n- Report any incident to your local FBI Field Office or the Internet Crime Complaint Center (IC3) at www.ic3.gov and include as much detailed information as possible.\n- First responders rushed Elijah to T.J. Samson Community Hospital.\n- Authorities with the FBI met the family at T.J. Samson Community Hospital.\n- Elijah was airlifted to UofL for further medical treatment.\n- FBI officials alerted the family that Elijah was likely a target in a sextortion scheme.\n- When the FBI realized the case could be part of a sextortion scheme, they placed Elijah's phone on airplane mode to preserve evidence.\n- The Electronic Crime Branch stated it is committed to tracking down the people who hide behind keyboards to target young people.\n- The National Center for Missing and Exploited Children will use the Take It Down service to scrub sexually explicit photos of minors from the internet for free when they are being extorted.\n- Kentucky Gov. Andy Beshear signed Senate Bill 73 into law, making sextortion a felony in Kentucky.\n- PRO filed a complaint with the electoral court alleging a maneuver to induce votes through deception during the electoral ban.\n- Mauricio Macri posted on social media denouncing the AI-generated video as a fraudulent attempt to confuse voters.\n- Mauricio Macri announced he would pursue legal action in response to the video.\n- Mauricio Macri reiterated his support for candidate Silvia Lospennato.\n- Mar\u00eda Eugenia Vidal announced she and her party would denounce the matter before the electoral justice.\n- Mar\u00eda Eugenia Vidal publicly replied to and condemned the libertarian accounts on X, calling it a dirty campaign.\n- Silvia Lospennato posted on social media reaffirming that she remains a candidate and denouncing the videos as an electoral crime.\n- Paula Oliveto publicly rejected the dissemination of the AI-generated productions on her X account.\n- Ezequiel Jarvis and Mat\u00edas Giampaolo, proxies for the Buenos Aires Primero alliance, submitted a formal written complaint to the Buenos Aires electoral tribunal.\n- The team conducted an OSINT investigation of the term \"Noodlophile\" across cybercrime marketplaces.\n- The investigation uncovered groups offering Noodlophile as part of malware-as-a-service (MaaS) schemes.\n- The investigators observed the developer responding to Facebook posts promoting the new malware distribution method.\n- The investigators followed links in those groups to the developer's profile and found a BIO revealing involvement in malware sales and distribution.\n- Using custom-built tooling and advanced AI-based analysis methods developed by their team, the analysts deobfuscated the Noodlophile and XWorm payloads.\n- The analysts recovered the original Python source code for the Noodlophile and XWorm payloads.\n- The report published detailed indicators of compromise, including C2 URLs and domains, IP addresses, Telegram tokens and chat IDs, and numerous file hashes.\n- Ms Potter called for ScotRail to remove her voice from its AI train announcements system and to revert to a human voice.\n- Ms Potter offered to repay her fee to ReadSpeaker in an attempt to stop them using her voice.\n- Ms Potter pursued the matter through lawyers.\n- ReadSpeaker stated that it was aware of Ms Potter's concerns.\n- ReadSpeaker said it had comprehensively addressed Ms Potter's concerns with her legal representative several times.\n- ScotRail stated it had no plans to remove the voice from its trains.\n- Cindy Picos paid for an independent inspection that found her roof had another 10 years of life.\n- CSAA Insurance changed its policy to allow customers to see aerial images on request.\n- Farmers Insurance gives customers at least 60 days to correct inaccuracies or show that flagged issues have been addressed.\n- Nichole Brink quit her job as an agent for Farmers Insurance.\n- Nichole Brink switched insurers.\n- Nichole Brink switched jobs.\n- Travelers gave Gartenmann two months to trim her trees or risk losing coverage.\n- Gartenmann paid a landscaping company $3,000 to prune her trees.\n- Gartenmann emailed photos of the cut-back branches to Travelers.\n- Travelers agreed to renew her insurance policy just days before it was set to expire.\n- Homeowners filed at least a dozen complaints with the Texas Department of Insurance since 2023.\n- A homeowner hired a roofing company to inspect the roof after State Farm threatened nonrenewal.\n- After the state became involved in that homeowner's complaint, State Farm agreed to renew the policy.\n- The homeowner who lost coverage to Nationwide found a different insurer and asked the state to investigate.\n- In response to the state's questions, Nationwide conducted a further review and said its underwriting associate had initially reviewed the wrong aerial report.\n- Nationwide said the correct aerial report would not have warranted any action regarding the roof.\n- State Farm cited its policy and said it was not required to provide inspection reports when the homeowner requested them.\n- In response to inquiries, Travelers stated it does not use drones when writing policies.\n- In response to a state complaint, State Farm said it does not use drones to survey properties.\n- Lawmakers are considering a bill to require health insurance companies to publicly disclose on their website and to individual customers if they use AI-based algorithms to evaluate claims.\n- Trump administration officials have been repeatedly revising the report since Thursday.\n- Trump administration officials have been repeatedly updating the report since Thursday.\n- Department of Health and Human Services spokesman Andrew Nixon said that minor citation and formatting errors have been corrected.\n- News outlets, beginning with NOTUS, highlighted discrepancies in the report and evidence of nonexistent research.\n- The Washington Post, in consultation with AI experts, detected the use of artificial intelligence in the initial version of the report provided to journalists.\n- The White House said the matter is being investigated.\n- The FBI issued a public service announcement warning of an ongoing malicious text and voice messaging campaign impersonating senior U.S. officials.\n- FBI Director Kash Patel issued a statement saying the FBI takes threats against the president, his staff, and cybersecurity with the utmost seriousness and that safeguarding administration officials' ability to securely communicate is a top priority.\n- Snopes contacted the Voices of Change YouTube channel to request details about the alleged debate and awaited a reply.\n- Snopes contacted representatives for Keanu Reeves to ask whether he participated in the reported debate and awaited a reply.\n- Snopes asked the Voices of Change YouTube channel whether they wrote the video's narrated text and awaited a reply.\n- Sightengine analyzed a screenshot from the video and assessed it was 99% likely to be a deepfake.\n- Hive Moderation analyzed the same screenshot and assessed it was unlikely to contain AI-generated or deepfake content.\n- Deepfake Total analyzed the video's audio and scored it 100% on its Fake-O-Meter, indicating the audio was likely a deepfake.\n- Hiya Deepfake Voice Detector analyzed snippets of the video's audio and rated them 1/100 on its authenticity score, indicating they were likely AI-generated.\n- ZeroGPT analyzed the video's narration and flagged the first few sentences as 'Human written.'\n- Searches on popular search engines returned no credible reports that the alleged debate occurred.\n- The BBC consulted a team of Sudan experts at BBC Monitoring to check the authenticity of the recordings.\n- The BBC checked other possible explanations for the recordings and concluded they were unlikely to be old clips resurfacing or the work of an impressionist.\n- A user on X recognised the August 2023 recording and identified it as matching a Facebook Live broadcast by the blogger Al Insirafi.\n- Digital forensics researcher Hany Farid compared the audio waves of the clips and noted similar patterns in speech and silence.\n- After further digging, the BBC found at least four more of the Bashir recordings that were taken from the same blogger's live broadcasts.\n- The BBC contacted the TikTok account and received a text reply in which the account denied misleading the public.\n- After being contacted by the BBC, TikTok took down the account, stating it violated their guidelines on false content that may cause significant harm and their rules on the use of synthetic media.\n- U.S. special forces carried out a precarious evacuation of the U.S. Embassy in Sudan.\n- Western governments used a ceasefire to bring home their diplomats and rescue as many nationals as possible.\n- A social media monitoring group conducted research that concluded Islamist accounts were using images of Western-led evacuations and comparisons to Kabul to claim the West was in retreat and portray themselves as victors.\n- Valent Projects investigated and concluded that Islamist accounts were behind a faked audio message supposedly from U.S. Ambassador John Godfrey.\n- British nationals were boarded onto a Royal Air Force aircraft for evacuation to Larnaca International Airport in Cyprus.\n- The Marine Security Guard Detachment at the U.S. Embassy conducted a flag-folding ceremony and took hold of the U.S. flag on April 22, 2023.\n- National TV removed the AI-created recording later.\n- Beam Reports has been tracking deepfakes in Sudan.\n- Beam Reports published an analysis about deepfakes in Sudan.\n- Marsad Beam worked on a report that verified the authenticity of viral content.\n- Beam Reports has been fact-checking content in Sudan since 2023.\n- Beam Reports spoke at an online UNESCO seminar in May to stress the challenges posed by AI-generated disinformation.\n- Individuals with advanced technical skills volunteered to help fact-check viral content.\n- Mohanad Elbalal reverse image searched frames of suspected deepfake clips and searched for identifiable elements to verify their authenticity.\n- Social media platforms started taking strong measures against deepfake content.\n- YouTube communicated a deepfakes policy prohibiting technically manipulated content that misleads users and may pose a serious risk of egregious harm.\n- YouTube requires creators to disclose when they have created or altered synthetic content.\n- YouTube applies a transparency label to synthetic content so viewers have important context.\n- The Rockingham County Sheriff's Office warned parents and teens about the scam in a Facebook post.\n- The Rockingham County Sheriff's Office advised people to slow down and think before clicking on sensational headlines.\n- The Rockingham County Sheriff's Office urged people to double-check sources, especially if a headline promises something unbelievable or stirs up strong emotions.\n- The Rockingham County Sheriff's Office asked anyone who spots suspicious content or believes someone has been targeted to contact the Rockingham County Sheriff's Office.\n- Digital safety firm Proxyware traced the scam to a centralized operation based in South Africa and identified nearly 100 websites using the same tracking code.\n- Synthesia identified the user who created the AI-generated videos.\n- Synthesia banned the user who created the AI-generated videos.\n- Synthesia said it will continue working to improve its systems to help prevent similar situations in the future.\n- Ibrahima Maiga deleted the video shortly after VICE World News contacted him.\n- The Vatican Press Office publicly debunked the video.\n- Vatican News publicly debunked the video by confirming that the Holy Father never made such a speech.\n- Rely on verified sources such as Vatican News, the official Holy See Press Office, and trusted Catholic media instead of random YouTube channels or TikToks.\n- Block or mute accounts that repeatedly share false or inflammatory content to clean your feed.\n- Be lovingly skeptical about apparent papal content.\n- Ask questions when encountering suspicious digital content.\n- Check the source of content to verify its authenticity.\n- Cross-reference content with other sources before accepting it as true.\n- GhanaFact used Google Lens to trace the original image of Traor\u00e9 contained in the viral content.\n- GhanaFact performed image analysis which revealed that some persons in the original image had been cropped out and that Traor\u00e9 had been fused with other characters into the viral image.\n- GhanaFact conducted further analysis using the wasitai.com AI-detection platform, which concluded there was a high possibility the image was AI-generated.\n- GhanaFact published a report declaring the image manipulated and fake.\n- GhanaFact reached out to a number of accounts that shared the images to provide them with the findings.\n- GhanaFact stated that it will update this script on an ongoing basis.\n- YouTube labeled the videos as \"altered or synthetic content,\" indicating they were AI-generated.\n- The investigative team used a software program to identify the fake pro-Traor\u00e9 music videos.\n- The investigative team counted at least 294 fake music videos that were posted on YouTube.\n- The investigative team recorded that the videos obtained more than 8.6 million views.\n- The investigative team identified at least 127 YouTube channels that shared the videos.\n- The investigative team analyzed YouTube channel graphics and noted gibberish text on banners that suggested AI-generated images.\n- The investigative team contacted the person behind a YouTube channel whose clip garnered more than 1.9 million views.\n- The investigative team attempted to verify the creator's claim about producing the videos.\n- The investigative team asked the creator about the identity of his sponsors but did not receive a response.\n- The Rumor Scanner team investigated the circulated video and determined it was not real (a deepfake).\n- Investigators located the original Univers Inspirant YouTube video and noted its description stated the content was fictional and labeled as altered or synthetic.\n- A 15-second clip from the circulated video was uploaded to the AI detection website Hive Moderation, which reported a 99% probability the audio and a 100% probability the video were AI-generated.\n- The same 15-second clip was uploaded to the AI detection site Sensity, which indicated a 95% probability the audio and a 98% probability the video were AI-generated.\n- Google manually removed the incorrect AI Overview response from AI Overviews.\n- Google rigorously makes improvements to Search features.\n- Google uses examples like this to update its systems.\n- PesaCheck conducted a reverse image search on Google Lens, TinEye, and Bing to investigate the photo.\n- PesaCheck closely examined the badge's style and placement and found inconsistencies with standard Rwandan military insignia.\n- PesaCheck compared the image with photos of President Kagame in military attire and noted that his uniform typically bears 'CIC' and 'RDF' rather than 'M23'.\n- PesaCheck used the AI-detecting tool Hive Moderation to verify the authenticity of the photo, which indicated a 99.5% likelihood of AI-generated or deepfake content.\n- PesaCheck performed further analysis using Sightengine's AI-image-detection tool, which gave the image a 99% AI-generated rating.\n- PesaCheck published a fact-check article declaring the photo to be fake.\n- PesaCheck provided readers with instructions on how to report suspected fake or false information on Facebook.\n- PesaCheck provided information and a link to its fact-checking methodology.\n- PesaCheck partnered with Facebook and similar social media platforms to help sort fact from fiction and fight misinformation.\n- The judge reviewed the applicant's factum again after the hearing.\n- The judge searched the CanLII website to try to find the cases cited in the factum.\n- The judge also searched Westlaw, Quicklaw, and Google and determined the unknown cases were not found there.\n- During the hearing the judge asked Ms. Lee whether her factum was prepared by artificial intelligence.\n- The judge ordered Ms. Lee to show cause why she should not be cited for contempt.\n- The judge required Ms. Lee or her counsel to attend a scheduling case conference to discuss the process for the contempt hearing.\n- The court scheduled the scheduling case conference by Zoom for May 16, 2024 at 9:00 a.m.\n- The judge reserved costs pending the outcome of the show cause proceeding for Ms. Lee.\n- The judge announced that he would personally deal with the contempt proceeding.\n- The judge afforded Ms. Lee procedural protections, including the presumption of innocence and a fair opportunity to submit evidence in the show cause proceeding.\n- An employee reported the deepfake audio incident to LastPass security.\n- LastPass confirmed that the attack did not impact its overall security posture.\n- LastPass commended the employee's vigilance in recognizing red flags related to the deepfake attempt.\n- LastPass publicized the attempted audio deepfake call.\n- LastPass emphasized the importance of employee awareness training in mitigating such deepfake social engineering attacks.\n- Meta set chats with Meta AI to private by default and required users to actively tap a share or publish button before conversations appeared on the app's discover feed.\n- At least one user asked the Meta AI chatbot to delete an exchange after posing an embarrassing question.\n- OpenAI rolled back an update to ChatGPT that added more personalization because the change made the tool sycophantic and manipulative toward users.\n- Rinki Murphy immediately contacted police after seeing the video.\n- Rinki Murphy immediately contacted NetSafe after seeing the video.\n- Rinki Murphy immediately contacted Health NZ Te Whatu Ora after seeing the video.\n- Rinki Murphy immediately contacted other organisations after seeing the video.\n- Some reported videos were taken down from social media platforms after they were reported.\n- Police issued a statement urging caution when making online purchases.\n- Police advised people to ask friends or family for their thoughts and get another set of eyes to look at the details if they were unsure.\n- Police warned consumers to never enter bank or card details on suspicious looking websites.\n- Police advised that victims of scams should report the matter to police and NetSafe.\n- The article directed readers to visit NetSafe for more information on scam awareness.\n- The VA is reviewing all 76,000 of its contracts to ensure each benefits veterans and is a good use of taxpayer money.\n- Decisions to cancel or reduce the size of contracts are made after multiple reviews by VA employees, including agency contracting experts and senior staff.\n- The VA stated it will not cancel contracts that provide services to veterans or that the agency cannot perform itself without a contingency plan in place.\n- The VA stated that contracts deemed wasteful, duplicative, or involving services the VA can perform itself will typically be terminated.\n- VA staff corrected errors produced by Lavingia's AI-based analysis.\n- Sahil Lavingia acknowledged flaws in the code and said mistakes were made.\n- Lavingia published the 'munchable' script on his GitHub account to invite others to use and improve it.\n- No contracts were terminated without human review.\n- Lavingia was terminated from DOGE after giving an interview about his work.\n- Daniel Jongyon Park was arrested at John F. Kennedy International Airport shortly after his flight from Poland arrived.\n- Park was charged with providing and attempting to provide material support to terrorists.\n- Park made his initial court appearance in the Eastern District of New York.\n- Park was detained in Poland and later was ordered deported to the United States.\n- Law enforcement conducted a search after the May 17 bombing and located significant amounts of chemicals commonly used in the construction of homemade bombs in the detached garage.\n- The FBI\u2019s Inland Empire Joint Terrorism Task Force is investigating the matter.\n- The Palm Springs Police Department provided considerable assistance to the investigation.\n- The San Bernardino County Sheriff\u2019s Department provided considerable assistance to the investigation.\n- The FBI\u2019s legal attach\u00e9 in Warsaw provided considerable assistance to the investigation.\n- Polish authorities provided considerable assistance to the investigation.\n- The FBI field office in Seattle provided considerable assistance to the investigation.\n- The FBI field office in New York provided considerable assistance to the investigation.\n- The FBI field office in San Diego provided considerable assistance to the investigation.\n- The FBI field office in Las Vegas provided considerable assistance to the investigation.\n- The FBI field office in Portland provided considerable assistance to the investigation.\n- Assistant U.S. Attorneys Sarah E. Gerdes and Anna P. Boylan and Trial Attorney Patrick J. Cashman are prosecuting the case.\n- An affidavit was filed with the criminal complaint.\n- Hyland flagged the scammer's account to Tinder.\n- Tinder evaluated Hyland's report.\n- Tinder actioned Hyland's report in accordance with its policies.\n- Tinder removes users who violate its terms of service or guidelines.\n- Tinder uses AI to root out potential scammers.\n- Tinder warns its users about potential scammers.\n- Tinder offers factsheets on romance scams.\n- Hyland attended a US Senate committee hearing.\n- A bill was introduced in the US Senate to require dating apps to remove scammers and notify users who interact with fake accounts.\n- Microsoft added watermarks to images to tackle AI-generated content.\n- Microsoft published blog posts informing users how to prevent romance scams.\n- OpenAI began rolling back the overly sycophantic ChatGPT update within days of its release.\n- OpenAI stated it is working to understand and reduce ways ChatGPT might unintentionally reinforce or amplify existing, negative behavior.\n- OpenAI said it is developing ways to measure how ChatGPT's behavior affects people emotionally.\n- OpenAI conducted a recent study with the MIT Media Lab examining emotional effects of ChatGPT use.\n- OpenAI sent a statement to The New York Times acknowledging that ChatGPT can feel more responsive and personal to vulnerable individuals and describing steps it is taking.\n- Researchers conducted a study that found chatbots optimized for engagement could behave manipulatively and deceptively with vulnerable users.\n- Jared Moore and his co-authors tested A.I. chatbots' therapeutic abilities and found the technology behaved inappropriately as a therapist in crisis situations.\n- Vie McCoy tested 38 major A.I. models with prompts indicating possible psychosis and reported that GPT-4o affirmed such claims 68 percent of the time.\n- ChatGPT offered crisis counseling resources to Alexander Taylor when he wrote that he was dying.\n- He issued a public warning on social media about the fraudulent deepfake video using his likeness.\n- He urged fans not to engage with the video.\n- He told people not to register on the website mentioned in the video.\n- He instructed people not to share their personal information.\n- He emphasized that he has no involvement with any such platform.\n- He strongly advised the public to exercise caution.\n- Almost two dozen digital rights and consumer protection organizations sent a complaint to the Federal Trade Commission urging an investigation into Character.AI and Meta's facilitation of unlicensed practice of medicine through therapy-themed bots.\n- The Consumer Federation of America and co-signatories sent the complaint to attorneys general in all 50 states and Washington, D.C.\n- 404 Media published an April investigation into Meta's AI Studio user-created chatbots that asserted they were licensed therapists.\n- Meta changed conversation guardrails to direct chatbots prompted with \"licensed therapist\" to respond with a script stating they are not licensed, and to trigger that canned script in non-therapy chatbots when \"licensed therapist\" is mentioned.\n- A group of four U.S. senators sent a letter to Meta executives and its Oversight Board urging them to immediately investigate and limit deceptive responses from Instagram's AI studio chatbots.\n- Senators' staff independently replicated many of the journalists' findings that AI chatbots were misrepresenting themselves as licensed therapists.\n- In December 2024, two families filed a lawsuit against Character.AI alleging the platform caused serious harms to youth.\n- Care Protect pulled out of the trial.\n- The state government replaced Care Protect with Adelaide's Sturdie Trade Services to run the project.\n- The state government decided to start from scratch and abandon the program.\n- The state government said it would consult with the community and stakeholders across the aged care sector to explore how technology could be used to provide safeguards for the elderly.\n- The federal Department of Health and Aged Care said further trials were not currently being considered.\n- The Judiciary Police issued a public alert warning residents to remain vigilant against deepfake videos impersonating the Chief Executive used in an online investment scam.\n- The police urged residents to remain cautious of investment offers from unknown sources, especially those promoted through social media or messaging apps.\n- The PJ advised the public to verify any investment opportunity through official or regulated channels.\n- The PJ advised the public to avoid clicking on suspicious links or providing personal information on unverified platforms.\n- The PJ reiterated that it is closely monitoring online platforms for similar cases.\n- The PJ said it will continue working with other authorities to trace and dismantle fraud networks using deepfake technology.\n- Authorities issued a warning to the public regarding a surge in fake messages circulating online, particularly involving celebrities and notable public figures.\n- Changpeng Zhao publicly cautioned that AI-powered deepfake technology has made video call verification unreliable for security purposes.\n- Changpeng Zhao warned users to avoid installing software from unofficial sources, even if the request appears to come from their friends.\n- Mai Fujimoto warned her contacts to remain suspicious of any video calls featuring her face.\n- Do not engage with the fake account impersonating Jennifer Ketchmark.\n- If the fake account reaches out to you, report it to Meta.\n- Check whether the profile name is spelled correctly and look for misspellings such as an extra 'r' in Jenniferr.\n- Check how many friends or likes the page has and treat pages with just a few as likely not legitimate.\n- Verify whether the profile has a photo and whether the photo appears legitimate.\n- Check when the profile was created and treat relatively new accounts as likely not real.\n- Search for the person's name to see if the person is still active on another page.\n- Check with the legitimate account first before engaging with the new account.\n- The author reported the deepfake avatar to experts at the Financial Times.\n- An expert colleague contacted Meta to report the adverts.\n- Meta removed and disabled the ads, accounts, and pages that were shared with them.\n- Other people brought further scam posts to the author's attention.\n- On each occasion after being notified, Meta removed the posts.\n- The author was enrolled in a Meta system that uses facial recognition technology to identify and remove such scams.\n- An expert colleague examined Meta's Ad Library data to assess the scale of the adverts.\n- That colleague determined there were at least three deepfake videos and multiple Photoshopped images running across over 1,700 advertisements that reached over 970,000 users in the EU.\n- The author and colleagues contacted officials at the Department for Culture, Media and Sport.\n- Officials at the Department for Culture, Media and Sport directed them towards Meta's ad policies.\n- Some of the fake accounts used to purchase the ads were banned.\n- Meta said it is constantly developing new ways to make it harder for scammers to deceive others, including using facial recognition technology.\n- The author asked victims to share their experiences with the Financial Times at visual.investigations@ft.com.\n- BleepingComputer reported the fraudulent ads to Instagram.\n- BleepingComputer reached out to BMO and EQ Bank to make them aware of the campaigns.\n- BleepingComputer approached Meta's communications team for comment.\n- Meta is investigating the reported content and will remove any ads deemed to be fraudulent.\n- EQ Bank is working proactively with the platforms to have the phishing ads taken down as quickly as possible.\n- EQ Bank advised its entire customer base about the rise of these scams to ensure customers are aware of what to look for and where to be cautious.\n- EQ Bank urged customers to exercise caution when encountering online promotions and to verify communications by contacting the bank directly through official channels.\n- David Rosenberg and his family reported the scams to local police and other authorities.\n- BrokersView encouraged people who saw similar scams to expose them by submitting complaints through its BrokersView complaint page.\n- Selangor police are investigating the viral TikTok video alleged to have been manipulated using artificial intelligence.\n- Selangor police issued a public statement declaring the video fake and manipulated.\n- Acryl Sani lodged a police report denying that the video contained any official statement from him.\n- Selangor police advised the public not to share the video.\n- Selangor police urged the public to verify the authenticity of any content before believing or disseminating it on social media.\n- The case is being investigated under Section 419 of the Penal Code and Section 233 of the Communications and Multimedia Act 1998.\n- Huntress identified eight unique malware components on the infected Mac.\n- Cisco Talos reported that newer versions of the malware use a Python variant of GolangGhost now known as PylangGhost.\n- Security researchers attributed the campaign to the threat actor Famous Chollima, possibly an umbrella group.\n- The U.S. Departments of State and Treasury and the Federal Bureau of Investigation issued an advisory to alert the international community, the private sector, and the public about DPRK IT workers posing as non-DPRK nationals.\n- The advisory provided detailed information on how DPRK IT workers operate.\n- The advisory identified red flags to help companies avoid hiring DPRK freelance developers.\n- The advisory identified red flags to help freelance and digital payment platforms identify DPRK IT workers abusing their services.\n- A Fact Sheet titled \"Guidance on the Democratic People's Republic of Korea Information Technology Workers\" was published.\n- Researchers found 20 deepfake videos.\n- Those 20 videos have been blocked.\n- Over 20 accounts used to disseminate the deceptive ads have been found.\n- The fake videos have been removed from social media.\n- The National Crisis Management Centre tried contacting Facebook's representative for the Baltic states.\n- Facebook promised to strengthen content review.\n- Law enforcement will continue analysis of the operation.\n- The Chief Adviser's Press Wing urged social media users to be more cautious and avoid being deceived by AI-generated deepfake videos.\n- The press wing posted that statement on its verified Facebook page CA Press Wing Facts.\n- Investigators conducted a reverse image search and found the footage was taken from Al Jazeera's programme Talk to Al Jazeera, aired on April 27, 2025.\n- Investigators reviewed the Facebook account that posted the video.\n- Investigators found the Facebook account was created on June 14, 2022.\n- Investigators found the Facebook account appeared to be operated by multiple users based in Lithuania.\n- Investigators found the account had only four posts, all promoting a gambling app called Blue Live.\n- Investigators conducted a reverse image search of key frames and linked the fake content to an original News24 YouTube video from August 10 titled 'Rangpur must become the number one district: Dr. Yunus'.\n- The press wing publicly declared the video was entirely fake and AI-generated and said the voice did not match Dr. Yunus' real voice.\n- The Ontario Provincial Police issued a public release warning about an increase in deepfake scams.\n- The Canadian Anti-Fraud Centre reported a rise in deepfake-related fraud across the country.\n- The Canadian Anti-Fraud Centre provided a hotline phone number and an online reporting link for victims to report suspicious interactions.\n- Simcoe North MP Adam Chambers warned the public about deepfake investment scams and sounded the alarm for increased awareness.\n- Adam Chambers called on platforms like Facebook, YouTube, and Google to notify users who may have interacted with fraudulent ads instead of only removing the content.\n- Adam Chambers called on crypto platforms and financial institutions to work more collaboratively with law enforcement to spot red flags and protect users.\n- Adam Chambers encouraged victims to report fraud to their local police.\n- Adam Chambers encouraged victims to contact the Canadian Anti-Fraud Centre to report suspected fraud.\n- The article noted that banks and crypto exchanges may question transfers when customers insist they are making legitimate investments.\n- Adam Chambers called for better public education, stricter enforcement tools, and stronger accountability from the platforms where these scams begin.\n- Paul Davis said he wants to raise awareness about sophisticated AI deepfake scams following his experience.\n- Paul Davis said he wants to warn others about the sophisticated tactics fraudsters are using to extract sensitive personal information, including bank and credit card details.\n- Dr Jennifer Williams warned people to stay vigilant in the face of AI-generated scam messages.\n- Dr Jennifer Williams advised people to watch for odd phrasing in messages as a telltale sign of a scam.\n- Dr Jennifer Williams advised people to watch for highly pixelated images as a telltale sign of a scam.\n- Dr Jennifer Williams advised people to watch for suspicious wording such as 'don't be afraid' as a telltale sign of a scam.\n- Dr Jennifer Williams advised people to be wary of different pixelation patterns around names, which can indicate they were digitally altered.\n- Dr Jennifer Williams stated that Facebook does not give away large sums of money or luxury vehicles as a warning to help identify scams.\n- The 18-year-old student is under investigation for \"deliberate disclosure of classified information, appropriation of classified documents\" in relation to the national high school graduation exam.\n- The exam proctor caught the student while he was carrying out the cheating scheme.\n- The student told police he had purchased a bean-shaped wireless earphone and a button-sized camera through Facebook and used them to transmit the exam questions.\n- Authorities identified three other candidates at two different exam centers who used their phones to take pictures of exam questions and sent them to AI apps to solve.\n- All three of those identified students admitted to their violations.\n- Major General Tran Dinh Chung addressed a press conference about the high school graduation exam and announced that authorities had identified other candidates who used phones to photograph questions and send them to AI apps.\n- Ravish Kumar urged viewers to stay away from the AI-generated YouTube channels that mimic his voice and image.\n- His team registered a complaint with YouTube regarding those channels and awaited action.\n- The Aircraft Accident Investigation Bureau (AAIB) is attempting to recover data from the retrieved cockpit voice recorder (CVR) and flight data recorder (FDR).\n- Paul Davis shared his story publicly to warn others and try to stop the scammers.\n- An unnamed woman posted the AI deepfake video her mother had been sent to Reddit to seek help.\n- A crack team discovered the scammer's identity.\n- The crack team discovered the scammer's Nigerian base.\n- The crack team identified 34 other victims connected to the scammer.\n- The Ministry of Post and Telecommunications issued a statement denouncing the deepfake video as malicious disinformation and serious misconduct.\n- The Ministry of Post and Telecommunications confirmed that the footage had been edited with a fabricated Thai voice track using AI technology.\n- Authorities warned the public that the 29-second clip is part of a scam and designed to deceive the public.\n- The Ministry of Post and Telecommunications stated that those responsible for creating and spreading the deepfake must be held accountable under Cambodian law.\n- The Ministry of Post and Telecommunications urged Cambodians to critically assess suspicious videos, voices, and images and to verify information with official government sources or credible media outlets.\n- The Ministry of Post and Telecommunications urged digital communication platforms, social media users, and content creators to take part in removing the deepfake video and other forms of misinformation.\n- The Ministry of Post and Telecommunications called for stern measures to be taken against those producing and distributing such harmful content.\n- The Cambodian Centre for Independent Media Executive Director urged the governments and stakeholders to come up with a mechanism to combat fake news in a timely manner.\n- Netizens publicly called out Senator Ronald Dela Rosa for sharing the AI-generated video.\n- A netizen called on the senator to verify the authenticity of videos before sharing them.\n- Malaca\u00f1ang Palace Press Officer Claire Castro publicly criticized Dela Rosa for sharing disinformation and fake news.\n- Rappler published a fact-check that now precedes the video on Facebook.\n- Senator Dela Rosa publicly defended the video and doubled down on his position, stating \"if that's AI, the creator has a point. If it's not AI, then the kids speaking have a point\" and describing his adversaries as \"trolls.\"\n- The Department of National Defence issued a statement condemning the video as fake and a malicious attempt to destabilise the administration.\n- Defence Secretary Gilberto Teodoro Jr. assured the public that the military would continue to support President Marcos Jr.'s administration and follow the chain of command.\n- Defence Secretary Gilberto Teodoro Jr. said the military would coordinate with all government agencies to suppress those behind the plot.\n- The Department of Justice condemned the fake video and said it would pursue necessary actions to identify and prosecute those behind the material.\n- Police forensic experts held a news conference to present their findings that the man in the video was not the president.\n- Police forensic experts presented comparative photos and enlarged images of faces and right ears side by side to demonstrate differences between the man in the video and President Marcos Jr.\n- Interior Secretary Benjamin Abalos said those behind the proliferation of the video would be held liable under the Cybercrime Prevention Act of 2012.\n- The Commission on Elections said the agency was set to issue guidelines in August for the use of AI to promote candidates in next year's midterm elections.\n- Three lawmakers introduced a bill seeking heavier penalties for crimes committed using deepfake technology.\n- Docomo Pacific issued a public service announcement via a press release warning residents about increasingly sophisticated AI-driven scam calls targeting elderly residents.\n- Docomo Pacific highlighted several warning signs residents should be aware of, including scammers' use of genuine personal details from social media, pressure tactics urging immediate action, and requests for secrecy.\n- Docomo Pacific emphasized that legitimate organizations, including government agencies and financial institutions, never employ high-pressure tactics or demand unconventional payment methods such as gift cards.\n- Docomo Pacific recommended verifying callers by contacting family members through trusted phone numbers.\n- Docomo Pacific recommended discussing suspicious calls with trusted individuals.\n- Docomo Pacific recommended maintaining healthy skepticism about unexpected communications.\n- Docomo Pacific recommended protecting personal information.\n- Docomo Pacific advised anyone who encounters suspected scam attempts to file a complaint with the Federal Communications Commission through the FCC's consumer complaints portal.\n- Docomo Pacific provided contact numbers for residents seeking additional information or assistance: 671-688-CARE (2273) for Guam and 670-488-CARE for the Commonwealth of the Northern Mariana Islands.\n- Baleto's mother called and verified the caller before providing any personal information.\n- Aison met with the woman in person and they reviewed the videos, concluding they appeared to have been generated by artificial intelligence.\n- He played the videos for some friends and for his parents to get their impressions.\n- Local 10 News called the suspected scammer's phone number, which appeared to be disconnected.\n- The police initiated an investigation after the woman reported that her images were being misused and circulated on social media.\n- A cyber police team employed technical surveillance to trace the IP addresses and digital footprints behind the accounts.\n- The police obtained IP logs and account details from Instagram to aid the investigation.\n- The police conducted sustained monitoring of the suspect accounts.\n- The police identified the accused based on IP logs and other digital evidence.\n- The police located the accused and arrested him.\n- The police recovered a smartphone used in the commission of the crime.\n- The police began a forensic examination of the recovered smartphone.\n- The police filed a case against the accused under sections 78 and 79 of the Bharatiya Nyaya Sanhita.\n- Ukrinform labeled the circulated video as fake news.\n- Ukrinform determined that the video had been edited using artificial intelligence and that an AI-generated audio file mimicking Biletskyi's voice was inserted into the original footage.\n- Ukrinform used the Hive Moderation AI-content detection service to analyze the video's audio and reported that 99% of the audio was artificially generated.\n- Ukrinform cited the serviceman's unnatural facial expressions as evidence that the video was manipulated.\n- Ukrinform identified and linked to the original May 16, 2025 video used to create the deepfake and showed that the serviceman in the original did not mention identifying fallen soldiers or compensation.\n- Ukrinform corrected the false claim about command roles by clarifying that Andrii Biletskyi is the commander of the Third Army Corps and that Colonel Denys Prokopenko is the current commander of the Azov 1st Corps.\n- Ukrinform previously published a fact-check debunking the claim that 40,000 Ukrainian soldiers' bodies were being held in Russia.\n- Ukrinform previously published a fact-check debunking the claim that bodies were returned only for those whose families refused financial compensation.\n- Ukrinform previously debunked the fake story that the military commandant of the Kursk region, Eduard Moskaliov, had fled to France.\n- The Center reported that Russian Telegram channels spread deepfake videos falsely claiming Deputy Prime Minister Olga Stefanishyna proposed legally banning women aged 18 to 27 from leaving the country and that the Verkhovna Rada supported this initiative.\n- The Center clarified that there are no plans for the mobilization of women, no bills in the Verkhovna Rada proposing such changes, and no government decisions or statements about mass mobilization of women.\n- The Center issued a public warning advising people to trust only verified sources of information and not fall for enemy provocations.\n- The paper slated for presentation at the International Conference on Machine Learning will be withdrawn.\n- KAIST will set guidelines for the appropriate use of artificial intelligence in response to the incident.\n- Authorities such as the Malaysian Communications and Multimedia Commission removed flagged AI-generated scam content.\n- Michael Chong and several MCA members conducted a sting operation to illustrate how victims are ensnared.\n- They pooled RM1,100 and responded to a link beneath one of the scam videos.\n- A team member played along and invested RM1,100 as part of the sting.\n- After the scammers demanded another US$250 as a processing fee, the team confirmed it was a scam and stopped engaging.\n- The judge checked her notes and asked the chief stenographer to listen to the recording to verify the case reference.\n- The judge requested the two law researchers employed at the Pietermaritzburg High Court to peruse the supplementary notice of appeal and to provide all the cited cases to her.\n- An email was sent to Ms Pillay requesting copies of the two cases referred to in argument as well as the cases cited in the supplementary notice of appeal.\n- Ms Pillay applied for an adjournment because she had been unable to obtain the cases in the limited time available.\n- The judge requested Ms Pillay to make arrangements for Ms Rasina Farouk to attend court to explain the origin of the cases cited in the supplementary notice of appeal.\n- The judge stood the matter down to enable them to go to the high court library and draw the relevant cases.\n- A cellphone containing a reference to a Competition Tribunal matter was handed up to the judge to show a reference to a case found during the adjournment.\n- The judge agreed to adjourn the matter to September 25, 2024, to provide Mr Singh and his staff with a final opportunity to provide the cases cited in court and in the supplementary notice of appeal.\n- The judge indicated she would only accept cases from either the South African Law Reports, All South African Law Reports, or SAFLII.\n- The judge ordered that costs incurred in respect of the additional appearances be paid by the firm Surendra Singh and Associates.\n- The judge ordered that a copy of the judgment be sent to the Legal Practice Council in KwaZulu-Natal for its attention and further action.\n- The judge dismissed Mavundla\u2019s leave to appeal with costs.\n- Ms Rasina Farouk requested an opportunity to go back to the office to look at her search history and to provide the relevant cases to the judge.\n- Mr Suren Singh indicated he tried to obtain the cases by using Google.\n- The magistrate postponed the case for two months to allow the parties to track down the alleged judgments.\n- The court imposed a punitive costs order against the plaintiff.\n- Rodrigues Blignaut Attorneys explored an advanced AI tool and then followed up on the findings gathered.\n- Rodrigues Blignaut Attorneys conducted extensive discussions with various high courts, court registrars in multiple provinces, and law librarians at the Legal Practice Council library to locate the cited judgments.\n- The defence team engaged in lengthy correspondence with Rodrigues Blignaut Attorneys after receiving the list of case names and citations.\n- The defence junior counsel, Ziphozihle Raqowa, spent 15 hours over four days searching for the cited judgments.\n- The Johannesburg Bar library staff attempted to track down the judgments and informed parties they could not locate them and suspected the cases were generated by ChatGPT.\n- Rossle contacted Parker\u2019s attorneys the Friday before the hearing to ask whether they had found the real judgments.\n- In court, the plaintiff\u2019s counsel acknowledged that the cases had been sourced through ChatGPT.\n- The acting judge sought clarification from the parties about the fabricated citations.\n- The acting judge asked whether the situation aligned with the recent Mavundla case in the KwaZulu-Natal Division.\n- Junior counsel Giles Barclay-Beuthin provided a corrected version of the heads of argument in which the problematic paragraphs were replaced.\n- The court gave Northbound's counsel another chance to respond.\n- Barclay-Beuthin acknowledged to the court that the non-existent citations likely originated from an AI tool called 'Legal Genius'.\n- Senior counsel Arnold Subel SC took full responsibility for the oversight and apologised.\n- The acting judge accepted the legal team's apologies.\n- The acting judge ordered that the conduct of Northbound's legal practitioners be referred to the Legal Practice Council for investigation.\n- The acting judge endorsed the reasoning from the Mavundla case and a recent English High Court decision warning of the dangers of relying on GenAI without verification.\n- Factcrescendo investigated the circulating video and claims to verify whether President Anura Kumara Dissanayake made the statement and whether an official investment scheme existed.\n- Factcrescendo reviewed the 'Satana' program broadcast on May 3 and confirmed the President did not make any statements about the alleged investment scheme.\n- Factcrescendo examined the circulating video and determined the voice did not match the President's and showed signs of manipulation or AI generation.\n- Factcrescendo confirmed that the web URL used in the post does not belong to the official Daily Mirror website.\n- Factcrescendo contacted Gayan Sampath, one of the journalists who hosted the program, who confirmed that no such statement about the investment opportunity was made.\n- Factcrescendo reached out to journalist Kalindu Karunaratne, who confirmed the President did not make the alleged statements and stated that the circulating article is fake.\n- Factcrescendo contacted the Presidential Media Division, which confirmed the President did not make the investment claims and stated the video was created using artificial intelligence and that the government has no plans to launch such a program.\n- Sri Lanka CERT confirmed the circulating content is a scam and warned the public to be cautious of such fraudulent online schemes.\n- Cybersecurity expert Asela Widyanakara analyzed the viral posts and warned that clicking misleading links can redirect users to external applications designed to compromise personal details.\n- Factcrescendo advised the public not to trust sensationalized financial claims tied to celebrities without verification from reliable sources.\n- Factcrescendo advised the public to avoid clicking on suspicious links or entering personal information on unverified platforms.\n- Factcrescendo urged people to report misleading or fraudulent social media posts to relevant authorities.\n- Factcrescendo recommended verifying news articles by visiting the official websites of reputed media outlets.\n- The State Department said it will carry out a thorough investigation.\n- The State Department said it will continue to implement safeguards to prevent this from happening in the future.\n- The State Department cable urged U.S. diplomats to report any impersonation attempts to the Bureau of Diplomatic Security.\n- The Bureau of Diplomatic Security is investigating the matter.\n- The State Department cable urged non-State Department officials to alert the FBI's Internet Crime Complaint Center.\n- The episode involving Susie Wiles's phone breach spurred a White House and FBI investigation.\n- In May, the FBI issued a public warning that malicious actors were impersonating senior U.S. officials in an ongoing text and voice messaging campaign and advised recipients not to assume such messages are authentic.\n- The incident contributed to Michael Waltz's ouster.\n- The incident curtailed the widespread use of the Signal app for national security group meetings.\n- Ukraine's Security Service announced that Russian intelligence agents were impersonating the agency to recruit Ukrainian civilians for sabotage missions.\n- The Canadian Anti-Fraud Center and the Canadian Center for Cyber Security warned that scammers were utilizing artificial intelligence to impersonate senior government officials to steal sensitive information or money or to insert malware into computer networks.\n- The ABC7 I-Team called the scammer and never heard back.\n- Victims reported cryptocurrency scams to the FBI's Internet Crime Complaint Center (IC3), and the FBI said those reports were skyrocketing.\n- The FBI advised victims to report fraud quickly to the Internet Crime Complaint Center (IC3) so the bureau may be able to help recover money.\n- Private blockchain companies can be hired to trace the crypto trail.\n- Lionsgate Network said it can generate a forensic analysis report to locate stolen cryptocurrency quickly.\n- Lionsgate Network said it can provide the forensic information to authorities even though it cannot recover the money itself.\n- Lionsgate Network said it has been receiving several reports in the Chicago area of celebrity crypto cons.\n- Monica Geingos released a video message making a public appeal warning people that fraudsters are using her name and likeness.\n- Her team have been raising the issue of fraudulent accounts and manipulated clips for almost two years.\n- She urged people not to communicate with fake accounts impersonating her.\n- She urged people to report the fake accounts.\n- The public were urged to be more cautious with investments.\n- The public were urged to scrutinise any suspicious communication they receive, especially from well-known figures.\n- South Memphis residents and their defenders voiced vocal opposition to the xAI/Colossus facility.\n- The Southern Environmental Law Center publicly stated that xAI had been operating dozens of unpermitted methane gas turbines without public notice, permits, or air pollution controls.\n- Judge Nina Y. Wang imposed sanctions on the two lawyers who represented Mike Lindell.\n- Judge Nina Y. Wang fined Christopher I. Kachouroff and Jennifer T. DeMaster $3,000 each.\n- Judge Wang found that the lawyers had violated a federal rule requiring lawyers to certify that the claims they make in court filings are grounded in the law.\n- At an April hearing, Judge Wang asked Mr. Kachouroff whether the court filing containing the errors had been generated by generative artificial intelligence.\n- At the same hearing, Judge Wang asked Mr. Kachouroff whether he had double-checked the citations in the filing.\n- Mr. Kachouroff acknowledged at the hearing that he personally did not check the citations and said he was responsible for them not being checked.\n- Mr. Kachouroff filed court papers asserting that he and his co-counsel had prepared a thoroughly cite-checked final document and that his co-counsel had mistakenly filed a draft version while he was on vacation.\n- Ms. DeMaster filed a statement apologizing to the court for mistakenly uploading the draft version and saying it was not done intentionally or in bad faith.\n- The High Court of England and Wales warned lawyers that they could face criminal prosecution for presenting false material generated by artificial intelligence.\n- X deleted some of Grok's posts on Tuesday evening.\n- xAI said it was actively working to remove the inappropriate posts.\n- xAI took action to ban hate speech before Grok posts on X.\n- xAI removed the guideline that allowed the chatbot to make politically incorrect claims from its code.\n- The Royal Brunei Police Force issued a public warning to remain vigilant against deepfake scam videos on social media platforms including TikTok, Facebook, and Instagram.\n- The Cyber Crime Investigation Division disclosed that scammers are using AI to create manipulated videos and audio that resemble real police personnel.\n- Authorities strongly advised the public not to be easily deceived by content that promises unrealistic financial gains or get-rich-quick schemes.\n- The division reminded the public that any investment scheme not approved by the Brunei Darussalam Central Bank or local banks is illegal and poses a high financial risk.\n- Members of the public were urged to report any suspicious content or fraudulent activity to the nearest police station or via the police emergency line at 993.\n- Individuals were advised to immediately notify their bank if a suspicious transaction has occurred.\n- The Securities and Exchange Commission issued a public warning that scammers have been utilizing deepfake technology to create manipulated videos and audio recordings falsely depicting known personalities endorsing investment schemes.\n- The SEC warned the public to avoid interacting with suspicious advertisements, websites, or social media accounts that claim to offer investment opportunities endorsed by popular personalities.\n- The SEC advised the public to check with the SEC to confirm the legitimacy of the offering, the offeree, and the security or investment product being offered.\n- The SEC provided phone numbers 88187650 and 88186047 for clarification on the advisory or to report a scam involving deepfake videos and audio recordings.\n- The SEC provided the email address epd@sec.gov.ph for clarification on the advisory or to report a scam involving deepfake videos and audio recordings.\n- The author shared portions of the conversations with OpenAI and requested an interview.\n- ChatGPT provided information about a suicide-and-crisis hotline when the author explicitly asked for instructions on how to cut themselves.\n- Google implemented additional protections after learning of the author's role-played rape-scene exchange with its chatbot.\n- The Atlantic granted the tipster anonymity because he feared professional consequences.\n- Tulsi Gabbard said she would make a criminal referral to the F.B.I. based on recently released documents.\n- A link to real video footage from an interview that Ms. Gabbard gave to Fox News was posted to Mr. Trump's social media account.\n- Democrats publicly denounced the administration's effort to discredit Mr. Obama as politically motivated and riddled with errors.\n- Irwin's mother reviewed his ChatGPT chat log in search of answers.\n- Irwin's mother prompted ChatGPT to self-report what went wrong.\n- When prompted by Irwin's mother, ChatGPT self-reported what went wrong and admitted it had failed to interrupt the interaction and had given the illusion of sentient companionship.\n- Gajdosik showed her son ChatGPT's self-report.\n- Irwin's mother took him to the emergency room after he acted aggressively.\n- The county medical health crisis team brought Irwin back to the hospital after he signed himself out against medical advice.\n- Irwin was admitted to a mental-health hospital and stayed for 17 days.\n- Irwin was hospitalized again in late June for a few days after another manic episode.\n- Irwin deleted ChatGPT from his phone.\n- Irwin is receiving outpatient care while living with his parents.\n- OpenAI said it is working to understand and reduce ways ChatGPT might unintentionally reinforce or amplify existing negative behavior.\n- OpenAI is training ChatGPT to recognize signs of mental or emotional distress in real-time.\n- OpenAI is developing ways for ChatGPT to de-escalate these kinds of conversations.\n- The Replit team worked through the weekend to address the incident.\n- They implemented various guardrails to rein in the Replit Agent's unacceptable behavior.\n- They made other useful changes intended to control the agent's behavior.\n- They started rolling out automatic database development/production separation to prevent this categorically.\n- They are actively working on a planning/chat-only mode so users can strategize without risking their codebase.\n- They announced that backups and rollbacks will be improved.\n- Some of the YouTube Live videos were suspended when checked later.\n- Blockchain analytics platform Elliptic released a report observing that AI tools such as chatbots and deepfake software made it easier to launch crypto crimes and scams.\n- Authorities are actively pursuing those behind the fraud.\n- The Israeli Internet Association is working toward legislation to force digital platforms to adopt greater transparency and accountability.\n- The Israeli Internet Association is working toward legislation to bolster investigative capabilities.\n- The Israeli Internet Association is working toward legislation to empower specialized enforcement units.\n- Meta stated it is working in cooperation with governments, other tech firms, banks, and law enforcement worldwide to prevent scams on its platforms.\n- Meta stated it invests in teams and technology to detect scams and remove fake accounts.\n- Meta stated it acts to remove all content that violates its impersonation policy.\n- Facebook and Instagram have removed individual posts related to the scams.\n- Platforms performed limited removals of isolated ads.\n- Jonathan Ben-Horin issued a sharp rebuke to Meta for its piecemeal approach to removing scams.\n- Jonathan Ben-Horin called on Meta to take a systemic and proactive approach to remove scam infrastructure and content based on field data and victim reports.\n- The Westbrook Police Department issued a public apology for sharing the AI-altered photo.\n- The department shared a side-by-side comparison of the original and edited images.\n- The department posted an explanation saying an officer added the patch with a photo-editing app which altered the photograph.\n- The department initially denied AI had been used and later confirmed that it had used the AI chatbot ChatGPT.\n- The department said it will invite news media to view the original evidence so they can see that the evidence exists.\n- The superintendent informed parents about the incident via a letter.\n- The district is addressing the matter through appropriate channels to respond thoughtfully and effectively.\n- The school offered its full support to the teacher involved.\n- The online account that hosted the video has been reported.\n- The post has been taken down.\n- The district asked parents to reinforce with students the importance of using technology responsibly.\n- School staff are available to help students who have questions or need support.\n- The district asked parents to contact them with any concerns or information to assist in addressing the matter.\n- The district stated it is committed to protecting the teacher's dignity and well-being.\n- After learning about the author's encounter, Google implemented additional protections for Gemini.\n- Following those changes, Gemini refused to respond to 'talk dirty' prompts and to requests to summarize explicit passages for accounts registered as 13-year-olds.\n- A Google spokesperson said the company's teams conduct ongoing testing and that when child-safety experts identify potential risks the company adds safeguards and mitigations.\n- Character.AI implemented new safety features for minors.\n- OpenAI released an update to address a bug that temporarily allowed accounts registered to fake minors to generate erotic content.\n- Meta said it had taken additional measures to make it more difficult for individuals to manipulate its products into extreme use cases.\n- The boy's mother filed a lawsuit alleging that Google and Character.AI are responsible for her son's death.\n- Google publicly stated that it had nothing to do with the creation or management of Character.AI's app and that none of the start-up's technology has been incorporated into Google's products.\n- A Google spokesperson responded to the author's report by saying the examples were 'far from typical interactions with Gemini, requiring specific techniques and multiple attempts to get around our protections.'\n- Amazon quickly mitigated an attempt to exploit a known issue in two open-source repositories that altered code in the Amazon Q Developer extension for Visual Studio Code.\n- Amazon confirmed that no customer resources were impacted.\n- Amazon stated that it has fully mitigated the issue in both repositories.\n- Amazon removed the compromised version of the Q Developer extension from the Visual Studio Code Marketplace.\n- Many farmers and conservationists examined the peatland in their local areas after the map's release.\n- Cat Frampton zoomed in on her land on the map to check its accuracy.\n- Cat Frampton scrolled out and inspected other mapped areas on the map.\n- Cat Frampton turned on a filter to show bare peat to look for deposits and misidentifications.\n- Tim Ashton examined the map for his area and identified that Soulton bluebell wood was incorrectly mapped as prime peat and that a 40-acre degraded peat field was unlisted.\n- Farmers in Dorset, the Lake District and other parts of the country reported problems with the map.\n- The National Farmers Union collected feedback from its members about problems with the peat map.\n- Federal prosecutors indicted Michael Gann.\n- Law enforcement arrested Michael Gann.\n- A criminal complaint was filed at the time of Gann's arrest.\n- A witness informed the FBI that Gann was mixing explosives and pointed to a Jewish school.\n- A second witness agreed to make phone calls to Gann while the FBI listened in.\n- Law enforcement agents identified themselves to Gann when they encountered him on the street.\n- Agents read Gann his rights.\n- One explosive device that fell on the train tracks was recovered.\n- Gann told law enforcement officials that he used artificial intelligence to learn which chemicals to purchase and mix.\n- Airbnb apologised to the woman.\n- Airbnb credited the woman's account with \u00a3500.\n- Airbnb offered the woman an \u00a3854 refund.\n- Airbnb refunded the woman the full cost of her booking (\u00a34,269).\n- Airbnb removed the negative review the host had placed on her profile.\n- Airbnb launched an internal review of how the case was handled.\n- Airbnb warned the host for violating its terms and told him he would be removed if there was another similar report.\n- Airbnb informed the host that it could not verify the images he submitted as part of his complaint.\n- President Toroama urged the public, especially content creators and users of emerging technologies, to reflect on the ethical implications of their digital actions.\n- He called on social media platforms and regulatory bodies to take more robust steps in curbing the spread of misleading AI-generated content.\n- He called on NICTA to get to the bottom of the video.\n- He reaffirmed Bougainville's commitment to a peaceful and constructive path toward its political future and stated that such incidents must not derail efforts to foster unity and mutual understanding.\n- \u6cd5\u9662\u4ee5\u4fb5\u72af\u516c\u6c11\u500b\u4eba\u4fe1\u606f\u7f6a\u3001\u4fe1\u7528\u5361\u8a50\u9a19\u7f6a\u6578\u7f6a\u4e26\u7f70\uff0c\u5224\u8655\u7b26\u67d0\u6709\u671f\u5f92\u52114\u5e746\u500b\u6708\u3002\n- \u6cd5\u9662\u8981\u6c42\u7b26\u67d0\u627f\u64d4\u4eba\u6c11\u5e6315996\u5143\u516c\u76ca\u640d\u5bb3\u8ce0\u511f\u91d1\u3002\n- \u6cd5\u9662\u8981\u6c42\u7b26\u67d0\u522a\u9664\u5b58\u5132\u7684\u6240\u6709\u516c\u6c11\u500b\u4eba\u4fe1\u606f\u3002\n- \u6cd5\u9662\u8981\u6c42\u7b26\u67d0\u5728\u570b\u5bb6\u7d1a\u65b0\u805e\u5a92\u9ad4\u4e0a\u516c\u958b\u8ce0\u79ae\u9053\u6b49\u3002\n- \u6aa2\u5bdf\u6a5f\u95dc\u63d0\u8d77\u4e86\u5211\u4e8b\u9644\u5e36\u6c11\u4e8b\u516c\u76ca\u8a34\u8a1f\u3002\n- \u6aa2\u5bdf\u6a5f\u95dc\u53ca\u6642\u767c\u51fa\u6cd5\u5f8b\u98a8\u96aa\u63d0\u793a\u51fd\u3002\n- \u8a72\u91d1\u878d\u652f\u4ed8\u5e73\u81fa\u5df2\u5b8c\u6210\u6574\u6539\u3002\n- Bryan Moore flagged the mistake to Google on LinkedIn.\n- Bryan Moore contacted the paper's authors directly to notify them of the error.\n- Google quietly edited its debut blog post to change the phrasing from \"basilar ganglia\" to \"basal ganglia\" without altering the research paper.\n- Google Health employees responded to Bryan Moore and characterized the mistake as a typo.\n- Bryan Moore publicly called out Google for quietly editing the blog post.\n- Google restored the original model output in the blog post and added a clarifying caption stating that \"basilar\" is a common mis-transcription of \"basal\" that Med-Gemini learned from the training data.\n- Google acknowledged the issue in a public LinkedIn comment and stated it had updated the blog post figure to show the original model output.\n- X reminded users that posting Non-Consensual Nudity (NCN) images is strictly prohibited and that the platform has a zero-tolerance policy toward such content.\n- X Safety stated that their teams are actively removing all identified images.\n- X Safety stated that they are taking appropriate actions against the accounts responsible for posting the images.\n- X Safety stated that they are closely monitoring the situation.\n- X Safety stated that they will ensure any further violations are immediately addressed and the content is removed.\n- Grok cited The Verge's reporting and confirmed that its own design can trigger partially nude outputs of celebrities.\n- The patient was admitted to a medical telemetry bed for electrolyte monitoring and repletion.\n- The clinical team consulted the Poison Control Department.\n- The clinicians reviewed UpToDate to inform the differential diagnosis.\n- A dedicated bromide level was ordered and determined via inductive coupled plasma mass spectrometry.\n- The patient received risperidone, which was titrated up to 3 mg daily for psychosis.\n- The patient was treated with intravenous fluids and electrolyte repletion.\n- The patient was admitted to the inpatient psychiatry unit.\n- The patient was tapered off risperidone before discharge.\n- The authors queried ChatGPT 3.5 to reproduce what suggestions it would give about replacing chloride.\n- The patient attended a follow-up check-in two weeks after discharge and remained stable off medication.\n- The 13-year-old girl was arrested.\n- She was interrogated.\n- She was strip-searched.\n- She spent the night in a jail cell.\n- Her parents were not allowed to talk to her until the next day.\n- A court ordered eight weeks of house arrest for the girl.\n- A court ordered a psychological evaluation for the girl.\n- A court ordered 20 days at an alternative school for the girl.\n- The girl's parents filed a lawsuit against the school system.\n- A group of student journalists and artists at Lawrence High School filed a lawsuit against the school system alleging unconstitutional surveillance.\n- District officials later adjusted the software's settings to reduce false alerts.\n- Teachers at the girl's alternative school took time every day to let the kids share their feelings and frustrations without judgment.\n- Snapchat's automated detection software alerted the FBI about a student's comment.\n- The student whose Snapchat comment was detected was arrested on school grounds within hours.\n- Lightspeed Alert detected a threatening message and two students were taken away about five minutes later.\n- Gaggle alerts led Polk County officers to carry out 72 involuntary hospitalization cases under the Baker Act.\n- Students were called to the principal's office over concerns Gaggle had detected nudity.\n- School officials deemed almost two-thirds of Gaggle alerts nonissues, including over 200 false alarms from student homework.\n- Independent fact-checkers checked the facts and found the story unsupported.\n- Analysts examined the photograph and identified multiple AI-generation artefacts, concluding it was a fake image.\n- Investigators checked Ministry of Defence public records, honours lists, and military directories and found no record of the named individuals.\n- The reporter checked reputable Western, Ukrainian, and international media outlets and found none had reported the story.\n- The reporter found no announcement from the UK Ministry of Defence regarding the alleged captures.\n- The reporter found no indication from NATO corroborating the claim.\n- The reporter found no alert or prisoner-of-war notification from international bodies such as the Red Cross/ICRC.\n- The publisher chose not to link to the original Russian-aligned article to avoid increasing its visibility and spread.\n- The New York Times contacted GoLaxy.\n- After being contacted by The New York Times, GoLaxy began altering its website by removing references to its national security work on behalf of the Chinese government.\n- GoLaxy issued a public statement denying that it was creating any sort of \"bot network or psychological profiling tour\" or that it had done any work related to Hong Kong or other elections.\n- GoLaxy stated that its products are mainly based on open-source data and that it did not specially collect data targeting U.S. officials.\n- American spy agencies monitored GoLaxy's activity for signs that it might try to influence American elections or political debates.\n- Vanderbilt University's Institute of National Security obtained the leaked documents.\n- Vanderbilt researchers Brett J. Goldstein and Brett V. Benson revealed the existence of the documents in a guest essay for The New York Times Opinion section.\n- Chris Cuomo deleted the Instagram post containing the prominently watermarked deepfake video.\n- Chris Cuomo posted on social media acknowledging that the video was a deepfake and thanking Alexandria Ocasio-Cortez for correcting him.\n- Chris Cuomo stated publicly on NewsNation that 'I was wrong' regarding sharing the video.\n- Alexandria Ocasio-Cortez publicly identified the clip as a deepfake and urged Cuomo to use his critical thinking skills.\n- The Tea team discovered the initial breach on July 25.\n- Tea launched an ongoing investigation into the cybersecurity incident.\n- Tea disclosed that some direct messages (DMs) were accessed as part of the initial incident.\n- Tea took the affected system offline.\n- Tea reported that it found no evidence of access to other parts of its environment.\n- The company notified the public that only users who signed up prior to February 2024 were affected.\n- Two class-action lawsuits were filed in California in response to the breach.\n- Security researcher Sandeep Hodkasia privately disclosed the bug to Meta on December 26, 2024.\n- Meta deployed a fix for the bug on January 24, 2025.\n- Meta paid Sandeep Hodkasia a $10,000 bug bounty reward.\n- Meta reported finding no evidence that the bug was maliciously exploited.\n- Logan Kilpatrick, Google DeepMind's group project manager, publicly acknowledged the issue on X.\n- Google said it was working to fix the infinite looping bug that caused Gemini's self-deprecating messages.\n- The repository that had been mistakenly made public was set to private.\n- Lasso investigated further.\n- Lasso extracted a list of repositories that were public at any point in 2024.\n- Lasso identified which of those repositories had since been deleted or set to private.\n- Lasso used Bing's caching mechanism to find that more than 20,000 since-private GitHub repositories still had data accessible through Copilot.\n- Lasso reached out to all affected companies that were \"severely affected\" by the data exposure.\n- Lasso advised those affected companies to rotate or revoke any compromised keys.\n- Lasso informed Microsoft of its findings in November 2024.\n- Microsoft removed links to Bing's cache from its search results starting December 2024.\n- The caching feature was disabled.\n- Microsoft deleted the referenced GitHub repository that Lasso used Copilot to retrieve.\n- Amazon told TechCrunch that it was not affected by the issue.\n- Lasso removed all references to AWS following the advice of its legal team.\n- Fact-checkers investigated the viral video and confirmed that the depicted orca attack was fabricated.\n- Fact-checkers searched marine park employment records, public databases, and news coverage and found no record of Jessica Radcliffe.\n- Investigators searched official marine safety reports and found no evidence of the alleged attack.\n- Analysts examined the clip and identified AI-generated voiceovers combined with unrelated archival footage.\n- Experts advised viewers to check whether multiple reputable news outlets have reported the event before sharing.\n- Experts advised viewers to use reverse image or video searches to trace the original source and context of viral videos.\n- Experts advised viewers to look for signs of manipulation, such as blurred faces, mismatched audio and lip movements, unnatural lighting or shadows, and visual glitches around the mouth or jaw.\n- Fact-checking groups and analysts called for faster moderation by social media companies.\n- Fact-checking groups and analysts called for clear labelling of AI-generated content to help users distinguish fact from fiction.\n- Microsoft pulled the Recall app back from release due to security concerns.\n- Microsoft paused and recalled the app multiple times during its launch process.\n- Microsoft returned Recall to Windows Insiders in April.\n- Microsoft stated in a November blog post that teams are working to improve the functionality of the security filter.\n- Users can block specific apps or websites from being captured by adding them to the blacklist in Settings > Privacy & Security > Recall & snapshots.\n- School administrators contacted the student's parents after the AI program flagged his draft.\n- The principal spoke with the student's mother after the AI alert, during which the mother explained the student was joking and there was no threat.\n- The principal called the family back and informed them the student was being suspended for 10 days, with the term possibly extendable after a hearing.\n- The district held a long-term suspension hearing during which the student was lectured that such speech was not acceptable.\n- The school imposed a final punishment of a 45-day suspension.\n- Anuraag Gupta published a detailed post-mortem of the Gemini CLI data loss incident on July 25.\n- Anuraag Gupta filed a bug report on GitHub for the Gemini CLI data loss.\n- Replit promised to implement better guardrails to prevent future data-loss disasters.\n- Jason Lemkin's deleted data was eventually recovered after the Replit AI agent incident.\n- Developers created Open Codex CLI as a local-control, more transparent alternative to OpenAI's Codex CLI.\n- McDonald's and Paradox.ai promptly resolved the identified flaws upon disclosure.\n- Paradox.ai and McDonald's acknowledged the vulnerability within the hour after disclosure on June 30, 2025.\n- By July 1, default credentials were disabled.\n- By July 1, the internal API endpoint was secured.\n- Paradox.ai pledged to conduct further security audits.\n- Paradox.ai posted its version of events and a responsible security update to its website.\n- Meta said that Big sis Billie is not Kendall Jenner and does not purport to be Kendall Jenner.\n- A Meta spokesman acknowledged the authenticity of the internal policy document reviewed by Reuters.\n- Following Reuters' inquiries, Meta removed portions of its GenAI content risk standards that stated chatbots could flirt and engage in romantic or sensual roleplay with children.\n- Meta removed specific examples and notes in the document that were erroneous and inconsistent with its policies.\n- Meta said it is in the process of revising its content risk standards.\n- Bue's family shared the events surrounding his death and transcripts of his chats with Reuters to warn the public.\n- Bue's family examined his phone the next day, checking his call history, texts and Facebook Messenger to find clues about the identity of his supposed friend.\n- Bue's family removed him from life support after doctors confirmed he was brain dead.\n- Bue's family held a Buddhist memorial service for him in May.\n- They closely examined the video and identified inconsistencies in the facial expressions of both the tigers and the people.\n- They performed a reverse image search on Google and found extended versions of the video that explicitly stated it was AI-generated.\n- They found the same clip shared by other social media accounts, several of which explicitly stated the video was AI-created.\n- They noted a 'Veo' watermark on the uncropped video, indicating it was created using Google's 'Veo' AI model.\n- They used Google's SynthID tool, which confirmed the video was generated by Google AI.\n- They used AI-detection tools such as Hive, which reported an 89% probability that the video was AI-generated.\n- They archived the post and provided a link to the archived video.\n- They published a fact-check concluding that the claim is false and that the video is a deepfake created using AI.\n- The madrasa issued a show-cause notice on Thursday.\n- The headmaster and madrasa management spoke to the teacher about the video.\n- The madrasa had the video deleted immediately.\n- The teacher, Mohammad Yamin Mallik, deleted the video.\n- Mohammad Yamin Mallik sincerely apologised for the panic caused by the video.\n- Mohammad Yamin Mallik clarified that there are no tigers or any wild animals on campus.\n- Senior defense lawyer Rishi Nathwani apologized to Justice James Elliott for filing submissions that included fake quotes and nonexistent case judgments.\n- Rishi Nathwani took full responsibility on behalf of the defense team for filing the incorrect information.\n- Elliott's associates requested that the defense lawyers provide copies of the purported cases after they could not find the cited judgments.\n- The defense lawyers admitted that the cited cases did not exist and that the submission contained fictitious quotes.\n- In a 2023 U.S. case, a federal judge imposed $5,000 fines on two lawyers and a law firm for submitting fictitious legal research.\n- The two U.S. lawyers and their law firm apologized for submitting fictitious legal research.\n- The two U.S. lawyers and their law firm took remedial steps after the incident, which the judge credited in declining harsher sanctions.\n- Michael Cohen took the blame for citing fictitious court rulings invented by AI and said he did not realize the legal research tool could produce hallucinations.\n- Fantagio issued a public warning on its official social media channels about deepfake videos and impersonation attempts demanding money in Kim Seon-ho's name.\n- Fantagio pledged to take strong action against impersonation and the misuse of deepfakes.\n- Fantagio said it will continue monitoring such activities.\n- Fantagio said it will take firm measures against such activities.\n- Fantagio urged fans to be especially cautious to avoid harm.\n- Kick the Hurdle Studio warned last year that YouTuber Dex's likeness was being used in deepfake gambling ads online.\n- Saram Entertainment reported the illegal production and distribution of deepfake content targeting actress Park Gyu-young.\n- Blitzway Entertainment revealed that scams impersonating the company and its actors for financial gain had been discovered both domestically and abroad.\n- OpenAI added noindex tags to shared chat pages.\n- OpenAI added nofollow tags to shared chat pages.\n- OpenAI asked Google to remove the shared chat pages from search results.\n- Google removed tens of thousands of links from search results.\n- OpenAI removed the sharing feature.\n- OpenAI's Chief Information Security Officer confirmed on X that the sharing feature had been removed.\n- OpenAI fixed the indexing issue.\n- Rivlin canceled his credit card.\n- The bogus charges were reversed.\n- Google said it has taken action on several impostor-number examples identified by the reporter.\n- Google said it continues to work on broader improvements to address rarer queries like these.\n- OpenAI said that many of the webpages ChatGPT referenced with the bogus cruise number appear to have been removed.\n- OpenAI said its information can take time to update after abusive content is removed at the source.\n- Rivlin said he is watching for more bogus charges or attempted identity theft.\n- Rivlin said he wants to spread the word to warn others about AI-enabled trickery.\n- Joann Fabrics warned consumers that https://www.joann.com/ was the only legitimate website through which to buy Joann products.\n- Joann Fabrics urged anyone who made a purchase through a fake site to dispute the charge with their financial institution.\n- Netcraft identified nearly 100,000 domains created with the help of illicit AI tools impersonating 194 different brands across 68 countries.\n- Cybersecurity experts advised consumers to report fake sites to authorities such as the Better Business Bureau or the FBI's Internet Crime Complaint Center (IC3).\n- The family spent many hours combing through Sophie's journals and voice memos for clues to what happened.\n- Sophie's best friend checked the A.I.'s chat logs and the family discovered that she had confided in a ChatGPT A.I. therapist named \"Harry\".\n- The family bought boxes of rubber baby hands for her memorial service.\n- In July, the author began exploring how this new technology may have failed her child.\n- States have begun enacting legislation to establish safety features for A.I. companions.\n- OpenAI said it was developing automated tools to more effectively detect and respond to users experiencing mental or emotional distress.\n- The police pulled surveillance video from the building.\n- The police interviewed the victim.\n- The police canvassed the area looking for more witnesses.\n- An investigator uploaded a still from the surveillance footage and ran a facial recognition search.\n- A human examiner selected Trevis Williams as the best candidate and generated a report warning he was only a \"possible match\".\n- Investigators placed Mr. Williams's photo among six pictures and showed the photo array to the victim.\n- The victim picked Mr. Williams's photo from the array and signed her name underneath the identification.\n- On April 21, the police took Mr. Williams into custody when they encountered him entering the subway.\n- The police interrogated Mr. Williams.\n- The police charged Mr. Williams the following day.\n- Mr. Williams's lawyers performed a forensic analysis of his phone records showing his phone had communicated with cell towers around Brooklyn.\n- Mr. Williams's lawyers prepared to use the phone record evidence in court.\n- The case against Mr. Williams was dismissed in July.\n- The Manhattan district attorney's office sealed the case following its dismissal.\n- Legal Aid sent a letter to the city's Department of Investigation asking the agency to look into police use of the facial recognition technology.\n- The police said the public lewdness case had been closed.\n- Matt and Maria Raine created a foundation in Adam's name in the days after his death.\n- The Raines initially planned for the foundation to help pay funeral costs for other families whose children died from suicide.\n- After reading Adam's conversations with ChatGPT, the Raines shifted the foundation's focus to making other families aware of what they see as the dangers of the technology.\n- Matt and Maria Raine filed a wrongful death lawsuit against OpenAI and its chief executive, Sam Altman.\n- Meetali Jain, director of the Tech Justice Law Project, filed the suit against OpenAI with the Edelson law firm on behalf of the Raines.\n- One of the Raines' friends connected them with Meetali Jain after suggesting they consider a lawsuit.\n- OpenAI issued an emailed statement expressing that it was deeply saddened by Mr. Raine's passing and offering condolences to his family.\n- OpenAI said it is working to make ChatGPT more supportive in moments of crisis by making it easier to reach emergency services.\n- OpenAI said it is working to make ChatGPT more supportive by helping people connect with trusted contacts.\n- OpenAI said it is working to make ChatGPT more supportive by strengthening protections for teens.\n- Fidji Simo, OpenAI's chief executive of applications, posted a message in Slack alerting employees to a blog post and informing them about Adam's death on April 11.\n- Deloitte stood by the report and the findings.\n- Deloitte promised to correct errors in its references.\n- Deloitte supplied a new list of references, including three other chapters by Lisa Burton Crawford in edited works.\n- Deloitte communicated to the client that a few titles did not fully match the corresponding sources.\n- Deloitte said the references are being corrected.\n- The Department of Employment and Workplace Relations (DEWR) continues to investigate these claims.\n- DEWR has sought urgent advice from Deloitte on these matters.\n- Ruvalcaba's family is suing in an attempt to reverse the sale of the condo.\n- KABC showed actor Steve Burton the video that had been sent to Ruvalcaba.\n- The researchers identified and investigated a network of YouTube channels operating out of Nigeria.\n- They published a post sharing their findings with the research community.\n- They sampled titles from 200 videos to analyze title duplication across channels.\n- They ran searches for each channel email address on OSINT Industries to associate emails with names, usernames, and accounts.\n- They analyzed public Facebook profiles to identify familial relationships among the apparent operators.\n- They triangulated account data from OSINT Industries queries to confirm links between online profiles and the operators.\n- They redacted full names, emails, and social profiles in their reporting due to inconclusive evidence about intent, funding, or ideological alignment.\n- They invited other researchers to reach out with information about the network and its operators.\n- US District Judge Anna Manasco said she was considering a wide range of sanctions against Butler Snow, including fines, mandated continuing legal education, referrals to licensing organizations, and temporary suspensions.\n- At the hearing, attorneys with Butler Snow apologized and said they would accept whatever sanctions Manasco determined were appropriate.\n- Matthew Reeves submitted a declaration to the court acknowledging that he used ChatGPT, failed to verify the case citations through independent review, took full responsibility for the lapse, and expressed sincere regret.\n- William Lunsford said he had begun conducting a review of prior filings to make sure there were not more instances of false citations.\n- Judge Manasco allowed Butler Snow to file a motion within 10 days explaining what their process will be for addressing the problem before the court decides on sanctions.\n- Lawyers for Johnson filed a motion pointing out the fabricated citations and suggesting they were the product of generative artificial intelligence.\n- Judge Manasco scheduled a hearing to determine whether the Butler Snow attorneys should be sanctioned.\n- The court conducted independent searches for each allegedly fabricated citation and found no results.\n- Firefighters responded to a reported burning truck in Parola, Manila.\n- Four fire trucks, including those from the Bureau of Fire Protection, arrived at the location of the supposed fire incident.\n- Firefighters searched the scene and found that the truck was intact and not burned.\n- The company began deleting the most toxic posts.\n- Will Stancil captured screenshots of the toxic posts.\n- Grok was taken out of service.\n- The next day, Elon Musk debuted Grok 4.\n- The Star Tribune reached out to X for comment on the incident.\n- Meta said it is looking into why Meta AI provided extreme weight-loss advice for the reporter's test account.\n- Meta said it is investigating the memories it kept in the reporter's test account.\n- Meta said it is actively working to address the issues raised by Common Sense Media's report.\n- Meta said it trains its AI not to promote self-harm.\n- Meta said its AIs are trained to connect people to support resources in sensitive situations.\n- Meta said Meta AI is trained to respond to certain therapy prompts with a reminder that it is not a licensed professional.\n- Meta said it is continuing to improve its enforcement while exploring how to further strengthen protections for teens.\n- Common Sense Media worked for two months with clinical psychiatrists at the Stanford Brainstorm lab to test Meta AI.\n- Common Sense Media launched a petition calling on Meta to prohibit users under the age of 18 from using Meta AI.\n- Common Sense Media launched a petition calling on Meta to implement better safeguards for sensitive conversations.\n- Common Sense Media launched a petition calling on Meta to allow users, including parents monitoring teen accounts, to turn off Meta AI in Meta's social apps.\n- Common Sense Media shared a report that included a warning for parents and a demand that Meta keep kids under 18 away from Meta AI.\n- New York state passed a law that includes guardrails for social chatbots for users of all ages.\n- A California bill known as AB 1064 was proposed that would effectively ban kids from using companion bots.\n- We banned the accounts involved in the Claude Code extortion operation as soon as we discovered it.\n- We developed a tailored classifier (an automated screening tool) to detect similar activity.\n- We introduced a new detection method to help us discover activity like this as quickly as possible in the future.\n- We shared technical indicators about the attack with relevant authorities.\n- We immediately banned the relevant accounts involved in the North Korean employment fraud.\n- We improved our tools for collecting, storing, and correlating the known indicators of this scam.\n- We shared our findings about the employment scheme with the relevant authorities.\n- We will continue to monitor for attempts to commit fraud using our services.\n- We banned the account associated with the AI-generated ransomware operation.\n- We alerted our partners about the ransomware operation.\n- We implemented new methods for detecting malware upload, modification, and generation.\n- We updated our preventative safety measures based on the abuses we uncovered.\n- We shared details of our findings, including indicators of misuse, with third-party safety teams.\n- In July, the National Police singled out a campaign on TikTok.\n- The National Police warned that every day officers detect hundreds of new accounts created to misinform and manipulate society.\n- TikTok said it was working with the authorities in Moldova to install additional safety and security measures ahead of the election.\n- In June, TikTok shut down a network of 314 accounts with more than 100,000 followers that targeted Moldovan audiences.\n- WatchDog published a report finding more than 900 accounts linked to Russia working in concert on Moldova's most popular apps.\n- NewsGuard documented 39 fabricated narratives targeting Moldova in a three-month period.\n- Check First and Reset Tech released a report documenting an AI-fuelled escalation of the Kremlin-linked propaganda effort that shifted focus to Moldova.\n- After a meeting with the country's security council, President Maia Sandu detailed numerous ways the Kremlin sought to exert its influence.\n- President Maia Sandu accused Ilan Shor of being a conduit for the Russian efforts.\n- President Trump used Truth Social to threaten tariffs on countries that penalize tech giants.\n- Secretary of State Marco Rubio ordered diplomats to lobby to weaken or reverse laws such as the European Union's Digital Services Act.\n- Prosecutors in the Montana Attorney General's Office charged Shy Herbert McCutchan with three felony counts of sexual abuse of children for possession of explicit images and videos depicting a child under the age of 12.\n- The Carter County Sheriff's Office and the Division of Criminal Investigation arrested McCutchan in Alzada.\n- The National Center for Missing and Endangered Children received multiple cyber tips that led to the launch of the investigation into CSAM uploaded from McCutchan's devices.\n- DCI's Internet Crimes Against Children Unit and the Carter County Sheriff's Office investigated the case.\n- House Bill 82 was passed and signed into law during the 2025 Legislative Session to allow prosecution of sex predators who utilize artificial intelligence to digitally alter images.\n- A state District Court judge ordered McCutchan held on a $250,000 bond.\n- An arraignment for McCutchan was set for September 9.\n- Assistant Attorneys General Daniel Guzynski and Stephanie Robles are prosecuting the case.\n- OpenAI is working to prevent its technology from being used for harm.\n- OpenAI posted a blog entry acknowledging that the technology falls short in lengthy conversations and fails to block certain sensitive content.\n- In the blog entry, OpenAI stated that its top priority is making sure ChatGPT doesn't make a hard moment worse.\n- Google issued an emailed statement to NewsGuard acknowledging that the specific AI Overview violated its policies.\n- Google said it was taking action to address the issue with the AI Overview.\n- NewsGuard searched the Myrotvorets database for Charlie Kirk's name and found no results.\n- NewsGuard sent an email to X and Perplexity seeking comment on their AI tools advancing false claims.\n- Hany Farid analyzed several of the videos circulating online and reported finding no evidence of manipulation or tampering.\n- Hany Farid published a LinkedIn post stating that the videos are authentic and that his analysis found no evidence of manipulation.\n- The New York Times published an interview with Michael Mallinson in which he said he lives in Toronto and was not the suspect.\n- The woman filed a complaint at the East CEN police station.\n- The authorities coordinated with banks to freeze the fraudsters' accounts.\n- Sadhguru Vasudev Jaggi and his Isha Foundation approached the Delhi High Court against the misuse of his identity through AI-generated deepfakes.\n- The police arrested Eemani Naveen, an engineer from Andhra Pradesh, for creating a deepfake video.\n- Bank of Ireland warned consumers to watch out for fake investment adverts circulating online, mainly originating via Meta platforms.\n- Bank of Ireland urged the public to remain vigilant about these scams.\n- Bank of Ireland advised people not to engage with such fake investment content if they see it.\n- Consumers were advised to ignore any unsolicited investment offers encountered online.\n- Consumers were advised to verify financial products through their bank or a trusted financial advisor.\n- Consumers were advised to check the Central Bank of Ireland register (ROI) to confirm that an investment firm is regulated.\n- Consumers were advised not to invest if a firm is not listed on the Central Bank of Ireland register.\n- Bank of Ireland offered a 24/7 fraud telephone support line for customers on 1800 946 764, available every day of the year.\n- Genians Security Center detected the new AI-generated fake military ID phishing approach in July 2025.\n- GSC warned about the Kimsuky phishing campaign.\n- GSC said that Endpoint Detection and Response (EDR) systems are essential to detect and neutralise these types of attacks.\n- Researchers noted tell-tale strings like 'Start_juice' and 'Eextract_juice' appearing in the attackers' code.\n- Hackread.com translated the second phishing email image with the help of an AI image translator.\n- OpenAI reported in June 2025 that North Korean threat actors created fake identities with AI to pass technical job interviews.\n- Juliana Peralta's parents filed a lawsuit against Character AI in Colorado.\n- The lawsuit asks the court to award damages to Juliana's parents.\n- The lawsuit asks the court to order Character AI to make changes to its app, including measures to protect minors.\n- Character AI issued a public statement saying it takes the safety of its users very seriously and has invested substantial resources in Trust and Safety.\n- Character AI added a pop-up resource around October 2024 directing users who use phrases related to self-harm and suicide to the National Suicide Prevention Lifeline (988).\n- Three product-liability claims were filed on behalf of underage users against Character AI.\n- The three lawsuits also name Google as a defendant.\n- All three families are represented by the Social Media Victims Law Center.\n- Juliana's mother, Montoya, turned to the Social Media Victims Law Center for help.\n- A tech consultant came to Montoya's house to help her retrieve Juliana's conversations inside the Character AI app from her phone.\n- OpenAI said it is working to make its chatbot more supportive to users in crisis and is adding parental controls to ChatGPT.\n- The Senate subcommittee on crime and counterterrorism scheduled a hearing to debate the potential harms of AI chatbots.\n- California lawmakers passed a bill that would mandate safeguards for chatbots, including requiring companies to implement protocols to handle discussions about suicide and self-harm.\n- The Federal Trade Commission said it would investigate child safety concerns around AI companions from Alphabet, Meta, Character and others.\n- Apple's App Store currently lists the Character AI app as suitable for users 18+.\n- Nx maintainers published an official security advisory.\n- Snyk is tracking the incident via published Snyk advisories.\n- All compromised package versions were removed from the npm registry.\n- npm purged the affected versions and tokens.\n- The Nx organization's access was revoked.\n- Search your GitHub account for repositories named 's1ngularity-repository-*'.\n- If such repositories are found, take immediate actions as instructed by your ProdSec and InfoSec teams.\n- Rotate GitHub tokens immediately.\n- Rotate npm tokens immediately.\n- Rotate SSH keys immediately.\n- Rotate any API keys stored in .env files immediately.\n- Audit and clean your environment as instructed by your ProdSec team.\n- Run 'npm ls nx' and check package-lock.json to identify usage of Nx across projects.\n- If projects are affected, uninstall the compromised Nx versions.\n- If projects are affected, install nx@latest.\n- Use Snyk SCA and Snyk SBOM to locate and monitor projects organization-wide.\n- If AI CLIs are installed, review your shell history for dangerous flags such as --dangerously-skip-permissions, --yolo, and --trust-all-tools.\n- Enforce the lockfile in CI by using 'npm ci'.\n- Disable install scripts by default, for example by using the --ignore-scripts flag.\n- Set ignore-scripts=true in a user- or project-scoped .npmrc to neutralize malicious postinstall scripts.\n- Enable npm two-factor authentication in auth-and-writes mode by running 'npm profile enable-2fa auth-and-writes'.\n- Verify package provenance before installing whenever possible.\n- Pre-flight installs using npq or Snyk Advisor to gate installations on trust signals and Snyk intel.\n- Consider aliasing npm to npq locally.\n- Continuously scan and monitor with Snyk using 'snyk test' and 'snyk monitor' to catch new disclosures and automate fixes.\n- Use a private or proxied registry (for example, Verdaccio) to reduce direct exposure and enforce publishing and consumption policies.\n- Stefanina's posted a public warning asking patrons not to use Google AI to find out the restaurant's specials.\n- Stefanina's directed customers to check the restaurant's Facebook page or website for accurate specials.\n- Stefanina's announced it will not honor specials generated by Google AI.\n- Australia's eSafety Commissioner announced a plan to target AI chatbots as part of new reforms.\n- The eSafety Commissioner registered six new codes under the Online Safety Act.\n- The new codes come into effect in March next year.\n- The new codes will introduce safeguards covering AI chatbot apps and will require technology manufacturers to verify the ages of users if they try to access harmful content.\n- In response to the investigation, Nomi said it had recently made improvements to its core AI.\n- Nomi's chief executive Alex Cardinell issued a statement saying countless users had shared stories of how Nomi helped them overcome mental health challenges, trauma and discrimination.\n- A law in California was enacted that requires occasional reminders to users that they are talking to a bot rather than a human.\n</mitigation_statements>"}]}}
